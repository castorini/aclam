K17-1000:
  address: Vancouver, Canada
  author:
  - first: Roger
    full: Roger Levy
    id: roger-levy
    last: Levy
  - first: Lucia
    full: Lucia Specia
    id: lucia-specia
    last: Specia
  author_string: Roger Levy, Lucia Specia
  bibkey: conll-2017-natural
  bibtype: proceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  doi: 10.18653/v1/K17-1
  month: August
  paper_id: '0'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1000.jpg
  title: Proceedings of the 21st Conference on Computational Natural Language Learning
    (CoNLL 2017)
  title_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  url: https://www.aclweb.org/anthology/K17-1000
  year: '2017'
K17-1001:
  abstract: "I explore the hypothesis that conventional neural network models (e.g.,\
    \ recurrent neural networks) are incorrectly biased for making linguistically\
    \ sensible generalizations when learning, and that a better class of models is\
    \ based on architectures that reflect hierarchical structures for which considerable\
    \ behavioral evidence exists. I focus on the problem of modeling and representing\
    \ the meanings of sentences. On the generation front, I introduce recurrent neural\
    \ network grammars (RNNGs), a joint, generative model of phrase-structure trees\
    \ and sentences. RNNGs operate via a recursive syntactic process reminiscent of\
    \ probabilistic context-free grammar generation, but decisions are parameterized\
    \ using RNNs that condition on the entire (top-down, left-to-right) syntactic\
    \ derivation history, thus relaxing context-free independence assumptions, while\
    \ retaining a bias toward explaining decisions via \u201Csyntactically local\u201D\
    \ conditioning contexts. Experiments show that RNNGs obtain better results in\
    \ generating language than models that don\u2019t exploit linguistic structure.\
    \ On the representation front, I explore unsupervised learning of syntactic structures\
    \ based on distant semantic supervision using a reinforcement-learning algorithm.\
    \ The learner seeks a syntactic structure that provides a compositional architecture\
    \ that produces a good representation for a downstream semantic task. Although\
    \ the inferred structures are quite different from traditional syntactic analyses,\
    \ the performance on the downstream tasks surpasses that of systems that use sequential\
    \ RNNs and tree-structured RNNs based on treebank dependencies. This is joint\
    \ work with Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed\
    \ Grefenstette, Wang Ling, and Noah A. Smith."
  address: Vancouver, Canada
  author:
  - first: Chris
    full: Chris Dyer
    id: chris-dyer
    last: Dyer
  author_string: Chris Dyer
  bibkey: dyer-2017-neural
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1001
  month: August
  pages: '1'
  paper_id: '1'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1001.jpg
  title: Should Neural Network Architecture Reflect Linguistic Structure?
  title_html: Should Neural Network Architecture Reflect Linguistic Structure?
  url: https://www.aclweb.org/anthology/K17-1001
  year: '2017'
K17-1002:
  abstract: "Language acquisition can be modeled as a statistical inference problem:\
    \ children use sentences and sounds in their input to infer linguistic structure.\
    \ However, in many cases, children learn from data whose statistical structure\
    \ is distorted relative to the language they are learning. Such distortions can\
    \ arise either in the input itself, or as a result of children\u2019s immature\
    \ strategies for encoding their input. This work examines several cases in which\
    \ the statistical structure of children\u2019s input differs from the language\
    \ being learned. Analyses show that these distortions of the input can be accounted\
    \ for with a statistical learning framework by carefully considering the inference\
    \ problems that learners solve during language acquisition"
  address: Vancouver, Canada
  author:
  - first: Naomi
    full: Naomi Feldman
    id: naomi-feldman
    last: Feldman
  author_string: Naomi Feldman
  bibkey: feldman-2017-rational
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1002
  month: August
  pages: '2'
  paper_id: '2'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1002.jpg
  title: "Rational Distortions of Learners\u2019 Linguistic Input"
  title_html: "Rational Distortions of Learners\u2019 Linguistic Input"
  url: https://www.aclweb.org/anthology/K17-1002
  year: '2017'
K17-1003:
  abstract: Recent work has explored the syntactic abilities of RNNs using the subject-verb
    agreement task, which diagnoses sensitivity to sentence structure. RNNs performed
    this task well in common cases, but faltered in complex sentences (Linzen et al.,
    2016). We test whether these errors are due to inherent limitations of the architecture
    or to the relatively indirect supervision provided by most agreement dependencies
    in a corpus. We trained a single RNN to perform both the agreement task and an
    additional task, either CCG supertagging or language modeling. Multi-task training
    led to significantly lower error rates, in particular on complex sentences, suggesting
    that RNNs have the ability to evolve more sophisticated syntactic representations
    than shown before. We also show that easily available agreement training data
    can improve performance on other syntactic tasks, in particular when only a limited
    amount of training data is available for those tasks. The multi-task paradigm
    can also be leveraged to inject grammatical knowledge into language models.
  address: Vancouver, Canada
  author:
  - first: "\xC9mile"
    full: "\xC9mile Enguehard"
    id: emile-enguehard
    last: Enguehard
  - first: Yoav
    full: Yoav Goldberg
    id: yoav-goldberg
    last: Goldberg
  - first: Tal
    full: Tal Linzen
    id: tal-linzen
    last: Linzen
  author_string: "\xC9mile Enguehard, Yoav Goldberg, Tal Linzen"
  bibkey: enguehard-etal-2017-exploring
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1003
  month: August
  page_first: '3'
  page_last: '14'
  pages: "3\u201314"
  paper_id: '3'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1003.jpg
  title: Exploring the Syntactic Abilities of RNNs with Multi-task Learning
  title_html: Exploring the Syntactic Abilities of <span class="acl-fixed-case">RNN</span>s
    with Multi-task Learning
  url: https://www.aclweb.org/anthology/K17-1003
  year: '2017'
K17-1004:
  abstract: "A writer\u2019s style depends not just on personal traits but also on\
    \ her intent and mental state. In this paper, we show how variants of the same\
    \ writing task can lead to measurable differences in writing style. We present\
    \ a case study based on the story cloze task (Mostafazadeh et al., 2016a), where\
    \ annotators were assigned similar writing tasks with different constraints: (1)\
    \ writing an entire story, (2) adding a story ending for a given story context,\
    \ and (3) adding an incoherent ending to a story. We show that a simple linear\
    \ classifier informed by stylistic features is able to successfully distinguish\
    \ among the three cases, without even looking at the story context. In addition,\
    \ combining our stylistic features with language model predictions reaches state\
    \ of the art performance on the story cloze challenge. Our results demonstrate\
    \ that different task framings can dramatically affect the way people write."
  address: Vancouver, Canada
  author:
  - first: Roy
    full: Roy Schwartz
    id: roy-schwartz
    last: Schwartz
  - first: Maarten
    full: Maarten Sap
    id: maarten-sap
    last: Sap
  - first: Ioannis
    full: Ioannis Konstas
    id: ioannis-konstas
    last: Konstas
  - first: Leila
    full: Leila Zilles
    id: leila-zilles
    last: Zilles
  - first: Yejin
    full: Yejin Choi
    id: yejin-choi
    last: Choi
  - first: Noah A.
    full: Noah A. Smith
    id: noah-a-smith
    last: Smith
  author_string: Roy Schwartz, Maarten Sap, Ioannis Konstas, Leila Zilles, Yejin Choi,
    Noah A. Smith
  bibkey: schwartz-etal-2017-effect
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1004
  month: August
  page_first: '15'
  page_last: '25'
  pages: "15\u201325"
  paper_id: '4'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1004.jpg
  title: 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study
    of the ROC Story Cloze Task'
  title_html: 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study
    of the <span class="acl-fixed-case">ROC</span> Story Cloze Task'
  url: https://www.aclweb.org/anthology/K17-1004
  year: '2017'
K17-1005:
  abstract: 'This paper is concerned with building deep grammatical relation (GR)
    analysis using data-driven approach. To deal with this problem, we propose graph
    merging, a new perspective, for building flexible dependency graphs: Constructing
    complex graphs via constructing simple subgraphs. We discuss two key problems
    in this perspective: (1) how to decompose a complex graph into simple subgraphs,
    and (2) how to combine subgraphs into a coherent complex graph. Experiments demonstrate
    the effectiveness of graph merging. Our parser reaches state-of-the-art performance
    and is significantly better than two transition-based parsers.'
  address: Vancouver, Canada
  author:
  - first: Weiwei
    full: Weiwei Sun
    id: weiwei-sun
    last: Sun
  - first: Yantao
    full: Yantao Du
    id: yantao-du
    last: Du
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  author_string: Weiwei Sun, Yantao Du, Xiaojun Wan
  bibkey: sun-etal-2017-parsing
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1005
  month: August
  page_first: '26'
  page_last: '35'
  pages: "26\u201335"
  paper_id: '5'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1005.jpg
  title: Parsing for Grammatical Relations via Graph Merging
  title_html: Parsing for Grammatical Relations via Graph Merging
  url: https://www.aclweb.org/anthology/K17-1005
  year: '2017'
K17-1006:
  abstract: Metaphor detection has been both challenging and rewarding in natural
    language processing applications. This study offers a new approach based on eventive
    information in detecting metaphors by leveraging the Chinese writing system, which
    is a culturally bound ontological system organized according to the basic concepts
    represented by radicals. As such, the information represented is available in
    all Chinese text without pre-processing. Since metaphor detection is another culturally
    based conceptual representation, we hypothesize that sub-textual information can
    facilitate the identification and classification of the types of metaphoric events
    denoted in Chinese text. We propose a set of syntactic conditions crucial to event
    structures to improve the model based on the classification of radical groups.
    With the proposed syntactic conditions, the model achieves a performance of 0.8859
    in terms of F-scores, making 1.7% of improvement than the same classifier with
    only Bag-of-word features. Results show that eventive information can improve
    the effectiveness of metaphor detection. Event information is rooted in every
    language, and thus this approach has a high potential to be applied to metaphor
    detection in other languages.
  address: Vancouver, Canada
  author:
  - first: I-Hsuan
    full: I-Hsuan Chen
    id: i-hsuan-chen
    last: Chen
  - first: Yunfei
    full: Yunfei Long
    id: yunfei-long
    last: Long
  - first: Qin
    full: Qin Lu
    id: qin-lu
    last: Lu
  - first: Chu-Ren
    full: Chu-Ren Huang
    id: chu-ren-huang
    last: Huang
  author_string: I-Hsuan Chen, Yunfei Long, Qin Lu, Chu-Ren Huang
  bibkey: chen-etal-2017-leveraging
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1006
  month: August
  page_first: '36'
  page_last: '46'
  pages: "36\u201346"
  paper_id: '6'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1006.jpg
  title: Leveraging Eventive Information for Better Metaphor Detection and Classification
  title_html: Leveraging Eventive Information for Better Metaphor Detection and Classification
  url: https://www.aclweb.org/anthology/K17-1006
  year: '2017'
K17-1007:
  abstract: "This paper presents a collaborative partitioning algorithm\u2014a novel\
    \ ensemble-based approach to coreference resolution. Starting from the all-singleton\
    \ partition, we search for a solution close to the ensemble\u2019s outputs in\
    \ terms of a task-specific similarity measure. Our approach assumes a loose integration\
    \ of individual components of the ensemble and can therefore combine arbitrary\
    \ coreference resolvers, regardless of their models. Our experiments on the CoNLL\
    \ dataset show that collaborative partitioning yields results superior to those\
    \ attained by the individual components, for ensembles of both strong and weak\
    \ systems. Moreover, by applying the collaborative partitioning algorithm on top\
    \ of three state-of-the-art resolvers, we obtain the best coreference performance\
    \ reported so far in the literature (MELA v08 score of 64.47)."
  address: Vancouver, Canada
  author:
  - first: Olga
    full: Olga Uryupina
    id: olga-uryupina
    last: Uryupina
  - first: Alessandro
    full: Alessandro Moschitti
    id: alessandro-moschitti
    last: Moschitti
  author_string: Olga Uryupina, Alessandro Moschitti
  bibkey: uryupina-moschitti-2017-collaborative
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1007
  month: August
  page_first: '47'
  page_last: '57'
  pages: "47\u201357"
  paper_id: '7'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1007.jpg
  title: Collaborative Partitioning for Coreference Resolution
  title_html: Collaborative Partitioning for Coreference Resolution
  url: https://www.aclweb.org/anthology/K17-1007
  year: '2017'
K17-1008:
  abstract: We address the task of Named Entity Disambiguation (NED) for noisy text.
    We present WikilinksNED, a large-scale NED dataset of text fragments from the
    web, which is significantly noisier and more challenging than existing news-based
    datasets. To capture the limited and noisy local context surrounding each mention,
    we design a neural model and train it with a novel method for sampling informative
    negative examples. We also describe a new way of initializing word and entity
    embeddings that significantly improves performance. Our model significantly outperforms
    existing state-of-the-art methods on WikilinksNED while achieving comparable performance
    on a smaller newswire dataset.
  address: Vancouver, Canada
  author:
  - first: Yotam
    full: Yotam Eshel
    id: yotam-eshel
    last: Eshel
  - first: Noam
    full: Noam Cohen
    id: noam-cohen
    last: Cohen
  - first: Kira
    full: Kira Radinsky
    id: kira-radinsky
    last: Radinsky
  - first: Shaul
    full: Shaul Markovitch
    id: shaul-markovitch
    last: Markovitch
  - first: Ikuya
    full: Ikuya Yamada
    id: ikuya-yamada
    last: Yamada
  - first: Omer
    full: Omer Levy
    id: omer-levy
    last: Levy
  author_string: Yotam Eshel, Noam Cohen, Kira Radinsky, Shaul Markovitch, Ikuya Yamada,
    Omer Levy
  bibkey: eshel-etal-2017-named
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1008
  month: August
  page_first: '58'
  page_last: '68'
  pages: "58\u201368"
  paper_id: '8'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1008.jpg
  title: Named Entity Disambiguation for Noisy Text
  title_html: Named Entity Disambiguation for Noisy Text
  url: https://www.aclweb.org/anthology/K17-1008
  year: '2017'
K17-1009:
  abstract: For many applications of question answering (QA), being able to explain
    why a given model chose an answer is critical. However, the lack of labeled data
    for answer justifications makes learning this difficult and expensive. Here we
    propose an approach that uses answer ranking as distant supervision for learning
    how to select informative justifications, where justifications serve as inferential
    connections between the question and the correct answer while often containing
    little lexical overlap with either. We propose a neural network architecture for
    QA that reranks answer justifications as an intermediate (and human-interpretable)
    step in answer selection. Our approach is informed by a set of features designed
    to combine both learned representations and explicit features to capture the connection
    between questions, answers, and answer justifications. We show that with this
    end-to-end approach we are able to significantly improve upon a strong IR baseline
    in both justification ranking (+9% rated highly relevant) and answer selection
    (+6% P@1).
  address: Vancouver, Canada
  author:
  - first: Rebecca
    full: Rebecca Sharp
    id: rebecca-sharp
    last: Sharp
  - first: Mihai
    full: Mihai Surdeanu
    id: mihai-surdeanu
    last: Surdeanu
  - first: Peter
    full: Peter Jansen
    id: peter-jansen
    last: Jansen
  - first: Marco A.
    full: "Marco A. Valenzuela-Esc\xE1rcega"
    id: marco-a-valenzuela-escarcega
    last: "Valenzuela-Esc\xE1rcega"
  - first: Peter
    full: Peter Clark
    id: peter-clark
    last: Clark
  - first: Michael
    full: Michael Hammond
    id: michael-hammond
    last: Hammond
  author_string: "Rebecca Sharp, Mihai Surdeanu, Peter Jansen, Marco A. Valenzuela-Esc\xE1\
    rcega, Peter Clark, Michael Hammond"
  bibkey: sharp-etal-2017-tell
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1009
  month: August
  page_first: '69'
  page_last: '79'
  pages: "69\u201379"
  paper_id: '9'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1009.jpg
  title: 'Tell Me Why: Using Question Answering as Distant Supervision for Answer
    Justification'
  title_html: 'Tell Me Why: Using Question Answering as Distant Supervision for Answer
    Justification'
  url: https://www.aclweb.org/anthology/K17-1009
  year: '2017'
K17-1010:
  abstract: "Question answering (QA) systems are easily distracted by irrelevant or\
    \ redundant words in questions, especially when faced with long or multi-sentence\
    \ questions in difficult domains. This paper introduces and studies the notion\
    \ of essential question terms with the goal of improving such QA solvers. We illustrate\
    \ the importance of essential question terms by showing that humans\u2019 ability\
    \ to answer questions drops significantly when essential terms are eliminated\
    \ from questions.We then develop a classifier that reliably (90% mean average\
    \ precision) identifies and ranks essential terms in questions. Finally, we use\
    \ the classifier to demonstrate that the notion of question term essentiality\
    \ allows state-of-the-art QA solver for elementary-level science questions to\
    \ make better and more informed decisions,improving performance by up to 5%.We\
    \ also introduce a new dataset of over 2,200 crowd-sourced essential terms annotated\
    \ science questions."
  address: Vancouver, Canada
  author:
  - first: Daniel
    full: Daniel Khashabi
    id: daniel-khashabi
    last: Khashabi
  - first: Tushar
    full: Tushar Khot
    id: tushar-khot
    last: Khot
  - first: Ashish
    full: Ashish Sabharwal
    id: ashish-sabharwal
    last: Sabharwal
  - first: Dan
    full: Dan Roth
    id: dan-roth
    last: Roth
  author_string: Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Dan Roth
  bibkey: khashabi-etal-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1010
  month: August
  page_first: '80'
  page_last: '89'
  pages: "80\u201389"
  paper_id: '10'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1010.jpg
  title: Learning What is Essential in Questions
  title_html: Learning What is Essential in Questions
  url: https://www.aclweb.org/anthology/K17-1010
  year: '2017'
K17-1011:
  abstract: "Pairwise ranking methods are the most widely used discriminative training\
    \ approaches for structure prediction problems in natural language processing\
    \ (NLP). Decomposing the problem of ranking hypotheses into pairwise comparisons\
    \ enables simple and efficient solutions. However, neglecting the global ordering\
    \ of the hypothesis list may hinder learning. We propose a listwise learning framework\
    \ for structure prediction problems such as machine translation. Our framework\
    \ directly models the entire translation list\u2019s ordering to learn parameters\
    \ which may better fit the given listwise samples. Furthermore, we propose top-rank\
    \ enhanced loss functions, which are more sensitive to ranking errors at higher\
    \ positions. Experiments on a large-scale Chinese-English translation task show\
    \ that both our listwise learning framework and top-rank enhanced listwise losses\
    \ lead to significant improvements in translation quality."
  address: Vancouver, Canada
  author:
  - first: Huadong
    full: Huadong Chen
    id: huadong-chen
    last: Chen
  - first: Shujian
    full: Shujian Huang
    id: shujian-huang
    last: Huang
  - first: David
    full: David Chiang
    id: david-chiang
    last: Chiang
  - first: Xinyu
    full: Xinyu Dai
    id: xinyu-dai
    last: Dai
  - first: Jiajun
    full: Jiajun Chen
    id: jiajun-chen
    last: Chen
  author_string: Huadong Chen, Shujian Huang, David Chiang, Xinyu Dai, Jiajun Chen
  bibkey: chen-etal-2017-top
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1011
  month: August
  page_first: '90'
  page_last: '99'
  pages: "90\u201399"
  paper_id: '11'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1011.jpg
  title: Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation
  title_html: Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation
  url: https://www.aclweb.org/anthology/K17-1011
  year: '2017'
K17-1012:
  abstract: Word embeddings are widely used in Natural Language Processing, mainly
    due to their success in capturing semantic information from massive corpora. However,
    their creation process does not allow the different meanings of a word to be automatically
    separated, as it conflates them into a single vector. We address this issue by
    proposing a new model which learns word and sense embeddings jointly. Our model
    exploits large corpora and knowledge from semantic networks in order to produce
    a unified vector space of word and sense embeddings. We evaluate the main features
    of our approach both qualitatively and quantitatively in a variety of tasks, highlighting
    the advantages of the proposed method in comparison to state-of-the-art word-
    and sense-based models.
  address: Vancouver, Canada
  attachment:
  - filename: K17-1012.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/K17-1012.Presentation.pdf
  author:
  - first: Massimiliano
    full: Massimiliano Mancini
    id: massimiliano-mancini
    last: Mancini
  - first: Jose
    full: Jose Camacho-Collados
    id: jose-camacho-collados
    last: Camacho-Collados
  - first: Ignacio
    full: Ignacio Iacobacci
    id: ignacio-iacobacci
    last: Iacobacci
  - first: Roberto
    full: Roberto Navigli
    id: roberto-navigli
    last: Navigli
  author_string: Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, Roberto
    Navigli
  bibkey: mancini-etal-2017-embedding
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1012
  month: August
  page_first: '100'
  page_last: '111'
  pages: "100\u2013111"
  paper_id: '12'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1012.jpg
  title: Embedding Words and Senses Together via Joint Knowledge-Enhanced Training
  title_html: Embedding Words and Senses Together via Joint Knowledge-Enhanced Training
  url: https://www.aclweb.org/anthology/K17-1012
  year: '2017'
K17-1013:
  abstract: "This paper is concerned with identifying contexts useful for training\
    \ word representation models for different word classes such as adjectives (A),\
    \ verbs (V), and nouns (N). We introduce a simple yet effective framework for\
    \ an automatic selection of class-specific context configurations. We construct\
    \ a context configuration space based on universal dependency relations between\
    \ words, and efficiently search this space with an adapted beam search algorithm.\
    \ In word similarity tasks for each word class, we show that our framework is\
    \ both effective and efficient. Particularly, it improves the Spearman\u2019s\
    \ rho correlation with human scores on SimLex-999 over the best previously proposed\
    \ class-specific contexts by 6 (A), 6 (V) and 5 (N) rho points. With our selected\
    \ context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of\
    \ all dependency-based contexts, resulting in a reduced training time. Our results\
    \ generalise: we show that the configurations our algorithm learns for one English\
    \ training setup outperform previously proposed context types in another training\
    \ setup for English. Moreover, basing the configuration space on universal dependencies,\
    \ it is possible to transfer the learned configurations to German and Italian.\
    \ We also demonstrate improved per-class results over other context types in these\
    \ two languages.."
  address: Vancouver, Canada
  author:
  - first: Ivan
    full: "Ivan Vuli\u0107"
    id: ivan-vulic
    last: "Vuli\u0107"
  - first: Roy
    full: Roy Schwartz
    id: roy-schwartz
    last: Schwartz
  - first: Ari
    full: Ari Rappoport
    id: ari-rappoport
    last: Rappoport
  - first: Roi
    full: Roi Reichart
    id: roi-reichart
    last: Reichart
  - first: Anna
    full: Anna Korhonen
    id: anna-korhonen
    last: Korhonen
  author_string: "Ivan Vuli\u0107, Roy Schwartz, Ari Rappoport, Roi Reichart, Anna\
    \ Korhonen"
  bibkey: vulic-etal-2017-automatic
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1013
  month: August
  page_first: '112'
  page_last: '122'
  pages: "112\u2013122"
  paper_id: '13'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1013.jpg
  title: Automatic Selection of Context Configurations for Improved Class-Specific
    Word Representations
  title_html: Automatic Selection of Context Configurations for Improved Class-Specific
    Word Representations
  url: https://www.aclweb.org/anthology/K17-1013
  year: '2017'
K17-1014:
  abstract: Vector representations of word meaning have found many applications in
    the field of natural language processing. Word vectors intuitively represent the
    average context in which a given word tends to occur, but they cannot explicitly
    model the diversity of these contexts. Although region representations of word
    meaning offer a natural alternative to word vectors, only few methods have been
    proposed that can effectively learn word regions. In this paper, we propose a
    new word embedding model which is based on SVM regression. We show that the underlying
    ranking interpretation of word contexts is sufficient to match, and sometimes
    outperform, the performance of popular methods such as Skip-gram. Furthermore,
    we show that by using a quadratic kernel, we can effectively learn word regions,
    which outperform existing unsupervised models for the task of hypernym detection.
  address: Vancouver, Canada
  author:
  - first: Shoaib
    full: Shoaib Jameel
    id: shoaib-jameel
    last: Jameel
  - first: Steven
    full: Steven Schockaert
    id: steven-schockaert
    last: Schockaert
  author_string: Shoaib Jameel, Steven Schockaert
  bibkey: jameel-schockaert-2017-modeling
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1014
  month: August
  page_first: '123'
  page_last: '133'
  pages: "123\u2013133"
  paper_id: '14'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1014.jpg
  title: 'Modeling Context Words as Regions: An Ordinal Regression Approach to Word
    Embedding'
  title_html: 'Modeling Context Words as Regions: An Ordinal Regression Approach to
    Word Embedding'
  url: https://www.aclweb.org/anthology/K17-1014
  year: '2017'
K17-1015:
  abstract: Recent studies of distributional semantic models have set up a competition
    between word embeddings obtained from predictive neural networks and word vectors
    obtained from abstractive count-based models. This paper is an attempt to reveal
    the underlying contribution of additional training data and post-processing steps
    on each type of model in word similarity and relatedness inference tasks. We do
    so by designing an artificial language framework, training a predictive and a
    count-based model on data sampled from this grammar, and evaluating the resulting
    word vectors in paradigmatic and syntagmatic tasks defined with respect to the
    grammar.
  address: Vancouver, Canada
  author:
  - first: Fatemeh
    full: Fatemeh Torabi Asr
    id: fatemeh-torabi-asr
    last: Torabi Asr
  - first: Michael
    full: Michael Jones
    id: michael-jones
    last: Jones
  author_string: Fatemeh Torabi Asr, Michael Jones
  bibkey: torabi-asr-jones-2017-artificial
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1015
  month: August
  page_first: '134'
  page_last: '142'
  pages: "134\u2013142"
  paper_id: '15'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1015.jpg
  title: An Artificial Language Evaluation of Distributional Semantic Models
  title_html: An Artificial Language Evaluation of Distributional Semantic Models
  url: https://www.aclweb.org/anthology/K17-1015
  year: '2017'
K17-1016:
  abstract: Conventional word embeddings are trained with specific criteria (e.g.,
    based on language modeling or co-occurrence) inside a single information source,
    disregarding the opportunity for further calibration using external knowledge.
    This paper presents a unified framework that leverages pre-learned or external
    priors, in the form of a regularizer, for enhancing conventional language model-based
    embedding learning. We consider two types of regularizers. The first type is derived
    from topic distribution by running LDA on unlabeled data. The second type is based
    on dictionaries that are created with human annotation efforts. To effectively
    learn with the regularizers, we propose a novel data structure, trajectory softmax,
    in this paper. The resulting embeddings are evaluated by word similarity and sentiment
    classification. Experimental results show that our learning framework with regularization
    from prior knowledge improves embedding quality across multiple datasets, compared
    to a diverse collection of baseline methods.
  address: Vancouver, Canada
  author:
  - first: Yan
    full: Yan Song
    id: yan-song
    last: Song
  - first: Chia-Jung
    full: Chia-Jung Lee
    id: chia-jung-lee
    last: Lee
  - first: Fei
    full: Fei Xia
    id: fei-xia
    last: Xia
  author_string: Yan Song, Chia-Jung Lee, Fei Xia
  bibkey: song-etal-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1016
  month: August
  page_first: '143'
  page_last: '152'
  pages: "143\u2013152"
  paper_id: '16'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1016.jpg
  title: Learning Word Representations with Regularization from Prior Knowledge
  title_html: Learning Word Representations with Regularization from Prior Knowledge
  url: https://www.aclweb.org/anthology/K17-1016
  year: '2017'
K17-1017:
  abstract: Neural network models have recently been applied to the task of automatic
    essay scoring, giving promising results. Existing work used recurrent neural networks
    and convolutional neural networks to model input essays, giving grades based on
    a single vector representation of the essay. On the other hand, the relative advantages
    of RNNs and CNNs have not been compared. In addition, different parts of the essay
    can contribute differently for scoring, which is not captured by existing models.
    We address these issues by building a hierarchical sentence-document model to
    represent essays, using the attention mechanism to automatically decide the relative
    weights of words and sentences. Results show that our model outperforms the previous
    state-of-the-art methods, demonstrating the effectiveness of the attention mechanism.
  address: Vancouver, Canada
  author:
  - first: Fei
    full: Fei Dong
    id: fei-dong
    last: Dong
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Jie
    full: Jie Yang
    id: jie-yang
    last: Yang
  author_string: Fei Dong, Yue Zhang, Jie Yang
  bibkey: dong-etal-2017-attention
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1017
  month: August
  page_first: '153'
  page_last: '162'
  pages: "153\u2013162"
  paper_id: '17'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1017.jpg
  title: Attention-based Recurrent Convolutional Neural Network for Automatic Essay
    Scoring
  title_html: Attention-based Recurrent Convolutional Neural Network for Automatic
    Essay Scoring
  url: https://www.aclweb.org/anthology/K17-1017
  year: '2017'
K17-1018:
  abstract: This paper proposes a matching technique for learning causal associations
    between word features and class labels in document classification. The goal is
    to identify more meaningful and generalizable features than with only correlational
    approaches. Experiments with sentiment classification show that the proposed method
    identifies interpretable word associations with sentiment and improves classification
    performance in a majority of cases. The proposed feature selection method is particularly
    effective when applied to out-of-domain data.
  address: Vancouver, Canada
  author:
  - first: Michael J.
    full: Michael J. Paul
    id: michael-paul
    last: Paul
  author_string: Michael J. Paul
  bibkey: paul-2017-feature
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1018
  month: August
  page_first: '163'
  page_last: '172'
  pages: "163\u2013172"
  paper_id: '18'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1018.jpg
  title: 'Feature Selection as Causal Inference: Experiments with Text Classification'
  title_html: 'Feature Selection as Causal Inference: Experiments with Text Classification'
  url: https://www.aclweb.org/anthology/K17-1018
  year: '2017'
K17-1019:
  abstract: "Understanding stories \u2013 sequences of events \u2013 is a crucial\
    \ yet challenging natural language understanding task. These events typically\
    \ carry multiple aspects of semantics including actions, entities and emotions.\
    \ Not only does each individual aspect contribute to the meaning of the story,\
    \ so does the interaction among these aspects. Building on this intuition, we\
    \ propose to jointly model important aspects of semantic knowledge \u2013 frames,\
    \ entities and sentiments \u2013 via a semantic language model. We achieve this\
    \ by first representing these aspects\u2019 semantic units at an appropriate level\
    \ of abstraction and then using the resulting vector representations for each\
    \ semantic aspect to learn a joint representation via a neural language model.\
    \ We show that the joint semantic language model is of high quality and can generate\
    \ better semantic sequences than models that operate on the word level. We further\
    \ demonstrate that our joint model can be applied to story cloze test and shallow\
    \ discourse parsing tasks with improved performance and that each semantic aspect\
    \ contributes to the model."
  address: Vancouver, Canada
  author:
  - first: Haoruo
    full: Haoruo Peng
    id: haoruo-peng
    last: Peng
  - first: Snigdha
    full: Snigdha Chaturvedi
    id: snigdha-chaturvedi
    last: Chaturvedi
  - first: Dan
    full: Dan Roth
    id: dan-roth
    last: Roth
  author_string: Haoruo Peng, Snigdha Chaturvedi, Dan Roth
  bibkey: peng-etal-2017-joint
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1019
  month: August
  page_first: '173'
  page_last: '183'
  pages: "173\u2013183"
  paper_id: '19'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1019.jpg
  title: 'A Joint Model for Semantic Sequences: Frames, Entities, Sentiments'
  title_html: 'A Joint Model for Semantic Sequences: Frames, Entities, Sentiments'
  url: https://www.aclweb.org/anthology/K17-1019
  year: '2017'
K17-1020:
  abstract: Learning internal word structure has recently been recognized as an important
    step in various multilingual processing tasks and in theoretical language comparison.
    In this paper, we present a neural encoder-decoder model for learning canonical
    morphological segmentation. Our model combines character-level sequence-to-sequence
    transformation with a language model over canonical segments. We obtain up to
    4% improvement over a strong character-level encoder-decoder baseline for three
    languages. Our model outperforms the previous state-of-the-art for two languages,
    while eliminating the need for external resources such as large dictionaries.
    Finally, by comparing the performance of encoder-decoder and classical statistical
    machine translation systems trained with and without corpus counts, we show that
    including corpus counts is beneficial to both approaches.
  address: Vancouver, Canada
  author:
  - first: Tatyana
    full: Tatyana Ruzsics
    id: tatyana-ruzsics
    last: Ruzsics
  - first: Tanja
    full: "Tanja Samard\u017Ei\u0107"
    id: tanja-samardzic
    last: "Samard\u017Ei\u0107"
  author_string: "Tatyana Ruzsics, Tanja Samard\u017Ei\u0107"
  bibkey: ruzsics-samardzic-2017-neural
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1020
  month: August
  page_first: '184'
  page_last: '194'
  pages: "184\u2013194"
  paper_id: '20'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1020.jpg
  title: Neural Sequence-to-sequence Learning of Internal Word Structure
  title_html: Neural Sequence-to-sequence Learning of Internal Word Structure
  url: https://www.aclweb.org/anthology/K17-1020
  year: '2017'
K17-1021:
  abstract: Automatic summarisation is a popular approach to reduce a document to
    its main arguments. Recent research in the area has focused on neural approaches
    to summarisation, which can be very data-hungry. However, few large datasets exist
    and none for the traditionally popular domain of scientific publications, which
    opens up challenging research avenues centered on encoding large, complex documents.
    In this paper, we introduce a new dataset for summarisation of computer science
    publications by exploiting a large resource of author provided summaries and show
    straightforward ways of extending it further. We develop models on the dataset
    making use of both neural sentence encoding and traditionally used summarisation
    features and show that models which encode sentences as well as their local and
    global context perform best, significantly outperforming well-established baseline
    methods.
  address: Vancouver, Canada
  author:
  - first: Ed
    full: Ed Collins
    id: edward-collins
    last: Collins
  - first: Isabelle
    full: Isabelle Augenstein
    id: isabelle-augenstein
    last: Augenstein
  - first: Sebastian
    full: Sebastian Riedel
    id: sebastian-riedel
    last: Riedel
  author_string: Ed Collins, Isabelle Augenstein, Sebastian Riedel
  bibkey: collins-etal-2017-supervised
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1021
  month: August
  page_first: '195'
  page_last: '205'
  pages: "195\u2013205"
  paper_id: '21'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1021.jpg
  title: A Supervised Approach to Extractive Summarisation of Scientific Papers
  title_html: A Supervised Approach to Extractive Summarisation of Scientific Papers
  url: https://www.aclweb.org/anthology/K17-1021
  year: '2017'
K17-1022:
  abstract: Topic models jointly learn topics and document-level topic distribution.
    Extrinsic evaluation of topic models tends to focus exclusively on topic-level
    evaluation, e.g. by assessing the coherence of topics. We demonstrate that there
    can be large discrepancies between topic- and document-level model quality, and
    that basing model evaluation on topic-level analysis can be highly misleading.
    We propose a method for automatically predicting topic model quality based on
    analysis of document-level topic allocations, and provide empirical evidence for
    its robustness.
  address: Vancouver, Canada
  author:
  - first: Shraey
    full: Shraey Bhatia
    id: shraey-bhatia
    last: Bhatia
  - first: Jey Han
    full: Jey Han Lau
    id: jey-han-lau
    last: Lau
  - first: Timothy
    full: Timothy Baldwin
    id: timothy-baldwin
    last: Baldwin
  author_string: Shraey Bhatia, Jey Han Lau, Timothy Baldwin
  bibkey: bhatia-etal-2017-automatic
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1022
  month: August
  page_first: '206'
  page_last: '215'
  pages: "206\u2013215"
  paper_id: '22'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1022.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1022.jpg
  title: An Automatic Approach for Document-level Topic Model Evaluation
  title_html: An Automatic Approach for Document-level Topic Model Evaluation
  url: https://www.aclweb.org/anthology/K17-1022
  year: '2017'
K17-1023:
  abstract: This paper presents a novel approach to character identification, that
    is an entity linking task that maps mentions to characters in dialogues from TV
    show transcripts. We first augment and correct several cases of annotation errors
    in an existing corpus so the corpus is clearer and cleaner for statistical learning.
    We also introduce the agglomerative convolutional neural network that takes groups
    of features and learns mention and mention-pair embeddings for coreference resolution.
    We then propose another neural model that employs the embeddings learned and creates
    cluster embeddings for entity linking. Our coreference resolution model shows
    comparable results to other state-of-the-art systems. Our entity linking model
    significantly outperforms the previous work, showing the F1 score of 86.76% and
    the accuracy of 95.30% for character identification.
  address: Vancouver, Canada
  author:
  - first: Henry Y.
    full: Henry Y. Chen
    id: henry-y-chen
    last: Chen
  - first: Ethan
    full: Ethan Zhou
    id: ethan-zhou
    last: Zhou
  - first: Jinho D.
    full: Jinho D. Choi
    id: jinho-d-choi
    last: Choi
  author_string: Henry Y. Chen, Ethan Zhou, Jinho D. Choi
  bibkey: chen-etal-2017-robust
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1023
  month: August
  page_first: '216'
  page_last: '225'
  pages: "216\u2013225"
  paper_id: '23'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1023.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1023.jpg
  title: 'Robust Coreference Resolution and Entity Linking on Dialogues: Character
    Identification on TV Show Transcripts'
  title_html: 'Robust Coreference Resolution and Entity Linking on Dialogues: Character
    Identification on <span class="acl-fixed-case">TV</span> Show Transcripts'
  url: https://www.aclweb.org/anthology/K17-1023
  year: '2017'
K17-1024:
  abstract: We address the problem of cross-language adaptation for question-question
    similarity reranking in community question answering, with the objective to port
    a system trained on one input language to another input language given labeled
    training data for the first language and only unlabeled data for the second language.
    In particular, we propose to use adversarial training of neural networks to learn
    high-level features that are discriminative for the main learning task, and at
    the same time are invariant across the input languages. The evaluation results
    show sizable improvements for our cross-language adversarial neural network (CLANN)
    model over a strong non-adversarial system.
  address: Vancouver, Canada
  author:
  - first: Shafiq
    full: Shafiq Joty
    id: shafiq-joty
    last: Joty
  - first: Preslav
    full: Preslav Nakov
    id: preslav-nakov
    last: Nakov
  - first: "Llu\xEDs"
    full: "Llu\xEDs M\xE0rquez"
    id: lluis-marquez
    last: "M\xE0rquez"
  - first: Israa
    full: Israa Jaradat
    id: israa-jaradat
    last: Jaradat
  author_string: "Shafiq Joty, Preslav Nakov, Llu\xEDs M\xE0rquez, Israa Jaradat"
  bibkey: joty-etal-2017-cross
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1024
  month: August
  page_first: '226'
  page_last: '237'
  pages: "226\u2013237"
  paper_id: '24'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1024.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1024.jpg
  title: Cross-language Learning with Adversarial Neural Networks
  title_html: Cross-language Learning with Adversarial Neural Networks
  url: https://www.aclweb.org/anthology/K17-1024
  year: '2017'
K17-1025:
  abstract: "We present a feature-rich knowledge tracing method that captures a student\u2019\
    s acquisition and retention of knowledge during a foreign language phrase learning\
    \ task. We model the student\u2019s behavior as making predictions under a log-linear\
    \ model, and adopt a neural gating mechanism to model how the student updates\
    \ their log-linear parameters in response to feedback. The gating mechanism allows\
    \ the model to learn complex patterns of retention and acquisition for each feature,\
    \ while the log-linear parameterization results in an interpretable knowledge\
    \ state. We collect human data and evaluate several versions of the model."
  address: Vancouver, Canada
  author:
  - first: Adithya
    full: Adithya Renduchintala
    id: adithya-renduchintala
    last: Renduchintala
  - first: Philipp
    full: Philipp Koehn
    id: philipp-koehn
    last: Koehn
  - first: Jason
    full: Jason Eisner
    id: jason-eisner
    last: Eisner
  author_string: Adithya Renduchintala, Philipp Koehn, Jason Eisner
  bibkey: renduchintala-etal-2017-knowledge
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1025
  month: August
  page_first: '238'
  page_last: '247'
  pages: "238\u2013247"
  paper_id: '25'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1025.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1025.jpg
  title: Knowledge Tracing in Sequential Learning of Inflected Vocabulary
  title_html: Knowledge Tracing in Sequential Learning of Inflected Vocabulary
  url: https://www.aclweb.org/anthology/K17-1025
  year: '2017'
K17-1026:
  abstract: We present a generative model of natural language sentences and demonstrate
    its application to semantic parsing. In the generative process, a logical form
    sampled from a prior, and conditioned on this logical form, a grammar probabilistically
    generates the output sentence. Grammar induction using MCMC is applied to learn
    the grammar given a set of labeled sentences with corresponding logical forms.
    We develop a semantic parser that finds the logical form with the highest posterior
    probability exactly. We obtain strong results on the GeoQuery dataset and achieve
    state-of-the-art F1 on Jobs.
  address: Vancouver, Canada
  author:
  - first: Abulhair
    full: Abulhair Saparov
    id: abulhair-saparov
    last: Saparov
  - first: Vijay
    full: Vijay Saraswat
    id: vijay-saraswat
    last: Saraswat
  - first: Tom
    full: Tom Mitchell
    id: tom-mitchell
    last: Mitchell
  author_string: Abulhair Saparov, Vijay Saraswat, Tom Mitchell
  bibkey: saparov-etal-2017-probabilistic
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1026
  month: August
  page_first: '248'
  page_last: '259'
  pages: "248\u2013259"
  paper_id: '26'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1026.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1026.jpg
  title: A Probabilistic Generative Grammar for Semantic Parsing
  title_html: A Probabilistic Generative Grammar for Semantic Parsing
  url: https://www.aclweb.org/anthology/K17-1026
  year: '2017'
K17-1027:
  abstract: Tree kernels (TKs) and neural networks are two effective approaches for
    automatic feature engineering. In this paper, we combine them by modeling context
    word similarity in semantic TKs. This way, the latter can operate subtree matching
    by applying neural-based similarity on tree lexical nodes. We study how to learn
    representations for the words in context such that TKs can exploit more focused
    information. We found that neural embeddings produced by current methods do not
    provide a suitable contextual similarity. Thus, we define a new approach based
    on a Siamese Network, which produces word representations while learning a binary
    text similarity. We set the latter considering examples in the same category as
    similar. The experiments on question and sentiment classification show that our
    semantic TK highly improves previous results.
  address: Vancouver, Canada
  author:
  - first: Massimo
    full: Massimo Nicosia
    id: massimo-nicosia
    last: Nicosia
  - first: Alessandro
    full: Alessandro Moschitti
    id: alessandro-moschitti
    last: Moschitti
  author_string: Massimo Nicosia, Alessandro Moschitti
  bibkey: nicosia-moschitti-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1027
  month: August
  page_first: '260'
  page_last: '270'
  pages: "260\u2013270"
  paper_id: '27'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1027.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1027.jpg
  title: Learning Contextual Embeddings for Structural Semantic Similarity using Categorical
    Information
  title_html: Learning Contextual Embeddings for Structural Semantic Similarity using
    Categorical Information
  url: https://www.aclweb.org/anthology/K17-1027
  year: '2017'
K17-1028:
  abstract: 'Recent development of large-scale question answering (QA) datasets triggered
    a substantial amount of research into end-to-end neural architectures for QA.
    Increasingly complex systems have been conceived without comparison to simpler
    neural baseline systems that would justify their complexity. In this work, we
    propose a simple heuristic that guides the development of neural baseline systems
    for the extractive QA task. We find that there are two ingredients necessary for
    building a high-performing neural QA system: first, the awareness of question
    words while processing the context and second, a composition function that goes
    beyond simple bag-of-words modeling, such as recurrent neural networks. Our results
    show that FastQA, a system that meets these two requirements, can achieve very
    competitive performance compared with existing models. We argue that this surprising
    finding puts results of previous systems and the complexity of recent QA datasets
    into perspective.'
  address: Vancouver, Canada
  author:
  - first: Dirk
    full: Dirk Weissenborn
    id: dirk-weissenborn
    last: Weissenborn
  - first: Georg
    full: Georg Wiese
    id: georg-wiese
    last: Wiese
  - first: Laura
    full: Laura Seiffe
    id: laura-seiffe
    last: Seiffe
  author_string: Dirk Weissenborn, Georg Wiese, Laura Seiffe
  bibkey: weissenborn-etal-2017-making
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1028
  month: August
  page_first: '271'
  page_last: '280'
  pages: "271\u2013280"
  paper_id: '28'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1028.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1028.jpg
  title: Making Neural QA as Simple as Possible but not Simpler
  title_html: Making Neural <span class="acl-fixed-case">QA</span> as Simple as Possible
    but not Simpler
  url: https://www.aclweb.org/anthology/K17-1028
  year: '2017'
K17-1029:
  abstract: Factoid question answering (QA) has recently benefited from the development
    of deep learning (DL) systems. Neural network models outperform traditional approaches
    in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for
    Wikipedia articles. However, these systems have not yet been applied to QA in
    more specific domains, such as biomedicine, because datasets are generally too
    small to train a DL system from scratch. For example, the BioASQ dataset for biomedical
    QA comprises less then 900 factoid (single answer) and list (multiple answers)
    QA instances. In this work, we adapt a neural QA system trained on a large open-domain
    dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing
    various transfer learning techniques. Our network architecture is based on a state-of-the-art
    QA system, extended with biomedical word embeddings and a novel mechanism to answer
    list questions. In contrast to existing biomedical QA systems, our system does
    not rely on domain-specific ontologies, parsers or entity taggers, which are expensive
    to create. Despite this fact, our systems achieve state-of-the-art results on
    factoid questions and competitive results on list questions.
  address: Vancouver, Canada
  attachment:
  - filename: K17-1029.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/K17-1029.Poster.pdf
  author:
  - first: Georg
    full: Georg Wiese
    id: georg-wiese
    last: Wiese
  - first: Dirk
    full: Dirk Weissenborn
    id: dirk-weissenborn
    last: Weissenborn
  - first: Mariana
    full: Mariana Neves
    id: mariana-neves
    last: Neves
  author_string: Georg Wiese, Dirk Weissenborn, Mariana Neves
  bibkey: wiese-etal-2017-neural-domain
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1029
  month: August
  page_first: '281'
  page_last: '289'
  pages: "281\u2013289"
  paper_id: '29'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1029.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1029.jpg
  title: Neural Domain Adaptation for Biomedical Question Answering
  title_html: Neural Domain Adaptation for Biomedical Question Answering
  url: https://www.aclweb.org/anthology/K17-1029
  year: '2017'
K17-1030:
  abstract: 'This paper explores a divisive hierarchical clustering algorithm based
    on the well-known Obligatory Contour Principle in phonology. The purpose is twofold:
    to see if such an algorithm could be used for unsupervised classification of phonemes
    or graphemes in corpora, and to investigate whether this purported universal constraint
    really holds for several classes of phonological distinctive features. The algorithm
    achieves very high accuracies in an unsupervised setting of inferring a consonant-vowel
    distinction, and also has a strong tendency to detect coronal phonemes in an unsupervised
    fashion. Remaining classes, however, do not correspond as neatly to phonological
    distinctive feature splits. While the results offer only mixed support for a universal
    Obligatory Contour Principle, the algorithm can be very useful for many NLP tasks
    due to the high accuracy in revealing consonant/vowel/coronal distinctions.'
  address: Vancouver, Canada
  author:
  - first: Mans
    full: Mans Hulden
    id: mans-hulden
    last: Hulden
  author_string: Mans Hulden
  bibkey: hulden-2017-phoneme
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1030
  month: August
  page_first: '290'
  page_last: '300'
  pages: "290\u2013300"
  paper_id: '30'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1030.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1030.jpg
  title: A phoneme clustering algorithm based on the obligatory contour principle
  title_html: A phoneme clustering algorithm based on the obligatory contour principle
  url: https://www.aclweb.org/anthology/K17-1030
  year: '2017'
K17-1031:
  abstract: Previous studies have shown that investor sentiment indicators can predict
    stock market change. A domain-specific sentiment lexicon and sentiment-oriented
    word embedding model would help the sentiment analysis in financial domain and
    stock market. In this paper, we present a new approach to learning stock market
    lexicon from StockTwits, a popular financial social network for investors to share
    ideas. It learns word polarity by predicting message sentiment, using a neural
    net-work. The sentiment-oriented word embeddings are learned from tens of millions
    of StockTwits posts, and this is the first study presenting sentiment-oriented
    word embeddings for stock market. The experiments of predicting investor sentiment
    show that our lexicon outperformed other lexicons built by the state-of-the-art
    methods, and the sentiment-oriented word vector was much better than the general
    word embeddings.
  address: Vancouver, Canada
  author:
  - first: Quanzhi
    full: Quanzhi Li
    id: quanzhi-li
    last: Li
  - first: Sameena
    full: Sameena Shah
    id: sameena-shah
    last: Shah
  author_string: Quanzhi Li, Sameena Shah
  bibkey: li-shah-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1031
  month: August
  page_first: '301'
  page_last: '310'
  pages: "301\u2013310"
  paper_id: '31'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1031.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1031.jpg
  title: Learning Stock Market Sentiment Lexicon and Sentiment-Oriented Word Vector
    from StockTwits
  title_html: Learning Stock Market Sentiment Lexicon and Sentiment-Oriented Word
    Vector from <span class="acl-fixed-case">S</span>tock<span class="acl-fixed-case">T</span>wits
  url: https://www.aclweb.org/anthology/K17-1031
  year: '2017'
K17-1032:
  abstract: The task of relation classification in the biomedical domain is complex
    due to the presence of samples obtained from heterogeneous sources such as research
    articles, discharge summaries, or electronic health records. It is also a constraint
    for classifiers which employ manual feature engineering. In this paper, we propose
    a convolutional recurrent neural network (CRNN) architecture that combines RNNs
    and CNNs in sequence to solve this problem. The rationale behind our approach
    is that CNNs can effectively identify coarse-grained local features in a sentence,
    while RNNs are more suited for long-term dependencies. We compare our CRNN model
    with several baselines on two biomedical datasets, namely the i2b2-2010 clinical
    relation extraction challenge dataset, and the SemEval-2013 DDI extraction dataset.
    We also evaluate an attentive pooling technique and report its performance in
    comparison with the conventional max pooling method. Our results indicate that
    the proposed model achieves state-of-the-art performance on both datasets.
  address: Vancouver, Canada
  author:
  - first: Desh
    full: Desh Raj
    id: desh-raj
    last: Raj
  - first: Sunil
    full: Sunil Sahu
    id: sunil-sahu
    last: Sahu
  - first: Ashish
    full: Ashish Anand
    id: ashish-anand
    last: Anand
  author_string: Desh Raj, Sunil Sahu, Ashish Anand
  bibkey: raj-etal-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1032
  month: August
  page_first: '311'
  page_last: '321'
  pages: "311\u2013321"
  paper_id: '32'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1032.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1032.jpg
  title: Learning local and global contexts using a convolutional recurrent network
    model for relation classification in biomedical text
  title_html: Learning local and global contexts using a convolutional recurrent network
    model for relation classification in biomedical text
  url: https://www.aclweb.org/anthology/K17-1032
  year: '2017'
K17-1033:
  abstract: "Idea Density (ID) measures the rate at which ideas or elementary predications\
    \ are expressed in an utterance or in a text. Lower ID is found to be associated\
    \ with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon\
    \ et al., 1996; Engelman et al., 2010). ID has been used in two different versions:\
    \ propositional idea density (PID) counts the expressed ideas and can be applied\
    \ to any text while semantic idea density (SID) counts pre-defined information\
    \ content units and is naturally more applicable to normative domains, such as\
    \ picture description tasks. In this paper, we develop DEPID, a novel dependency-based\
    \ method for computing PID, and its version DEPID-R that enables to exclude repeating\
    \ ideas\u2014a feature characteristic to AD speech. We conduct the first comparison\
    \ of automatically extracted PID and SID in the diagnostic classification task\
    \ on two different AD datasets covering both closed-topic and free-recall domains.\
    \ While SID performs better on the normative dataset, adding PID leads to a small\
    \ but significant improvement (+1.7 F-score). On the free-topic dataset, PID performs\
    \ better than SID as expected (77.6 vs 72.3 in F-score) but adding the features\
    \ derived from the word embedding clustering underlying the automatic SID increases\
    \ the results considerably, leading to an F-score of 84.8."
  address: Vancouver, Canada
  author:
  - first: Kairit
    full: Kairit Sirts
    id: kairit-sirts
    last: Sirts
  - first: Olivier
    full: Olivier Piguet
    id: olivier-piguet
    last: Piguet
  - first: Mark
    full: Mark Johnson
    id: mark-johnson
    last: Johnson
  author_string: Kairit Sirts, Olivier Piguet, Mark Johnson
  bibkey: sirts-etal-2017-idea
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1033
  month: August
  page_first: '322'
  page_last: '332'
  pages: "322\u2013332"
  paper_id: '33'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1033.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1033.jpg
  title: "Idea density for predicting Alzheimer\u2019s disease from transcribed speech"
  title_html: "Idea density for predicting <span class=\"acl-fixed-case\">A</span>lzheimer\u2019\
    s disease from transcribed speech"
  url: https://www.aclweb.org/anthology/K17-1033
  year: '2017'
K17-1034:
  abstract: 'We show that relation extraction can be reduced to answering simple reading
    comprehension questions, by associating one or more natural-language questions
    with each relation slot. This reduction has several advantages: we can (1) learn
    relation-extraction models by extending recent neural reading-comprehension techniques,
    (2) build very large training sets for those models by combining relation-specific
    crowd-sourced questions with distant supervision, and even (3) do zero-shot learning
    by extracting new relation types that are only specified at test-time, for which
    we have no labeled training examples. Experiments on a Wikipedia slot-filling
    task demonstrate that the approach can generalize to new questions for known relation
    types with high accuracy, and that zero-shot generalization to unseen relation
    types is possible, at lower accuracy levels, setting the bar for future work on
    this task.'
  address: Vancouver, Canada
  author:
  - first: Omer
    full: Omer Levy
    id: omer-levy
    last: Levy
  - first: Minjoon
    full: Minjoon Seo
    id: minjoon-seo
    last: Seo
  - first: Eunsol
    full: Eunsol Choi
    id: eunsol-choi
    last: Choi
  - first: Luke
    full: Luke Zettlemoyer
    id: luke-zettlemoyer
    last: Zettlemoyer
  author_string: Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer
  bibkey: levy-etal-2017-zero
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1034
  month: August
  page_first: '333'
  page_last: '342'
  pages: "333\u2013342"
  paper_id: '34'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1034.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1034.jpg
  title: Zero-Shot Relation Extraction via Reading Comprehension
  title_html: Zero-Shot Relation Extraction via Reading Comprehension
  url: https://www.aclweb.org/anthology/K17-1034
  year: '2017'
K17-1035:
  abstract: This paper is concerned with whether deep syntactic information can help
    surface parsing, with a particular focus on empty categories. We design new algorithms
    to produce dependency trees in which empty elements are allowed, and evaluate
    the impact of information about empty category on parsing overt elements. Such
    information is helpful to reduce the approximation error in a structured parsing
    model, but increases the search space for inference and accordingly the estimation
    error. To deal with structure-based overfitting, we propose to integrate disambiguation
    models with and without empty elements, and perform structure regularization via
    joint decoding. Experiments on English and Chinese TreeBanks with different parsing
    models indicate that incorporating empty elements consistently improves surface
    parsing.
  address: Vancouver, Canada
  author:
  - first: Xun
    full: Xun Zhang
    id: xun-zhang
    last: Zhang
  - first: Weiwei
    full: Weiwei Sun
    id: weiwei-sun
    last: Sun
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  author_string: Xun Zhang, Weiwei Sun, Xiaojun Wan
  bibkey: zhang-etal-2017-covert
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1035
  month: August
  page_first: '343'
  page_last: '353'
  pages: "343\u2013353"
  paper_id: '35'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1035.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1035.jpg
  title: The Covert Helps Parse the Overt
  title_html: The Covert Helps Parse the Overt
  url: https://www.aclweb.org/anthology/K17-1035
  year: '2017'
K17-1036:
  abstract: This paper explores the information-theoretic measure entropy to detect
    metaphoric change, transferring ideas from hypernym detection to research on language
    change. We build the first diachronic test set for German as a standard for metaphoric
    change annotation. Our model is unsupervised, language-independent and generalizable
    to other processes of semantic change.
  address: Vancouver, Canada
  attachment:
  - filename: K17-1036.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/K17-1036.Presentation.pdf
  author:
  - first: Dominik
    full: Dominik Schlechtweg
    id: dominik-schlechtweg
    last: Schlechtweg
  - first: Stefanie
    full: Stefanie Eckmann
    id: stefanie-eckmann
    last: Eckmann
  - first: Enrico
    full: Enrico Santus
    id: enrico-santus
    last: Santus
  - first: Sabine
    full: Sabine Schulte im Walde
    id: sabine-schulte-im-walde
    last: Schulte im Walde
  - first: Daniel
    full: Daniel Hole
    id: daniel-hole
    last: Hole
  author_string: Dominik Schlechtweg, Stefanie Eckmann, Enrico Santus, Sabine Schulte
    im Walde, Daniel Hole
  bibkey: schlechtweg-etal-2017-german
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1036
  month: August
  page_first: '354'
  page_last: '367'
  pages: "354\u2013367"
  paper_id: '36'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1036.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1036.jpg
  title: 'German in Flux: Detecting Metaphoric Change via Word Entropy'
  title_html: '<span class="acl-fixed-case">G</span>erman in Flux: Detecting Metaphoric
    Change via Word Entropy'
  url: https://www.aclweb.org/anthology/K17-1036
  year: '2017'
K17-1037:
  abstract: We study the representation and encoding of phonemes in a recurrent neural
    network model of grounded speech. We use a model which processes images and their
    spoken descriptions, and projects the visual and auditory representations into
    the same semantic space. We perform a number of analyses on how information about
    individual phonemes is encoded in the MFCC features extracted from the speech
    signal, and the activations of the layers of the model. Via experiments with phoneme
    decoding and phoneme discrimination we show that phoneme representations are most
    salient in the lower layers of the model, where low-level signals are processed
    at a fine-grained level, although a large amount of phonological information is
    retain at the top recurrent layer. We further find out that the attention mechanism
    following the top recurrent layer significantly attenuates encoding of phonology
    and makes the utterance embeddings much more invariant to synonymy. Moreover,
    a hierarchical clustering of phoneme representations learned by the network shows
    an organizational structure of phonemes similar to those proposed in linguistics.
  address: Vancouver, Canada
  attachment:
  - filename: K17-1037.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/K17-1037.Presentation.pdf
  author:
  - first: Afra
    full: Afra Alishahi
    id: afra-alishahi
    last: Alishahi
  - first: Marie
    full: Marie Barking
    id: marie-barking
    last: Barking
  - first: Grzegorz
    full: "Grzegorz Chrupa\u0142a"
    id: grzegorz-chrupala
    last: "Chrupa\u0142a"
  author_string: "Afra Alishahi, Marie Barking, Grzegorz Chrupa\u0142a"
  bibkey: alishahi-etal-2017-encoding
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1037
  month: August
  page_first: '368'
  page_last: '378'
  pages: "368\u2013378"
  paper_id: '37'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1037.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1037.jpg
  title: Encoding of phonology in a recurrent neural model of grounded speech
  title_html: Encoding of phonology in a recurrent neural model of grounded speech
  url: https://www.aclweb.org/anthology/K17-1037
  year: '2017'
K17-1038:
  abstract: Extending semantic parsing systems to new domains and languages is a highly
    expensive, time-consuming process, so making effective use of existing resources
    is critical. In this paper, we describe a transfer learning method using crosslingual
    word embeddings in a sequence-to-sequence model. On the NLmaps corpus, our approach
    achieves state-of-the-art accuracy of 85.7% for English. Most importantly, we
    observed a consistent improvement for German compared with several baseline domain
    adaptation techniques. As a by-product of this approach, our models that are trained
    on a combination of English and German utterances perform reasonably well on code-switching
    utterances which contain a mixture of English and German, even though the training
    data does not contain any such. As far as we know, this is the first study of
    code-switching in semantic parsing. We manually constructed the set of code-switching
    test utterances for the NLmaps corpus and achieve 78.3% accuracy on this dataset.
  address: Vancouver, Canada
  author:
  - first: Long
    full: Long Duong
    id: long-duong
    last: Duong
  - first: Hadi
    full: Hadi Afshar
    id: hadi-afshar
    last: Afshar
  - first: Dominique
    full: Dominique Estival
    id: dominique-estival
    last: Estival
  - first: Glen
    full: Glen Pink
    id: glen-pink
    last: Pink
  - first: Philip
    full: Philip Cohen
    id: philip-r-cohen
    last: Cohen
  - first: Mark
    full: Mark Johnson
    id: mark-johnson
    last: Johnson
  author_string: Long Duong, Hadi Afshar, Dominique Estival, Glen Pink, Philip Cohen,
    Mark Johnson
  bibkey: duong-etal-2017-multilingual-semantic
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1038
  month: August
  page_first: '379'
  page_last: '389'
  pages: "379\u2013389"
  paper_id: '38'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1038.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1038.jpg
  title: Multilingual Semantic Parsing And Code-Switching
  title_html: Multilingual Semantic Parsing And Code-Switching
  url: https://www.aclweb.org/anthology/K17-1038
  year: '2017'
K17-1039:
  abstract: Coreference evaluation metrics are hard to optimize directly as they are
    non-differentiable functions, not easily decomposable into elementary decisions.
    Consequently, most approaches optimize objectives only indirectly related to the
    end goal, resulting in suboptimal performance. Instead, we propose a differentiable
    relaxation that lends itself to gradient-based optimisation, thus bypassing the
    need for reinforcement learning or heuristic modification of cross-entropy. We
    show that by modifying the training objective of a competitive neural coreference
    system, we obtain a substantial gain in performance. This suggests that our approach
    can be regarded as a viable alternative to using reinforcement learning or more
    computationally expensive imitation learning.
  address: Vancouver, Canada
  author:
  - first: Phong
    full: Phong Le
    id: phong-le
    last: Le
  - first: Ivan
    full: Ivan Titov
    id: ivan-titov
    last: Titov
  author_string: Phong Le, Ivan Titov
  bibkey: le-titov-2017-optimizing
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1039
  month: August
  page_first: '390'
  page_last: '399'
  pages: "390\u2013399"
  paper_id: '39'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1039.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1039.jpg
  title: Optimizing Differentiable Relaxations of Coreference Evaluation Metrics
  title_html: Optimizing Differentiable Relaxations of Coreference Evaluation Metrics
  url: https://www.aclweb.org/anthology/K17-1039
  year: '2017'
K17-1040:
  abstract: 'We introduce a neural network model that marries together ideas from
    two prominent strands of research on domain adaptation through representation
    learning: structural correspondence learning (SCL, (Blitzer et al., 2006)) and
    autoencoder neural networks (NNs). Our model is a three-layer NN that learns to
    encode the non-pivot features of an input example into a low dimensional representation,
    so that the existence of pivot features (features that are prominent in both domains
    and convey useful information for the NLP task) in the example can be decoded
    from that representation. The low-dimensional representation is then employed
    in a learning algorithm for the task. Moreover, we show how to inject pre-trained
    word embeddings into our model in order to improve generalization across examples
    with similar pivot features. We experiment with the task of cross-domain sentiment
    classification on 16 domain pairs and show substantial improvements over strong
    baselines.'
  address: Vancouver, Canada
  author:
  - first: Yftah
    full: Yftah Ziser
    id: yftah-ziser
    last: Ziser
  - first: Roi
    full: Roi Reichart
    id: roi-reichart
    last: Reichart
  author_string: Yftah Ziser, Roi Reichart
  bibkey: ziser-reichart-2017-neural
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1040
  month: August
  page_first: '400'
  page_last: '410'
  pages: "400\u2013410"
  paper_id: '40'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1040.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1040.jpg
  title: Neural Structural Correspondence Learning for Domain Adaptation
  title_html: Neural Structural Correspondence Learning for Domain Adaptation
  url: https://www.aclweb.org/anthology/K17-1040
  year: '2017'
K17-1041:
  abstract: We introduce a simple and accurate neural model for dependency-based semantic
    role labeling. Our model predicts predicate-argument dependencies relying on states
    of a bidirectional LSTM encoder. The semantic role labeler achieves competitive
    performance on English, even without any kind of syntactic information and only
    using local inference. However, when automatically predicted part-of-speech tags
    are provided as input, it substantially outperforms all previous local models
    and approaches the best reported results on the English CoNLL-2009 dataset. We
    also consider Chinese, Czech and Spanish where our approach also achieves competitive
    results. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e.,
    syntactically-informed) SRL models are hindered when tested in this setting. Our
    syntax-agnostic model appears more robust, resulting in the best reported results
    on standard out-of-domain test sets.
  address: Vancouver, Canada
  author:
  - first: Diego
    full: Diego Marcheggiani
    id: diego-marcheggiani
    last: Marcheggiani
  - first: Anton
    full: Anton Frolov
    id: anton-frolov
    last: Frolov
  - first: Ivan
    full: Ivan Titov
    id: ivan-titov
    last: Titov
  author_string: Diego Marcheggiani, Anton Frolov, Ivan Titov
  bibkey: marcheggiani-etal-2017-simple
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1041
  month: August
  page_first: '411'
  page_last: '420'
  pages: "411\u2013420"
  paper_id: '41'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1041.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1041.jpg
  title: A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic
    Role Labeling
  title_html: A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based
    Semantic Role Labeling
  url: https://www.aclweb.org/anthology/K17-1041
  year: '2017'
K17-1042:
  abstract: Part-of-speech (POS) tagging for morphologically rich languages such as
    Arabic is a challenging problem because of their enormous tag sets. One reason
    for this is that in the tagging scheme for such languages, a complete POS tag
    is formed by combining tags from multiple tag sets defined for each morphosyntactic
    category. Previous approaches in Arabic POS tagging applied one model for each
    morphosyntactic tagging task, without utilizing shared information between the
    tasks. In this paper, we propose an approach that utilizes this information by
    jointly modeling multiple morphosyntactic tagging tasks with a multi-task learning
    framework. We also propose a method of incorporating tag dictionary information
    into our neural models by combining word representations with representations
    of the sets of possible tags. Our experiments showed that the joint model with
    tag dictionary information results in an accuracy of 91.38% on the Penn Arabic
    Treebank data set, with an absolute improvement of 2.11% over the current state-of-the-art
    tagger.
  address: Vancouver, Canada
  author:
  - first: Go
    full: Go Inoue
    id: go-inoue
    last: Inoue
  - first: Hiroyuki
    full: Hiroyuki Shindo
    id: hiroyuki-shindo
    last: Shindo
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Go Inoue, Hiroyuki Shindo, Yuji Matsumoto
  bibkey: inoue-etal-2017-joint
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1042
  month: August
  page_first: '421'
  page_last: '431'
  pages: "421\u2013431"
  paper_id: '42'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1042.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1042.jpg
  title: Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech
    Tagging Exploiting Tag Dictionary Information
  title_html: Joint Prediction of Morphosyntactic Categories for Fine-Grained <span
    class="acl-fixed-case">A</span>rabic Part-of-Speech Tagging Exploiting Tag Dictionary
    Information
  url: https://www.aclweb.org/anthology/K17-1042
  year: '2017'
K17-1043:
  abstract: "Arabic dialects do not just share a common koin\xE9, but there are shared\
    \ pan-dialectal linguistic phenomena that allow computational models for dialects\
    \ to learn from each other. In this paper we build a unified segmentation model\
    \ where the training data for different dialects are combined and a single model\
    \ is trained. The model yields higher accuracies than dialect-specific models,\
    \ eliminating the need for dialect identification before segmentation. We also\
    \ measure the degree of relatedness between four major Arabic dialects by testing\
    \ how a segmentation model trained on one dialect performs on the other dialects.\
    \ We found that linguistic relatedness is contingent with geographical proximity.\
    \ In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling."
  address: Vancouver, Canada
  author:
  - first: Younes
    full: Younes Samih
    id: younes-samih
    last: Samih
  - first: Mohamed
    full: Mohamed Eldesouki
    id: mohamed-eldesouki
    last: Eldesouki
  - first: Mohammed
    full: Mohammed Attia
    id: mohammed-attia
    last: Attia
  - first: Kareem
    full: Kareem Darwish
    id: kareem-darwish
    last: Darwish
  - first: Ahmed
    full: Ahmed Abdelali
    id: ahmed-abdelali
    last: Abdelali
  - first: Hamdy
    full: Hamdy Mubarak
    id: hamdy-mubarak
    last: Mubarak
  - first: Laura
    full: Laura Kallmeyer
    id: laura-kallmeyer
    last: Kallmeyer
  author_string: Younes Samih, Mohamed Eldesouki, Mohammed Attia, Kareem Darwish,
    Ahmed Abdelali, Hamdy Mubarak, Laura Kallmeyer
  bibkey: samih-etal-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1043
  month: August
  page_first: '432'
  page_last: '441'
  pages: "432\u2013441"
  paper_id: '43'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1043.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1043.jpg
  title: 'Learning from Relatives: Unified Dialectal Arabic Segmentation'
  title_html: 'Learning from Relatives: Unified Dialectal <span class="acl-fixed-case">A</span>rabic
    Segmentation'
  url: https://www.aclweb.org/anthology/K17-1043
  year: '2017'
K17-1044:
  abstract: Natural language generation (NLG) is a critical component in a spoken
    dialogue system. This paper presents a Recurrent Neural Network based Encoder-Decoder
    architecture, in which an LSTM-based decoder is introduced to select, aggregate
    semantic elements produced by an attention mechanism over the input elements,
    and to produce the required utterances. The proposed generator can be jointly
    trained both sentence planning and surface realization to produce natural language
    sentences. The proposed model was extensively evaluated on four different NLG
    datasets. The experimental results showed that the proposed generators not only
    consistently outperform the previous methods across all the NLG domains but also
    show an ability to generalize from a new, unseen domain and learn from multi-domain
    datasets.
  address: Vancouver, Canada
  author:
  - first: Van-Khanh
    full: Van-Khanh Tran
    id: van-khanh-tran
    last: Tran
  - first: Le-Minh
    full: Le-Minh Nguyen
    id: minh-le-nguyen
    last: Nguyen
  author_string: Van-Khanh Tran, Le-Minh Nguyen
  bibkey: tran-nguyen-2017-natural
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1044
  month: August
  page_first: '442'
  page_last: '451'
  pages: "442\u2013451"
  paper_id: '44'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1044.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1044.jpg
  title: Natural Language Generation for Spoken Dialogue System using RNN Encoder-Decoder
    Networks
  title_html: Natural Language Generation for Spoken Dialogue System using <span class="acl-fixed-case">RNN</span>
    Encoder-Decoder Networks
  url: https://www.aclweb.org/anthology/K17-1044
  year: '2017'
K17-1045:
  abstract: We propose a neural multi-document summarization system that incorporates
    sentence relation graphs. We employ a Graph Convolutional Network (GCN) on the
    relation graphs, with sentence embeddings obtained from Recurrent Neural Networks
    as input node features. Through multiple layer-wise propagation, the GCN generates
    high-level hidden sentence features for salience estimation. We then use a greedy
    heuristic to extract salient sentences that avoid redundancy. In our experiments
    on DUC 2004, we consider three types of sentence relation graphs and demonstrate
    the advantage of combining sentence relations in graphs with the representation
    power of deep neural networks. Our model improves upon other traditional graph-based
    extractive approaches and the vanilla GRU sequence model with no graph, and it
    achieves competitive results against other state-of-the-art multi-document summarization
    systems.
  address: Vancouver, Canada
  author:
  - first: Michihiro
    full: Michihiro Yasunaga
    id: michihiro-yasunaga
    last: Yasunaga
  - first: Rui
    full: Rui Zhang
    id: rui-zhang
    last: Zhang
  - first: Kshitijh
    full: Kshitijh Meelu
    id: kshitijh-meelu
    last: Meelu
  - first: Ayush
    full: Ayush Pareek
    id: ayush-pareek
    last: Pareek
  - first: Krishnan
    full: Krishnan Srinivasan
    id: krishnan-srinivasan
    last: Srinivasan
  - first: Dragomir
    full: Dragomir Radev
    id: dragomir-radev
    last: Radev
  author_string: Michihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan
    Srinivasan, Dragomir Radev
  bibkey: yasunaga-etal-2017-graph
  bibtype: inproceedings
  booktitle: Proceedings of the 21st Conference on Computational Natural Language
    Learning (CoNLL 2017)
  booktitle_html: Proceedings of the 21st Conference on Computational Natural Language
    Learning (<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017)
  doi: 10.18653/v1/K17-1045
  month: August
  page_first: '452'
  page_last: '462'
  pages: "452\u2013462"
  paper_id: '45'
  parent_volume_id: K17-1
  pdf: https://www.aclweb.org/anthology/K17-1045.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-1045.jpg
  title: Graph-based Neural Multi-Document Summarization
  title_html: Graph-based Neural Multi-Document Summarization
  url: https://www.aclweb.org/anthology/K17-1045
  year: '2017'
K17-2000:
  address: Vancouver
  author:
  - first: Mans
    full: Mans Hulden
    id: mans-hulden
    last: Hulden
  author_string: Mans Hulden
  bibkey: conll-2017-conll
  bibtype: proceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  doi: 10.18653/v1/K17-2
  month: August
  paper_id: '0'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2000.jpg
  title: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  title_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    <span class="acl-fixed-case">SIGMORPHON</span> 2017 Shared Task: Universal Morphological
    Reinflection'
  url: https://www.aclweb.org/anthology/K17-2000
  year: '2017'
K17-2001:
  address: Vancouver
  author:
  - first: Ryan
    full: Ryan Cotterell
    id: ryan-cotterell
    last: Cotterell
  - first: Christo
    full: Christo Kirov
    id: christo-kirov
    last: Kirov
  - first: John
    full: John Sylak-Glassman
    id: john-sylak-glassman
    last: Sylak-Glassman
  - first: "G\xE9raldine"
    full: "G\xE9raldine Walther"
    id: geraldine-walther
    last: Walther
  - first: Ekaterina
    full: Ekaterina Vylomova
    id: ekaterina-vylomova
    last: Vylomova
  - first: Patrick
    full: Patrick Xia
    id: patrick-xia
    last: Xia
  - first: Manaal
    full: Manaal Faruqui
    id: manaal-faruqui
    last: Faruqui
  - first: Sandra
    full: "Sandra K\xFCbler"
    id: sandra-kubler
    last: "K\xFCbler"
  - first: David
    full: David Yarowsky
    id: david-yarowsky
    last: Yarowsky
  - first: Jason
    full: Jason Eisner
    id: jason-eisner
    last: Eisner
  - first: Mans
    full: Mans Hulden
    id: mans-hulden
    last: Hulden
  author_string: "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\xE9raldine\
    \ Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Sandra K\xFCbler,\
    \ David Yarowsky, Jason Eisner, Mans Hulden"
  bibkey: cotterell-etal-2017-conll
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2001
  month: August
  page_first: '1'
  page_last: '30'
  pages: "1\u201330"
  paper_id: '1'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2001.jpg
  title: 'CoNLL-SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection
    in 52 Languages'
  title_html: '<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>-<span
    class="acl-fixed-case">SIGMORPHON</span> 2017 Shared Task: Universal Morphological
    Reinflection in 52 Languages'
  url: https://www.aclweb.org/anthology/K17-2001
  year: '2017'
K17-2002:
  address: Vancouver
  author:
  - first: Toms
    full: Toms Bergmanis
    id: toms-bergmanis
    last: Bergmanis
  - first: Katharina
    full: Katharina Kann
    id: katharina-kann
    last: Kann
  - first: Hinrich
    full: "Hinrich Sch\xFCtze"
    id: hinrich-schutze
    last: "Sch\xFCtze"
  - first: Sharon
    full: Sharon Goldwater
    id: sharon-goldwater
    last: Goldwater
  author_string: "Toms Bergmanis, Katharina Kann, Hinrich Sch\xFCtze, Sharon Goldwater"
  bibkey: bergmanis-etal-2017-training
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2002
  month: August
  page_first: '31'
  page_last: '39'
  pages: "31\u201339"
  paper_id: '2'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2002.jpg
  title: Training Data Augmentation for Low-Resource Morphological Inflection
  title_html: Training Data Augmentation for Low-Resource Morphological Inflection
  url: https://www.aclweb.org/anthology/K17-2002
  year: '2017'
K17-2003:
  address: Vancouver
  author:
  - first: Katharina
    full: Katharina Kann
    id: katharina-kann
    last: Kann
  - first: Hinrich
    full: "Hinrich Sch\xFCtze"
    id: hinrich-schutze
    last: "Sch\xFCtze"
  author_string: "Katharina Kann, Hinrich Sch\xFCtze"
  bibkey: kann-schutze-2017-lmu
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2003
  month: August
  page_first: '40'
  page_last: '48'
  pages: "40\u201348"
  paper_id: '3'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2003.jpg
  title: The LMU System for the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological
    Reinflection
  title_html: The <span class="acl-fixed-case">LMU</span> System for the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span>-<span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task on Universal Morphological Reinflection
  url: https://www.aclweb.org/anthology/K17-2003
  year: '2017'
K17-2004:
  address: Vancouver
  author:
  - first: Peter
    full: Peter Makarov
    id: peter-makarov
    last: Makarov
  - first: Tatiana
    full: Tatiana Ruzsics
    id: tatyana-ruzsics
    last: Ruzsics
  - first: Simon
    full: Simon Clematide
    id: simon-clematide
    last: Clematide
  author_string: Peter Makarov, Tatiana Ruzsics, Simon Clematide
  bibkey: makarov-etal-2017-align
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2004
  month: August
  page_first: '49'
  page_last: '57'
  pages: "49\u201357"
  paper_id: '4'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2004.jpg
  title: 'Align and Copy: UZH at SIGMORPHON 2017 Shared Task for Morphological Reinflection'
  title_html: 'Align and Copy: <span class="acl-fixed-case">UZH</span> at <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task for Morphological Reinflection'
  url: https://www.aclweb.org/anthology/K17-2004
  year: '2017'
K17-2005:
  address: Vancouver
  author:
  - first: Chunting
    full: Chunting Zhou
    id: chunting-zhou
    last: Zhou
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  author_string: Chunting Zhou, Graham Neubig
  bibkey: zhou-neubig-2017-morphological
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2005
  month: August
  page_first: '58'
  page_last: '65'
  pages: "58\u201365"
  paper_id: '5'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2005.jpg
  title: Morphological Inflection Generation with Multi-space Variational Encoder-Decoders
  title_html: Morphological Inflection Generation with Multi-space Variational Encoder-Decoders
  url: https://www.aclweb.org/anthology/K17-2005
  year: '2017'
K17-2006:
  address: Vancouver
  author:
  - first: Abhisek
    full: Abhisek Chakrabarty
    id: abhisek-chakrabarty
    last: Chakrabarty
  - first: Utpal
    full: Utpal Garain
    id: utpal-garain
    last: Garain
  author_string: Abhisek Chakrabarty, Utpal Garain
  bibkey: chakrabarty-garain-2017-isi
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2006
  month: August
  page_first: '66'
  page_last: '70'
  pages: "66\u201370"
  paper_id: '6'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2006.jpg
  title: ISI at the SIGMORPHON 2017 Shared Task on Morphological Reinflection
  title_html: <span class="acl-fixed-case">ISI</span> at the <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task on Morphological Reinflection
  url: https://www.aclweb.org/anthology/K17-2006
  year: '2017'
K17-2007:
  address: Vancouver
  author:
  - first: Akhilesh
    full: Akhilesh Sudhakar
    id: akhilesh-sudhakar
    last: Sudhakar
  - first: Anil Kumar
    full: Anil Kumar Singh
    id: anil-kumar-singh
    last: Singh
  author_string: Akhilesh Sudhakar, Anil Kumar Singh
  bibkey: sudhakar-singh-2017-experiments
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2007
  month: August
  page_first: '71'
  page_last: '78'
  pages: "71\u201378"
  paper_id: '7'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2007.jpg
  title: 'Experiments on Morphological Reinflection: CoNLL-2017 Shared Task'
  title_html: 'Experiments on Morphological Reinflection: <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span>-2017 Shared Task'
  url: https://www.aclweb.org/anthology/K17-2007
  year: '2017'
K17-2008:
  address: Vancouver
  author:
  - first: Garrett
    full: Garrett Nicolai
    id: garrett-nicolai
    last: Nicolai
  - first: Bradley
    full: Bradley Hauer
    id: bradley-hauer
    last: Hauer
  - first: Mohammad
    full: Mohammad Motallebi
    id: mohammad-motallebi
    last: Motallebi
  - first: Saeed
    full: Saeed Najafi
    id: saeed-najafi
    last: Najafi
  - first: Grzegorz
    full: Grzegorz Kondrak
    id: grzegorz-kondrak
    last: Kondrak
  author_string: Garrett Nicolai, Bradley Hauer, Mohammad Motallebi, Saeed Najafi,
    Grzegorz Kondrak
  bibkey: nicolai-etal-2017-cant
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2008
  month: August
  page_first: '79'
  page_last: '84'
  pages: "79\u201384"
  paper_id: '8'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2008.jpg
  title: "If you can\u2019t beat them, join them: the University of Alberta system\
    \ description"
  title_html: "If you can\u2019t beat them, join them: the University of Alberta system\
    \ description"
  url: https://www.aclweb.org/anthology/K17-2008
  year: '2017'
K17-2009:
  address: Vancouver
  author:
  - first: Qile
    full: Qile Zhu
    id: qile-zhu
    last: Zhu
  - first: Yanjun
    full: Yanjun Li
    id: yanjun-li
    last: Li
  - first: Xiaolin
    full: Xiaolin Li
    id: xiaolin-li
    last: Li
  author_string: Qile Zhu, Yanjun Li, Xiaolin Li
  bibkey: zhu-etal-2017-character
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2009
  month: August
  page_first: '85'
  page_last: '89'
  pages: "85\u201389"
  paper_id: '9'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2009.jpg
  title: Character Sequence-to-Sequence Model with Global Attention for Universal
    Morphological Reinflection
  title_html: Character Sequence-to-Sequence Model with Global Attention for Universal
    Morphological Reinflection
  url: https://www.aclweb.org/anthology/K17-2009
  year: '2017'
K17-2010:
  address: Vancouver
  author:
  - first: Miikka
    full: Miikka Silfverberg
    id: miikka-silfverberg
    last: Silfverberg
  - first: Adam
    full: Adam Wiemerslage
    id: adam-wiemerslage
    last: Wiemerslage
  - first: Ling
    full: Ling Liu
    id: ling-liu
    last: Liu
  - first: Lingshuang Jack
    full: Lingshuang Jack Mao
    id: lingshuang-jack-mao
    last: Mao
  author_string: Miikka Silfverberg, Adam Wiemerslage, Ling Liu, Lingshuang Jack Mao
  bibkey: silfverberg-etal-2017-data
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2010
  month: August
  page_first: '90'
  page_last: '99'
  pages: "90\u201399"
  paper_id: '10'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2010.jpg
  title: Data Augmentation for Morphological Reinflection
  title_html: Data Augmentation for Morphological Reinflection
  url: https://www.aclweb.org/anthology/K17-2010
  year: '2017'
K17-2011:
  address: Vancouver
  author:
  - first: Hajime
    full: Hajime Senuma
    id: hajime-senuma
    last: Senuma
  - first: Akiko
    full: Akiko Aizawa
    id: akiko-aizawa
    last: Aizawa
  author_string: Hajime Senuma, Akiko Aizawa
  bibkey: senuma-aizawa-2017-seq2seq
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2011
  month: August
  page_first: '100'
  page_last: '109'
  pages: "100\u2013109"
  paper_id: '11'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2011.jpg
  title: 'Seq2seq for Morphological Reinflection: When Deep Learning Fails'
  title_html: 'Seq2seq for Morphological Reinflection: When Deep Learning Fails'
  url: https://www.aclweb.org/anthology/K17-2011
  year: '2017'
K17-2012:
  address: Vancouver
  author:
  - first: Robert
    full: "Robert \xD6stling"
    id: robert-ostling
    last: "\xD6stling"
  - first: Johannes
    full: Johannes Bjerva
    id: johannes-bjerva
    last: Bjerva
  author_string: "Robert \xD6stling, Johannes Bjerva"
  bibkey: ostling-bjerva-2017-su
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological
    Reinflection'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> <span class="acl-fixed-case">SIGMORPHON</span>
    2017 Shared Task: Universal Morphological Reinflection'
  doi: 10.18653/v1/K17-2012
  month: August
  page_first: '110'
  page_last: '113'
  pages: "110\u2013113"
  paper_id: '12'
  parent_volume_id: K17-2
  pdf: https://www.aclweb.org/anthology/K17-2012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-2012.jpg
  title: 'SU-RUG at the CoNLL-SIGMORPHON 2017 shared task: Morphological Inflection
    with Attentional Sequence-to-Sequence Models'
  title_html: '<span class="acl-fixed-case">SU</span>-<span class="acl-fixed-case">RUG</span>
    at the <span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>-<span
    class="acl-fixed-case">SIGMORPHON</span> 2017 shared task: Morphological Inflection
    with Attentional Sequence-to-Sequence Models'
  url: https://www.aclweb.org/anthology/K17-2012
  year: '2017'
K17-3000:
  address: Vancouver, Canada
  author:
  - first: Jan
    full: "Jan Haji\u010D"
    id: jan-hajic
    last: "Haji\u010D"
  - first: Dan
    full: Dan Zeman
    id: daniel-zeman
    last: Zeman
  author_string: "Jan Haji\u010D, Dan Zeman"
  bibkey: conll-2017-conll-2017
  bibtype: proceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3
  month: August
  paper_id: '0'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3000.jpg
  title: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw
    Text to Universal Dependencies'
  title_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies'
  url: https://www.aclweb.org/anthology/K17-3000
  year: '2017'
K17-3001:
  abstract: The Conference on Computational Natural Language Learning (CoNLL) features
    a shared task, in which participants train and test their learning systems on
    the same data sets. In 2017, the task was devoted to learning dependency parsers
    for a large number of languages, in a real-world setting without any gold-standard
    annotation on input. All test sets followed a unified annotation scheme, namely
    that of Universal Dependencies. In this paper, we define the task and evaluation
    methodology, describe how the data sets were prepared, report and analyze the
    main results, and provide a brief categorization of the different approaches of
    the participating systems.
  address: Vancouver, Canada
  author:
  - first: Daniel
    full: Daniel Zeman
    id: daniel-zeman
    last: Zeman
  - first: Martin
    full: Martin Popel
    id: martin-popel
    last: Popel
  - first: Milan
    full: Milan Straka
    id: milan-straka
    last: Straka
  - first: Jan
    full: "Jan Haji\u010D"
    id: jan-hajic
    last: "Haji\u010D"
  - first: Joakim
    full: Joakim Nivre
    id: joakim-nivre
    last: Nivre
  - first: Filip
    full: Filip Ginter
    id: filip-ginter
    last: Ginter
  - first: Juhani
    full: Juhani Luotolahti
    id: juhani-luotolahti
    last: Luotolahti
  - first: Sampo
    full: Sampo Pyysalo
    id: sampo-pyysalo
    last: Pyysalo
  - first: Slav
    full: Slav Petrov
    id: slav-petrov
    last: Petrov
  - first: Martin
    full: Martin Potthast
    id: martin-potthast
    last: Potthast
  - first: Francis
    full: Francis Tyers
    id: francis-tyers
    last: Tyers
  - first: Elena
    full: Elena Badmaeva
    id: elena-badmaeva
    last: Badmaeva
  - first: Memduh
    full: Memduh Gokirmak
    id: memduh-gokirmak
    last: Gokirmak
  - first: Anna
    full: Anna Nedoluzhko
    id: anna-nedoluzhko
    last: Nedoluzhko
  - first: Silvie
    full: "Silvie Cinkov\xE1"
    id: silvie-cinkova
    last: "Cinkov\xE1"
  - first: Jan
    full: "Jan Haji\u010D jr."
    id: jan-hajic-jr
    last: "Haji\u010D jr."
  - first: Jaroslava
    full: "Jaroslava Hlav\xE1\u010Dov\xE1"
    id: jaroslava-hlavacova
    last: "Hlav\xE1\u010Dov\xE1"
  - first: "V\xE1clava"
    full: "V\xE1clava Kettnerov\xE1"
    id: vaclava-kettnerova
    last: "Kettnerov\xE1"
  - first: "Zde\u0148ka"
    full: "Zde\u0148ka Ure\u0161ov\xE1"
    id: zdenka-uresova
    last: "Ure\u0161ov\xE1"
  - first: Jenna
    full: Jenna Kanerva
    id: jenna-kanerva
    last: Kanerva
  - first: Stina
    full: Stina Ojala
    id: stina-ojala
    last: Ojala
  - first: Anna
    full: "Anna Missil\xE4"
    id: anna-missila
    last: "Missil\xE4"
  - first: Christopher D.
    full: Christopher D. Manning
    id: christopher-d-manning
    last: Manning
  - first: Sebastian
    full: Sebastian Schuster
    id: sebastian-schuster
    last: Schuster
  - first: Siva
    full: Siva Reddy
    id: siva-reddy
    last: Reddy
  - first: Dima
    full: Dima Taji
    id: dima-taji
    last: Taji
  - first: Nizar
    full: Nizar Habash
    id: nizar-habash
    last: Habash
  - first: Herman
    full: Herman Leung
    id: herman-leung
    last: Leung
  - first: Marie-Catherine
    full: Marie-Catherine de Marneffe
    id: marie-catherine-de-marneffe
    last: de Marneffe
  - first: Manuela
    full: Manuela Sanguinetti
    id: manuela-sanguinetti
    last: Sanguinetti
  - first: Maria
    full: Maria Simi
    id: maria-simi
    last: Simi
  - first: Hiroshi
    full: Hiroshi Kanayama
    id: hiroshi-kanayama
    last: Kanayama
  - first: Valeria
    full: Valeria de Paiva
    id: valeria-de-paiva
    last: de Paiva
  - first: Kira
    full: Kira Droganova
    id: kira-droganova
    last: Droganova
  - first: "H\xE9ctor"
    full: "H\xE9ctor Mart\xEDnez Alonso"
    id: hector-martinez-alonso
    last: "Mart\xEDnez Alonso"
  - first: "\xC7a\u011Fr\u0131"
    full: "\xC7a\u011Fr\u0131 \xC7\xF6ltekin"
    id: cagri-coltekin
    last: "\xC7\xF6ltekin"
  - first: Umut
    full: Umut Sulubacak
    id: umut-sulubacak
    last: Sulubacak
  - first: Hans
    full: Hans Uszkoreit
    id: hans-uszkoreit
    last: Uszkoreit
  - first: Vivien
    full: Vivien Macketanz
    id: vivien-macketanz
    last: Macketanz
  - first: Aljoscha
    full: Aljoscha Burchardt
    id: aljoscha-burchardt
    last: Burchardt
  - first: Kim
    full: Kim Harris
    id: kim-harris
    last: Harris
  - first: Katrin
    full: Katrin Marheinecke
    id: katrin-marheinecke
    last: Marheinecke
  - first: Georg
    full: Georg Rehm
    id: georg-rehm
    last: Rehm
  - first: Tolga
    full: Tolga Kayadelen
    id: tolga-kayadelen
    last: Kayadelen
  - first: Mohammed
    full: Mohammed Attia
    id: mohammed-attia
    last: Attia
  - first: Ali
    full: Ali Elkahky
    id: ali-elkahky
    last: Elkahky
  - first: Zhuoran
    full: Zhuoran Yu
    id: zhuoran-yu
    last: Yu
  - first: Emily
    full: Emily Pitler
    id: emily-pitler
    last: Pitler
  - first: Saran
    full: Saran Lertpradit
    id: saran-lertpradit
    last: Lertpradit
  - first: Michael
    full: Michael Mandl
    id: michael-mandel
    last: Mandl
  - first: Jesse
    full: Jesse Kirchner
    id: jesse-kirchner
    last: Kirchner
  - first: Hector Fernandez
    full: Hector Fernandez Alcalde
    id: hector-fernandez-alcalde
    last: Alcalde
  - first: Jana
    full: "Jana Strnadov\xE1"
    id: jana-strnadova
    last: "Strnadov\xE1"
  - first: Esha
    full: Esha Banerjee
    id: esha-banerjee
    last: Banerjee
  - first: Ruli
    full: Ruli Manurung
    id: ruli-manurung
    last: Manurung
  - first: Antonio
    full: Antonio Stella
    id: antonio-stella
    last: Stella
  - first: Atsuko
    full: Atsuko Shimada
    id: atsuko-shimada
    last: Shimada
  - first: Sookyoung
    full: Sookyoung Kwak
    id: sookyoung-kwak
    last: Kwak
  - first: Gustavo
    full: "Gustavo Mendon\xE7a"
    id: gustavo-mendonca
    last: "Mendon\xE7a"
  - first: Tatiana
    full: Tatiana Lando
    id: tatiana-lando
    last: Lando
  - first: Rattima
    full: Rattima Nitisaroj
    id: rattima-nitisaroj
    last: Nitisaroj
  - first: Josie
    full: Josie Li
    id: josie-li
    last: Li
  author_string: "Daniel Zeman, Martin Popel, Milan Straka, Jan Haji\u010D, Joakim\
    \ Nivre, Filip Ginter, Juhani Luotolahti, Sampo Pyysalo, Slav Petrov, Martin Potthast,\
    \ Francis Tyers, Elena Badmaeva, Memduh Gokirmak, Anna Nedoluzhko, Silvie Cinkov\xE1\
    , Jan Haji\u010D jr., Jaroslava Hlav\xE1\u010Dov\xE1, V\xE1clava Kettnerov\xE1\
    , Zde\u0148ka Ure\u0161ov\xE1, Jenna Kanerva, Stina Ojala, Anna Missil\xE4, Christopher\
    \ D. Manning, Sebastian Schuster, Siva Reddy, Dima Taji, Nizar Habash, Herman\
    \ Leung, Marie-Catherine de Marneffe, Manuela Sanguinetti, Maria Simi, Hiroshi\
    \ Kanayama, Valeria de Paiva, Kira Droganova, H\xE9ctor Mart\xEDnez Alonso, \xC7\
    a\u011Fr\u0131 \xC7\xF6ltekin, Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz,\
    \ Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga Kayadelen,\
    \ Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael\
    \ Mandl, Jesse Kirchner, Hector Fernandez Alcalde, Jana Strnadov\xE1, Esha Banerjee,\
    \ Ruli Manurung, Antonio Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendon\xE7\
    a, Tatiana Lando, Rattima Nitisaroj, Josie Li"
  bibkey: zeman-etal-2017-conll
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3001
  month: August
  page_first: '1'
  page_last: '19'
  pages: "1\u201319"
  paper_id: '1'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3001.jpg
  title: 'CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal
    Dependencies'
  title_html: '<span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies'
  url: https://www.aclweb.org/anthology/K17-3001
  year: '2017'
K17-3002:
  abstract: 'This paper describes the neural dependency parser submitted by Stanford
    to the CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses
    relatively simple LSTM networks to produce part of speech tags and labeled dependency
    parses from segmented and tokenized sequences of words. In order to address the
    rare word problem that abounds in languages with complex morphology, we include
    a character-based word representation that uses an LSTM to produce embeddings
    from sequences of characters. Our system was ranked first according to all five
    relevant metrics for the system: UPOS tagging (93.09%), XPOS tagging (82.27%),
    unlabeled attachment score (81.30%), labeled attachment score (76.30%), and content
    word labeled attachment score (72.57%).'
  address: Vancouver, Canada
  author:
  - first: Timothy
    full: Timothy Dozat
    id: timothy-dozat
    last: Dozat
  - first: Peng
    full: Peng Qi
    id: peng-qi
    last: Qi
  - first: Christopher D.
    full: Christopher D. Manning
    id: christopher-d-manning
    last: Manning
  author_string: Timothy Dozat, Peng Qi, Christopher D. Manning
  bibkey: dozat-etal-2017-stanfords
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3002
  month: August
  page_first: '20'
  page_last: '30'
  pages: "20\u201330"
  paper_id: '2'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3002.jpg
  title: "Stanford\u2019s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared\
    \ Task"
  title_html: "<span class=\"acl-fixed-case\">S</span>tanford\u2019s Graph-based Neural\
    \ Dependency Parser at the <span class=\"acl-fixed-case\">C</span>o<span class=\"\
    acl-fixed-case\">NLL</span> 2017 Shared Task"
  url: https://www.aclweb.org/anthology/K17-3002
  year: '2017'
K17-3003:
  abstract: We describe our entry, C2L2, to the CoNLL 2017 shared task on parsing
    Universal Dependencies from raw text. Our system features an ensemble of three
    global parsing paradigms, one graph-based and two transition-based. Each model
    leverages character-level bi-directional LSTMs as lexical feature extractors to
    encode morphological information. Though relying on baseline tokenizers and focusing
    only on parsing, our system ranked second in the official end-to-end evaluation
    with a macro-average of 75.00 LAS F1 score over 81 test treebanks. In addition,
    we had the top average performance on the four surprise languages and on the small
    treebank subset.
  address: Vancouver, Canada
  author:
  - first: Tianze
    full: Tianze Shi
    id: tianze-shi
    last: Shi
  - first: Felix G.
    full: Felix G. Wu
    id: felix-g-wu
    last: Wu
  - first: Xilun
    full: Xilun Chen
    id: xilun-chen
    last: Chen
  - first: Yao
    full: Yao Cheng
    id: yao-cheng
    last: Cheng
  author_string: Tianze Shi, Felix G. Wu, Xilun Chen, Yao Cheng
  bibkey: shi-etal-2017-combining
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3003
  month: August
  page_first: '31'
  page_last: '39'
  pages: "31\u201339"
  paper_id: '3'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3003.jpg
  title: Combining Global Models for Parsing Universal Dependencies
  title_html: Combining Global Models for Parsing Universal Dependencies
  url: https://www.aclweb.org/anthology/K17-3003
  year: '2017'
K17-3004:
  abstract: This paper presents the IMS contribution to the CoNLL 2017 Shared Task.
    In the preprocessing step we employed a CRF POS/morphological tagger and a neural
    tagger predicting supertags. On some languages, we also applied word segmentation
    with the CRF tagger and sentence segmentation with a perceptron-based parser.
    For parsing we took an ensemble approach by blending multiple instances of three
    parsers with very different architectures. Our system achieved the third place
    overall and the second place for the surprise languages.
  address: Vancouver, Canada
  author:
  - first: Anders
    full: "Anders Bj\xF6rkelund"
    id: anders-bjorkelund
    last: "Bj\xF6rkelund"
  - first: Agnieszka
    full: Agnieszka Falenska
    id: agnieszka-falenska
    last: Falenska
  - first: Xiang
    full: Xiang Yu
    id: xiang-yu
    last: Yu
  - first: Jonas
    full: Jonas Kuhn
    id: jonas-kuhn
    last: Kuhn
  author_string: "Anders Bj\xF6rkelund, Agnieszka Falenska, Xiang Yu, Jonas Kuhn"
  bibkey: bjorkelund-etal-2017-ims
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3004
  month: August
  page_first: '40'
  page_last: '51'
  pages: "40\u201351"
  paper_id: '4'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3004.jpg
  title: 'IMS at the CoNLL 2017 UD Shared Task: CRFs and Perceptrons Meet Neural Networks'
  title_html: '<span class="acl-fixed-case">IMS</span> at the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 <span class="acl-fixed-case">UD</span>
    Shared Task: <span class="acl-fixed-case">CRF</span>s and Perceptrons Meet Neural
    Networks'
  url: https://www.aclweb.org/anthology/K17-3004
  year: '2017'
K17-3005:
  abstract: 'This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared
    task: Multilingual Parsing from Raw Text to Universal Dependencies. Our system
    includes three pipelined components: tokenization, Part-of-Speech (POS) tagging
    and dependency parsing. We use character-based bidirectional long short-term memory
    (LSTM) networks for both tokenization and POS tagging. Afterwards, we employ a
    list-based transition-based algorithm for general non-projective parsing and present
    an improved Stack-LSTM-based architecture for representing each transition state
    and making predictions. Furthermore, to parse low/zero-resource languages and
    cross-domain data, we use a model transfer approach to make effective use of existing
    resources. We demonstrate substantial gains against the UDPipe baseline, with
    an average improvement of 3.76% in LAS of all languages. And finally, we rank
    the 4th place on the official test sets.'
  address: Vancouver, Canada
  author:
  - first: Wanxiang
    full: Wanxiang Che
    id: wanxiang-che
    last: Che
  - first: Jiang
    full: Jiang Guo
    id: jiang-guo
    last: Guo
  - first: Yuxuan
    full: Yuxuan Wang
    id: yuxuan-wang
    last: Wang
  - first: Bo
    full: Bo Zheng
    id: bo-zheng
    last: Zheng
  - first: Huaipeng
    full: Huaipeng Zhao
    id: huaipeng-zhao
    last: Zhao
  - first: Yang
    full: Yang Liu
    id: yang-liu
    last: Liu
  - first: Dechuan
    full: Dechuan Teng
    id: dechuan-teng
    last: Teng
  - first: Ting
    full: Ting Liu
    id: ting-liu
    last: Liu
  author_string: Wanxiang Che, Jiang Guo, Yuxuan Wang, Bo Zheng, Huaipeng Zhao, Yang
    Liu, Dechuan Teng, Ting Liu
  bibkey: che-etal-2017-hit
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3005
  month: August
  page_first: '52'
  page_last: '62'
  pages: "52\u201362"
  paper_id: '5'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3005.jpg
  title: The HIT-SCIR System for End-to-End Parsing of Universal Dependencies
  title_html: The <span class="acl-fixed-case">HIT</span>-<span class="acl-fixed-case">SCIR</span>
    System for End-to-End Parsing of Universal Dependencies
  url: https://www.aclweb.org/anthology/K17-3005
  year: '2017'
K17-3006:
  abstract: "In this paper, we present our multilingual dependency parser developed\
    \ for the CoNLL 2017 UD Shared Task dealing with \u201CMultilingual Parsing from\
    \ Raw Text to Universal Dependencies\u201D. Our parser extends the monolingual\
    \ BIST-parser as a multi-source multilingual trainable parser. Thanks to multilingual\
    \ word embeddings and one hot encodings for languages, our system can use both\
    \ monolingual and multi-source training. We trained 69 monolingual language models\
    \ and 13 multilingual models for the shared task. Our multilingual approach making\
    \ use of different resources yield better results than the monolingual approach\
    \ for 11 languages. Our system ranked 5 th and achieved 70.93 overall LAS score\
    \ over the 81 test corpora (macro-averaged LAS F1 score)."
  address: Vancouver, Canada
  author:
  - first: KyungTae
    full: KyungTae Lim
    id: kyungtae-lim
    last: Lim
  - first: Thierry
    full: Thierry Poibeau
    id: thierry-poibeau
    last: Poibeau
  author_string: KyungTae Lim, Thierry Poibeau
  bibkey: lim-poibeau-2017-system
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3006
  month: August
  page_first: '63'
  page_last: '70'
  pages: "63\u201370"
  paper_id: '6'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3006.jpg
  title: A System for Multilingual Dependency Parsing based on Bidirectional LSTM
    Feature Representations
  title_html: A System for Multilingual Dependency Parsing based on Bidirectional
    <span class="acl-fixed-case">LSTM</span> Feature Representations
  url: https://www.aclweb.org/anthology/K17-3006
  year: '2017'
K17-3007:
  abstract: We describe our submission to the CoNLL 2017 shared task, which exploits
    the shared common knowledge of a language across different domains via a domain
    adaptation technique. Our approach is an extension to the recently proposed adversarial
    training technique for domain adaptation, which we apply on top of a graph-based
    neural dependency parsing model on bidirectional LSTMs. In our experiments, we
    find our baseline graph-based parser already outperforms the official baseline
    model (UDPipe) by a large margin. Further, by applying our technique to the treebanks
    of the same language with different domains, we observe an additional gain in
    the performance, in particular for the domains with less training data.
  address: Vancouver, Canada
  author:
  - first: Motoki
    full: Motoki Sato
    id: motoki-sano
    last: Sato
  - first: Hitoshi
    full: Hitoshi Manabe
    id: hitoshi-manabe
    last: Manabe
  - first: Hiroshi
    full: Hiroshi Noji
    id: hiroshi-noji
    last: Noji
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Motoki Sato, Hitoshi Manabe, Hiroshi Noji, Yuji Matsumoto
  bibkey: sato-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3007
  month: August
  page_first: '71'
  page_last: '79'
  pages: "71\u201379"
  paper_id: '7'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3007.jpg
  title: Adversarial Training for Cross-Domain Universal Dependency Parsing
  title_html: Adversarial Training for Cross-Domain Universal Dependency Parsing
  url: https://www.aclweb.org/anthology/K17-3007
  year: '2017'
K17-3008:
  abstract: "We introduce context embeddings, dense vectors derived from a language\
    \ model that represent the left/right context of a word instance, and demonstrate\
    \ that context embeddings significantly improve the accuracy of our transition\
    \ based parser. Our model consists of a bidirectional LSTM (BiLSTM) based language\
    \ model that is pre-trained to predict words in plain text, and a multi-layer\
    \ perceptron (MLP) decision model that uses features from the language model to\
    \ predict the correct actions for an ArcHybrid transition based parser. We participated\
    \ in the CoNLL 2017 UD Shared Task as the \u201CKo\xE7 University\u201D team and\
    \ our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49 languages."
  address: Vancouver, Canada
  author:
  - first: "\xD6mer"
    full: "\xD6mer K\u0131rnap"
    id: omer-kirnap
    last: "K\u0131rnap"
  - first: Berkay Furkan
    full: "Berkay Furkan \xD6nder"
    id: berkay-furkan-onder
    last: "\xD6nder"
  - first: Deniz
    full: Deniz Yuret
    id: deniz-yuret
    last: Yuret
  author_string: "\xD6mer K\u0131rnap, Berkay Furkan \xD6nder, Deniz Yuret"
  bibkey: kirnap-etal-2017-parsing
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3008
  month: August
  page_first: '80'
  page_last: '87'
  pages: "80\u201387"
  paper_id: '8'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3008.jpg
  title: Parsing with Context Embeddings
  title_html: Parsing with Context Embeddings
  url: https://www.aclweb.org/anthology/K17-3008
  year: '2017'
K17-3009:
  abstract: "Many natural language processing tasks, including the most advanced ones,\
    \ routinely start by several basic processing steps \u2013 tokenization and segmentation,\
    \ most likely also POS tagging and lemmatization, and commonly parsing as well.\
    \ A multilingual pipeline performing these steps can be trained using the Universal\
    \ Dependencies project, which contains annotations of the described tasks for\
    \ 50 languages in the latest release UD 2.0. We present an update to UDPipe, a\
    \ simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs\
    \ these tasks for multiple languages without requiring additional external data.\
    \ We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline\
    \ can be trained easily using data in CoNLL-U format. UDPipe is a standalone application\
    \ in C++, with bindings available for Python, Java, C# and Perl. In the CoNLL\
    \ 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,\
    \ UDPipe was the eight best system, while achieving low running times and moderately\
    \ sized models."
  address: Vancouver, Canada
  attachment:
  - filename: K17-3009.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/K17-3009.Poster.pdf
  author:
  - first: Milan
    full: Milan Straka
    id: milan-straka
    last: Straka
  - first: Jana
    full: "Jana Strakov\xE1"
    id: jana-strakova
    last: "Strakov\xE1"
  author_string: "Milan Straka, Jana Strakov\xE1"
  bibkey: straka-strakova-2017-tokenizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3009
  month: August
  page_first: '88'
  page_last: '99'
  pages: "88\u201399"
  paper_id: '9'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3009.jpg
  title: Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe
  title_html: Tokenizing, <span class="acl-fixed-case">POS</span> Tagging, Lemmatizing
    and Parsing <span class="acl-fixed-case">UD</span> 2.0 with <span class="acl-fixed-case">UDP</span>ipe
  url: https://www.aclweb.org/anthology/K17-3009
  year: '2017'
K17-3010:
  abstract: This paper presents our submissions for the CoNLL 2017 UD Shared Task.
    Our parser, called UParse, is based on a neural network graph-based dependency
    parser. The parser uses features from a bidirectional LSTM to to produce a distribution
    over possible heads for each word in the sentence. To allow transfer learning
    for low-resource treebanks and surprise languages, we train several multilingual
    models for related languages, grouped by their genus and language families. Out
    of 33 participants, our system achieves rank 9th in the main results, with 75.49
    UAS and 68.87 LAS F-1 scores (average across 81 treebanks).
  address: Vancouver, Canada
  author:
  - first: Clara
    full: Clara Vania
    id: clara-vania
    last: Vania
  - first: Xingxing
    full: Xingxing Zhang
    id: xingxing-zhang
    last: Zhang
  - first: Adam
    full: Adam Lopez
    id: adam-lopez
    last: Lopez
  author_string: Clara Vania, Xingxing Zhang, Adam Lopez
  bibkey: vania-etal-2017-uparse
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3010
  month: August
  page_first: '100'
  page_last: '110'
  pages: "100\u2013110"
  paper_id: '10'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3010.jpg
  title: 'UParse: the Edinburgh system for the CoNLL 2017 UD shared task'
  title_html: '<span class="acl-fixed-case">UP</span>arse: the <span class="acl-fixed-case">E</span>dinburgh
    system for the <span class="acl-fixed-case">C</span>o<span class="acl-fixed-case">NLL</span>
    2017 <span class="acl-fixed-case">UD</span> shared task'
  url: https://www.aclweb.org/anthology/K17-3010
  year: '2017'
K17-3011:
  abstract: "This paper describes the system of the Team Orange-Deski\xF1, used for\
    \ the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. We based our\
    \ approach on an existing open source tool (BistParser), which we modified in\
    \ order to produce the required output. Additionally we added a kind of pseudo-projectivisation.\
    \ This was needed since some of the task\u2019s languages have a high percentage\
    \ of non-projective dependency trees. In most cases we also employed word embeddings.\
    \ For the 4 surprise languages, the data provided seemed too little to train on.\
    \ Thus we decided to use the training data of typologically close languages instead.\
    \ Our system achieved a macro-averaged LAS of 68.61% (10th in the overall ranking)\
    \ which improved to 69.38% after bug fixes."
  address: Vancouver, Canada
  attachment:
  - filename: K17-3011.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/K17-3011.Poster.pdf
  author:
  - first: Johannes
    full: Johannes Heinecke
    id: johannes-heinecke
    last: Heinecke
  - first: Munshi
    full: Munshi Asadullah
    id: munshi-asadullah
    last: Asadullah
  author_string: Johannes Heinecke, Munshi Asadullah
  bibkey: heinecke-asadullah-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3011
  month: August
  page_first: '111'
  page_last: '118'
  pages: "111\u2013118"
  paper_id: '11'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3011.jpg
  title: Multi-Model and Crosslingual Dependency Analysis
  title_html: Multi-Model and Crosslingual Dependency Analysis
  url: https://www.aclweb.org/anthology/K17-3011
  year: '2017'
K17-3012:
  abstract: We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual
    Parsing from Raw Text to Universal Dependencies. The system is based on the UDPipe
    parser with our focus being in exploring various techniques to pre-train the word
    embeddings used by the parser in order to improve its performance especially on
    languages with small training sets. The system ranked 11th among the 33 participants
    overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on
    the parallel test sets, and 26th on the surprise languages.
  address: Vancouver, Canada
  author:
  - first: Jenna
    full: Jenna Kanerva
    id: jenna-kanerva
    last: Kanerva
  - first: Juhani
    full: Juhani Luotolahti
    id: juhani-luotolahti
    last: Luotolahti
  - first: Filip
    full: Filip Ginter
    id: filip-ginter
    last: Ginter
  author_string: Jenna Kanerva, Juhani Luotolahti, Filip Ginter
  bibkey: kanerva-etal-2017-turkunlp
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3012
  month: August
  page_first: '119'
  page_last: '125'
  pages: "119\u2013125"
  paper_id: '12'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3012.jpg
  title: 'TurkuNLP: Delexicalized Pre-training of Word Embeddings for Dependency Parsing'
  title_html: '<span class="acl-fixed-case">T</span>urku<span class="acl-fixed-case">NLP</span>:
    Delexicalized Pre-training of Word Embeddings for Dependency Parsing'
  url: https://www.aclweb.org/anthology/K17-3012
  year: '2017'
K17-3013:
  abstract: 'We developed two simple systems for dependency parsing: darc, a transition-based
    parser, and mstnn, a graph-based parser. We tested our systems in the CoNLL 2017
    UD Shared Task, with darc being the official system. Darc ranked 12th among 33
    systems, just above the baseline. Mstnn had no official ranking, but its main
    score was above the 27th. In this paper, we describe our two systems, examine
    their strengths and weaknesses, and discuss the lessons we learned.'
  address: Vancouver, Canada
  author:
  - first: Kuan
    full: Kuan Yu
    id: kuan-yu
    last: Yu
  - first: Pavel
    full: Pavel Sofroniev
    id: pavel-sofroniev
    last: Sofroniev
  - first: Erik
    full: Erik Schill
    id: erik-schill
    last: Schill
  - first: Erhard
    full: Erhard Hinrichs
    id: erhard-hinrichs
    last: Hinrichs
  author_string: Kuan Yu, Pavel Sofroniev, Erik Schill, Erhard Hinrichs
  bibkey: yu-etal-2017-parse
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3013
  month: August
  page_first: '126'
  page_last: '133'
  pages: "126\u2013133"
  paper_id: '13'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3013.jpg
  title: 'The parse is darc and full of errors: Universal dependency parsing with
    transition-based and graph-based algorithms'
  title_html: 'The parse is darc and full of errors: Universal dependency parsing
    with transition-based and graph-based algorithms'
  url: https://www.aclweb.org/anthology/K17-3013
  year: '2017'
K17-3014:
  abstract: 'We present a novel neural network model that learns POS tagging and graph-based
    dependency parsing jointly. Our model uses bidirectional LSTMs to learn feature
    representations shared for both POS tagging and dependency parsing tasks, thus
    handling the feature-engineering problem. Our extensive experiments, on 19 languages
    from the Universal Dependencies project, show that our model outperforms the state-of-the-art
    neural network-based Stack-propagation model for joint POS tagging and transition-based
    dependency parsing, resulting in a new state of the art. Our code is open-source
    and available together with pre-trained models at: https://github.com/datquocnguyen/jPTDP'
  address: Vancouver, Canada
  author:
  - first: Dat Quoc
    full: Dat Quoc Nguyen
    id: dat-quoc-nguyen
    last: Nguyen
  - first: Mark
    full: Mark Dras
    id: mark-dras
    last: Dras
  - first: Mark
    full: Mark Johnson
    id: mark-johnson
    last: Johnson
  author_string: Dat Quoc Nguyen, Mark Dras, Mark Johnson
  bibkey: nguyen-etal-2017-novel
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3014
  month: August
  page_first: '134'
  page_last: '142'
  pages: "134\u2013142"
  paper_id: '14'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3014.jpg
  title: A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency
    Parsing
  title_html: A Novel Neural Network Model for Joint <span class="acl-fixed-case">POS</span>
    Tagging and Graph-based Dependency Parsing
  url: https://www.aclweb.org/anthology/K17-3014
  year: '2017'
K17-3015:
  abstract: "For this year\u2019s multilingual dependency parsing shared task, we\
    \ developed a pipeline system, which uses a variety of features for each of its\
    \ components. Unlike the recent popular deep learning approaches that learn low\
    \ dimensional dense features using non-linear classifier, our system uses structured\
    \ linear classifiers to learn millions of sparse features. Specifically, we trained\
    \ a linear classifier for sentence boundary prediction, linear chain conditional\
    \ random fields (CRFs) for tokenization, part-of-speech tagging and morph analysis.\
    \ A second order graph based parser learns the tree structure (without relations),\
    \ and fa linear tree CRF then assigns relations to the dependencies in the tree.\
    \ Our system achieves reasonable performance \u2013 67.87% official averaged macro\
    \ F1 score"
  address: Vancouver, Canada
  author:
  - first: Xian
    full: Xian Qian
    id: xian-qian
    last: Qian
  - first: Yang
    full: Yang Liu
    id: yang-liu-icsi
    last: Liu
  author_string: Xian Qian, Yang Liu
  bibkey: qian-liu-2017-non
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3015
  month: August
  page_first: '143'
  page_last: '151'
  pages: "143\u2013151"
  paper_id: '15'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3015.jpg
  title: "A non-DNN Feature Engineering Approach to Dependency Parsing \u2013 FBAML\
    \ at CoNLL 2017 Shared Task"
  title_html: "A non-<span class=\"acl-fixed-case\">DNN</span> Feature Engineering\
    \ Approach to Dependency Parsing \u2013 <span class=\"acl-fixed-case\">FBAML</span>\
    \ at <span class=\"acl-fixed-case\">C</span>o<span class=\"acl-fixed-case\">NLL</span>\
    \ 2017 Shared Task"
  url: https://www.aclweb.org/anthology/K17-3015
  year: '2017'
K17-3016:
  abstract: "The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation\
    \ of the Covington (2001) algorithm for non-projective dependency parsing. The\
    \ bidirectional LSTM approach by Kiperwasser and Goldberg (2016) is used to train\
    \ a greedy parser with a dynamic oracle to mitigate error propagation. The model\
    \ participated in the CoNLL 2017 UD Shared Task. In spite of not using any ensemble\
    \ methods and using the baseline segmentation and PoS tagging, the parser obtained\
    \ good results on both macro-average LAS and UAS in the big treebanks category\
    \ (55 languages), ranking 7th out of 33 teams. In the all treebanks category (LAS\
    \ and UAS) we ranked 16th and 12th. The gap between the all and big categories\
    \ is mainly due to the poor performance on four parallel PUD treebanks, suggesting\
    \ that some \u2018suffixed\u2019 treebanks (e.g. Spanish-AnCora) perform poorly\
    \ on cross-treebank settings, which does not occur with the corresponding \u2018\
    unsuffixed\u2019 treebank (e.g. Spanish). By changing that, we obtain the 11th\
    \ best LAS among all runs (official and unofficial). The code is made available\
    \ at https://github.com/CoNLL-UD-2017/LyS-FASTPARSE"
  address: Vancouver, Canada
  author:
  - first: David
    full: David Vilares
    id: david-vilares
    last: Vilares
  - first: Carlos
    full: "Carlos G\xF3mez-Rodr\xEDguez"
    id: carlos-gomez-rodriguez
    last: "G\xF3mez-Rodr\xEDguez"
  author_string: "David Vilares, Carlos G\xF3mez-Rodr\xEDguez"
  bibkey: vilares-gomez-rodriguez-2017-non
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3016
  month: August
  page_first: '152'
  page_last: '162'
  pages: "152\u2013162"
  paper_id: '16'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3016.jpg
  title: A non-projective greedy dependency parser with bidirectional LSTMs
  title_html: A non-projective greedy dependency parser with bidirectional <span class="acl-fixed-case">LSTM</span>s
  url: https://www.aclweb.org/anthology/K17-3016
  year: '2017'
K17-3017:
  abstract: "This paper describes LIMSI\u2019s submission to the CoNLL 2017 UD Shared\
    \ Task, which is focused on small treebanks, and how to improve low-resourced\
    \ parsing only by ad hoc combination of multiple views and resources. We present\
    \ our approach for low-resourced parsing, together with a detailed analysis of\
    \ the results for each test treebank. We also report extensive analysis experiments\
    \ on model selection for the PUD treebanks, and on annotation consistency among\
    \ UD treebanks."
  address: Vancouver, Canada
  author:
  - first: Lauriane
    full: Lauriane Aufrant
    id: lauriane-aufrant
    last: Aufrant
  - first: Guillaume
    full: Guillaume Wisniewski
    id: guillaume-wisniewski
    last: Wisniewski
  - first: "Fran\xE7ois"
    full: "Fran\xE7ois Yvon"
    id: francois-yvon
    last: Yvon
  author_string: "Lauriane Aufrant, Guillaume Wisniewski, Fran\xE7ois Yvon"
  bibkey: aufrant-etal-2017-limsi
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3017
  month: August
  page_first: '163'
  page_last: '173'
  pages: "163\u2013173"
  paper_id: '17'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3017.jpg
  title: "LIMSI@CoNLL\u201917: UD Shared Task"
  title_html: "LIMSI@CoNLL\u201917: UD Shared Task"
  url: https://www.aclweb.org/anthology/K17-3017
  year: '2017'
K17-3018:
  abstract: "This paper presents RACAI\u2019s approach, experiments and results at\
    \ CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.\
    \ We handle raw text and we cover tokenization, sentence splitting, word segmentation,\
    \ tagging, lemmatization and parsing. All results are reported under strict training,\
    \ development and testing conditions, in which the corpora provided for the shared\
    \ tasks is used \u201Cas is\u201D, without any modifications to the composition\
    \ of the train and development sets."
  address: Vancouver, Canada
  author:
  - first: Stefan Daniel
    full: Stefan Daniel Dumitrescu
    id: stefan-daniel-dumitrescu
    last: Dumitrescu
  - first: Tiberiu
    full: Tiberiu Boros
    id: tiberiu-boros
    last: Boros
  - first: Dan
    full: Dan Tufis
    id: dan-tufis
    last: Tufis
  author_string: Stefan Daniel Dumitrescu, Tiberiu Boros, Dan Tufis
  bibkey: dumitrescu-etal-2017-racais
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3018
  month: August
  page_first: '174'
  page_last: '181'
  pages: "174\u2013181"
  paper_id: '18'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3018.jpg
  title: "RACAI\u2019s Natural Language Processing pipeline for Universal Dependencies"
  title_html: "<span class=\"acl-fixed-case\">RACAI</span>\u2019s Natural Language\
    \ Processing pipeline for Universal Dependencies"
  url: https://www.aclweb.org/anthology/K17-3018
  year: '2017'
K17-3019:
  abstract: This paper describes our dependency parsing system in CoNLL-2017 shared
    task on Multilingual Parsing from Raw Text to Universal Dependencies. We primarily
    focus on the low-resource languages (surprise languages). We have developed a
    framework to combine multiple treebanks to train parsers for low resource languages
    by delexicalization method. We have applied transformation on source language
    treebanks based on syntactic features of the low-resource language to improve
    performance of the parser. In the official evaluation, our system achieves an
    macro-averaged LAS score of 67.61 and 37.16 on the entire blind test data and
    the surprise language test data respectively.
  address: Vancouver, Canada
  author:
  - first: Ayan
    full: Ayan Das
    id: ayan-das
    last: Das
  - first: Affan
    full: Affan Zaffar
    id: affan-zaffar
    last: Zaffar
  - first: Sudeshna
    full: Sudeshna Sarkar
    id: sudeshna-sarkar
    last: Sarkar
  author_string: Ayan Das, Affan Zaffar, Sudeshna Sarkar
  bibkey: das-etal-2017-delexicalized
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3019
  month: August
  page_first: '182'
  page_last: '190'
  pages: "182\u2013190"
  paper_id: '19'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3019.jpg
  title: Delexicalized transfer parsing for low-resource languages using transformed
    and combined treebanks
  title_html: Delexicalized transfer parsing for low-resource languages using transformed
    and combined treebanks
  url: https://www.aclweb.org/anthology/K17-3019
  year: '2017'
K17-3020:
  abstract: 'This paper describes the system for our participation in the CoNLL 2017
    Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. In
    this work, we design a system based on UDPipe1 for universal dependency parsing,
    where multilingual transition-based models are trained for different treebanks.
    Our system directly takes raw texts as input, performing several intermediate
    steps like tokenizing and tagging, and finally generates the corresponding dependency
    trees. For the special surprise languages for this task, we adopt a delexicalized
    strategy and predict basing on transfer learning from other related languages.
    In the final evaluation of the shared task, our system achieves a result of 66.53%
    in macro-averaged LAS F1-score.'
  address: Vancouver, Canada
  author:
  - first: Hao
    full: Hao Wang
    id: hao-wang
    last: Wang
  - first: Hai
    full: Hai Zhao
    id: hai-zhao
    last: Zhao
  - first: Zhisong
    full: Zhisong Zhang
    id: zhisong-zhang
    last: Zhang
  author_string: Hao Wang, Hai Zhao, Zhisong Zhang
  bibkey: wang-etal-2017-transition-based
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3020
  month: August
  page_first: '191'
  page_last: '197'
  pages: "191\u2013197"
  paper_id: '20'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3020.jpg
  title: A Transition-based System for Universal Dependency Parsing
  title_html: A Transition-based System for Universal Dependency Parsing
  url: https://www.aclweb.org/anthology/K17-3020
  year: '2017'
K17-3021:
  abstract: "This paper describes UALing\u2019s approach to the CoNLL 2017 UD Shared\
    \ Task using corpus selection techniques to reduce training data size. The methodology\
    \ is simple: we use similarity measures to select a corpus from available training\
    \ data (even from multiple corpora for surprise languages) and use the resulting\
    \ corpus to complete the parsing task. The training and parsing is done with the\
    \ baseline UDPipe system (Straka et al., 2016). While our approach reduces the\
    \ size of training data significantly, it retains performance within 0.5% of the\
    \ baseline system. Due to the reduction in training data size, our system performs\
    \ faster than the na\xEFve, complete corpus method. Specifically, our system runs\
    \ in less than 10 minutes, ranking it among the fastest entries for this task.\
    \ Our system is available at https://github.com/CoNLL-UD-2017/UALING."
  address: Vancouver, Canada
  author:
  - first: Ryan
    full: Ryan Hornby
    id: ryan-hornby
    last: Hornby
  - first: Clark
    full: Clark Taylor
    id: clark-taylor
    last: Taylor
  - first: Jungyeul
    full: Jungyeul Park
    id: jungyeul-park
    last: Park
  author_string: Ryan Hornby, Clark Taylor, Jungyeul Park
  bibkey: hornby-etal-2017-corpus
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3021
  month: August
  page_first: '198'
  page_last: '206'
  pages: "198\u2013206"
  paper_id: '21'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3021.jpg
  title: Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal
    Dependencies
  title_html: Corpus Selection Approaches for Multilingual Parsing from Raw Text to
    Universal Dependencies
  url: https://www.aclweb.org/anthology/K17-3021
  year: '2017'
K17-3022:
  abstract: We present the Uppsala submission to the CoNLL 2017 shared task on parsing
    from raw text to universal dependencies. Our system is a simple pipeline consisting
    of two components. The first performs joint word and sentence segmentation on
    raw text; the second predicts dependency trees from raw words. The parser bypasses
    the need for part-of-speech tagging, but uses word embeddings based on universal
    tag distributions. We achieved a macro-averaged LAS F1 of 65.11 in the official
    test run, which improved to 70.49 after bug fixes. We obtained the 2nd best result
    for sentence segmentation with a score of 89.03.
  address: Vancouver, Canada
  attachment:
  - filename: K17-3022.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/K17-3022.Poster.pdf
  author:
  - first: Miryam
    full: Miryam de Lhoneux
    id: miryam-de-lhoneux
    last: de Lhoneux
  - first: Yan
    full: Yan Shao
    id: yan-shao
    last: Shao
  - first: Ali
    full: Ali Basirat
    id: ali-basirat
    last: Basirat
  - first: Eliyahu
    full: Eliyahu Kiperwasser
    id: eliyahu-kiperwasser
    last: Kiperwasser
  - first: Sara
    full: Sara Stymne
    id: sara-stymne
    last: Stymne
  - first: Yoav
    full: Yoav Goldberg
    id: yoav-goldberg
    last: Goldberg
  - first: Joakim
    full: Joakim Nivre
    id: joakim-nivre
    last: Nivre
  author_string: Miryam de Lhoneux, Yan Shao, Ali Basirat, Eliyahu Kiperwasser, Sara
    Stymne, Yoav Goldberg, Joakim Nivre
  bibkey: de-lhoneux-etal-2017-raw
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3022
  month: August
  page_first: '207'
  page_last: '217'
  pages: "207\u2013217"
  paper_id: '22'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3022.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3022.jpg
  title: From Raw Text to Universal Dependencies - Look, No Tags!
  title_html: From Raw Text to Universal Dependencies - Look, No Tags!
  url: https://www.aclweb.org/anthology/K17-3022
  year: '2017'
K17-3023:
  abstract: In this paper we describe the system by METU team for universal dependency
    parsing of multilingual text. We use a neural network-based dependency parser
    that has a greedy transition approach to dependency parsing. CCG supertags contain
    rich structural information that proves useful in certain NLP tasks. We experiment
    with CCG supertags as additional features in our experiments. The neural network
    parser is trained together with dependencies and simplified CCG tags as well as
    other features provided.
  address: Vancouver, Canada
  author:
  - first: Burak Kerim
    full: Burak Kerim Akkus
    id: burak-kerim-akkus
    last: Akkus
  - first: Heval
    full: Heval Azizoglu
    id: heval-azizoglu
    last: Azizoglu
  - first: Ruket
    full: Ruket Cakici
    id: ruket-cakici
    last: Cakici
  author_string: Burak Kerim Akkus, Heval Azizoglu, Ruket Cakici
  bibkey: akkus-etal-2017-initial
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3023
  month: August
  page_first: '218'
  page_last: '227'
  pages: "218\u2013227"
  paper_id: '23'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3023.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3023.jpg
  title: Initial Explorations of CCG Supertagging for Universal Dependency Parsing
  title_html: Initial Explorations of <span class="acl-fixed-case">CCG</span> Supertagging
    for Universal Dependency Parsing
  url: https://www.aclweb.org/anthology/K17-3023
  year: '2017'
K17-3024:
  abstract: "This paper describes the University of Geneva\u2019s submission to the\
    \ CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies\
    \ (listed as the CLCL (Geneva) entry). Our submitted parsing system is the grandchild\
    \ of the first transition-based neural network dependency parser, which was the\
    \ University of Geneva\u2019s entry in the CoNLL 2007 multilingual dependency\
    \ parsing shared task, with some improvements to speed and portability. These\
    \ results provide a baseline for investigating how far we have come in the past\
    \ ten years of work on neural network dependency parsing."
  address: Vancouver, Canada
  author:
  - first: Christophe
    full: Christophe Moor
    id: christophe-moor
    last: Moor
  - first: Paola
    full: Paola Merlo
    id: paola-merlo
    last: Merlo
  - first: James
    full: James Henderson
    id: james-henderson
    last: Henderson
  - first: Haozhou
    full: Haozhou Wang
    id: haozhou-wang
    last: Wang
  author_string: Christophe Moor, Paola Merlo, James Henderson, Haozhou Wang
  bibkey: moor-etal-2017-clcl
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3024
  month: August
  page_first: '228'
  page_last: '236'
  pages: "228\u2013236"
  paper_id: '24'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3024.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3024.jpg
  title: 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years
    Later'
  title_html: '<span class="acl-fixed-case">CLCL</span> (Geneva) <span class="acl-fixed-case">DINN</span>
    Parser: a Neural Network Dependency Parser Ten Years Later'
  url: https://www.aclweb.org/anthology/K17-3024
  year: '2017'
K17-3025:
  abstract: 'We present a multilingual dependency parser with a bidirectional-LSTM
    (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier. We trained
    our transition-based projective parser in UD version 2.0 datasets without any
    additional data. The parser is fast, lightweight and effective on big treebanks.
    In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal
    Dependencies, the official results show that the macro-averaged LAS F1 score of
    our system Mengest is 61.33%.'
  address: Vancouver, Canada
  author:
  - first: Tao
    full: Tao Ji
    id: tao-ji
    last: Ji
  - first: Yuanbin
    full: Yuanbin Wu
    id: yuanbin-wu
    last: Wu
  - first: Man
    full: Man Lan
    id: man-lan
    last: Lan
  author_string: Tao Ji, Yuanbin Wu, Man Lan
  bibkey: ji-etal-2017-fast
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3025
  month: August
  page_first: '237'
  page_last: '242'
  pages: "237\u2013242"
  paper_id: '25'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3025.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3025.jpg
  title: A Fast and Lightweight System for Multilingual Dependency Parsing
  title_html: A Fast and Lightweight System for Multilingual Dependency Parsing
  url: https://www.aclweb.org/anthology/K17-3025
  year: '2017'
K17-3026:
  abstract: "We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task.\
    \ In addition to the UDpipe models provided, we built our own data-driven tokenization\
    \ models, sentence segmenter and lexicon-based morphological analyzers. All of\
    \ these were used with a range of different parsing models (neural or not, feature-rich\
    \ or not, transition or graph-based, etc.) and the best combination for each language\
    \ was selected. Unfortunately, a glitch in the shared task\u2019s Matrix led our\
    \ model selector to run generic, weakly lexicalized models, tailored for surprise\
    \ languages, instead of our dataset-specific models. Because of this #ParsingTragedy,\
    \ we officially ranked 27th, whereas our real models finally unofficially ranked\
    \ 6th."
  address: Vancouver, Canada
  author:
  - first: "\xC9ric"
    full: "\xC9ric de La Clergerie"
    id: eric-villemonte-de-la-clergerie
    last: de La Clergerie
  - first: "Beno\xEEt"
    full: "Beno\xEEt Sagot"
    id: benoit-sagot
    last: Sagot
  - first: "Djam\xE9"
    full: "Djam\xE9 Seddah"
    id: djame-seddah
    last: Seddah
  author_string: "\xC9ric de La Clergerie, Beno\xEEt Sagot, Djam\xE9 Seddah"
  bibkey: de-la-clergerie-etal-2017-parisnlp
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3026
  month: August
  page_first: '243'
  page_last: '252'
  pages: "243\u2013252"
  paper_id: '26'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3026.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3026.jpg
  title: 'The ParisNLP entry at the ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy'
  title_html: 'The <span class="acl-fixed-case">P</span>aris<span class="acl-fixed-case">NLP</span>
    entry at the <span class="acl-fixed-case">C</span>on<span class="acl-fixed-case">LL</span>
    <span class="acl-fixed-case">UD</span> Shared Task 2017: A Tale of a #<span class="acl-fixed-case">P</span>arsing<span
    class="acl-fixed-case">T</span>ragedy'
  url: https://www.aclweb.org/anthology/K17-3026
  year: '2017'
K17-3027:
  abstract: "We present the Open University\u2019s submission to the CoNLL 2017 Shared\
    \ Task on multilingual parsing from raw text to Universal Dependencies. The core\
    \ of our system is a joint morphological disambiguator and syntactic parser which\
    \ accepts morphologically analyzed surface tokens as input and returns morphologically\
    \ disambiguated dependency trees as output. Our parser requires a lattice as input,\
    \ so we generate morphological analyses of surface tokens using a data-driven\
    \ morphological analyzer that derives its lexicon from the UD training corpora,\
    \ and we rely on UDPipe for sentence segmentation and surface-level tokenization.\
    \ We report our official macro-average LAS is 56.56. Although our model is not\
    \ as performant as many others, it does not make use of neural networks, therefore\
    \ we do not rely on word embeddings or any other data source other than the corpora\
    \ themselves. In addition, we show the utility of a lexicon-backed morphological\
    \ analyzer for the MRL Modern Hebrew. We use our results on Modern Hebrew to argue\
    \ that the UD community should define a UD-compatible standard for access to lexical\
    \ resources, which we argue is crucial for MRLs and low resource languages in\
    \ particular."
  address: Vancouver, Canada
  author:
  - first: Amir
    full: Amir More
    id: amir-more
    last: More
  - first: Reut
    full: Reut Tsarfaty
    id: reut-tsarfaty
    last: Tsarfaty
  author_string: Amir More, Reut Tsarfaty
  bibkey: more-tsarfaty-2017-universal
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3027
  month: August
  page_first: '253'
  page_last: '264'
  pages: "253\u2013264"
  paper_id: '27'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3027.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3027.jpg
  title: "Universal Joint Morph-Syntactic Processing: The Open University of Israel\u2019\
    s Submission to The CoNLL 2017 Shared Task"
  title_html: "Universal Joint Morph-Syntactic Processing: The Open University of\
    \ <span class=\"acl-fixed-case\">I</span>srael\u2019s Submission to The <span\
    \ class=\"acl-fixed-case\">C</span>o<span class=\"acl-fixed-case\">NLL</span>\
    \ 2017 Shared Task"
  url: https://www.aclweb.org/anthology/K17-3027
  year: '2017'
K17-3028:
  abstract: "This paper presents our system submitted for the CoNLL 2017 Shared Task,\
    \ \u201CMultilingual Parsing from Raw Text to Universal Dependencies.\u201D We\
    \ ran the system for all languages with our own fully pipelined components without\
    \ relying on re-trained baseline systems. To train the dependency parser, we used\
    \ only the universal part-of-speech tags and distance between words, and applied\
    \ deterministic rules to assign dependency labels. The simple and delexicalized\
    \ models are suitable for cross-lingual transfer approaches and a universal language\
    \ model. Experimental results show that our model performed well in some metrics\
    \ and leads discussion on topics such as contribution of each component and on\
    \ syntactic similarities among languages."
  address: Vancouver, Canada
  author:
  - first: Hiroshi
    full: Hiroshi Kanayama
    id: hiroshi-kanayama
    last: Kanayama
  - first: Masayasu
    full: Masayasu Muraoka
    id: masayasu-muraoka
    last: Muraoka
  - first: Katsumasa
    full: Katsumasa Yoshikawa
    id: katsumasa-yoshikawa
    last: Yoshikawa
  author_string: Hiroshi Kanayama, Masayasu Muraoka, Katsumasa Yoshikawa
  bibkey: kanayama-etal-2017-semi
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3028
  month: August
  page_first: '265'
  page_last: '273'
  pages: "265\u2013273"
  paper_id: '28'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3028.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3028.jpg
  title: A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task
  title_html: A Semi-universal Pipelined Approach to the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 <span class="acl-fixed-case">UD</span>
    Shared Task
  url: https://www.aclweb.org/anthology/K17-3028
  year: '2017'
K17-3029:
  abstract: 'This article describes MetaRomance, a rule-based cross-lingual parser
    for Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing
    from Raw Text to Universal Dependencies. The system is an almost delexicalized
    parser which does not need training data to analyze Romance languages. It contains
    linguistically motivated rules based on PoS-tag patterns. The rules included in
    MetaRomance were developed in about 12 hours by one expert with no prior knowledge
    in Universal Dependencies, and can be easily extended using a transparent formalism.
    In this paper we compare the performance of MetaRomance with other supervised
    systems participating in the competition, paying special attention to the parsing
    of different treebanks of the same language. We also compare our system with a
    delexicalized parser for Romance languages, and take advantage of the harmonized
    annotation of Universal Dependencies to propose a language ranking based on the
    syntactic distance each variety has from Romance languages.'
  address: Vancouver, Canada
  author:
  - first: Marcos
    full: Marcos Garcia
    id: marcos-garcia
    last: Garcia
  - first: Pablo
    full: Pablo Gamallo
    id: pablo-gamallo
    last: Gamallo
  author_string: Marcos Garcia, Pablo Gamallo
  bibkey: garcia-gamallo-2017-rule
  bibtype: inproceedings
  booktitle: 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  booktitle_html: 'Proceedings of the <span class="acl-fixed-case">C</span>o<span
    class="acl-fixed-case">NLL</span> 2017 Shared Task: Multilingual Parsing from
    Raw Text to Universal Dependencies'
  doi: 10.18653/v1/K17-3029
  month: August
  page_first: '274'
  page_last: '282'
  pages: "274\u2013282"
  paper_id: '29'
  parent_volume_id: K17-3
  pdf: https://www.aclweb.org/anthology/K17-3029.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/K17-3029.jpg
  title: A rule-based system for cross-lingual parsing of Romance languages with Universal
    Dependencies
  title_html: A rule-based system for cross-lingual parsing of Romance languages with
    Universal Dependencies
  url: https://www.aclweb.org/anthology/K17-3029
  year: '2017'
