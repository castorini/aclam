I17-1000:
  address: Taipei, Taiwan
  author:
  - first: Greg
    full: Greg Kondrak
    id: greg-kondrak
    last: Kondrak
  - first: Taro
    full: Taro Watanabe
    id: taro-watanabe
    last: Watanabe
  author_string: Greg Kondrak, Taro Watanabe
  bibkey: ijcnlp-2017-international
  bibtype: proceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  paper_id: '0'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1000.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1000.jpg
  title: 'Proceedings of the Eighth International Joint Conference on Natural Language
    Processing (Volume 1: Long Papers)'
  title_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  url: https://www.aclweb.org/anthology/I17-1000
  year: '2017'
I17-1001:
  abstract: 'While neural machine translation (NMT) models provide improved translation
    quality in an elegant framework, it is less clear what they learn about language.
    Recent work has started evaluating the quality of vector representations learned
    by NMT models on morphological and syntactic tasks. In this paper, we investigate
    the representations learned at different layers of NMT encoders. We train NMT
    systems on parallel data and use the models to extract features for training a
    classifier on two tasks: part-of-speech and semantic tagging. We then measure
    the performance of the classifier as a proxy to the quality of the original NMT
    model for the given task. Our quantitative analysis yields interesting insights
    regarding representation learning in NMT models. For instance, we find that higher
    layers are better at learning semantics while lower layers tend to be better for
    part-of-speech tagging. We also observe little effect of the target language on
    source-side representations, especially in higher quality models.'
  address: Taipei, Taiwan
  author:
  - first: Yonatan
    full: Yonatan Belinkov
    id: yonatan-belinkov
    last: Belinkov
  - first: "Llu\xEDs"
    full: "Llu\xEDs M\xE0rquez"
    id: lluis-marquez
    last: "M\xE0rquez"
  - first: Hassan
    full: Hassan Sajjad
    id: hassan-sajjad
    last: Sajjad
  - first: Nadir
    full: Nadir Durrani
    id: nadir-durrani
    last: Durrani
  - first: Fahim
    full: Fahim Dalvi
    id: fahim-dalvi
    last: Dalvi
  - first: James
    full: James Glass
    id: james-glass
    last: Glass
  author_string: "Yonatan Belinkov, Llu\xEDs M\xE0rquez, Hassan Sajjad, Nadir Durrani,\
    \ Fahim Dalvi, James Glass"
  bibkey: belinkov-etal-2017-evaluating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '1'
  page_last: '10'
  pages: "1\u201310"
  paper_id: '1'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1001.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1001.jpg
  title: Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech
    and Semantic Tagging Tasks
  title_html: Evaluating Layers of Representation in Neural Machine Translation on
    Part-of-Speech and Semantic Tagging Tasks
  url: https://www.aclweb.org/anthology/I17-1001
  year: '2017'
I17-1002:
  abstract: "In Neural Machine Translation (NMT), each word is represented as a low-dimension,\
    \ real-value vector for encoding its syntax and semantic information. This means\
    \ that even if the word is in a different sentence context, it is represented\
    \ as the fixed vector to learn source representation. Moreover, a large number\
    \ of Out-Of-Vocabulary (OOV) words, which have different syntax and semantic information,\
    \ are represented as the same vector representation of \u201Cunk\u201D. To alleviate\
    \ this problem, we propose a novel context-aware smoothing method to dynamically\
    \ learn a sentence-specific vector for each word (including OOV words) depending\
    \ on its local context words in a sentence. The learned context-aware representation\
    \ is integrated into the NMT to improve the translation performance. Empirical\
    \ results on NIST Chinese-to-English translation task show that the proposed approach\
    \ achieves 1.78 BLEU improvements on average over a strong attentional NMT, and\
    \ outperforms some existing systems."
  address: Taipei, Taiwan
  author:
  - first: Kehai
    full: Kehai Chen
    id: kehai-chen
    last: Chen
  - first: Rui
    full: Rui Wang
    id: rui-wang
    last: Wang
  - first: Masao
    full: Masao Utiyama
    id: masao-utiyama
    last: Utiyama
  - first: Eiichiro
    full: Eiichiro Sumita
    id: eiichiro-sumita
    last: Sumita
  - first: Tiejun
    full: Tiejun Zhao
    id: tiejun-zhao
    last: Zhao
  author_string: Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Tiejun Zhao
  bibkey: chen-etal-2017-context
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '11'
  page_last: '20'
  pages: "11\u201320"
  paper_id: '2'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1002.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1002.jpg
  title: Context-Aware Smoothing for Neural Machine Translation
  title_html: Context-Aware Smoothing for Neural Machine Translation
  url: https://www.aclweb.org/anthology/I17-1002
  year: '2017'
I17-1003:
  abstract: "Sequence to Sequence Neural Machine Translation has achieved significant\
    \ performance in recent years. Yet, there are some existing issues that Neural\
    \ Machine Translation still does not solve completely. Two of them are translation\
    \ for long sentences and the \u201Cover-translation\u201D. To address these two\
    \ problems, we propose an approach that utilize more grammatical information such\
    \ as syntactic dependencies, so that the output can be generated based on more\
    \ abundant information. In our approach, syntactic dependencies is employed in\
    \ decoding. In addition, the output of the model is presented not as a simple\
    \ sequence of tokens but as a linearized tree construction. In order to assess\
    \ the performance, we construct model based on an attention mechanism encoder-decoder\
    \ model in which the source language is input to the encoder as a sequence and\
    \ the decoder generates the target language as a linearized dependency tree structure.\
    \ Experiments on the Europarl-v7 dataset of French-to-English translation demonstrate\
    \ that our proposed method improves BLEU scores by 1.57 and 2.40 on datasets consisting\
    \ of sentences with up to 50 and 80 tokens, respectively. Furthermore, the proposed\
    \ method also solved the two existing problems, ineffective translation for long\
    \ sentences and over-translation in Neural Machine Translation."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1003.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1003.Datasets.zip
  author:
  - first: An
    full: An Nguyen Le
    id: an-nguyen-le
    last: Nguyen Le
  - first: Ander
    full: Ander Martinez
    id: ander-martinez1
    last: Martinez
  - first: Akifumi
    full: Akifumi Yoshimoto
    id: akifumi-yoshimoto
    last: Yoshimoto
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: An Nguyen Le, Ander Martinez, Akifumi Yoshimoto, Yuji Matsumoto
  bibkey: nguyen-le-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '21'
  page_last: '29'
  pages: "21\u201329"
  paper_id: '3'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1003.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1003.jpg
  title: Improving Sequence to Sequence Neural Machine Translation by Utilizing Syntactic
    Dependency Information
  title_html: Improving Sequence to Sequence Neural Machine Translation by Utilizing
    Syntactic Dependency Information
  url: https://www.aclweb.org/anthology/I17-1003
  year: '2017'
I17-1004:
  abstract: Attention in neural machine translation provides the possibility to encode
    relevant parts of the source sentence at each translation step. As a result, attention
    is considered to be an alignment model as well. However, there is no work that
    specifically studies attention and provides analysis of what is being learned
    by attention models. Thus, the question still remains that how attention is similar
    or different from the traditional alignment. In this paper, we provide detailed
    analysis of attention and compare it to traditional alignment. We answer the question
    of whether attention is only capable of modelling translational equivalent or
    it captures more information. We show that attention is different from alignment
    in some cases and is capturing useful information other than alignments.
  address: Taipei, Taiwan
  author:
  - first: Hamidreza
    full: Hamidreza Ghader
    id: hamidreza-ghader
    last: Ghader
  - first: Christof
    full: Christof Monz
    id: christof-monz
    last: Monz
  author_string: Hamidreza Ghader, Christof Monz
  bibkey: ghader-monz-2017-attention
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '30'
  page_last: '39'
  pages: "30\u201339"
  paper_id: '4'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1004.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1004.jpg
  title: What does Attention in Neural Machine Translation Pay Attention to?
  title_html: What does Attention in Neural Machine Translation Pay Attention to?
  url: https://www.aclweb.org/anthology/I17-1004
  year: '2017'
I17-1005:
  abstract: 'In this study, we improve grammatical error detection by learning word
    embeddings that consider grammaticality and error patterns. Most existing algorithms
    for learning word embeddings usually model only the syntactic context of words
    so that classifiers treat erroneous and correct words as similar inputs. We address
    the problem of contextual information by considering learner errors. Specifically,
    we propose two models: one model that employs grammatical error patterns and another
    model that considers grammaticality of the target word. We determine grammaticality
    of n-gram sequence from the annotated error tags and extract grammatical error
    patterns for word embeddings from large-scale learner corpora. Experimental results
    show that a bidirectional long-short term memory model initialized by our word
    embeddings achieved the state-of-the-art accuracy by a large margin in an English
    grammatical error detection task on the First Certificate in English dataset.'
  address: Taipei, Taiwan
  author:
  - first: Masahiro
    full: Masahiro Kaneko
    id: masahiro-kaneko
    last: Kaneko
  - first: Yuya
    full: Yuya Sakaizawa
    id: yuya-sakaizawa
    last: Sakaizawa
  - first: Mamoru
    full: Mamoru Komachi
    id: mamoru-komachi
    last: Komachi
  author_string: Masahiro Kaneko, Yuya Sakaizawa, Mamoru Komachi
  bibkey: kaneko-etal-2017-grammatical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '40'
  page_last: '48'
  pages: "40\u201348"
  paper_id: '5'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1005.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1005.jpg
  title: Grammatical Error Detection Using Error- and Grammaticality-Specific Word
    Embeddings
  title_html: Grammatical Error Detection Using Error- and Grammaticality-Specific
    Word Embeddings
  url: https://www.aclweb.org/anthology/I17-1005
  year: '2017'
I17-1006:
  abstract: This paper describes and compares two straightforward approaches for dependency
    parsing with partial annotations (PA). The first approach is based on a forest-based
    training objective for two CRF parsers, i.e., a biaffine neural network graph-based
    parser (Biaffine) and a traditional log-linear graph-based parser (LLGPar). The
    second approach is based on the idea of constrained decoding for three parsers,
    i.e., a traditional linear graph-based parser (LGPar), a globally normalized neural
    network transition-based parser (GN3Par) and a traditional linear transition-based
    parser (LTPar). For the test phase, constrained decoding is also used for completing
    partial trees. We conduct experiments on Penn Treebank under three different settings
    for simulating PA, i.e., random, most uncertain, and divergent outputs from the
    five parsers. The results show that LLGPar is most effective in directly learning
    from PA, and other parsers can achieve best performance when PAs are completed
    into full trees by LLGPar.
  address: Taipei, Taiwan
  author:
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Zhenghua
    full: Zhenghua Li
    id: zhenghua-li
    last: Li
  - first: Jun
    full: Jun Lang
    id: jun-lang
    last: Lang
  - first: Qingrong
    full: Qingrong Xia
    id: qingrong-xia
    last: Xia
  - first: Min
    full: Min Zhang
    id: min-zhang
    last: Zhang
  author_string: Yue Zhang, Zhenghua Li, Jun Lang, Qingrong Xia, Min Zhang
  bibkey: zhang-etal-2017-dependency-parsing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '49'
  page_last: '58'
  pages: "49\u201358"
  paper_id: '6'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1006.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1006.jpg
  title: 'Dependency Parsing with Partial Annotations: An Empirical Comparison'
  title_html: 'Dependency Parsing with Partial Annotations: An Empirical Comparison'
  url: https://www.aclweb.org/anthology/I17-1006
  year: '2017'
I17-1007:
  abstract: "In this paper, we propose a probabilistic parsing model that defines\
    \ a proper conditional probability distribution over non-projective dependency\
    \ trees for a given sentence, using neural representations as inputs. The neural\
    \ network architecture is based on bi-directional LSTMCNNs, which automatically\
    \ benefits from both word- and character-level representations, by using a combination\
    \ of bidirectional LSTMs and CNNs. On top of the neural network, we introduce\
    \ a probabilistic structured layer, defining a conditional log-linear model over\
    \ non-projective trees. By exploiting Kirchhoff\u2019s Matrix-Tree Theorem (Tutte,\
    \ 1984), the partition functions and marginals can be computed efficiently, leading\
    \ to a straightforward end-to-end model training procedure via back-propagation.\
    \ We evaluate our model on 17 different datasets, across 14 different languages.\
    \ Our parser achieves state-of-the-art parsing performance on nine datasets."
  address: Taipei, Taiwan
  author:
  - first: Xuezhe
    full: Xuezhe Ma
    id: xuezhe-ma
    last: Ma
  - first: Eduard
    full: Eduard Hovy
    id: eduard-hovy
    last: Hovy
  author_string: Xuezhe Ma, Eduard Hovy
  bibkey: ma-hovy-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '59'
  page_last: '69'
  pages: "59\u201369"
  paper_id: '7'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1007.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1007.jpg
  title: Neural Probabilistic Model for Non-projective MST Parsing
  title_html: Neural Probabilistic Model for Non-projective <span class="acl-fixed-case">MST</span>
    Parsing
  url: https://www.aclweb.org/anthology/I17-1007
  year: '2017'
I17-1008:
  abstract: The research question we explore in this study is how to obtain syntactically
    plausible word representations without using human annotations. Our underlying
    hypothesis is that word ordering tests, or linearizations, is suitable for learning
    syntactic knowledge about words. To verify this hypothesis, we develop a differentiable
    model called Word Ordering Network (WON) that explicitly learns to recover correct
    word order while implicitly acquiring word embeddings representing syntactic knowledge.
    We evaluate the word embeddings produced by the proposed method on downstream
    syntax-related tasks such as part-of-speech tagging and dependency parsing. The
    experimental results demonstrate that the WON consistently outperforms both order-insensitive
    and order-sensitive baselines on these tasks.
  address: Taipei, Taiwan
  author:
  - first: Noriki
    full: Noriki Nishida
    id: noriki-nishida
    last: Nishida
  - first: Hideki
    full: Hideki Nakayama
    id: hideki-nakayama
    last: Nakayama
  author_string: Noriki Nishida, Hideki Nakayama
  bibkey: nishida-nakayama-2017-word
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '70'
  page_last: '79'
  pages: "70\u201379"
  paper_id: '8'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1008.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1008.jpg
  title: Word Ordering as Unsupervised Learning Towards Syntactically Plausible Word
    Representations
  title_html: Word Ordering as Unsupervised Learning Towards Syntactically Plausible
    Word Representations
  url: https://www.aclweb.org/anthology/I17-1008
  year: '2017'
I17-1009:
  abstract: "We present a pointwise mutual information (PMI)-based approach to formalize\
    \ paraphrasability and propose a variant of PMI, called MIPA, for the paraphrase\
    \ acquisition. Our paraphrase acquisition method first acquires lexical paraphrase\
    \ pairs by bilingual pivoting and then reranks them by PMI and distributional\
    \ similarity. The complementary nature of information from bilingual corpora and\
    \ from monolingual corpora makes the proposed method robust. Experimental results\
    \ show that the proposed method substantially outperforms bilingual pivoting and\
    \ distributional similarity themselves in terms of metrics such as MRR, MAP, coverage,\
    \ and Spearman\u2019s correlation."
  address: Taipei, Taiwan
  author:
  - first: Tomoyuki
    full: Tomoyuki Kajiwara
    id: tomoyuki-kajiwara
    last: Kajiwara
  - first: Mamoru
    full: Mamoru Komachi
    id: mamoru-komachi
    last: Komachi
  - first: Daichi
    full: Daichi Mochihashi
    id: daichi-mochihashi
    last: Mochihashi
  author_string: Tomoyuki Kajiwara, Mamoru Komachi, Daichi Mochihashi
  bibkey: kajiwara-etal-2017-mipa
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '80'
  page_last: '89'
  pages: "80\u201389"
  paper_id: '9'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1009.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1009.jpg
  title: 'MIPA: Mutual Information Based Paraphrase Acquisition via Bilingual Pivoting'
  title_html: '<span class="acl-fixed-case">MIPA</span>: Mutual Information Based
    Paraphrase Acquisition via Bilingual Pivoting'
  url: https://www.aclweb.org/anthology/I17-1009
  year: '2017'
I17-1010:
  abstract: Implicit semantic role labeling (iSRL) is the task of predicting the semantic
    roles of a predicate that do not appear as explicit arguments, but rather regard
    common sense knowledge or are mentioned earlier in the discourse. We introduce
    an approach to iSRL based on a predictive recurrent neural semantic frame model
    (PRNSFM) that uses a large unannotated corpus to learn the probability of a sequence
    of semantic arguments given a predicate. We leverage the sequence probabilities
    predicted by the PRNSFM to estimate selectional preferences for predicates and
    their arguments. On the NomBank iSRL test set, our approach improves state-of-the-art
    performance on implicit semantic role labeling with less reliance than prior work
    on manually constructed language resources.
  address: Taipei, Taiwan
  author:
  - first: Quynh Ngoc Thi
    full: Quynh Ngoc Thi Do
    id: quynh-ngoc-thi-do
    last: Do
  - first: Steven
    full: Steven Bethard
    id: steven-bethard
    last: Bethard
  - first: Marie-Francine
    full: Marie-Francine Moens
    id: marie-francine-moens
    last: Moens
  author_string: Quynh Ngoc Thi Do, Steven Bethard, Marie-Francine Moens
  bibkey: do-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '90'
  page_last: '99'
  pages: "90\u201399"
  paper_id: '10'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1010.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1010.jpg
  title: Improving Implicit Semantic Role Labeling by Predicting Semantic Frame Arguments
  title_html: Improving Implicit Semantic Role Labeling by Predicting Semantic Frame
    Arguments
  url: https://www.aclweb.org/anthology/I17-1010
  year: '2017'
I17-1011:
  abstract: We define a novel textual entailment task that requires inference over
    multiple premise sentences. We present a new dataset for this task that minimizes
    trivial lexical inferences, emphasizes knowledge of everyday events, and presents
    a more challenging setting for textual entailment. We evaluate several strong
    neural baselines and analyze how the multiple premise task differs from standard
    textual entailment.
  address: Taipei, Taiwan
  author:
  - first: Alice
    full: Alice Lai
    id: alice-lai
    last: Lai
  - first: Yonatan
    full: Yonatan Bisk
    id: yonatan-bisk
    last: Bisk
  - first: Julia
    full: Julia Hockenmaier
    id: julia-hockenmaier
    last: Hockenmaier
  author_string: Alice Lai, Yonatan Bisk, Julia Hockenmaier
  bibkey: lai-etal-2017-natural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '100'
  page_last: '109'
  pages: "100\u2013109"
  paper_id: '11'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1011.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1011.jpg
  title: Natural Language Inference from Multiple Premises
  title_html: Natural Language Inference from Multiple Premises
  url: https://www.aclweb.org/anthology/I17-1011
  year: '2017'
I17-1012:
  abstract: To learn more knowledge, enabling transitivity is a vital step for lexical
    inference. However, most of the lexical inference models with good performance
    are for nouns or noun phrases, which cannot be directly applied to the inference
    on events or states. In this paper, we construct the largest Chinese verb lexical
    inference dataset containing 18,029 verb pairs, where for each pair one of four
    inference relations are annotated. We further build a probabilistic soft logic
    (PSL) model to infer verb lexicons using the logic language. With PSL, we easily
    enable transitivity in two layers, the observed layer and the feature layer, which
    are included in the knowledge base. We further discuss the effect of transitives
    within and between these layers. Results show the performance of the proposed
    PSL model can be improved at least 3.5% (relative) when the transitivity is enabled.
    Furthermore, experiments show that enabling transitivity in the observed layer
    benefits the most.
  address: Taipei, Taiwan
  author:
  - first: Wei-Chung
    full: Wei-Chung Wang
    id: wei-chung-wang
    last: Wang
  - first: Lun-Wei
    full: Lun-Wei Ku
    id: lun-wei-ku
    last: Ku
  author_string: Wei-Chung Wang, Lun-Wei Ku
  bibkey: wang-ku-2017-enabling
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '110'
  page_last: '119'
  pages: "110\u2013119"
  paper_id: '12'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1012.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1012.jpg
  title: Enabling Transitivity for Lexical Inference on Chinese Verbs Using Probabilistic
    Soft Logic
  title_html: Enabling Transitivity for Lexical Inference on <span class="acl-fixed-case">C</span>hinese
    Verbs Using Probabilistic Soft Logic
  url: https://www.aclweb.org/anthology/I17-1012
  year: '2017'
I17-1013:
  abstract: "In this work, we explore multiple neural architectures adapted for the\
    \ task of automatic post-editing of machine translation output. We focus on neural\
    \ end-to-end models that combine both inputs mt (raw MT output) and (raw MT output)\
    \ and src (source language input) in a single neural architecture, modeling (source\
    \ language input) in a single neural architecture, modeling {mt, src} \u2192 pe\
    \ directly. Apart from that, we investigate the influence of hard-attention models\
    \ which seem to be well-suited for monolingual tasks, as well as combinations\
    \ of both ideas. We report results on data sets provided during the WMT-2016 shared\
    \ task on automatic post-editing and can demonstrate that dual-attention models\
    \ that incorporate all available data in the APE scenario in a single model improve\
    \ on the best shared task system and on all other published results after the\
    \ shared task. Dual-attention models that are combined with hard attention remain\
    \ competitive despite applying fewer changes to the input. directly. Apart from\
    \ that, we investigate the influence of hard-attention models which seem to be\
    \ well-suited for monolingual tasks, as well as combinations of both ideas. We\
    \ report results on data sets provided during the WMT-2016 shared task on automatic\
    \ post-editing and can demonstrate that dual-attention models that incorporate\
    \ all available data in the APE scenario in a single model improve on the best\
    \ shared task system and on all other published results after the shared task.\
    \ Dual-attention models that are combined with hard attention remain competitive\
    \ despite applying fewer changes to the input."
  address: Taipei, Taiwan
  author:
  - first: Marcin
    full: Marcin Junczys-Dowmunt
    id: marcin-junczys-dowmunt
    last: Junczys-Dowmunt
  - first: Roman
    full: Roman Grundkiewicz
    id: roman-grundkiewicz
    last: Grundkiewicz
  author_string: Marcin Junczys-Dowmunt, Roman Grundkiewicz
  bibkey: junczys-dowmunt-grundkiewicz-2017-exploration
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '120'
  page_last: '129'
  pages: "120\u2013129"
  paper_id: '13'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1013.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1013.jpg
  title: An Exploration of Neural Sequence-to-Sequence Architectures for Automatic
    Post-Editing
  title_html: An Exploration of Neural Sequence-to-Sequence Architectures for Automatic
    Post-Editing
  url: https://www.aclweb.org/anthology/I17-1013
  year: '2017'
I17-1014:
  abstract: 'We decompose multimodal translation into two sub-tasks: learning to translate
    and learning visually grounded representations. In a multitask learning framework,
    translations are learned in an attention-based encoder-decoder, and grounded representations
    are learned through image representation prediction. Our approach improves translation
    performance compared to the state of the art on the Multi30K dataset. Furthermore,
    it is equally effective if we train the image prediction task on the external
    MS COCO dataset, and we find improvements if we train the translation model on
    the external News Commentary parallel text.'
  address: Taipei, Taiwan
  author:
  - first: Desmond
    full: Desmond Elliott
    id: desmond-elliott
    last: Elliott
  - first: "\xC1kos"
    full: "\xC1kos K\xE1d\xE1r"
    id: akos-kadar
    last: "K\xE1d\xE1r"
  author_string: "Desmond Elliott, \xC1kos K\xE1d\xE1r"
  bibkey: elliott-kadar-2017-imagination
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '130'
  page_last: '141'
  pages: "130\u2013141"
  paper_id: '14'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1014.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1014.jpg
  title: Imagination Improves Multimodal Translation
  title_html: Imagination Improves Multimodal Translation
  url: https://www.aclweb.org/anthology/I17-1014
  year: '2017'
I17-1015:
  abstract: "End-to-end training makes the neural machine translation (NMT) architecture\
    \ simpler, yet elegant compared to traditional statistical machine translation\
    \ (SMT). However, little is known about linguistic patterns of morphology, syntax\
    \ and semantics learned during the training of NMT systems, and more importantly,\
    \ which parts of the architecture are responsible for learning each of these phenomenon.\
    \ In this paper we i) analyze how much morphology an NMT decoder learns, and ii)\
    \ investigate whether injecting target morphology in the decoder helps it to produce\
    \ better translations. To this end we present three methods: i) simultaneous translation,\
    \ ii) joint-data learning, and iii) multi-task learning. Our results show that\
    \ explicit morphological information helps the decoder learn target language morphology\
    \ and improves the translation quality by 0.2\u20130.6 BLEU points."
  address: Taipei, Taiwan
  author:
  - first: Fahim
    full: Fahim Dalvi
    id: fahim-dalvi
    last: Dalvi
  - first: Nadir
    full: Nadir Durrani
    id: nadir-durrani
    last: Durrani
  - first: Hassan
    full: Hassan Sajjad
    id: hassan-sajjad
    last: Sajjad
  - first: Yonatan
    full: Yonatan Belinkov
    id: yonatan-belinkov
    last: Belinkov
  - first: Stephan
    full: Stephan Vogel
    id: stephan-vogel
    last: Vogel
  author_string: Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, Stephan
    Vogel
  bibkey: dalvi-etal-2017-understanding
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '142'
  page_last: '151'
  pages: "142\u2013151"
  paper_id: '15'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1015.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1015.jpg
  title: Understanding and Improving Morphological Learning in the Neural Machine
    Translation Decoder
  title_html: Understanding and Improving Morphological Learning in the Neural Machine
    Translation Decoder
  url: https://www.aclweb.org/anthology/I17-1015
  year: '2017'
I17-1016:
  abstract: Compared to traditional statistical machine translation (SMT), neural
    machine translation (NMT) often sacrifices adequacy for the sake of fluency. We
    propose a method to combine the advantages of traditional SMT and NMT by exploiting
    an existing phrase-based SMT model to compute the phrase-based decoding cost for
    an NMT output and then using the phrase-based decoding cost to rerank the n-best
    NMT outputs. The main challenge in implementing this approach is that NMT outputs
    may not be in the search space of the standard phrase-based decoding algorithm,
    because the search space of phrase-based SMT is limited by the phrase-based translation
    rule table. We propose a soft forced decoding algorithm, which can always successfully
    find a decoding path for any NMT output. We show that using the forced decoding
    cost to rerank the NMT outputs can successfully improve translation quality on
    four different language pairs.
  address: Taipei, Taiwan
  author:
  - first: Jingyi
    full: Jingyi Zhang
    id: jingyi-zhang
    last: Zhang
  - first: Masao
    full: Masao Utiyama
    id: masao-utiyama
    last: Utiyama
  - first: Eiichro
    full: Eiichro Sumita
    id: eiichiro-sumita
    last: Sumita
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  - first: Satoshi
    full: Satoshi Nakamura
    id: satoshi-nakamura
    last: Nakamura
  author_string: Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Graham Neubig, Satoshi
    Nakamura
  bibkey: zhang-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '152'
  page_last: '162'
  pages: "152\u2013162"
  paper_id: '16'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1016.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1016.jpg
  title: Improving Neural Machine Translation through Phrase-based Forced Decoding
  title_html: Improving Neural Machine Translation through Phrase-based Forced Decoding
  url: https://www.aclweb.org/anthology/I17-1016
  year: '2017'
I17-1017:
  abstract: "Character-based sequence labeling framework is flexible and efficient\
    \ for Chinese word segmentation (CWS). Recently, many character-based neural models\
    \ have been applied to CWS. While they obtain good performance, they have two\
    \ obvious weaknesses. The first is that they heavily rely on manually designed\
    \ bigram feature, i.e. they are not good at capturing n-gram features automatically.\
    \ The second is that they make no use of full word information. For the first\
    \ weakness, we propose a convolutional neural model, which is able to capture\
    \ rich -gram features automatically. The second is that they make no use of full\
    \ word information. For the first weakness, we propose a convolutional neural\
    \ model, which is able to capture rich n-gram features without any feature engineering.\
    \ For the second one, we propose an effective approach to integrate the proposed\
    \ model with word embeddings. We evaluate the model on two benchmark datasets:\
    \ PKU and MSR. Without any feature engineering, the model obtains competitive\
    \ performance \u2014 95.7% on PKU and 97.3% on MSR. Armed with word embeddings,\
    \ the model achieves state-of-the-art performance on both datasets \u2014 96.5%\
    \ on PKU and 98.0% on MSR, without using any external labeled resource.-gram features\
    \ without any feature engineering. For the second one, we propose an effective\
    \ approach to integrate the proposed model with word embeddings. We evaluate the\
    \ model on two benchmark datasets: PKU and MSR. Without any feature engineering,\
    \ the model obtains competitive performance \u2014 95.7% on PKU and 97.3% on MSR.\
    \ Armed with word embeddings, the model achieves state-of-the-art performance\
    \ on both datasets \u2014 96.5% on PKU and 98.0% on MSR, without using any external\
    \ labeled resource."
  address: Taipei, Taiwan
  author:
  - first: Chunqi
    full: Chunqi Wang
    id: chunqi-wang
    last: Wang
  - first: Bo
    full: Bo Xu
    id: bo-xu
    last: Xu
  author_string: Chunqi Wang, Bo Xu
  bibkey: wang-xu-2017-convolutional
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '163'
  page_last: '172'
  pages: "163\u2013172"
  paper_id: '17'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1017.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1017.jpg
  title: Convolutional Neural Network with Word Embeddings for Chinese Word Segmentation
  title_html: Convolutional Neural Network with Word Embeddings for <span class="acl-fixed-case">C</span>hinese
    Word Segmentation
  url: https://www.aclweb.org/anthology/I17-1017
  year: '2017'
I17-1018:
  abstract: We present a character-based model for joint segmentation and POS tagging
    for Chinese. The bidirectional RNN-CRF architecture for general sequence tagging
    is adapted and applied with novel vector representations of Chinese characters
    that capture rich contextual information and lower-than-character level features.
    The proposed model is extensively evaluated and compared with a state-of-the-art
    tagger respectively on CTB5, CTB9 and UD Chinese. The experimental results indicate
    that our model is accurate and robust across datasets in different sizes, genres
    and annotation schemes. We obtain state-of-the-art performance on CTB5, achieving
    94.38 F1-score for joint segmentation and POS tagging.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1018.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/I17-1018.Software.zip
  author:
  - first: Yan
    full: Yan Shao
    id: yan-shao
    last: Shao
  - first: Christian
    full: Christian Hardmeier
    id: christian-hardmeier
    last: Hardmeier
  - first: "J\xF6rg"
    full: "J\xF6rg Tiedemann"
    id: jorg-tiedemann
    last: Tiedemann
  - first: Joakim
    full: Joakim Nivre
    id: joakim-nivre
    last: Nivre
  author_string: "Yan Shao, Christian Hardmeier, J\xF6rg Tiedemann, Joakim Nivre"
  bibkey: shao-etal-2017-character
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '173'
  page_last: '183'
  pages: "173\u2013183"
  paper_id: '18'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1018.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1018.jpg
  title: Character-based Joint Segmentation and POS Tagging for Chinese using Bidirectional
    RNN-CRF
  title_html: Character-based Joint Segmentation and <span class="acl-fixed-case">POS</span>
    Tagging for <span class="acl-fixed-case">C</span>hinese using Bidirectional <span
    class="acl-fixed-case">RNN</span>-<span class="acl-fixed-case">CRF</span>
  url: https://www.aclweb.org/anthology/I17-1018
  year: '2017'
I17-1019:
  abstract: Boundary features are widely used in traditional Chinese Word Segmentation
    (CWS) methods as they can utilize unlabeled data to help improve the Out-of-Vocabulary
    (OOV) word recognition performance. Although various neural network methods for
    CWS have achieved performance competitive with state-of-the-art systems, these
    methods, constrained by the domain and size of the training corpus, do not work
    well in domain adaptation. In this paper, we propose a novel BLSTM-based neural
    network model which incorporates a global recurrent structure designed for modeling
    boundary features dynamically. Experiments show that the proposed structure can
    effectively boost the performance of Chinese Word Segmentation, especially OOV-Recall,
    which brings benefits to domain adaptation. We achieved state-of-the-art results
    on 6 domains of CNKI articles, and competitive results to the best reported on
    the 4 domains of SIGHAN Bakeoff 2010 data.
  address: Taipei, Taiwan
  author:
  - first: Shen
    full: Shen Huang
    id: shen-huang
    last: Huang
  - first: Xu
    full: Xu Sun
    id: xu-sun
    last: Sun
  - first: Houfeng
    full: Houfeng Wang
    id: houfeng-wang
    last: Wang
  author_string: Shen Huang, Xu Sun, Houfeng Wang
  bibkey: huang-etal-2017-addressing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '184'
  page_last: '193'
  pages: "184\u2013193"
  paper_id: '19'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1019.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1019.jpg
  title: Addressing Domain Adaptation for Chinese Word Segmentation with Global Recurrent
    Structure
  title_html: Addressing Domain Adaptation for <span class="acl-fixed-case">C</span>hinese
    Word Segmentation with Global Recurrent Structure
  url: https://www.aclweb.org/anthology/I17-1019
  year: '2017'
I17-1020:
  abstract: We present a novel technique for segmenting chat conversations using the
    information bottleneck method (Tishby et al., 2000), augmented with sequential
    continuity constraints. Furthermore, we utilize critical non-textual clues such
    as time between two consecutive posts and people mentions within the posts. To
    ascertain the effectiveness of the proposed method, we have collected data from
    public Slack conversations and Fresco, a proprietary platform deployed inside
    our organization. Experiments demonstrate that the proposed method yields an absolute
    (relative) improvement of as high as 3.23% (11.25%). To facilitate future research,
    we are releasing manual annotations for segmentation on public Slack conversations.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1020.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1020.Datasets.zip
  author:
  - first: S
    full: S Vishal
    id: s-vishal
    last: Vishal
  - first: Mohit
    full: Mohit Yadav
    id: mohit-yadav
    last: Yadav
  - first: Lovekesh
    full: Lovekesh Vig
    id: lovekesh-vig
    last: Vig
  - first: Gautam
    full: Gautam Shroff
    id: gautam-shroff
    last: Shroff
  author_string: S Vishal, Mohit Yadav, Lovekesh Vig, Gautam Shroff
  bibkey: vishal-etal-2017-information
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '194'
  page_last: '203'
  pages: "194\u2013203"
  paper_id: '20'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1020.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1020.jpg
  title: Information Bottleneck Inspired Method For Chat Text Segmentation
  title_html: Information Bottleneck Inspired Method For Chat Text Segmentation
  url: https://www.aclweb.org/anthology/I17-1020
  year: '2017'
I17-1021:
  abstract: We test whether distributional models can do one-shot learning of definitional
    properties from text only. Using Bayesian models, we find that first learning
    overarching structure in the known data, regularities in textual contexts and
    in properties, helps one-shot learning, and that individual context items can
    be highly informative.
  address: Taipei, Taiwan
  author:
  - first: Su
    full: Su Wang
    id: su-wang
    last: Wang
  - first: Stephen
    full: Stephen Roller
    id: stephen-roller
    last: Roller
  - first: Katrin
    full: Katrin Erk
    id: katrin-erk
    last: Erk
  author_string: Su Wang, Stephen Roller, Katrin Erk
  bibkey: wang-etal-2017-distributional
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '204'
  page_last: '213'
  pages: "204\u2013213"
  paper_id: '21'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1021.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1021.jpg
  title: 'Distributional Modeling on a Diet: One-shot Word Learning from Text Only'
  title_html: 'Distributional Modeling on a Diet: One-shot Word Learning from Text
    Only'
  url: https://www.aclweb.org/anthology/I17-1021
  year: '2017'
I17-1022:
  abstract: A distributed representation has become a popular approach to capturing
    a word meaning. Besides its success and practical value, however, questions arise
    about the relationships between a true word meaning and its distributed representation.
    In this paper, we examine such a relationship via polymodal embedding approach
    inspired by the theory that humans tend to use diverse sources in developing a
    word meaning. The result suggests that the existing embeddings lack in capturing
    certain aspects of word meanings which can be significantly improved by the polymodal
    approach. Also, we show distinct characteristics of different types of words (e.g.
    concreteness) via computational studies. Finally, we show our proposed embedding
    method outperforms the baselines in the word similarity measure tasks and the
    hypernym prediction tasks.
  address: Taipei, Taiwan
  author:
  - first: Joohee
    full: Joohee Park
    id: joohee-park
    last: Park
  - first: Sung-hyon
    full: Sung-hyon Myaeng
    id: sung-hyon-myaeng
    last: Myaeng
  author_string: Joohee Park, Sung-hyon Myaeng
  bibkey: park-myaeng-2017-computational
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '214'
  page_last: '223'
  pages: "214\u2013223"
  paper_id: '22'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1022.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1022.jpg
  title: A Computational Study on Word Meanings and Their Distributed Representations
    via Polymodal Embedding
  title_html: A Computational Study on Word Meanings and Their Distributed Representations
    via Polymodal Embedding
  url: https://www.aclweb.org/anthology/I17-1022
  year: '2017'
I17-1023:
  abstract: Word embeddings are commonly compared either with human-annotated word
    similarities or through improvements in natural language processing tasks. We
    propose a novel principle which compares the information from word embeddings
    with reality. We implement this principle by comparing the information in the
    word embeddings with geographical positions of cities. Our evaluation linearly
    transforms the semantic space to optimally fit the real positions of cities and
    measures the deviation between the position given by word embeddings and the real
    position. A set of well-known word embeddings with state-of-the-art results were
    evaluated. We also introduce a visualization that helps with error analysis.
  address: Taipei, Taiwan
  author:
  - first: Michal
    full: Michal Konkol
    id: michal-konkol
    last: Konkol
  - first: "Tom\xE1\u0161"
    full: "Tom\xE1\u0161 Brychc\xEDn"
    id: tomas-brychcin
    last: "Brychc\xEDn"
  - first: Michal
    full: Michal Nykl
    id: michal-nykl
    last: Nykl
  - first: "Tom\xE1\u0161"
    full: "Tom\xE1\u0161 Hercig"
    id: tomas-hercig
    last: Hercig
  author_string: "Michal Konkol, Tom\xE1\u0161 Brychc\xEDn, Michal Nykl, Tom\xE1\u0161\
    \ Hercig"
  bibkey: konkol-etal-2017-geographical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '224'
  page_last: '232'
  pages: "224\u2013232"
  paper_id: '23'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1023.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1023.jpg
  title: Geographical Evaluation of Word Embeddings
  title_html: Geographical Evaluation of Word Embeddings
  url: https://www.aclweb.org/anthology/I17-1023
  year: '2017'
I17-1024:
  abstract: To enhance the expression ability of distributional word representation
    learning model, many researchers tend to induce word senses through clustering,
    and learn multiple embedding vectors for each word, namely multi-prototype word
    embedding model. However, most related work ignores the relatedness among word
    senses which actually plays an important role. In this paper, we propose a novel
    approach to capture word sense relatedness in multi-prototype word embedding model.
    Particularly, we differentiate the original sense and extended senses of a word
    by introducing their global occurrence information and model their relatedness
    through the local textual context information. Based on the idea of fuzzy clustering,
    we introduce a random process to integrate these two types of senses and design
    two non-parametric methods for word sense induction. To make our model more scalable
    and efficient, we use an online joint learning framework extended from the Skip-gram
    model. The experimental results demonstrate that our model outperforms both conventional
    single-prototype embedding models and other multi-prototype embedding models,
    and achieves more stable performance when trained on smaller data.
  address: Taipei, Taiwan
  author:
  - first: Yixin
    full: Yixin Cao
    id: yixin-cao
    last: Cao
  - first: Jiaxin
    full: Jiaxin Shi
    id: jiaxin-shi
    last: Shi
  - first: Juanzi
    full: Juanzi Li
    id: juanzi-li
    last: Li
  - first: Zhiyuan
    full: Zhiyuan Liu
    id: zhiyuan-liu
    last: Liu
  - first: Chengjiang
    full: Chengjiang Li
    id: chengjiang-li
    last: Li
  author_string: Yixin Cao, Jiaxin Shi, Juanzi Li, Zhiyuan Liu, Chengjiang Li
  bibkey: cao-etal-2017-modeling
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '233'
  page_last: '242'
  pages: "233\u2013242"
  paper_id: '24'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1024.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1024.jpg
  title: On Modeling Sense Relatedness in Multi-prototype Word Embedding
  title_html: On Modeling Sense Relatedness in Multi-prototype Word Embedding
  url: https://www.aclweb.org/anthology/I17-1024
  year: '2017'
I17-1025:
  abstract: Unsupervised segmentation of phoneme sequences is an essential process
    to obtain unknown words during spoken dialogues. In this segmentation, an input
    phoneme sequence without delimiters is converted into segmented sub-sequences
    corresponding to words. The Pitman-Yor semi-Markov model (PYSMM) is promising
    for this problem, but its performance degrades when it is applied to phoneme-level
    word segmentation. This is because of insufficient cues for the segmentation,
    e.g., homophones are improperly treated as single entries and their different
    contexts are also confused. We propose a phoneme-length context model for PYSMM
    to give a helpful cue at the phoneme-level and to predict succeeding segments
    more accurately. Our experiments showed that the peak performance with our context
    model outperformed those without such a context model by 0.045 at most in terms
    of F-measures of estimated segmentation.
  address: Taipei, Taiwan
  author:
  - first: Ryu
    full: Ryu Takeda
    id: ryu-takeda
    last: Takeda
  - first: Kazunori
    full: Kazunori Komatani
    id: kazunori-komatani
    last: Komatani
  author_string: Ryu Takeda, Kazunori Komatani
  bibkey: takeda-komatani-2017-unsupervised
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '243'
  page_last: '252'
  pages: "243\u2013252"
  paper_id: '25'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1025.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1025.jpg
  title: Unsupervised Segmentation of Phoneme Sequences based on Pitman-Yor Semi-Markov
    Model using Phoneme Length Context
  title_html: Unsupervised Segmentation of Phoneme Sequences based on Pitman-Yor Semi-<span
    class="acl-fixed-case">M</span>arkov Model using Phoneme Length Context
  url: https://www.aclweb.org/anthology/I17-1025
  year: '2017'
I17-1026:
  abstract: Convolutional Neural Networks (CNNs) have recently achieved remarkably
    strong performance on the practically important task of sentence classification
    (Kim, 2014; Kalchbrenner et al., 2014; Johnson and Zhang, 2014; Zhang et al.,
    2016). However, these models require practitioners to specify an exact model architecture
    and set accompanying hyperparameters, including the filter region size, regularization
    parameters, and so on. It is currently unknown how sensitive model performance
    is to changes in these configurations for the task of sentence classification.
    We thus conduct a sensitivity analysis of one-layer CNNs to explore the effect
    of architecture components on model performance; our aim is to distinguish between
    important and comparatively inconsequential design decisions for sentence classification.
    We focus on one-layer CNNs (to the exclusion of more complex models) due to their
    comparative simplicity and strong empirical performance, which makes it a modern
    standard baseline method akin to Support Vector Machine (SVMs) and logistic regression.
    We derive practical advice from our extensive empirical results for those interested
    in getting the most out of CNNs for sentence classification in real world settings.
  address: Taipei, Taiwan
  author:
  - first: Ye
    full: Ye Zhang
    id: ye-zhang
    last: Zhang
  - first: Byron
    full: Byron Wallace
    id: byron-c-wallace
    last: Wallace
  author_string: Ye Zhang, Byron Wallace
  bibkey: zhang-wallace-2017-sensitivity
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '253'
  page_last: '263'
  pages: "253\u2013263"
  paper_id: '26'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1026.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1026.jpg
  title: "A Sensitivity Analysis of (and Practitioners\u2019 Guide to) Convolutional\
    \ Neural Networks for Sentence Classification"
  title_html: "A Sensitivity Analysis of (and Practitioners\u2019 Guide to) Convolutional\
    \ Neural Networks for Sentence Classification"
  url: https://www.aclweb.org/anthology/I17-1026
  year: '2017'
I17-1027:
  abstract: We propose a neural network model for coordination boundary detection.
    Our method relies on the two common properties - similarity and replaceability
    in conjuncts - in order to detect both similar pairs of conjuncts and dissimilar
    pairs of conjuncts. The model improves identification of clause-level coordination
    using bidirectional RNNs incorporating two properties as features. We show that
    our model outperforms the existing state-of-the-art methods on the coordination
    annotated Penn Treebank and Genia corpus without any syntactic information from
    parsers.
  address: Taipei, Taiwan
  author:
  - first: Hiroki
    full: Hiroki Teranishi
    id: hiroki-teranishi
    last: Teranishi
  - first: Hiroyuki
    full: Hiroyuki Shindo
    id: hiroyuki-shindo
    last: Shindo
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Hiroki Teranishi, Hiroyuki Shindo, Yuji Matsumoto
  bibkey: teranishi-etal-2017-coordination
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '264'
  page_last: '272'
  pages: "264\u2013272"
  paper_id: '27'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1027.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1027.jpg
  title: Coordination Boundary Identification with Similarity and Replaceability
  title_html: Coordination Boundary Identification with Similarity and Replaceability
  url: https://www.aclweb.org/anthology/I17-1027
  year: '2017'
I17-1028:
  abstract: 'In this article, we propose to investigate a new problem consisting in
    turning a distributional thesaurus into dense word vectors. We propose more precisely
    a method for performing such task by associating graph embedding and distributed
    representation adaptation. We have applied and evaluated it for English nouns
    at a large scale about its ability to retrieve synonyms. In this context, we have
    also illustrated the interest of the developed method for three different tasks:
    the improvement of already existing word embeddings, the fusion of heterogeneous
    representations and the expansion of synsets.'
  address: Taipei, Taiwan
  author:
  - first: Olivier
    full: Olivier Ferret
    id: olivier-ferret
    last: Ferret
  author_string: Olivier Ferret
  bibkey: ferret-2017-turning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '273'
  page_last: '283'
  pages: "273\u2013283"
  paper_id: '28'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1028.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1028.jpg
  title: Turning Distributional Thesauri into Word Vectors for Synonym Extraction
    and Expansion
  title_html: Turning Distributional Thesauri into Word Vectors for Synonym Extraction
    and Expansion
  url: https://www.aclweb.org/anthology/I17-1028
  year: '2017'
I17-1029:
  abstract: "We propose to improve word sense embeddings by enriching an automatic\
    \ corpus-based method with lexicographic data. Information from a lexicon is introduced\
    \ into the learning algorithm\u2019s objective function through a regularizer.\
    \ The incorporation of lexicographic data yields embeddings that are able to reflect\
    \ expert-defined word senses, while retaining the robustness, high quality, and\
    \ coverage of automatic corpus-based methods. These properties are observed in\
    \ a manual inspection of the semantic clusters that different degrees of regularizer\
    \ strength create in the vector space. Moreover, we evaluate the sense embeddings\
    \ in two downstream applications: word sense disambiguation and semantic frame\
    \ prediction, where they outperform simpler approaches. Our results show that\
    \ a corpus-based model balanced with lexicographic data learns better representations\
    \ and improve their performance in downstream tasks."
  address: Taipei, Taiwan
  author:
  - first: Luis
    full: "Luis Nieto-Pi\xF1a"
    id: luis-nieto-pina1
    last: "Nieto-Pi\xF1a"
  - first: Richard
    full: Richard Johansson
    id: richard-johansson
    last: Johansson
  author_string: "Luis Nieto-Pi\xF1a, Richard Johansson"
  bibkey: nieto-pina-johansson-2017-training
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '284'
  page_last: '294'
  pages: "284\u2013294"
  paper_id: '29'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1029.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1029.jpg
  title: Training Word Sense Embeddings With Lexicon-based Regularization
  title_html: Training Word Sense Embeddings With Lexicon-based Regularization
  url: https://www.aclweb.org/anthology/I17-1029
  year: '2017'
I17-1030:
  abstract: 'Current research in text simplification has been hampered by two central
    problems: (i) the small amount of high-quality parallel simplification data available,
    and (ii) the lack of explicit annotations of simplification operations, such as
    deletions or substitutions, on existing data. While the recently introduced Newsela
    corpus has alleviated the first problem, simplifications still need to be learned
    directly from parallel text using black-box, end-to-end approaches rather than
    from explicit annotations. These complex-simple parallel sentence pairs often
    differ to such a high degree that generalization becomes difficult. End-to-end
    models also make it hard to interpret what is actually learned from data. We propose
    a method that decomposes the task of TS into its sub-problems. We devise a way
    to automatically identify operations in a parallel corpus and introduce a sequence-labeling
    approach based on these annotations. Finally, we provide insights on the types
    of transformations that different approaches can model.'
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1030.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-1030.Notes.pdf
  author:
  - first: Fernando
    full: Fernando Alva-Manchego
    id: fernando-alva-manchego
    last: Alva-Manchego
  - first: Joachim
    full: Joachim Bingel
    id: joachim-bingel
    last: Bingel
  - first: Gustavo
    full: Gustavo Paetzold
    id: gustavo-paetzold
    last: Paetzold
  - first: Carolina
    full: Carolina Scarton
    id: carolina-scarton
    last: Scarton
  - first: Lucia
    full: Lucia Specia
    id: lucia-specia
    last: Specia
  author_string: Fernando Alva-Manchego, Joachim Bingel, Gustavo Paetzold, Carolina
    Scarton, Lucia Specia
  bibkey: alva-manchego-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '295'
  page_last: '305'
  pages: "295\u2013305"
  paper_id: '30'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1030.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1030.jpg
  title: Learning How to Simplify From Explicit Labeling of Complex-Simplified Text
    Pairs
  title_html: Learning How to Simplify From Explicit Labeling of Complex-Simplified
    Text Pairs
  url: https://www.aclweb.org/anthology/I17-1030
  year: '2017'
I17-1031:
  abstract: RDF ontologies provide structured data on entities in many domains and
    continue to grow in size and diversity. While they can be useful as a starting
    point for generating descriptions of entities, they often miss important information
    about an entity that cannot be captured as simple relations. In addition, generic
    approaches to generation from RDF cannot capture the unique style and content
    of specific domains. We describe a framework for hybrid generation of entity descriptions,
    which combines generation from RDF data with text extracted from a corpus, and
    extracts unique aspects of the domain from the corpus to create domain-specific
    generation systems. We show that each component of our approach significantly
    increases the satisfaction of readers with the text across multiple applications
    and domains.
  address: Taipei, Taiwan
  author:
  - first: Or
    full: Or Biran
    id: or-biran
    last: Biran
  - first: Kathleen
    full: Kathleen McKeown
    id: kathleen-mckeown
    last: McKeown
  author_string: Or Biran, Kathleen McKeown
  bibkey: biran-mckeown-2017-domain
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '306'
  page_last: '315'
  pages: "306\u2013315"
  paper_id: '31'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1031.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1031.jpg
  title: Domain-Adaptable Hybrid Generation of RDF Entity Descriptions
  title_html: Domain-Adaptable Hybrid Generation of <span class="acl-fixed-case">RDF</span>
    Entity Descriptions
  url: https://www.aclweb.org/anthology/I17-1031
  year: '2017'
I17-1032:
  abstract: With the advent of the Internet, the amount of Semantic Web documents
    that describe real-world entities and their inter-links as a set of statements
    have grown considerably. These descriptions are usually lengthy, which makes the
    utilization of the underlying entities a difficult task. Entity summarization,
    which aims to create summaries for real-world entities, has gained increasing
    attention in recent years. In this paper, we propose a probabilistic topic model,
    ES-LDA, that combines prior knowledge with statistical learning techniques within
    a single framework to create more reliable and representative summaries for entities.
    We demonstrate the effectiveness of our approach by conducting extensive experiments
    and show that our model outperforms the state-of-the-art techniques and enhances
    the quality of the entity summaries.
  address: Taipei, Taiwan
  author:
  - first: Seyedamin
    full: Seyedamin Pouriyeh
    id: seyedamin-pouriyeh
    last: Pouriyeh
  - first: Mehdi
    full: Mehdi Allahyari
    id: mehdi-allahyari
    last: Allahyari
  - first: Krzysztof
    full: Krzysztof Kochut
    id: krzysztof-kochut
    last: Kochut
  - first: Gong
    full: Gong Cheng
    id: gong-cheng
    last: Cheng
  - first: Hamid Reza
    full: Hamid Reza Arabnia
    id: hamid-reza-arabnia
    last: Arabnia
  author_string: Seyedamin Pouriyeh, Mehdi Allahyari, Krzysztof Kochut, Gong Cheng,
    Hamid Reza Arabnia
  bibkey: pouriyeh-etal-2017-es
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '316'
  page_last: '325'
  pages: "316\u2013325"
  paper_id: '32'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1032.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1032.jpg
  title: 'ES-LDA: Entity Summarization using Knowledge-based Topic Modeling'
  title_html: '<span class="acl-fixed-case">ES</span>-<span class="acl-fixed-case">LDA</span>:
    Entity Summarization using Knowledge-based Topic Modeling'
  url: https://www.aclweb.org/anthology/I17-1032
  year: '2017'
I17-1033:
  abstract: In recent years, there has been a surge of interest in automatically describing
    images or videos in a natural language. These descriptions are useful for image/video
    search, etc. In this paper, we focus on procedure execution videos, in which a
    human makes or repairs something and propose a method for generating procedural
    texts from them. Since video/text pairs available are limited in size, the direct
    application of end-to-end deep learning is not feasible. Thus we propose to train
    Faster R-CNN network for object recognition and LSTM for text generation and combine
    them at run time. We took pairs of recipe and cooking video, generated a recipe
    from a video, and compared it with the original recipe. The experimental results
    showed that our method can produce a recipe as accurate as the state-of-the-art
    scene descriptions.
  address: Taipei, Taiwan
  author:
  - first: Atsushi
    full: Atsushi Ushiku
    id: atsushi-ushiku
    last: Ushiku
  - first: Hayato
    full: Hayato Hashimoto
    id: hayato-hashimoto
    last: Hashimoto
  - first: Atsushi
    full: Atsushi Hashimoto
    id: atsushi-hashimoto
    last: Hashimoto
  - first: Shinsuke
    full: Shinsuke Mori
    id: shinsuke-mori
    last: Mori
  author_string: Atsushi Ushiku, Hayato Hashimoto, Atsushi Hashimoto, Shinsuke Mori
  bibkey: ushiku-etal-2017-procedural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '326'
  page_last: '335'
  pages: "326\u2013335"
  paper_id: '33'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1033.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1033.jpg
  title: Procedural Text Generation from an Execution Video
  title_html: Procedural Text Generation from an Execution Video
  url: https://www.aclweb.org/anthology/I17-1033
  year: '2017'
I17-1034:
  abstract: 'Tree-structured Long Short-Term Memory (Tree-LSTM) has been proved to
    be an effective method in the sentiment analysis task. It extracts structural
    information on text, and uses Long Short-Term Memory (LSTM) cell to prevent gradient
    vanish. However, though combining the LSTM cell, it is still a kind of model that
    extracts the structural information and almost not extracts serialization information.
    In this paper, we propose three new models in order to combine those two kinds
    of information: the structural information generated by the Constituency Tree-LSTM
    and the serialization information generated by Long-Short Term Memory neural network.
    Our experiments show that combining those two kinds of information can give contributes
    to the performance of the sentiment analysis task compared with the single Constituency
    Tree-LSTM model and the LSTM model.'
  address: Taipei, Taiwan
  author:
  - first: Ling
    full: Ling Gan
    id: ling-gan
    last: Gan
  - first: Houyu
    full: Houyu Gong
    id: houyu-gong
    last: Gong
  author_string: Ling Gan, Houyu Gong
  bibkey: gan-gong-2017-text
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '336'
  page_last: '341'
  pages: "336\u2013341"
  paper_id: '34'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1034.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1034.jpg
  title: Text Sentiment Analysis based on Fusion of Structural Information and Serialization
    Information
  title_html: Text Sentiment Analysis based on Fusion of Structural Information and
    Serialization Information
  url: https://www.aclweb.org/anthology/I17-1034
  year: '2017'
I17-1035:
  abstract: In this work, we provide insight into three key aspects related to predicting
    argument convincingness. First, we explicitly display the power that text length
    possesses for predicting convincingness in an unsupervised setting. Second, we
    show that a bag-of-words embedding model posts state-of-the-art on a dataset of
    arguments annotated for convincingness, outperforming an SVM with numerous hand-crafted
    features as well as recurrent neural network models that attempt to capture semantic
    composition. Finally, we assess the feasibility of integrating external knowledge
    when predicting convincingness, as arguments are often more convincing when they
    contain abundant information and facts. We finish by analyzing the correlations
    between the various models we propose.
  address: Taipei, Taiwan
  author:
  - first: Peter
    full: Peter Potash
    id: peter-potash
    last: Potash
  - first: Robin
    full: Robin Bhattacharya
    id: robin-bhattacharya
    last: Bhattacharya
  - first: Anna
    full: Anna Rumshisky
    id: anna-rumshisky
    last: Rumshisky
  author_string: Peter Potash, Robin Bhattacharya, Anna Rumshisky
  bibkey: potash-etal-2017-length
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '342'
  page_last: '351'
  pages: "342\u2013351"
  paper_id: '35'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1035.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1035.jpg
  title: 'Length, Interchangeability, and External Knowledge: Observations from Predicting
    Argument Convincingness'
  title_html: 'Length, Interchangeability, and External Knowledge: Observations from
    Predicting Argument Convincingness'
  url: https://www.aclweb.org/anthology/I17-1035
  year: '2017'
I17-1036:
  abstract: 'This paper tackles the task of event detection, which involves identifying
    and categorizing events. The previous work mainly exist two problems: (1) the
    traditional feature-based methods apply cross-sentence information, yet need taking
    a large amount of human effort to design complicated feature sets and inference
    rules; (2) the representation-based methods though overcome the problem of manually
    extracting features, while just depend on local sentence representation. Considering
    local sentence context is insufficient to resolve ambiguities in identifying particular
    event types, therefore, we propose a novel document level Recurrent Neural Networks
    (DLRNN) model, which can automatically extract cross-sentence clues to improve
    sentence level event detection without designing complex reasoning rules. Experiment
    results show that our approach outperforms other state-of-the-art methods on ACE
    2005 dataset without external knowledge base.'
  address: Taipei, Taiwan
  author:
  - first: Shaoyang
    full: Shaoyang Duan
    id: shaoyang-duan
    last: Duan
  - first: Ruifang
    full: Ruifang He
    id: ruifang-he
    last: He
  - first: Wenli
    full: Wenli Zhao
    id: wenli-zhao
    last: Zhao
  author_string: Shaoyang Duan, Ruifang He, Wenli Zhao
  bibkey: duan-etal-2017-exploiting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '352'
  page_last: '361'
  pages: "352\u2013361"
  paper_id: '36'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1036.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1036.jpg
  title: Exploiting Document Level Information to Improve Event Detection via Recurrent
    Neural Networks
  title_html: Exploiting Document Level Information to Improve Event Detection via
    Recurrent Neural Networks
  url: https://www.aclweb.org/anthology/I17-1036
  year: '2017'
I17-1037:
  abstract: Current supervised name tagging approaches are inadequate for most low-resource
    languages due to the lack of annotated data and actionable linguistic knowledge.
    All supervised learning methods (including deep neural networks (DNN)) are sensitive
    to noise and thus they are not quite portable without massive clean annotations.
    We found that the F-scores of DNN-based name taggers drop rapidly (20%-30%) when
    we replace clean manual annotations with noisy annotations in the training data.
    We propose a new solution to incorporate many non-traditional language universal
    resources that are readily available but rarely explored in the Natural Language
    Processing (NLP) community, such as the World Atlas of Linguistic Structure, CIA
    names, PanLex and survival guides. We acquire and encode various types of non-traditional
    linguistic resources into a DNN name tagger. Experiments on three low-resource
    languages show that feeding linguistic knowledge can make DNN significantly more
    robust to noise, achieving 8%-22% absolute F-score gains on name tagging without
    using any human annotation
  address: Taipei, Taiwan
  author:
  - first: Boliang
    full: Boliang Zhang
    id: boliang-zhang
    last: Zhang
  - first: Di
    full: Di Lu
    id: di-lu
    last: Lu
  - first: Xiaoman
    full: Xiaoman Pan
    id: xiaoman-pan
    last: Pan
  - first: Ying
    full: Ying Lin
    id: ying-lin
    last: Lin
  - first: Halidanmu
    full: Halidanmu Abudukelimu
    id: halidanmu-abudukelimu
    last: Abudukelimu
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  - first: Kevin
    full: Kevin Knight
    id: kevin-knight
    last: Knight
  author_string: Boliang Zhang, Di Lu, Xiaoman Pan, Ying Lin, Halidanmu Abudukelimu,
    Heng Ji, Kevin Knight
  bibkey: zhang-etal-2017-embracing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '362'
  page_last: '372'
  pages: "362\u2013372"
  paper_id: '37'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1037.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1037.jpg
  title: Embracing Non-Traditional Linguistic Resources for Low-resource Language
    Name Tagging
  title_html: Embracing Non-Traditional Linguistic Resources for Low-resource Language
    Name Tagging
  url: https://www.aclweb.org/anthology/I17-1037
  year: '2017'
I17-1038:
  abstract: "The recent technological shift in machine translation from statistical\
    \ machine translation (SMT) to neural machine translation (NMT) raises the question\
    \ of the strengths and weaknesses of NMT. In this paper, we present an analysis\
    \ of NMT and SMT systems\u2019 outputs from narrow domain English-Latvian MT systems\
    \ that were trained on a rather small amount of data. We analyze post-edits produced\
    \ by professional translators and manually annotated errors in these outputs.\
    \ Analysis of post-edits allowed us to conclude that both approaches are comparably\
    \ successful, allowing for an increase in translators\u2019 productivity, with\
    \ the NMT system showing slightly worse results. Through the analysis of annotated\
    \ errors, we found that NMT translations are more fluent than SMT translations.\
    \ However, errors related to accuracy, especially, mistranslation and omission\
    \ errors, occur more often in NMT outputs. The word form errors, that characterize\
    \ the morphological richness of Latvian, are frequent for both systems, but slightly\
    \ fewer in NMT outputs."
  address: Taipei, Taiwan
  author:
  - first: Inguna
    full: "Inguna Skadi\u0146a"
    id: inguna-skadina
    last: "Skadi\u0146a"
  - first: "M\u0101rcis"
    full: "M\u0101rcis Pinnis"
    id: marcis-pinnis
    last: Pinnis
  author_string: "Inguna Skadi\u0146a, M\u0101rcis Pinnis"
  bibkey: skadina-pinnis-2017-nmt
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '373'
  page_last: '383'
  pages: "373\u2013383"
  paper_id: '38'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1038.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1038.jpg
  title: 'NMT or SMT: Case Study of a Narrow-domain English-Latvian Post-editing Project'
  title_html: '<span class="acl-fixed-case">NMT</span> or <span class="acl-fixed-case">SMT</span>:
    Case Study of a Narrow-domain <span class="acl-fixed-case">E</span>nglish-<span
    class="acl-fixed-case">L</span>atvian Post-editing Project'
  url: https://www.aclweb.org/anthology/I17-1038
  year: '2017'
I17-1039:
  abstract: While neural machine translation (NMT) has become the new paradigm, the
    parameter optimization requires large-scale parallel data which is scarce in many
    domains and language pairs. In this paper, we address a new translation scenario
    in which there only exists monolingual corpora and phrase pairs. We propose a
    new method towards translation with partially aligned sentence pairs which are
    derived from the phrase pairs and monolingual corpora. To make full use of the
    partially aligned corpora, we adapt the conventional NMT training method in two
    aspects. On one hand, different generation strategies are designed for aligned
    and unaligned target words. On the other hand, a different objective function
    is designed to model the partially aligned parts. The experiments demonstrate
    that our method can achieve a relatively good result in such a translation scenario,
    and tiny bitexts can boost translation quality to a large extent.
  address: Taipei, Taiwan
  author:
  - first: Yining
    full: Yining Wang
    id: yining-wang
    last: Wang
  - first: Yang
    full: Yang Zhao
    id: yang-zhao
    last: Zhao
  - first: Jiajun
    full: Jiajun Zhang
    id: jiajun-zhang
    last: Zhang
  - first: Chengqing
    full: Chengqing Zong
    id: chengqing-zong
    last: Zong
  - first: Zhengshan
    full: Zhengshan Xue
    id: zhengshan-xue
    last: Xue
  author_string: Yining Wang, Yang Zhao, Jiajun Zhang, Chengqing Zong, Zhengshan Xue
  bibkey: wang-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '384'
  page_last: '393'
  pages: "384\u2013393"
  paper_id: '39'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1039.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1039.jpg
  title: Towards Neural Machine Translation with Partially Aligned Corpora
  title_html: Towards Neural Machine Translation with Partially Aligned Corpora
  url: https://www.aclweb.org/anthology/I17-1039
  year: '2017'
I17-1040:
  abstract: "In this paper we introduce the problem of identifying usage expression\
    \ sentences in a consumer product review. We create a human-annotated gold standard\
    \ dataset of 565 reviews spanning five distinct product categories. Our dataset\
    \ consists of more than 3,000 annotated sentences. We further introduce a classification\
    \ system to label sentences according to whether or not they describe some \u201C\
    usage\u201D. The system combines lexical, syntactic, and semantic features in\
    \ a product-agnostic fashion to yield good classification performance. We show\
    \ the effectiveness of our approach using importance ranking of features, error\
    \ analysis, and cross-product classification experiments."
  address: Taipei, Taiwan
  author:
  - first: Shibamouli
    full: Shibamouli Lahiri
    id: shibamouli-lahiri
    last: Lahiri
  - first: V.G.Vinod
    full: V.G.Vinod Vydiswaran
    id: v-g-vinod-vydiswaran
    last: Vydiswaran
  - first: Rada
    full: Rada Mihalcea
    id: rada-mihalcea
    last: Mihalcea
  author_string: Shibamouli Lahiri, V.G.Vinod Vydiswaran, Rada Mihalcea
  bibkey: lahiri-etal-2017-identifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '394'
  page_last: '403'
  pages: "394\u2013403"
  paper_id: '40'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1040.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1040.jpg
  title: Identifying Usage Expression Sentences in Consumer Product Reviews
  title_html: Identifying Usage Expression Sentences in Consumer Product Reviews
  url: https://www.aclweb.org/anthology/I17-1040
  year: '2017'
I17-1041:
  abstract: "This article presents a contrastive analysis between reading time and\
    \ syntactic/semantic categories in Japanese. We overlaid the reading time annotation\
    \ of BCCWJ-EyeTrack and a syntactic/semantic category information annotation on\
    \ the \u2018Balanced Corpus of Contemporary Written Japanese\u2019. Statistical\
    \ analysis based on a mixed linear model showed that verbal phrases tend to have\
    \ shorter reading times than adjectives, adverbial phrases, or nominal phrases.\
    \ The results suggest that the preceding phrases associated with the presenting\
    \ phrases promote the reading process to shorten the gazing time."
  address: Taipei, Taiwan
  author:
  - first: Masayuki
    full: Masayuki Asahara
    id: masayuki-asahara
    last: Asahara
  - first: Sachi
    full: Sachi Kato
    id: sachi-kato
    last: Kato
  author_string: Masayuki Asahara, Sachi Kato
  bibkey: asahara-kato-2017-reading
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '404'
  page_last: '412'
  pages: "404\u2013412"
  paper_id: '41'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1041.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1041.jpg
  title: Between Reading Time and Syntactic/Semantic Categories
  title_html: Between Reading Time and Syntactic/Semantic Categories
  url: https://www.aclweb.org/anthology/I17-1041
  year: '2017'
I17-1042:
  abstract: We revisit the idea of mining Wikipedia in order to generate named-entity
    annotations. We propose a new methodology that we applied to English Wikipedia
    to build WiNER, a large, high quality, annotated corpus. We evaluate its usefulness
    on 6 NER tasks, comparing 4 popular state-of-the art approaches. We show that
    LSTM-CRF is the approach that benefits the most from our corpus. We report impressive
    gains with this model when using a small portion of WiNER on top of the CONLL
    training material. Last, we propose a simple but efficient method for exploiting
    the full range of WiNER, leading to further improvements.
  address: Taipei, Taiwan
  author:
  - first: Abbas
    full: Abbas Ghaddar
    id: abbas-ghaddar
    last: Ghaddar
  - first: Phillippe
    full: Phillippe Langlais
    id: philippe-langlais
    last: Langlais
  author_string: Abbas Ghaddar, Phillippe Langlais
  bibkey: ghaddar-langlais-2017-winer
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '413'
  page_last: '422'
  pages: "413\u2013422"
  paper_id: '42'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1042.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1042.jpg
  title: 'WiNER: A Wikipedia Annotated Corpus for Named Entity Recognition'
  title_html: '<span class="acl-fixed-case">W</span>i<span class="acl-fixed-case">NER</span>:
    A <span class="acl-fixed-case">W</span>ikipedia Annotated Corpus for Named Entity
    Recognition'
  url: https://www.aclweb.org/anthology/I17-1042
  year: '2017'
I17-1043:
  abstract: Acoustic emotion recognition aims to categorize the affective state of
    the speaker and is still a difficult task for machine learning models. The difficulties
    come from the scarcity of training data, general subjectivity in emotion perception
    resulting in low annotator agreement, and the uncertainty about which features
    are the most relevant and robust ones for classification. In this paper, we will
    tackle the latter problem. Inspired by the recent success of transfer learning
    methods we propose a set of architectures which utilize neural representations
    inferred by training on large speech databases for the acoustic emotion recognition
    task. Our experiments on the IEMOCAP dataset show ~10% relative improvements in
    the accuracy and F1-score over the baseline recurrent neural network which is
    trained end-to-end for emotion recognition.
  address: Taipei, Taiwan
  author:
  - first: Egor
    full: Egor Lakomkin
    id: egor-lakomkin
    last: Lakomkin
  - first: Cornelius
    full: Cornelius Weber
    id: cornelius-weber
    last: Weber
  - first: Sven
    full: Sven Magg
    id: sven-magg
    last: Magg
  - first: Stefan
    full: Stefan Wermter
    id: stefan-wermter
    last: Wermter
  author_string: Egor Lakomkin, Cornelius Weber, Sven Magg, Stefan Wermter
  bibkey: lakomkin-etal-2017-reusing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '423'
  page_last: '430'
  pages: "423\u2013430"
  paper_id: '43'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1043.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1043.jpg
  title: Reusing Neural Speech Representations for Auditory Emotion Recognition
  title_html: Reusing Neural Speech Representations for Auditory Emotion Recognition
  url: https://www.aclweb.org/anthology/I17-1043
  year: '2017'
I17-1044:
  abstract: Recently, encoder-decoder neural networks have shown impressive performance
    on many sequence-related tasks. The architecture commonly uses an attentional
    mechanism which allows the model to learn alignments between the source and the
    target sequence. Most attentional mechanisms used today is based on a global attention
    property which requires a computation of a weighted summarization of the whole
    input sequence generated by encoder states. However, it is computationally expensive
    and often produces misalignment on the longer input sequence. Furthermore, it
    does not fit with monotonous or left-to-right nature in several tasks, such as
    automatic speech recognition (ASR), grapheme-to-phoneme (G2P), etc. In this paper,
    we propose a novel attention mechanism that has local and monotonic properties.
    Various ways to control those properties are also explored. Experimental results
    on ASR, G2P and machine translation between two languages with similar sentence
    structures, demonstrate that the proposed encoder-decoder model with local monotonic
    attention could achieve significant performance improvements and reduce the computational
    complexity in comparison with the one that used the standard global attention
    architecture.
  address: Taipei, Taiwan
  author:
  - first: Andros
    full: Andros Tjandra
    id: andros-tjandra
    last: Tjandra
  - first: Sakriani
    full: Sakriani Sakti
    id: sakriani-sakti
    last: Sakti
  - first: Satoshi
    full: Satoshi Nakamura
    id: satoshi-nakamura
    last: Nakamura
  author_string: Andros Tjandra, Sakriani Sakti, Satoshi Nakamura
  bibkey: tjandra-etal-2017-local
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '431'
  page_last: '440'
  pages: "431\u2013440"
  paper_id: '44'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1044.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1044.jpg
  title: Local Monotonic Attention Mechanism for End-to-End Speech And Language Processing
  title_html: Local Monotonic Attention Mechanism for End-to-End Speech And Language
    Processing
  url: https://www.aclweb.org/anthology/I17-1044
  year: '2017'
I17-1045:
  abstract: "In this paper, we extend Recurrent Neural Network Language Models (RNN-LMs)\
    \ with an attention mechanism. We show that an \u201Cattentive\u201D RNN-LM (with\
    \ 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters)\
    \ and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.\
    \ We also show that an \u201Cattentive\u201D RNN-LM needs less contextual information\
    \ to achieve similar results to the state-of-the-art on the wikitext2 dataset."
  address: Taipei, Taiwan
  author:
  - first: Giancarlo
    full: Giancarlo Salton
    id: giancarlo-salton
    last: Salton
  - first: Robert
    full: Robert Ross
    id: robert-ross
    last: Ross
  - first: John
    full: John Kelleher
    id: john-kelleher
    last: Kelleher
  author_string: Giancarlo Salton, Robert Ross, John Kelleher
  bibkey: salton-etal-2017-attentive
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '441'
  page_last: '450'
  pages: "441\u2013450"
  paper_id: '45'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1045.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1045.jpg
  title: Attentive Language Models
  title_html: Attentive Language Models
  url: https://www.aclweb.org/anthology/I17-1045
  year: '2017'
I17-1046:
  abstract: "Although features of linguistic typology are a promising alternative\
    \ to lexical evidence for tracing evolutionary history of languages, a large number\
    \ of missing values in the dataset pose serious difficulties for statistical modeling.\
    \ In this paper, we combine two existing approaches to the problem: (1) the synchronic\
    \ approach that focuses on interdependencies between features and (2) the diachronic\
    \ approach that exploits phylogenetically- and/or spatially-related languages.\
    \ Specifically, we propose a Bayesian model that (1) represents each language\
    \ as a sequence of binary latent parameters encoding inter-feature dependencies\
    \ and (2) relates a language\u2019s parameters to those of its phylogenetic and\
    \ spatial neighbors. Experiments show that the proposed model recovers missing\
    \ values more accurately than others and that induced representations retain phylogenetic\
    \ and spatial signals observed for surface features."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1046.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-1046.Notes.pdf
  author:
  - first: Yugo
    full: Yugo Murawaki
    id: yugo-murawaki
    last: Murawaki
  author_string: Yugo Murawaki
  bibkey: murawaki-2017-diachrony
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '451'
  page_last: '461'
  pages: "451\u2013461"
  paper_id: '46'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1046.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1046.jpg
  title: Diachrony-aware Induction of Binary Latent Representations from Typological
    Features
  title_html: Diachrony-aware Induction of Binary Latent Representations from Typological
    Features
  url: https://www.aclweb.org/anthology/I17-1046
  year: '2017'
I17-1047:
  abstract: The popularity of image sharing on social media and the engagement it
    creates between users reflect the important role that visual context plays in
    everyday conversations. We present a novel task, Image Grounded Conversations
    (IGC), in which natural-sounding conversations are generated about a shared image.
    To benchmark progress, we introduce a new multiple reference dataset of crowd-sourced,
    event-centric conversations on images. IGC falls on the continuum between chit-chat
    and goal-directed conversation models, where visual grounding constrains the topic
    of conversation to event-driven utterances. Experiments with models trained on
    social media data show that the combination of visual and textual context enhances
    the quality of generated conversational turns. In human evaluation, the gap between
    human performance and that of both neural and retrieval architectures suggests
    that multi-modal IGC presents an interesting challenge for dialog research.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1047.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-1047.Notes.pdf
  author:
  - first: Nasrin
    full: Nasrin Mostafazadeh
    id: nasrin-mostafazadeh
    last: Mostafazadeh
  - first: Chris
    full: Chris Brockett
    id: chris-brockett
    last: Brockett
  - first: Bill
    full: Bill Dolan
    id: bill-dolan
    last: Dolan
  - first: Michel
    full: Michel Galley
    id: michel-galley
    last: Galley
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  - first: Georgios
    full: Georgios Spithourakis
    id: georgios-spithourakis
    last: Spithourakis
  - first: Lucy
    full: Lucy Vanderwende
    id: lucy-vanderwende
    last: Vanderwende
  author_string: Nasrin Mostafazadeh, Chris Brockett, Bill Dolan, Michel Galley, Jianfeng
    Gao, Georgios Spithourakis, Lucy Vanderwende
  bibkey: mostafazadeh-etal-2017-image
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '462'
  page_last: '472'
  pages: "462\u2013472"
  paper_id: '47'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1047.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1047.jpg
  title: 'Image-Grounded Conversations: Multimodal Context for Natural Question and
    Response Generation'
  title_html: 'Image-Grounded Conversations: Multimodal Context for Natural Question
    and Response Generation'
  url: https://www.aclweb.org/anthology/I17-1047
  year: '2017'
I17-1048:
  abstract: This study addresses the problem of identifying the meaning of unknown
    words or entities in a discourse with respect to the word embedding approaches
    used in neural language models. We proposed a method for on-the-fly construction
    and exploitation of word embeddings in both the input and output layers of a neural
    model by tracking contexts. This extends the dynamic entity representation used
    in Kobayashi et al. (2016) and incorporates a copy mechanism proposed independently
    by Gu et al. (2016) and Gulcehre et al. (2016). In addition, we construct a new
    task and dataset called Anonymized Language Modeling for evaluating the ability
    to capture word meanings while reading. Experiments conducted using our novel
    dataset show that the proposed variant of RNN language model outperformed the
    baseline model. Furthermore, the experiments also demonstrate that dynamic updates
    of an output layer help a model predict reappearing entities, whereas those of
    an input layer are effective to predict words following reappearing entities.
  address: Taipei, Taiwan
  author:
  - first: Sosuke
    full: Sosuke Kobayashi
    id: sosuke-kobayashi
    last: Kobayashi
  - first: Naoaki
    full: Naoaki Okazaki
    id: naoaki-okazaki
    last: Okazaki
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Sosuke Kobayashi, Naoaki Okazaki, Kentaro Inui
  bibkey: kobayashi-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '473'
  page_last: '483'
  pages: "473\u2013483"
  paper_id: '48'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1048.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1048.jpg
  title: A Neural Language Model for Dynamically Representing the Meanings of Unknown
    Words and Entities in a Discourse
  title_html: A Neural Language Model for Dynamically Representing the Meanings of
    Unknown Words and Entities in a Discourse
  url: https://www.aclweb.org/anthology/I17-1048
  year: '2017'
I17-1049:
  abstract: "Implicit discourse relation recognition is an extremely challenging task\
    \ due to the lack of indicative connectives. Various neural network architectures\
    \ have been proposed for this task recently, but most of them suffer from the\
    \ shortage of labeled data. In this paper, we address this problem by procuring\
    \ additional training data from parallel corpora: When humans translate a text,\
    \ they sometimes add connectives (a process known as explicitation). We\tautomatically\
    \ back-translate it into an English connective and use it to infer\ta label with\
    \ high confidence. We show that a training set several times larger\tthan the\
    \ original training set can be generated this way. With the extra\tlabeled instances,\
    \ we show that even a simple bidirectional Long Short-Term\tMemory Network can\
    \ outperform the current state-of-the-art."
  address: Taipei, Taiwan
  author:
  - first: Wei
    full: Wei Shi
    id: wei-shi
    last: Shi
  - first: Frances
    full: Frances Yung
    id: frances-yung
    last: Yung
  - first: Raphael
    full: Raphael Rubino
    id: raphael-rubino
    last: Rubino
  - first: Vera
    full: Vera Demberg
    id: vera-demberg
    last: Demberg
  author_string: Wei Shi, Frances Yung, Raphael Rubino, Vera Demberg
  bibkey: shi-etal-2017-using
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '484'
  page_last: '495'
  pages: "484\u2013495"
  paper_id: '49'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1049.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1049.jpg
  title: Using Explicit Discourse Connectives in Translation for Implicit Discourse
    Relation Classification
  title_html: Using Explicit Discourse Connectives in Translation for Implicit Discourse
    Relation Classification
  url: https://www.aclweb.org/anthology/I17-1049
  year: '2017'
I17-1050:
  abstract: Identifying implicit discourse relations between text spans is a challenging
    task because it requires understanding the meaning of the text. To tackle this
    task, recent studies have tried several deep learning methods but few of them
    exploited the syntactic information. In this work, we explore the idea of incorporating
    syntactic parse tree into neural networks. Specifically, we employ the Tree-LSTM
    model and Tree-GRU model, which is based on the tree structure, to encode the
    arguments in a relation. And we further leverage the constituent tags to control
    the semantic composition process in these tree-structured neural networks. Experimental
    results show that our method achieves state-of-the-art performance on PDTB corpus.
  address: Taipei, Taiwan
  author:
  - first: Yizhong
    full: Yizhong Wang
    id: yizhong-wang
    last: Wang
  - first: Sujian
    full: Sujian Li
    id: sujian-li
    last: Li
  - first: Jingfeng
    full: Jingfeng Yang
    id: jingfeng-yang
    last: Yang
  - first: Xu
    full: Xu Sun
    id: xu-sun
    last: Sun
  - first: Houfeng
    full: Houfeng Wang
    id: houfeng-wang
    last: Wang
  author_string: Yizhong Wang, Sujian Li, Jingfeng Yang, Xu Sun, Houfeng Wang
  bibkey: wang-etal-2017-tag
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '496'
  page_last: '505'
  pages: "496\u2013505"
  paper_id: '50'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1050.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1050.jpg
  title: Tag-Enhanced Tree-Structured Neural Networks for Implicit Discourse Relation
    Classification
  title_html: Tag-Enhanced Tree-Structured Neural Networks for Implicit Discourse
    Relation Classification
  url: https://www.aclweb.org/anthology/I17-1050
  year: '2017'
I17-1051:
  abstract: Current approaches to cross-lingual sentiment analysis try to leverage
    the wealth of labeled English data using bilingual lexicons, bilingual vector
    space embeddings, or machine translation systems. Here we show that it is possible
    to use a single linear transformation, with as few as 2000 word pairs, to capture
    fine-grained sentiment relationships between words in a cross-lingual setting.
    We apply these cross-lingual sentiment models to a diverse set of tasks to demonstrate
    their functionality in a non-English context. By effectively leveraging English
    sentiment knowledge without the need for accurate translation, we can analyze
    and extract features from other languages with scarce data at a very low cost,
    thus making sentiment and related analyses for many languages inexpensive.
  address: Taipei, Taiwan
  author:
  - first: Mohamed
    full: Mohamed Abdalla
    id: mohamed-abdalla
    last: Abdalla
  - first: Graeme
    full: Graeme Hirst
    id: graeme-hirst
    last: Hirst
  author_string: Mohamed Abdalla, Graeme Hirst
  bibkey: abdalla-hirst-2017-cross
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '506'
  page_last: '515'
  pages: "506\u2013515"
  paper_id: '51'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1051.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1051.jpg
  title: Cross-Lingual Sentiment Analysis Without (Good) Translation
  title_html: Cross-Lingual Sentiment Analysis Without (Good) Translation
  url: https://www.aclweb.org/anthology/I17-1051
  year: '2017'
I17-1052:
  abstract: Targeted sentiment analysis investigates the sentiment polarities on given
    target mentions from input texts. Different from sentence level sentiment, it
    offers more fine-grained knowledge on each entity mention. While early work leveraged
    syntactic information, recent research has used neural representation learning
    to induce features automatically, thereby avoiding error propagation of syntactic
    parsers, which are particularly severe on social media texts. We study a method
    to leverage syntactic information without explicitly building the parser outputs,
    by training an encoder-decoder structure parser model on standard syntactic treebanks,
    and then leveraging its hidden encoder layers when analysing tweets. Such hidden
    vectors do not contain explicit syntactic outputs, yet encode rich syntactic features.
    We use them to augment the inputs to a baseline state-of-the-art targeted sentiment
    classifier, observing significant improvements on various benchmark datasets.
    We obtain the best accuracies on all test sets.
  address: Taipei, Taiwan
  author:
  - first: Yuze
    full: Yuze Gao
    id: yuze-gao
    last: Gao
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Tong
    full: Tong Xiao
    id: tong-xiao
    last: Xiao
  author_string: Yuze Gao, Yue Zhang, Tong Xiao
  bibkey: gao-etal-2017-implicit
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '516'
  page_last: '524'
  pages: "516\u2013524"
  paper_id: '52'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1052.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1052.jpg
  title: Implicit Syntactic Features for Target-dependent Sentiment Analysis
  title_html: Implicit Syntactic Features for Target-dependent Sentiment Analysis
  url: https://www.aclweb.org/anthology/I17-1052
  year: '2017'
I17-1053:
  abstract: The sentiment aggregation problem accounts for analyzing the sentiment
    of a user towards various aspects/features of a product, and meaningfully assimilating
    the pragmatic significance of these features/aspects from an opinionated text.
    The current paper addresses the sentiment aggregation problem, by assigning weights
    to each aspect appearing in the user-generated content, that are proportionate
    to the strategic importance of the aspect in the pragmatic domain. The novelty
    of this paper is in computing the pragmatic significance (weight) of each aspect,
    using graph centrality measures (applied on domain specific ontology-graphs extracted
    from ConceptNet), and deeply ingraining these weights while aggregating the sentiments
    from opinionated text. We experiment over multiple real-life product review data.
    Our system consistently outperforms the state of the art - by as much as a F-score
    of 20.39% in one case.
  address: Taipei, Taiwan
  author:
  - first: Srikanth
    full: Srikanth Tamilselvam
    id: srikanth-tamilselvam
    last: Tamilselvam
  - first: Seema
    full: Seema Nagar
    id: seema-nagar
    last: Nagar
  - first: Abhijit
    full: Abhijit Mishra
    id: abhijit-mishra
    last: Mishra
  - first: Kuntal
    full: Kuntal Dey
    id: kuntal-dey
    last: Dey
  author_string: Srikanth Tamilselvam, Seema Nagar, Abhijit Mishra, Kuntal Dey
  bibkey: tamilselvam-etal-2017-graph
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '525'
  page_last: '535'
  pages: "525\u2013535"
  paper_id: '53'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1053.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1053.jpg
  title: Graph Based Sentiment Aggregation using ConceptNet Ontology
  title_html: Graph Based Sentiment Aggregation using <span class="acl-fixed-case">C</span>oncept<span
    class="acl-fixed-case">N</span>et Ontology
  url: https://www.aclweb.org/anthology/I17-1053
  year: '2017'
I17-1054:
  abstract: 'Tweet-level sentiment classification in Twitter social networking has
    many challenges: exploiting syntax, semantic, sentiment, and context in tweets.
    To address these problems, we propose a novel approach to sentiment analysis that
    uses lexicon features for building lexicon embeddings (LexW2Vs) and generates
    character attention vectors (CharAVs) by using a Deep Convolutional Neural Network
    (DeepCNN). Our approach integrates LexW2Vs and CharAVs with continuous word embeddings
    (ContinuousW2Vs) and dependency-based word embeddings (DependencyW2Vs) simultaneously
    in order to increase information for each word into a Bidirectional Contextual
    Gated Recurrent Neural Network (Bi-CGRNN). We evaluate our model on two Twitter
    sentiment classification datasets. Experimental results show that our model can
    improve the classification accuracy of sentence-level sentiment analysis in Twitter
    social networking.'
  address: Taipei, Taiwan
  author:
  - first: Huy Thanh
    full: Huy Thanh Nguyen
    id: huy-thanh-nguyen
    last: Nguyen
  - first: Minh Le
    full: Minh Le Nguyen
    id: minh-le-nguyen
    last: Nguyen
  author_string: Huy Thanh Nguyen, Minh Le Nguyen
  bibkey: nguyen-nguyen-2017-sentence
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '536'
  page_last: '544'
  pages: "536\u2013544"
  paper_id: '54'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1054.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1054.jpg
  title: Sentence Modeling with Deep Neural Architecture using Lexicon and Character
    Attention Mechanism for Sentiment Classification
  title_html: Sentence Modeling with Deep Neural Architecture using Lexicon and Character
    Attention Mechanism for Sentiment Classification
  url: https://www.aclweb.org/anthology/I17-1054
  year: '2017'
I17-1055:
  abstract: "In this paper we propose a lightly-supervised framework to rapidly build\
    \ text classifiers for contextual advertising. Traditionally text classification\
    \ techniques require labeled training documents for each predefined class. In\
    \ the scenario of contextual advertising, advertisers often want to target to\
    \ a specific class of webpages most relevant to their product or service, which\
    \ may not be covered by a pre-trained classifier. Moreover, the advertisers are\
    \ interested in whether a webpage is \u201Crelevant\u201D or \u201Cirrelevant\u201D\
    . It is time-consuming to solicit the advertisers for reliable training signals\
    \ for the negative class. Therefore, it is more suitable to model the problem\
    \ as a one-class classification problem, in contrast to traditional classification\
    \ problems where disjoint classes are defined a priori. We first apply two state-of-the-art\
    \ lightly-supervised classification models, generalized expectation (GE) criteria\
    \ (Druck et al., 2008) and multinomial naive Bayes (MNB) with priors (Settles,\
    \ 2011) to one-class classification where the user only needs to provide a small\
    \ list of labeled words for the target class. To combine the strengths of the\
    \ two models, we fuse them together by using MNB to automatically enrich the constraints\
    \ for GE training. We also explore ensemble method to combine classifiers. On\
    \ a corpus of webpages from real-time bidding requests, the proposed model achieves\
    \ the highest average F1 of 0.69 and closes more than half of the gap between\
    \ previous state-of-the-art lightly-supervised models to a fully-supervised MaxEnt\
    \ model."
  address: Taipei, Taiwan
  author:
  - first: Yiping
    full: Yiping Jin
    id: yiping-jin
    last: Jin
  - first: Dittaya
    full: Dittaya Wanvarie
    id: dittaya-wanvarie
    last: Wanvarie
  - first: Phu
    full: Phu Le
    id: phu-le
    last: Le
  author_string: Yiping Jin, Dittaya Wanvarie, Phu Le
  bibkey: jin-etal-2017-combining-lightly
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '545'
  page_last: '554'
  pages: "545\u2013554"
  paper_id: '55'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1055.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1055.jpg
  title: Combining Lightly-Supervised Text Classification Models for Accurate Contextual
    Advertising
  title_html: Combining Lightly-Supervised Text Classification Models for Accurate
    Contextual Advertising
  url: https://www.aclweb.org/anthology/I17-1055
  year: '2017'
I17-1056:
  abstract: "Despite successful applications across a broad range of NLP tasks, conditional\
    \ random fields (\u201CCRFs\u201D), in particular the linear-chain variant, are\
    \ only able to model local features. While this has important benefits in terms\
    \ of inference tractability, it limits the ability of the model to capture long-range\
    \ dependencies between items. Attempts to extend CRFs to capture long-range dependencies\
    \ have largely come at the cost of computational complexity and approximate inference.\
    \ In this work, we propose an extension to CRFs by integrating external memory,\
    \ taking inspiration from memory networks, thereby allowing CRFs to incorporate\
    \ information far beyond neighbouring steps. Experiments across two tasks show\
    \ substantial improvements over strong CRF and LSTM baselines."
  address: Taipei, Taiwan
  author:
  - first: Fei
    full: Fei Liu
    id: fei-liu-utdallas
    last: Liu
  - first: Timothy
    full: Timothy Baldwin
    id: timothy-baldwin
    last: Baldwin
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  author_string: Fei Liu, Timothy Baldwin, Trevor Cohn
  bibkey: liu-etal-2017-capturing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '555'
  page_last: '565'
  pages: "555\u2013565"
  paper_id: '56'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1056.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1056.jpg
  title: Capturing Long-range Contextual Dependencies with Memory-enhanced Conditional
    Random Fields
  title_html: Capturing Long-range Contextual Dependencies with Memory-enhanced Conditional
    Random Fields
  url: https://www.aclweb.org/anthology/I17-1056
  year: '2017'
I17-1057:
  abstract: Recurrent Neural Network models are the state-of-the-art for Named Entity
    Recognition (NER). We present two innovations to improve the performance of these
    models. The first innovation is the introduction of residual connections between
    the Stacked Recurrent Neural Network model to address the degradation problem
    of deep neural networks. The second innovation is a bias decoding mechanism that
    allows the trained system to adapt to non-differentiable and externally computed
    objectives, such as the entity-based F-measure. Our work improves the state-of-the-art
    results for both Spanish and English languages on the standard train/development/test
    split of the CoNLL 2003 Shared Task NER dataset.
  address: Taipei, Taiwan
  author:
  - first: Quan
    full: Quan Tran
    id: quan-hung-tran
    last: Tran
  - first: Andrew
    full: Andrew MacKinlay
    id: andrew-mackinlay
    last: MacKinlay
  - first: Antonio
    full: Antonio Jimeno Yepes
    id: antonio-jimeno-yepes
    last: Jimeno Yepes
  author_string: Quan Tran, Andrew MacKinlay, Antonio Jimeno Yepes
  bibkey: tran-etal-2017-named
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '566'
  page_last: '575'
  pages: "566\u2013575"
  paper_id: '57'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1057.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1057.jpg
  title: Named Entity Recognition with Stack Residual LSTM and Trainable Bias Decoding
  title_html: Named Entity Recognition with Stack Residual <span class="acl-fixed-case">LSTM</span>
    and Trainable Bias Decoding
  url: https://www.aclweb.org/anthology/I17-1057
  year: '2017'
I17-1058:
  abstract: The problem of blend formation in generative linguistics is interesting
    in the context of neologism, their quick adoption in modern life and the creative
    generative process guiding their formation. Blend quality depends on multitude
    of factors with high degrees of uncertainty. In this work, we investigate if the
    modern neural network models can sufficiently capture and recognize the creative
    blend composition process. We propose recurrent neural network sequence-to-sequence
    models, that are evaluated on multiple blend datasets available in the literature.
    We propose an ensemble neural and hybrid model that outperforms most of the baselines
    and heuristic models upon evaluation on test data.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1058.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-1058.Notes.pdf
  author:
  - first: Kollol
    full: Kollol Das
    id: kollol-das
    last: Das
  - first: Shaona
    full: Shaona Ghosh
    id: shaona-ghosh
    last: Ghosh
  author_string: Kollol Das, Shaona Ghosh
  bibkey: das-ghosh-2017-neuramanteau
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '576'
  page_last: '583'
  pages: "576\u2013583"
  paper_id: '58'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1058.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1058.jpg
  title: 'Neuramanteau: A Neural Network Ensemble Model for Lexical Blends'
  title_html: '<span class="acl-fixed-case">N</span>euramanteau: A Neural Network
    Ensemble Model for Lexical Blends'
  url: https://www.aclweb.org/anthology/I17-1058
  year: '2017'
I17-1059:
  abstract: We explore techniques to maximize the effectiveness of discourse information
    in the task of authorship attribution. We present a novel method to embed discourse
    features in a Convolutional Neural Network text classifier, which achieves a state-of-the-art
    result by a significant margin. We empirically investigate several featurization
    methods to understand the conditions under which discourse features contribute
    non-trivial performance gains, and analyze discourse embeddings.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1059.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/I17-1059.Presentation.pdf
  author:
  - first: Elisa
    full: Elisa Ferracane
    id: elisa-ferracane
    last: Ferracane
  - first: Su
    full: Su Wang
    id: su-wang
    last: Wang
  - first: Raymond
    full: Raymond Mooney
    id: raymond-mooney
    last: Mooney
  author_string: Elisa Ferracane, Su Wang, Raymond Mooney
  bibkey: ferracane-etal-2017-leveraging
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '584'
  page_last: '593'
  pages: "584\u2013593"
  paper_id: '59'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1059.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1059.jpg
  title: Leveraging Discourse Information Effectively for Authorship Attribution
  title_html: Leveraging Discourse Information Effectively for Authorship Attribution
  url: https://www.aclweb.org/anthology/I17-1059
  year: '2017'
I17-1060:
  abstract: "We propose the first lightly-supervised approach to scoring an argument\u2019\
    s persuasiveness. Key to our approach is the novel hypothesis that lightly-supervised\
    \ persuasiveness scoring is possible by explicitly modeling the major errors that\
    \ negatively impact persuasiveness. In an evaluation on a new annotated corpus\
    \ of online debate arguments, our approach rivals its fully-supervised counterparts\
    \ in performance by four scoring metrics when using only 10% of the available\
    \ training instances."
  address: Taipei, Taiwan
  author:
  - first: Isaac
    full: Isaac Persing
    id: isaac-persing
    last: Persing
  - first: Vincent
    full: Vincent Ng
    id: vincent-ng
    last: Ng
  author_string: Isaac Persing, Vincent Ng
  bibkey: persing-ng-2017-lightly
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '594'
  page_last: '604'
  pages: "594\u2013604"
  paper_id: '60'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1060.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1060.jpg
  title: Lightly-Supervised Modeling of Argument Persuasiveness
  title_html: Lightly-Supervised Modeling of Argument Persuasiveness
  url: https://www.aclweb.org/anthology/I17-1060
  year: '2017'
I17-1061:
  abstract: "Building a persona-based conversation agent is challenging owing to the\
    \ lack of large amounts of speaker-specific conversation data for model training.\
    \ This paper addresses the problem by proposing a multi-task learning approach\
    \ to training neural conversation models that leverages both conversation data\
    \ across speakers and other types of data pertaining to the speaker and speaker\
    \ roles to be modeled. Experiments show that our approach leads to significant\
    \ improvements over baseline model quality, generating responses that capture\
    \ more precisely speakers\u2019 traits and speaking styles. The model offers the\
    \ benefits of being algorithmically simple and easy to implement, and not relying\
    \ on large quantities of data representing specific individual speakers."
  address: Taipei, Taiwan
  author:
  - first: Yi
    full: Yi Luan
    id: yi-luan
    last: Luan
  - first: Chris
    full: Chris Brockett
    id: chris-brockett
    last: Brockett
  - first: Bill
    full: Bill Dolan
    id: bill-dolan
    last: Dolan
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  - first: Michel
    full: Michel Galley
    id: michel-galley
    last: Galley
  author_string: Yi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao, Michel Galley
  bibkey: luan-etal-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '605'
  page_last: '614'
  pages: "605\u2013614"
  paper_id: '61'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1061.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1061.jpg
  title: Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation Models
  title_html: Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation
    Models
  url: https://www.aclweb.org/anthology/I17-1061
  year: '2017'
I17-1062:
  abstract: Thread disentanglement is a precursor to any high-level analysis of multiparticipant
    chats. Existing research approaches the problem by calculating the likelihood
    of two messages belonging in the same thread. Our approach leverages a newly annotated
    dataset to identify reply relationships. Furthermore, we explore the usage of
    an RNN, along with large quantities of unlabeled data, to learn semantic relationships
    between messages. Our proposed pipeline, which utilizes a reply classifier and
    an RNN to generate a set of disentangled threads, is novel and performs well against
    previous work.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1062.Datasets.tgz
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1062.Datasets.tgz
  author:
  - first: Shikib
    full: Shikib Mehri
    id: shikib-mehri
    last: Mehri
  - first: Giuseppe
    full: Giuseppe Carenini
    id: giuseppe-carenini
    last: Carenini
  author_string: Shikib Mehri, Giuseppe Carenini
  bibkey: mehri-carenini-2017-chat
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '615'
  page_last: '623'
  pages: "615\u2013623"
  paper_id: '62'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1062.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1062.jpg
  title: 'Chat Disentanglement: Identifying Semantic Reply Relationships with Random
    Forests and Recurrent Neural Networks'
  title_html: 'Chat Disentanglement: Identifying Semantic Reply Relationships with
    Random Forests and Recurrent Neural Networks'
  url: https://www.aclweb.org/anthology/I17-1062
  year: '2017'
I17-1063:
  abstract: "We present a major step towards the creation of the first high-coverage\
    \ lexicon of polarity shifters. In this work, we bootstrap a lexicon of verbs\
    \ by exploiting various linguistic features. Polarity shifters, such as \u201C\
    abandon\u201D, are similar to negations (e.g. \u201Cnot\u201D) in that they move\
    \ the polarity of a phrase towards its inverse, as in \u201Cabandon all hope\u201D\
    . While there exist lists of negation words, creating comprehensive lists of polarity\
    \ shifters is far more challenging due to their sheer number. On a sample of manually\
    \ annotated verbs we examine a variety of linguistic features for this task. Then\
    \ we build a supervised classifier to increase coverage. We show that this approach\
    \ drastically reduces the annotation effort while ensuring a high-precision lexicon.\
    \ We also show that our acquired knowledge of verbal polarity shifters improves\
    \ phrase-level sentiment analysis."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1063.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/I17-1063.Presentation.pdf
  author:
  - first: Marc
    full: Marc Schulder
    id: marc-schulder
    last: Schulder
  - first: Michael
    full: Michael Wiegand
    id: michael-wiegand
    last: Wiegand
  - first: Josef
    full: Josef Ruppenhofer
    id: josef-ruppenhofer
    last: Ruppenhofer
  - first: Benjamin
    full: Benjamin Roth
    id: benjamin-roth
    last: Roth
  author_string: Marc Schulder, Michael Wiegand, Josef Ruppenhofer, Benjamin Roth
  bibkey: schulder-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '624'
  page_last: '633'
  pages: "624\u2013633"
  paper_id: '63'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1063.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1063.jpg
  title: Towards Bootstrapping a Polarity Shifter Lexicon using Linguistic Features
  title_html: Towards Bootstrapping a Polarity Shifter Lexicon using Linguistic Features
  url: https://www.aclweb.org/anthology/I17-1063
  year: '2017'
I17-1064:
  abstract: Document-level sentiment classification aims to assign the user reviews
    a sentiment polarity. Previous methods either just utilized the document content
    without consideration of user and product information, or did not comprehensively
    consider what roles the three kinds of information play in text modeling. In this
    paper, to reasonably use all the information, we present the idea that user, product
    and their combination can all influence the generation of attentions to words
    and sentences, when judging the sentiment of a document. With this idea, we propose
    a cascading multiway attention (CMA) model, where multiple ways of using user
    and product information are cascaded to influence the generation of attentions
    on the word and sentence layers. Then, sentences and documents are well modeled
    by multiple representation vectors, which provide rich information for sentiment
    classification. Experiments on IMDB and Yelp datasets demonstrate the effectiveness
    of our model.
  address: Taipei, Taiwan
  author:
  - first: Dehong
    full: Dehong Ma
    id: dehong-ma
    last: Ma
  - first: Sujian
    full: Sujian Li
    id: sujian-li
    last: Li
  - first: Xiaodong
    full: Xiaodong Zhang
    id: xiaodong-zhang
    last: Zhang
  - first: Houfeng
    full: Houfeng Wang
    id: houfeng-wang
    last: Wang
  - first: Xu
    full: Xu Sun
    id: xu-sun
    last: Sun
  author_string: Dehong Ma, Sujian Li, Xiaodong Zhang, Houfeng Wang, Xu Sun
  bibkey: ma-etal-2017-cascading
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '634'
  page_last: '643'
  pages: "634\u2013643"
  paper_id: '64'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1064.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1064.jpg
  title: Cascading Multiway Attentions for Document-level Sentiment Classification
  title_html: Cascading Multiway Attentions for Document-level Sentiment Classification
  url: https://www.aclweb.org/anthology/I17-1064
  year: '2017'
I17-1065:
  abstract: 'Deep learning models have recently been applied successfully in natural
    language processing, especially sentiment analysis. Each deep learning model has
    a particular advantage, but it is difficult to combine these advantages into one
    model, especially in the area of sentiment analysis. In our approach, Convolutional
    Neural Network (CNN) and Long Short Term Memory (LSTM) were utilized to learn
    sentiment-specific features in a freezing scheme. This scenario provides a novel
    and efficient way for integrating advantages of deep learning models. In addition,
    we also grouped documents into clusters by their similarity and applied the prediction
    score of Naive Bayes SVM (NBSVM) method to boost the classification accuracy of
    each group. The experiments show that our method achieves the state-of-the-art
    performance on two well-known datasets: IMDB large movie reviews for document
    level and Pang & Lee movie reviews for sentence level.'
  address: Taipei, Taiwan
  author:
  - first: Huy Tien
    full: Huy Tien Nguyen
    id: huy-tien-nguyen
    last: Nguyen
  - first: Minh Le
    full: Minh Le Nguyen
    id: minh-le-nguyen
    last: Nguyen
  author_string: Huy Tien Nguyen, Minh Le Nguyen
  bibkey: nguyen-nguyen-2017-ensemble
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '644'
  page_last: '653'
  pages: "644\u2013653"
  paper_id: '65'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1065.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1065.jpg
  title: An Ensemble Method with Sentiment Features and Clustering Support
  title_html: An Ensemble Method with Sentiment Features and Clustering Support
  url: https://www.aclweb.org/anthology/I17-1065
  year: '2017'
I17-1066:
  abstract: In this paper, we study domain adaptation with a state-of-the-art hierarchical
    neural network for document-level sentiment classification. We first design a
    new auxiliary task based on sentiment scores of domain-independent words. We then
    propose two neural network architectures to respectively induce document embeddings
    and sentence embeddings that work well for different domains. When these document
    and sentence embeddings are used for sentiment classification, we find that with
    both pseudo and external sentiment lexicons, our proposed methods can perform
    similarly to or better than several highly competitive domain adaptation methods
    on a benchmark dataset of product reviews.
  address: Taipei, Taiwan
  author:
  - first: Jianfei
    full: Jianfei Yu
    id: jianfei-yu
    last: Yu
  - first: Jing
    full: Jing Jiang
    id: jing-jiang
    last: Jiang
  author_string: Jianfei Yu, Jing Jiang
  bibkey: yu-jiang-2017-leveraging
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '654'
  page_last: '663'
  pages: "654\u2013663"
  paper_id: '66'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1066.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1066.jpg
  title: Leveraging Auxiliary Tasks for Document-Level Cross-Domain Sentiment Classification
  title_html: Leveraging Auxiliary Tasks for Document-Level Cross-Domain Sentiment
    Classification
  url: https://www.aclweb.org/anthology/I17-1066
  year: '2017'
I17-1067:
  abstract: "The things people do in their daily lives can provide valuable insights\
    \ into their personality, values, and interests. Unstructured text data on social\
    \ media platforms are rich in behavioral content, and automated systems can be\
    \ deployed to learn about human activity on a broad scale if these systems are\
    \ able to reason about the content of interest. In order to aid in the evaluation\
    \ of such systems, we introduce a new phrase-level semantic textual similarity\
    \ dataset comprised of human activity phrases, providing a testbed for automated\
    \ systems that analyze relationships between phrasal descriptions of people\u2019\
    s actions. Our set of 1,000 pairs of activities is annotated by human judges across\
    \ four relational dimensions including similarity, relatedness, motivational alignment,\
    \ and perceived actor congruence. We evaluate a set of strong baselines for the\
    \ task of generating scores that correlate highly with human ratings, and we introduce\
    \ several new approaches to the phrase-level similarity task in the domain of\
    \ human activities."
  address: Taipei, Taiwan
  author:
  - first: Steven
    full: Steven Wilson
    id: steven-wilson
    last: Wilson
  - first: Rada
    full: Rada Mihalcea
    id: rada-mihalcea
    last: Mihalcea
  author_string: Steven Wilson, Rada Mihalcea
  bibkey: wilson-mihalcea-2017-measuring
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '664'
  page_last: '673'
  pages: "664\u2013673"
  paper_id: '67'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1067.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1067.jpg
  title: Measuring Semantic Relations between Human Activities
  title_html: Measuring Semantic Relations between Human Activities
  url: https://www.aclweb.org/anthology/I17-1067
  year: '2017'
I17-1068:
  abstract: Typically, relation extraction models are trained to extract instances
    of a relation ontology using only training data from a single language. However,
    the concepts represented by the relation ontology (e.g. ResidesIn, EmployeeOf)
    are language independent. The numbers of annotated examples available for a given
    ontology vary between languages. For example, there are far fewer annotated examples
    in Spanish and Japanese than English and Chinese. Furthermore, using only language-specific
    training data results in the need to manually annotate equivalently large amounts
    of training for each new language a system encounters. We propose a deep neural
    network to learn transferable, discriminative bilingual representation. Experiments
    on the ACE 2005 multilingual training corpus demonstrate that the joint training
    process results in significant improvement in relation classification performance
    over the monolingual counterparts. The learnt representation is discriminative
    and transferable between languages. When using 10% (25K English words, or 30K
    Chinese characters) of the training data, our approach results in doubling F1
    compared to a monolingual baseline. We achieve comparable performance to the monolingual
    system trained with 250K English words (or 300K Chinese characters) With 50% of
    training data.
  address: Taipei, Taiwan
  author:
  - first: Bonan
    full: Bonan Min
    id: bonan-min
    last: Min
  - first: Zhuolin
    full: Zhuolin Jiang
    id: zhuolin-jiang
    last: Jiang
  - first: Marjorie
    full: Marjorie Freedman
    id: marjorie-freedman
    last: Freedman
  - first: Ralph
    full: Ralph Weischedel
    id: ralph-weischedel
    last: Weischedel
  author_string: Bonan Min, Zhuolin Jiang, Marjorie Freedman, Ralph Weischedel
  bibkey: min-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '674'
  page_last: '684'
  pages: "674\u2013684"
  paper_id: '68'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1068.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1068.jpg
  title: Learning Transferable Representation for Bilingual Relation Extraction via
    Convolutional Neural Networks
  title_html: Learning Transferable Representation for Bilingual Relation Extraction
    via Convolutional Neural Networks
  url: https://www.aclweb.org/anthology/I17-1068
  year: '2017'
I17-1069:
  abstract: "Bilingual lexicon extraction from comparable corpora is constrained by\
    \ the small amount of available data when dealing with specialized domains. This\
    \ aspect penalizes the performance of distributional-based approaches, which is\
    \ closely related to the reliability of word\u2019s cooccurrence counts extracted\
    \ from comparable corpora. A solution to avoid this limitation is to associate\
    \ external resources with the comparable corpus. Since bilingual word embeddings\
    \ have recently shown efficient models for learning bilingual distributed representation\
    \ of words, we explore different word embedding models and show how a general-domain\
    \ comparable corpus can enrich a specialized comparable corpus via neural networks"
  address: Taipei, Taiwan
  author:
  - first: Amir
    full: Amir Hazem
    id: amir-hazem
    last: Hazem
  - first: Emmanuel
    full: Emmanuel Morin
    id: emmanuel-morin
    last: Morin
  author_string: Amir Hazem, Emmanuel Morin
  bibkey: hazem-morin-2017-bilingual
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '685'
  page_last: '693'
  pages: "685\u2013693"
  paper_id: '69'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1069.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1069.jpg
  title: Bilingual Word Embeddings for Bilingual Terminology Extraction from Specialized
    Comparable Corpora
  title_html: Bilingual Word Embeddings for Bilingual Terminology Extraction from
    Specialized Comparable Corpora
  url: https://www.aclweb.org/anthology/I17-1069
  year: '2017'
I17-1070:
  abstract: 'In many languages such as Bambara or Arabic, tone markers (diacritics)
    may be written but are actually often omitted. NLP applications are confronted
    to ambiguities and subsequent difficulties when processing texts. To circumvent
    this problem, tonalization may be used, as a word sense disambiguation task, relying
    on context to add diacritics that partially disambiguate words as well as senses.
    In this paper, we describe our implementation of a Bambara tonalizer that adds
    tone markers using machine learning (CRFs). To make our tool efficient, we used
    differential coding, word segmentation and edit operation filtering. We describe
    our approach that allows tractable machine learning and improves accuracy: our
    model may be learned within minutes on a 358K-word corpus and reaches 92.3% accuracy.'
  address: Taipei, Taiwan
  author:
  - first: Luigi Yu-Cheng
    full: Luigi Yu-Cheng Liu
    id: luigi-yu-cheng-liu
    last: Liu
  - first: Damien
    full: Damien Nouvel
    id: damien-nouvel
    last: Nouvel
  author_string: Luigi Yu-Cheng Liu, Damien Nouvel
  bibkey: liu-nouvel-2017-bambara
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '694'
  page_last: '703'
  pages: "694\u2013703"
  paper_id: '70'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1070.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1070.jpg
  title: A Bambara Tonalization System for Word Sense Disambiguation Using Differential
    Coding, Segmentation and Edit Operation Filtering
  title_html: A <span class="acl-fixed-case">B</span>ambara Tonalization System for
    Word Sense Disambiguation Using Differential Coding, Segmentation and Edit Operation
    Filtering
  url: https://www.aclweb.org/anthology/I17-1070
  year: '2017'
I17-1071:
  abstract: "Dialog act segmentation and recognition are basic natural language understanding\
    \ tasks in spoken dialog systems. This paper investigates a unified architecture\
    \ for these two tasks, which aims to improve the model\u2019s performance on both\
    \ of the tasks. Compared with past joint models, the proposed architecture can\
    \ (1) incorporate contextual information in dialog act recognition, and (2) integrate\
    \ models for tasks of different levels as a whole, i.e. dialog act segmentation\
    \ on the word level and dialog act recognition on the segment level. Experimental\
    \ results show that the joint training system outperforms the simple cascading\
    \ system and the joint coding system on both dialog act segmentation and recognition\
    \ tasks."
  address: Taipei, Taiwan
  author:
  - first: Tianyu
    full: Tianyu Zhao
    id: tianyu-zhao
    last: Zhao
  - first: Tatsuya
    full: Tatsuya Kawahara
    id: tatsuya-kawahara
    last: Kawahara
  author_string: Tianyu Zhao, Tatsuya Kawahara
  bibkey: zhao-kawahara-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '704'
  page_last: '712'
  pages: "704\u2013712"
  paper_id: '71'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1071.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1071.jpg
  title: Joint Learning of Dialog Act Segmentation and Recognition in Spoken Dialog
    Using Neural Networks
  title_html: Joint Learning of Dialog Act Segmentation and Recognition in Spoken
    Dialog Using Neural Networks
  url: https://www.aclweb.org/anthology/I17-1071
  year: '2017'
I17-1072:
  abstract: "User experience is essential for human-computer dialogue systems. However,\
    \ it is impractical to ask users to provide explicit feedbacks when the agents\u2019\
    \ responses displease them. Therefore, in this paper, we explore to predict users\u2019\
    \ imminent dissatisfactions caused by intelligent agents by analysing the existing\
    \ utterances in the dialogue sessions. To our knowledge, this is the first work\
    \ focusing on this task. Several possible factors that trigger negative emotions\
    \ are modelled. A relation sequence model (RSM) is proposed to encode the sequence\
    \ of appropriateness of current response with respect to the earlier utterances.\
    \ The experimental results show that the proposed structure is effective in modelling\
    \ emotional risk (possibility of negative feedback) than existing conversation\
    \ modelling approaches. Besides, strategies of obtaining distance supervision\
    \ data for pre-training are also discussed in this work. Balanced sampling with\
    \ respect to the last response in the distance supervision data are shown to be\
    \ reliable for data augmentation."
  address: Taipei, Taiwan
  author:
  - first: Xin
    full: Xin Wang
    id: xin-wang
    last: Wang
  - first: Jianan
    full: Jianan Wang
    id: jianan-wang
    last: Wang
  - first: Yuanchao
    full: Yuanchao Liu
    id: yuanchao-liu
    last: Liu
  - first: Xiaolong
    full: Xiaolong Wang
    id: xiaolong-wang
    last: Wang
  - first: Zhuoran
    full: Zhuoran Wang
    id: zhuoran-wang
    last: Wang
  - first: Baoxun
    full: Baoxun Wang
    id: baoxun-wang
    last: Wang
  author_string: Xin Wang, Jianan Wang, Yuanchao Liu, Xiaolong Wang, Zhuoran Wang,
    Baoxun Wang
  bibkey: wang-etal-2017-predicting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '713'
  page_last: '722'
  pages: "713\u2013722"
  paper_id: '72'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1072.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1072.jpg
  title: "Predicting Users\u2019 Negative Feedbacks in Multi-Turn Human-Computer Dialogues"
  title_html: "Predicting Users\u2019 Negative Feedbacks in Multi-Turn Human-Computer\
    \ Dialogues"
  url: https://www.aclweb.org/anthology/I17-1072
  year: '2017'
I17-1073:
  abstract: There are several dialog frameworks which allow manual specification of
    intents and rule based dialog flow. The rule based framework provides good control
    to dialog designers at the expense of being more time consuming and laborious.
    The job of a dialog designer can be reduced if we could identify pairs of user
    intents and corresponding responses automatically from prior conversations between
    users and agents. In this paper we propose an approach to find these frequent
    user utterances (which serve as examples for intents) and corresponding agent
    responses. We propose a novel SimCluster algorithm that extends standard K-means
    algorithm to simultaneously cluster user utterances and agent utterances by taking
    their adjacency information into account. The method also aligns these clusters
    to provide pairs of intents and response groups. We compare our results with those
    produced by using simple Kmeans clustering on a real dataset and observe upto
    10% absolute improvement in F1-scores. Through our experiments on synthetic dataset,
    we show that our algorithm gains more advantage over K-means algorithm when the
    data has large variance.
  address: Taipei, Taiwan
  author:
  - first: Dhiraj
    full: Dhiraj Madan
    id: dhiraj-madan
    last: Madan
  - first: Sachindra
    full: Sachindra Joshi
    id: sachindra-joshi
    last: Joshi
  author_string: Dhiraj Madan, Sachindra Joshi
  bibkey: madan-joshi-2017-finding
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '723'
  page_last: '732'
  pages: "723\u2013732"
  paper_id: '73'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1073.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1073.jpg
  title: Finding Dominant User Utterances And System Responses in Conversations
  title_html: Finding Dominant User Utterances And System Responses in Conversations
  url: https://www.aclweb.org/anthology/I17-1073
  year: '2017'
I17-1074:
  abstract: One of the major drawbacks of modularized task-completion dialogue systems
    is that each module is trained individually, which presents several challenges.
    For example, downstream modules are affected by earlier modules, and the performance
    of the entire system is not robust to the accumulated errors. This paper presents
    a novel end-to-end learning framework for task-completion dialogue systems to
    tackle such issues.Our neural dialogue system can directly interact with a structured
    database to assist users in accessing information and accomplishing certain tasks.
    The reinforcement learning based dialogue manager offers robust capabilities to
    handle noises caused by other components of the dialogue system. Our experiments
    in a movie-ticket booking domain show that our end-to-end system not only outperforms
    modularized dialogue system baselines for both objective and subjective evaluation,
    but also is robust to noises as demonstrated by several systematic experiments
    with different error granularity and rates specific to the language understanding
    module.
  address: Taipei, Taiwan
  author:
  - first: Xiujun
    full: Xiujun Li
    id: xiujun-li
    last: Li
  - first: Yun-Nung
    full: Yun-Nung Chen
    id: yun-nung-chen
    last: Chen
  - first: Lihong
    full: Lihong Li
    id: lihong-li
    last: Li
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  - first: Asli
    full: Asli Celikyilmaz
    id: asli-celikyilmaz
    last: Celikyilmaz
  author_string: Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao, Asli Celikyilmaz
  bibkey: li-etal-2017-end
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '733'
  page_last: '743'
  pages: "733\u2013743"
  paper_id: '74'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1074.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1074.jpg
  title: End-to-End Task-Completion Neural Dialogue Systems
  title_html: End-to-End Task-Completion Neural Dialogue Systems
  url: https://www.aclweb.org/anthology/I17-1074
  year: '2017'
I17-1075:
  abstract: We propose an end-to-end neural network to predict the geolocation of
    a tweet. The network takes as input a number of raw Twitter metadata such as the
    tweet message and associated user account information. Our model is language independent,
    and despite minimal feature engineering, it is interpretable and capable of learning
    location indicative words and timing patterns. Compared to state-of-the-art systems,
    our model outperforms them by 2%-6%. Additionally, we propose extensions to the
    model to compress representation learnt by the network into binary codes. Experiments
    show that it produces compact codes compared to benchmark hashing algorithms.
    An implementation of the model is released publicly.
  address: Taipei, Taiwan
  author:
  - first: Jey Han
    full: Jey Han Lau
    id: jey-han-lau
    last: Lau
  - first: Lianhua
    full: Lianhua Chi
    id: lianhua-chi
    last: Chi
  - first: Khoi-Nguyen
    full: Khoi-Nguyen Tran
    id: khoi-nguyen-tran
    last: Tran
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  author_string: Jey Han Lau, Lianhua Chi, Khoi-Nguyen Tran, Trevor Cohn
  bibkey: lau-etal-2017-end
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '744'
  page_last: '753'
  pages: "744\u2013753"
  paper_id: '75'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1075.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1075.jpg
  title: End-to-end Network for Twitter Geolocation Prediction and Hashing
  title_html: End-to-end Network for Twitter Geolocation Prediction and Hashing
  url: https://www.aclweb.org/anthology/I17-1075
  year: '2017'
I17-1076:
  abstract: "When reporting the news, journalists rely on the statements of stakeholders,\
    \ experts, and officials. The attribution of such a statement is verifiable if\
    \ its fidelity to the source can be confirmed or denied. In this paper, we develop\
    \ a new NLP task: determining the verifiability of an attribution based on linguistic\
    \ cues. We operationalize the notion of verifiability as a score between 0 and\
    \ 1 using human judgments in a comparison-based approach. Using crowdsourcing,\
    \ we create a dataset of verifiability-scored attributions, and demonstrate a\
    \ model that achieves an RMSE of 0.057 and Spearman\u2019s rank correlation of\
    \ 0.95 to human-generated scores. We discuss the application of this technique\
    \ to the analysis of mass media."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1076.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1076.Datasets.zip
  author:
  - first: Edward
    full: Edward Newell
    id: edward-newell
    last: Newell
  - first: Ariane
    full: Ariane Schang
    id: ariane-schang
    last: Schang
  - first: Drew
    full: Drew Margolin
    id: drew-margolin
    last: Margolin
  - first: Derek
    full: Derek Ruths
    id: derek-ruths
    last: Ruths
  author_string: Edward Newell, Ariane Schang, Drew Margolin, Derek Ruths
  bibkey: newell-etal-2017-assessing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '754'
  page_last: '763'
  pages: "754\u2013763"
  paper_id: '76'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1076.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1076.jpg
  title: Assessing the Verifiability of Attributions in News Text
  title_html: Assessing the Verifiability of Attributions in News Text
  url: https://www.aclweb.org/anthology/I17-1076
  year: '2017'
I17-1077:
  abstract: Several studies have demonstrated how language models of user attributes,
    such as personality, can be built by using the Facebook language of social media
    users in conjunction with their responses to psychology questionnaires. It is
    challenging to apply these models to make general predictions about attributes
    of communities, such as personality distributions across US counties, because
    it requires 1. the potentially inavailability of the original training data because
    of privacy and ethical regulations, 2. adapting Facebook language models to Twitter
    language without retraining the model, and 3. adapting from users to county-level
    collections of tweets. We propose a two-step algorithm, Target Side Domain Adaptation
    (TSDA) for such domain adaptation when no labeled Twitter/county data is available.
    TSDA corrects for the different word distributions between Facebook and Twitter
    and for the varying word distributions across counties by adjusting target side
    word frequencies; no changes to the trained model are made. In the case of predicting
    the Big Five county-level personality traits, TSDA outperforms a state-of-the-art
    domain adaptation method, gives county-level predictions that have fewer extreme
    outliers, higher year-to-year stability, and higher correlation with county-level
    outcomes.
  address: Taipei, Taiwan
  author:
  - first: Daniel
    full: Daniel Rieman
    id: daniel-rieman
    last: Rieman
  - first: Kokil
    full: Kokil Jaidka
    id: kokil-jaidka
    last: Jaidka
  - first: H. Andrew
    full: H. Andrew Schwartz
    id: h-andrew-schwartz
    last: Schwartz
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  author_string: Daniel Rieman, Kokil Jaidka, H. Andrew Schwartz, Lyle Ungar
  bibkey: rieman-etal-2017-domain
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '764'
  page_last: '773'
  pages: "764\u2013773"
  paper_id: '77'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1077.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1077.jpg
  title: Domain Adaptation from User-level Facebook Models to County-level Twitter
    Predictions
  title_html: Domain Adaptation from User-level <span class="acl-fixed-case">F</span>acebook
    Models to County-level Twitter Predictions
  url: https://www.aclweb.org/anthology/I17-1077
  year: '2017'
I17-1078:
  abstract: In the wake of a polarizing election, social media is laden with hateful
    content. To address various limitations of supervised hate speech classification
    methods including corpus bias and huge cost of annotation, we propose a weakly
    supervised two-path bootstrapping approach for an online hate speech detection
    model leveraging large-scale unlabeled data. This system significantly outperforms
    hate speech detection systems that are trained in a supervised manner using manually
    annotated data. Applying this model on a large quantity of tweets collected before,
    after, and on election day reveals motivations and patterns of inflammatory language.
  address: Taipei, Taiwan
  author:
  - first: Lei
    full: Lei Gao
    id: lei-gao
    last: Gao
  - first: Alexis
    full: Alexis Kuppersmith
    id: alexis-kuppersmith
    last: Kuppersmith
  - first: Ruihong
    full: Ruihong Huang
    id: ruihong-huang
    last: Huang
  author_string: Lei Gao, Alexis Kuppersmith, Ruihong Huang
  bibkey: gao-etal-2017-recognizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '774'
  page_last: '782'
  pages: "774\u2013782"
  paper_id: '78'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1078.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1078.jpg
  title: Recognizing Explicit and Implicit Hate Speech Using a Weakly Supervised Two-path
    Bootstrapping Approach
  title_html: Recognizing Explicit and Implicit Hate Speech Using a Weakly Supervised
    Two-path Bootstrapping Approach
  url: https://www.aclweb.org/anthology/I17-1078
  year: '2017'
I17-1079:
  abstract: "Traditional approaches to recommendation focus on learning from large\
    \ volumes of historical feedback to estimate simple numerical quantities (Will\
    \ a user click on a product? Make a purchase? etc.). Natural language approaches\
    \ that model information like product reviews have proved to be incredibly useful\
    \ in improving the performance of such methods, as reviews provide valuable auxiliary\
    \ information that can be used to better estimate latent user preferences and\
    \ item properties. In this paper, rather than using reviews as an inputs to a\
    \ recommender system, we focus on generating reviews as the model\u2019s output.\
    \ This requires us to efficiently model text (at the character level) to capture\
    \ the preferences of the user, the properties of the item being consumed, and\
    \ the interaction between them (i.e., the user\u2019s preference). We show that\
    \ this can model can be used to (a) generate plausible reviews and estimate nuanced\
    \ reactions; (b) provide personalized rankings of existing reviews; and (c) recommend\
    \ existing products more effectively."
  address: Taipei, Taiwan
  author:
  - first: Jianmo
    full: Jianmo Ni
    id: jianmo-ni
    last: Ni
  - first: Zachary C.
    full: Zachary C. Lipton
    id: zachary-c-lipton
    last: Lipton
  - first: Sharad
    full: Sharad Vikram
    id: sharad-vikram
    last: Vikram
  - first: Julian
    full: Julian McAuley
    id: julian-mcauley
    last: McAuley
  author_string: Jianmo Ni, Zachary C. Lipton, Sharad Vikram, Julian McAuley
  bibkey: ni-etal-2017-estimating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '783'
  page_last: '791'
  pages: "783\u2013791"
  paper_id: '79'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1079.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1079.jpg
  title: Estimating Reactions and Recommending Products with Generative Models of
    Reviews
  title_html: Estimating Reactions and Recommending Products with Generative Models
    of Reviews
  url: https://www.aclweb.org/anthology/I17-1079
  year: '2017'
I17-1080:
  abstract: In this research, we propose the task of question summarization. We first
    analyzed question-summary pairs extracted from a Community Question Answering
    (CQA) site, and found that a proportion of questions cannot be summarized by extractive
    approaches but requires abstractive approaches. We created a dataset by regarding
    the question-title pairs posted on the CQA site as question-summary pairs. By
    using the data, we trained extractive and abstractive summarization models, and
    compared them based on ROUGE scores and manual evaluations. Our experimental results
    show an abstractive method using an encoder-decoder model with a copying mechanism
    achieves better scores for both ROUGE-2 F-measure and the evaluations by human
    judges.
  address: Taipei, Taiwan
  author:
  - first: Tatsuya
    full: Tatsuya Ishigaki
    id: tatsuya-ishigaki
    last: Ishigaki
  - first: Hiroya
    full: Hiroya Takamura
    id: hiroya-takamura
    last: Takamura
  - first: Manabu
    full: Manabu Okumura
    id: manabu-okumura
    last: Okumura
  author_string: Tatsuya Ishigaki, Hiroya Takamura, Manabu Okumura
  bibkey: ishigaki-etal-2017-summarizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '792'
  page_last: '800'
  pages: "792\u2013800"
  paper_id: '80'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1080.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1080.jpg
  title: Summarizing Lengthy Questions
  title_html: Summarizing Lengthy Questions
  url: https://www.aclweb.org/anthology/I17-1080
  year: '2017'
I17-1081:
  abstract: Concept-map-based multi-document summarization is a variant of traditional
    summarization that produces structured summaries in the form of concept maps.
    In this work, we propose a new model for the task that addresses several issues
    in previous methods. It learns to identify and merge coreferent concepts to reduce
    redundancy, determines their importance with a strong supervised model and finds
    an optimal summary concept map via integer linear programming. It is also computationally
    more efficient than previous methods, allowing us to summarize larger document
    sets. We evaluate the model on two datasets, finding that it outperforms several
    approaches from previous work.
  address: Taipei, Taiwan
  author:
  - first: Tobias
    full: Tobias Falke
    id: tobias-falke
    last: Falke
  - first: Christian M.
    full: Christian M. Meyer
    id: christian-m-meyer
    last: Meyer
  - first: Iryna
    full: Iryna Gurevych
    id: iryna-gurevych
    last: Gurevych
  author_string: Tobias Falke, Christian M. Meyer, Iryna Gurevych
  bibkey: falke-etal-2017-concept
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '801'
  page_last: '811'
  pages: "801\u2013811"
  paper_id: '81'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1081.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1081.jpg
  title: Concept-Map-Based Multi-Document Summarization using Concept Coreference
    Resolution and Global Importance Optimization
  title_html: Concept-Map-Based Multi-Document Summarization using Concept Coreference
    Resolution and Global Importance Optimization
  url: https://www.aclweb.org/anthology/I17-1081
  year: '2017'
I17-1082:
  abstract: Existing work for abstractive multidocument summarization utilise existing
    phrase structures directly extracted from input documents to generate summary
    sentences. These methods can suffer from lack of consistence and coherence in
    merging phrases. We introduce a novel approach for abstractive multidocument summarization
    through partial dependency tree extraction, recombination and linearization. The
    method entrusts the summarizer to generate its own topically coherent sequential
    structures from scratch for effective communication. Results on TAC 2011, DUC-2004
    and 2005 show that our system gives competitive results compared with state of
    the art abstractive summarization approaches in the literature. We also achieve
    competitive results in linguistic quality assessed by human evaluators.
  address: Taipei, Taiwan
  author:
  - first: Litton
    full: Litton J Kurisinkel
    id: litton-j-kurisinkel
    last: J Kurisinkel
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Vasudeva
    full: Vasudeva Varma
    id: vasudeva-varma
    last: Varma
  author_string: Litton J Kurisinkel, Yue Zhang, Vasudeva Varma
  bibkey: j-kurisinkel-etal-2017-abstractive
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '812'
  page_last: '821'
  pages: "812\u2013821"
  paper_id: '82'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1082.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1082.jpg
  title: Abstractive Multi-document Summarization by Partial Tree Extraction, Recombination
    and Linearization
  title_html: Abstractive Multi-document Summarization by Partial Tree Extraction,
    Recombination and Linearization
  url: https://www.aclweb.org/anthology/I17-1082
  year: '2017'
I17-1083:
  abstract: In this paper we investigate the performance of event argument identification.
    We show that the performance is tied to syntactic complexity. Based on this finding,
    we propose a novel and effective system for event argument identification. Recurrent
    Neural Networks learn to produce meaningful representations of long and short
    dependency paths. Convolutional Neural Networks learn to decompose the lexical
    context of argument candidates. They are combined into a simple system which outperforms
    a feature-based, state-of-the-art event argument identifier without any manual
    feature engineering.
  address: Taipei, Taiwan
  author:
  - first: Alex
    full: Alex Judea
    id: alex-judea
    last: Judea
  - first: Michael
    full: Michael Strube
    id: michael-strube
    last: Strube
  author_string: Alex Judea, Michael Strube
  bibkey: judea-strube-2017-event
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '822'
  page_last: '831'
  pages: "822\u2013831"
  paper_id: '83'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1083.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1083.jpg
  title: Event Argument Identification on Dependency Graphs with Bidirectional LSTMs
  title_html: Event Argument Identification on Dependency Graphs with Bidirectional
    <span class="acl-fixed-case">LSTM</span>s
  url: https://www.aclweb.org/anthology/I17-1083
  year: '2017'
I17-1084:
  abstract: Cross-lingual open information extraction is the task of distilling facts
    from the source language into representations in the target language. We propose
    a novel encoder-decoder model for this problem. It employs a novel selective decoding
    mechanism, which explicitly models the sequence labeling process as well as the
    sequence generation process on the decoder side. Compared to a standard encoder-decoder
    model, selective decoding significantly increases the performance on a Chinese-English
    cross-lingual open IE dataset by 3.87-4.49 BLEU and 1.91-5.92 F1. We also extend
    our approach to low-resource scenarios, and gain promising improvement.
  address: Taipei, Taiwan
  author:
  - first: Sheng
    full: Sheng Zhang
    id: sheng-zhang
    last: Zhang
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  author_string: Sheng Zhang, Kevin Duh, Benjamin Van Durme
  bibkey: zhang-etal-2017-selective
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '832'
  page_last: '842'
  pages: "832\u2013842"
  paper_id: '84'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1084.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1084.jpg
  title: Selective Decoding for Cross-lingual Open Information Extraction
  title_html: Selective Decoding for Cross-lingual Open Information Extraction
  url: https://www.aclweb.org/anthology/I17-1084
  year: '2017'
I17-1085:
  abstract: "This paper improves on several aspects of a sieve-based event ordering\
    \ architecture, CAEVO (Chambers et al., 2014), which creates globally consistent\
    \ temporal relations between events and time expressions. First, we examine the\
    \ usage of word embeddings and semantic role features. With the incorporation\
    \ of these new features, we demonstrate a 5% relative F1 gain over our replicated\
    \ version of CAEVO. Second, we reformulate the architecture\u2019s sieve-based\
    \ inference algorithm as a prediction reranking method that approximately optimizes\
    \ a scoring function computed using classifier precisions. Within this prediction\
    \ reranking framework, we propose an alternative scoring function, showing an\
    \ 8.8% relative gain over the original CAEVO. We further include an in-depth analysis\
    \ of one of the main datasets that is used to evaluate temporal classifiers, and\
    \ we show how despite using the densest corpus, there is still a danger of overfitting.\
    \ While this paper focuses on temporal ordering, its results are applicable to\
    \ other areas that use sieve-based architectures."
  address: Taipei, Taiwan
  author:
  - first: Bill
    full: Bill McDowell
    id: bill-mcdowell
    last: McDowell
  - first: Nathanael
    full: Nathanael Chambers
    id: nathanael-chambers
    last: Chambers
  - first: Alexander
    full: Alexander Ororbia II
    id: alexander-ororbia-ii
    last: Ororbia II
  - first: David
    full: David Reitter
    id: david-reitter
    last: Reitter
  author_string: Bill McDowell, Nathanael Chambers, Alexander Ororbia II, David Reitter
  bibkey: mcdowell-etal-2017-event
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '843'
  page_last: '853'
  pages: "843\u2013853"
  paper_id: '85'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1085.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1085.jpg
  title: Event Ordering with a Generalized Model for Sieve Prediction Ranking
  title_html: Event Ordering with a Generalized Model for Sieve Prediction Ranking
  url: https://www.aclweb.org/anthology/I17-1085
  year: '2017'
I17-1086:
  abstract: Previous open Relation Extraction (open RE) approaches mainly rely on
    linguistic patterns and constraints to extract important relational triples from
    large-scale corpora. However, they lack of abilities to cover diverse relation
    expressions or measure the relative importance of candidate triples within a sentence.
    It is also challenging to name the relation type of a relational triple merely
    based on context words, which could limit the usefulness of open RE in downstream
    applications. We propose a novel importance-based open RE approach by exploiting
    the global structure of a dependency tree to extract salient triples. We design
    an unsupervised relation type naming method by grounding relational triples to
    a large-scale Knowledge Base (KB) schema, leveraging KB triples and weighted context
    words associated with relational triples. Experiments on the English Slot Filling
    2013 dataset demonstrate that our approach achieves 8.1% higher F-score over state-of-the-art
    open RE methods.
  address: Taipei, Taiwan
  author:
  - first: Dian
    full: Dian Yu
    id: dian-yu
    last: Yu
  - first: Lifu
    full: Lifu Huang
    id: lifu-huang
    last: Huang
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  author_string: Dian Yu, Lifu Huang, Heng Ji
  bibkey: yu-etal-2017-open
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '854'
  page_last: '864'
  pages: "854\u2013864"
  paper_id: '86'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1086.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1086.jpg
  title: Open Relation Extraction and Grounding
  title_html: Open Relation Extraction and Grounding
  url: https://www.aclweb.org/anthology/I17-1086
  year: '2017'
I17-1087:
  abstract: 'Genetic information in the literature has been extensively looked into
    for the purpose of discovering the etiology of a disease. As the gene-disease
    relation is sensitive to external factors, their identification is important to
    study a disease. Environmental influences, which are usually called Gene-Environment
    interaction (GxE), have been considered as important factors and have extensively
    been researched in biology. Nevertheless, there is still a lack of systems for
    automatic GxE extraction from the biomedical literature due to new challenges:
    (1) there are no preprocessing tools and corpora for GxE, (2) expressions of GxE
    are often quite implicit, and (3) document-level comprehension is usually required.
    We propose to overcome these challenges with neural network models and show that
    a modified sequence-to-sequence model with a static RNN decoder produces a good
    performance in GxE recognition.'
  address: Taipei, Taiwan
  author:
  - first: Jinseon
    full: Jinseon You
    id: jinseon-you
    last: You
  - first: Jin-Woo
    full: Jin-Woo Chung
    id: jin-woo-chung
    last: Chung
  - first: Wonsuk
    full: Wonsuk Yang
    id: wonsuk-yang
    last: Yang
  - first: Jong C.
    full: Jong C. Park
    id: jong-c-park
    last: Park
  author_string: Jinseon You, Jin-Woo Chung, Wonsuk Yang, Jong C. Park
  bibkey: you-etal-2017-extraction
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '865'
  page_last: '874'
  pages: "865\u2013874"
  paper_id: '87'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1087.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1087.jpg
  title: Extraction of Gene-Environment Interaction from the Biomedical Literature
  title_html: Extraction of Gene-Environment Interaction from the Biomedical Literature
  url: https://www.aclweb.org/anthology/I17-1087
  year: '2017'
I17-1088:
  abstract: Massive Open Online Courses (MOOCs), offering a new way to study online,
    are revolutionizing education. One challenging issue in MOOCs is how to design
    effective and fine-grained course concepts such that students with different backgrounds
    can grasp the essence of the course. In this paper, we conduct a systematic investigation
    of the problem of course concept extraction for MOOCs. We propose to learn latent
    representations for candidate concepts via an embedding-based method. Moreover,
    we develop a graph-based propagation algorithm to rank the candidate concepts
    based on the learned representations. We evaluate the proposed method using different
    courses from XuetangX and Coursera. Experimental results show that our method
    significantly outperforms all the alternative methods (+0.013-0.318 in terms of
    R-precision; p<<0.01, t-test).
  address: Taipei, Taiwan
  author:
  - first: Liangming
    full: Liangming Pan
    id: liangming-pan
    last: Pan
  - first: Xiaochen
    full: Xiaochen Wang
    id: xiaochen-wang
    last: Wang
  - first: Chengjiang
    full: Chengjiang Li
    id: chengjiang-li
    last: Li
  - first: Juanzi
    full: Juanzi Li
    id: juanzi-li
    last: Li
  - first: Jie
    full: Jie Tang
    id: jie-tang
    last: Tang
  author_string: Liangming Pan, Xiaochen Wang, Chengjiang Li, Juanzi Li, Jie Tang
  bibkey: pan-etal-2017-course
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '875'
  page_last: '884'
  pages: "875\u2013884"
  paper_id: '88'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1088.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1088.jpg
  title: Course Concept Extraction in MOOCs via Embedding-Based Graph Propagation
  title_html: Course Concept Extraction in <span class="acl-fixed-case">MOOC</span>s
    via Embedding-Based Graph Propagation
  url: https://www.aclweb.org/anthology/I17-1088
  year: '2017'
I17-1089:
  abstract: This paper addresses the task of detecting identity deception in language.
    Using a novel identity deception dataset, consisting of real and portrayed identities
    from 600 individuals, we show that we can build accurate identity detectors targeting
    both age and gender, with accuracies of up to 88. We also perform an analysis
    of the linguistic patterns used in identity deception, which lead to interesting
    insights into identity portrayers.
  address: Taipei, Taiwan
  author:
  - first: "Ver\xF3nica"
    full: "Ver\xF3nica P\xE9rez-Rosas"
    id: veronica-perez-rosas
    last: "P\xE9rez-Rosas"
  - first: Quincy
    full: Quincy Davenport
    id: quincy-davenport
    last: Davenport
  - first: Anna Mengdan
    full: Anna Mengdan Dai
    id: anna-mengdan-dai
    last: Dai
  - first: Mohamed
    full: Mohamed Abouelenien
    id: mohamed-abouelenien
    last: Abouelenien
  - first: Rada
    full: Rada Mihalcea
    id: rada-mihalcea
    last: Mihalcea
  author_string: "Ver\xF3nica P\xE9rez-Rosas, Quincy Davenport, Anna Mengdan Dai,\
    \ Mohamed Abouelenien, Rada Mihalcea"
  bibkey: perez-rosas-etal-2017-identity
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '885'
  page_last: '894'
  pages: "885\u2013894"
  paper_id: '89'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1089.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1089.jpg
  title: Identity Deception Detection
  title_html: Identity Deception Detection
  url: https://www.aclweb.org/anthology/I17-1089
  year: '2017'
I17-1090:
  abstract: "Clinical diagnosis is a critical and non-trivial aspect of patient care\
    \ which often requires significant medical research and investigation based on\
    \ an underlying clinical scenario. This paper proposes a novel approach by formulating\
    \ clinical diagnosis as a reinforcement learning problem. During training, the\
    \ reinforcement learning agent mimics the clinician\u2019s cognitive process and\
    \ learns the optimal policy to obtain the most appropriate diagnoses for a clinical\
    \ narrative. This is achieved through an iterative search for candidate diagnoses\
    \ from external knowledge sources via a sentence-by-sentence analysis of the inherent\
    \ clinical context. A deep Q-network architecture is trained to optimize a reward\
    \ function that measures the accuracy of the candidate diagnoses. Experiments\
    \ on the TREC CDS datasets demonstrate the effectiveness of our system over various\
    \ non-reinforcement learning-based systems."
  address: Taipei, Taiwan
  author:
  - first: Yuan
    full: Yuan Ling
    id: yuan-ling
    last: Ling
  - first: Sadid A.
    full: Sadid A. Hasan
    id: sadid-a-hasan
    last: Hasan
  - first: Vivek
    full: Vivek Datla
    id: vivek-datla
    last: Datla
  - first: Ashequl
    full: Ashequl Qadir
    id: ashequl-qadir
    last: Qadir
  - first: Kathy
    full: Kathy Lee
    id: kathy-lee
    last: Lee
  - first: Joey
    full: Joey Liu
    id: joey-liu
    last: Liu
  - first: Oladimeji
    full: Oladimeji Farri
    id: oladimeji-farri
    last: Farri
  author_string: Yuan Ling, Sadid A. Hasan, Vivek Datla, Ashequl Qadir, Kathy Lee,
    Joey Liu, Oladimeji Farri
  bibkey: ling-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '895'
  page_last: '905'
  pages: "895\u2013905"
  paper_id: '90'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1090.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1090.jpg
  title: 'Learning to Diagnose: Assimilating Clinical Narratives using Deep Reinforcement
    Learning'
  title_html: 'Learning to Diagnose: Assimilating Clinical Narratives using Deep Reinforcement
    Learning'
  url: https://www.aclweb.org/anthology/I17-1090
  year: '2017'
I17-1091:
  abstract: Progress in natural language interfaces to databases (NLIDB) has been
    slow mainly due to linguistic issues (such as language ambiguity) and domain portability.
    Moreover, the lack of a large corpus to be used as a standard benchmark has made
    data-driven approaches difficult to develop and compare. In this paper, we revisit
    the problem of NLIDBs and recast it as a sequence translation problem. To this
    end, we introduce a large dataset extracted from the Stack Exchange Data Explorer
    website, which can be used for training neural natural language interfaces for
    databases. We also report encouraging baseline results on a smaller manually annotated
    test corpus, obtained using an attention-based sequence-to-sequence neural network.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1091.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1091.Datasets.zip
  author:
  - first: Florin
    full: Florin Brad
    id: florin-brad
    last: Brad
  - first: Radu Cristian Alexandru
    full: Radu Cristian Alexandru Iacob
    id: radu-cristian-alexandru-iacob
    last: Iacob
  - first: Ionel Alexandru
    full: Ionel Alexandru Hosu
    id: ionel-alexandru-hosu
    last: Hosu
  - first: Traian
    full: Traian Rebedea
    id: traian-rebedea
    last: Rebedea
  author_string: Florin Brad, Radu Cristian Alexandru Iacob, Ionel Alexandru Hosu,
    Traian Rebedea
  bibkey: brad-etal-2017-dataset
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '906'
  page_last: '914'
  pages: "906\u2013914"
  paper_id: '91'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1091.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1091.jpg
  title: Dataset for a Neural Natural Language Interface for Databases (NNLIDB)
  title_html: Dataset for a Neural Natural Language Interface for Databases (<span
    class="acl-fixed-case">NNLIDB</span>)
  url: https://www.aclweb.org/anthology/I17-1091
  year: '2017'
I17-1092:
  abstract: "In a dialogue system, the dialogue manager selects one of several system\
    \ actions and thereby determines the system\u2019s behaviour. Defining all possible\
    \ system actions in a dialogue system by hand is a tedious work. While efforts\
    \ have been made to automatically generate such system actions, those approaches\
    \ are mostly focused on providing functional system behaviour. Adapting the system\
    \ behaviour to the user becomes a difficult task due to the limited amount of\
    \ system actions available. We aim to increase the adaptability of a dialogue\
    \ system by automatically generating variants of system actions. In this work,\
    \ we introduce an approach to automatically generate action variants for elaborateness\
    \ and indirectness. Our proposed algorithm extracts RDF triplets from a knowledge\
    \ base and rates their relevance to the original system action to find suitable\
    \ content. We show that the results of our algorithm are mostly perceived similarly\
    \ to human generated elaborateness and indirectness and can be used to adapt a\
    \ conversation to the current user and situation. We also discuss where the results\
    \ of our algorithm are still lacking and how this could be improved: Taking into\
    \ account the conversation topic as well as the culture of the user is likely\
    \ to have beneficial effect on the user\u2019s perception."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1092.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-1092.Notes.pdf
  author:
  - first: Louisa
    full: Louisa Pragst
    id: louisa-pragst
    last: Pragst
  - first: Koichiro
    full: Koichiro Yoshino
    id: koichiro-yoshino
    last: Yoshino
  - first: Wolfgang
    full: Wolfgang Minker
    id: wolfgang-minker
    last: Minker
  - first: Satoshi
    full: Satoshi Nakamura
    id: satoshi-nakamura
    last: Nakamura
  - first: Stefan
    full: Stefan Ultes
    id: stefan-ultes
    last: Ultes
  author_string: Louisa Pragst, Koichiro Yoshino, Wolfgang Minker, Satoshi Nakamura,
    Stefan Ultes
  bibkey: pragst-etal-2017-acquisition
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '915'
  page_last: '925'
  pages: "915\u2013925"
  paper_id: '92'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1092.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1092.jpg
  title: Acquisition and Assessment of Semantic Content for the Generation of Elaborateness
    and Indirectness in Spoken Dialogue Systems
  title_html: Acquisition and Assessment of Semantic Content for the Generation of
    Elaborateness and Indirectness in Spoken Dialogue Systems
  url: https://www.aclweb.org/anthology/I17-1092
  year: '2017'
I17-1093:
  abstract: Most social media platforms grant users freedom of speech by allowing
    them to freely express their thoughts, beliefs, and opinions. Although this represents
    incredible and unique communication opportunities, it also presents important
    challenges. Online racism is such an example. In this study, we present a supervised
    learning strategy to detect racist language on Twitter based on word embedding
    that incorporate demographic (Age, Gender, and Location) information. Our methodology
    achieves reasonable classification accuracy over a gold standard dataset (F1=76.3%)
    and significantly improves over the classification performance of demographic-agnostic
    models.
  address: Taipei, Taiwan
  author:
  - first: Mohammed
    full: Mohammed Hasanuzzaman
    id: mohammed-hasanuzzaman
    last: Hasanuzzaman
  - first: "Ga\xEBl"
    full: "Ga\xEBl Dias"
    id: gael-dias
    last: Dias
  - first: Andy
    full: Andy Way
    id: andy-way
    last: Way
  author_string: "Mohammed Hasanuzzaman, Ga\xEBl Dias, Andy Way"
  bibkey: hasanuzzaman-etal-2017-demographic
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '926'
  page_last: '936'
  pages: "926\u2013936"
  paper_id: '93'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1093.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1093.jpg
  title: Demographic Word Embeddings for Racism Detection on Twitter
  title_html: Demographic Word Embeddings for Racism Detection on Twitter
  url: https://www.aclweb.org/anthology/I17-1093
  year: '2017'
I17-1094:
  abstract: Social media texts, such as tweets from Twitter, contain many types of
    non-standard tokens, and the number of normalization approaches for handling such
    noisy text has been increasing. We present a method for automatically extracting
    pairs of a variant word and its normal form from unsegmented text on the basis
    of a pair-wise similarity approach. We incorporated the acquired variant-normalization
    pairs into Japanese morphological analysis. The experimental results show that
    our method can extract widely covered variants from large Twitter data and improve
    the recall of normalization without degrading the overall accuracy of Japanese
    morphological analysis.
  address: Taipei, Taiwan
  author:
  - first: Itsumi
    full: Itsumi Saito
    id: itsumi-saito
    last: Saito
  - first: Kyosuke
    full: Kyosuke Nishida
    id: kyosuke-nishida
    last: Nishida
  - first: Kugatsu
    full: Kugatsu Sadamitsu
    id: kugatsu-sadamitsu
    last: Sadamitsu
  - first: Kuniko
    full: Kuniko Saito
    id: kuniko-saito
    last: Saito
  - first: Junji
    full: Junji Tomita
    id: junji-tomita
    last: Tomita
  author_string: Itsumi Saito, Kyosuke Nishida, Kugatsu Sadamitsu, Kuniko Saito, Junji
    Tomita
  bibkey: saito-etal-2017-automatically
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '937'
  page_last: '946'
  pages: "937\u2013946"
  paper_id: '94'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1094.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1094.jpg
  title: Automatically Extracting Variant-Normalization Pairs for Japanese Text Normalization
  title_html: Automatically Extracting Variant-Normalization Pairs for <span class="acl-fixed-case">J</span>apanese
    Text Normalization
  url: https://www.aclweb.org/anthology/I17-1094
  year: '2017'
I17-1095:
  abstract: In this paper, we model the document revision detection problem as a minimum
    cost branching problem that relies on computing document distances. Furthermore,
    we propose two new document distance measures, word vector-based Dynamic Time
    Warping (wDTW) and word vector-based Tree Edit Distance (wTED). Our revision detection
    system is designed for a large scale corpus and implemented in Apache Spark. We
    demonstrate that our system can more precisely detect revisions than state-of-the-art
    methods by utilizing the Wikipedia revision dumps and simulated data sets.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1095.Software.txt
    type: software
    url: https://www.aclweb.org/anthology/attachments/I17-1095.Software.txt
  - filename: I17-1095.Datasets.txt
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1095.Datasets.txt
  author:
  - first: Xiaofeng
    full: Xiaofeng Zhu
    id: xiaofeng-zhu
    last: Zhu
  - first: Diego
    full: Diego Klabjan
    id: diego-klabjan
    last: Klabjan
  - first: Patrick
    full: Patrick Bless
    id: patrick-bless
    last: Bless
  author_string: Xiaofeng Zhu, Diego Klabjan, Patrick Bless
  bibkey: zhu-etal-2017-semantic
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '947'
  page_last: '956'
  pages: "947\u2013956"
  paper_id: '95'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1095.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1095.jpg
  title: Semantic Document Distance Measures and Unsupervised Document Revision Detection
  title_html: Semantic Document Distance Measures and Unsupervised Document Revision
    Detection
  url: https://www.aclweb.org/anthology/I17-1095
  year: '2017'
I17-1096:
  abstract: Reading comprehension (RC) is a challenging task that requires synthesis
    of information across sentences and multiple turns of reasoning. Using a state-of-the-art
    RC model, we empirically investigate the performance of single-turn and multiple-turn
    reasoning on the SQuAD and MS MARCO datasets. The RC model is an end-to-end neural
    network with iterative attention, and uses reinforcement learning to dynamically
    control the number of turns. We find that multiple-turn reasoning outperforms
    single-turn reasoning for all question and answer types; further, we observe that
    enabling a flexible number of turns generally improves upon a fixed multiple-turn
    strategy. %across all question types, and is particularly beneficial to questions
    with lengthy, descriptive answers. We achieve results competitive to the state-of-the-art
    on these two datasets.
  address: Taipei, Taiwan
  author:
  - first: Yelong
    full: Yelong Shen
    id: yelong-shen
    last: Shen
  - first: Xiaodong
    full: Xiaodong Liu
    id: xiaodong-liu
    last: Liu
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  author_string: Yelong Shen, Xiaodong Liu, Kevin Duh, Jianfeng Gao
  bibkey: shen-etal-2017-empirical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '957'
  page_last: '966'
  pages: "957\u2013966"
  paper_id: '96'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1096.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1096.jpg
  title: An Empirical Analysis of Multiple-Turn Reasoning Strategies in Reading Comprehension
    Tasks
  title_html: An Empirical Analysis of Multiple-Turn Reasoning Strategies in Reading
    Comprehension Tasks
  url: https://www.aclweb.org/anthology/I17-1096
  year: '2017'
I17-1097:
  abstract: This paper presents a hybrid approach to the verification of statements
    about historical facts. The test data was collected from the world history examinations
    in a standardized achievement test for high school students. The data includes
    various kinds of false statements that were carefully written so as to deceive
    the students while they can be disproven on the basis of the teaching materials.
    Our system predicts the truth or falsehood of a statement based on text search,
    word cooccurrence statistics, factoid-style question answering, and temporal relation
    recognition. These features contribute to the judgement complementarily and achieved
    the state-of-the-art accuracy.
  address: Taipei, Taiwan
  author:
  - first: Mio
    full: Mio Kobayashi
    id: mio-kobayashi
    last: Kobayashi
  - first: Ai
    full: Ai Ishii
    id: ai-ishii
    last: Ishii
  - first: Chikara
    full: Chikara Hoshino
    id: chikara-hoshino
    last: Hoshino
  - first: Hiroshi
    full: Hiroshi Miyashita
    id: hiroshi-miyashita
    last: Miyashita
  - first: Takuya
    full: Takuya Matsuzaki
    id: takuya-matsuzaki
    last: Matsuzaki
  author_string: Mio Kobayashi, Ai Ishii, Chikara Hoshino, Hiroshi Miyashita, Takuya
    Matsuzaki
  bibkey: kobayashi-etal-2017-automated
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '967'
  page_last: '975'
  pages: "967\u2013975"
  paper_id: '97'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1097.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1097.jpg
  title: Automated Historical Fact-Checking by Passage Retrieval, Word Statistics,
    and Virtual Question-Answering
  title_html: Automated Historical Fact-Checking by Passage Retrieval, Word Statistics,
    and Virtual Question-Answering
  url: https://www.aclweb.org/anthology/I17-1097
  year: '2017'
I17-1098:
  abstract: This paper presents an approach to identify subject, type and property
    from knowledge base (KB) for answering simple questions. We propose new features
    to rank entity candidates in KB. Besides, we split a relation in KB into type
    and property. Each of them is modeled by a bi-directional LSTM. Experimental results
    show that our model achieves the state-of-the-art performance on the SimpleQuestions
    dataset. The hard questions in the experiments are also analyzed in detail.
  address: Taipei, Taiwan
  author:
  - first: Wei-Chuan
    full: Wei-Chuan Hsiao
    id: wei-chuan-hsiao
    last: Hsiao
  - first: Hen-Hsen
    full: Hen-Hsen Huang
    id: hen-hsen-huang
    last: Huang
  - first: Hsin-Hsi
    full: Hsin-Hsi Chen
    id: hsin-hsi-chen
    last: Chen
  author_string: Wei-Chuan Hsiao, Hen-Hsen Huang, Hsin-Hsi Chen
  bibkey: hsiao-etal-2017-integrating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '976'
  page_last: '985'
  pages: "976\u2013985"
  paper_id: '98'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1098.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1098.jpg
  title: Integrating Subject, Type, and Property Identification for Simple Question
    Answering over Knowledge Base
  title_html: Integrating Subject, Type, and Property Identification for Simple Question
    Answering over Knowledge Base
  url: https://www.aclweb.org/anthology/I17-1098
  year: '2017'
I17-1099:
  abstract: "We develop a high-quality multi-turn dialog dataset, DailyDialog,\twhich\
    \ is intriguing in several aspects. The language is human-written and less\tnoisy.\
    \ The dialogues in the dataset reflect our daily communication way and\tcover\
    \ various topics about our daily life. We also manually label the developed\t\
    dataset with communication intention and emotion information. Then, we evaluate\t\
    existing approaches on DailyDialog dataset and hope it benefit the research\t\
    field of dialog systems. The dataset is available on\thttp://yanran.li/dailydialog"
  address: Taipei, Taiwan
  attachment:
  - filename: I17-1099.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-1099.Datasets.zip
  author:
  - first: Yanran
    full: Yanran Li
    id: yanran-li
    last: Li
  - first: Hui
    full: Hui Su
    id: hui-su
    last: Su
  - first: Xiaoyu
    full: Xiaoyu Shen
    id: xiaoyu-shen
    last: Shen
  - first: Wenjie
    full: Wenjie Li
    id: wenjie-li
    last: Li
  - first: Ziqiang
    full: Ziqiang Cao
    id: ziqiang-cao
    last: Cao
  - first: Shuzi
    full: Shuzi Niu
    id: shuzi-niu
    last: Niu
  author_string: Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, Shuzi Niu
  bibkey: li-etal-2017-dailydialog
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '986'
  page_last: '995'
  pages: "986\u2013995"
  paper_id: '99'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1099.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1099.jpg
  title: 'DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset'
  title_html: '<span class="acl-fixed-case">D</span>aily<span class="acl-fixed-case">D</span>ialog:
    A Manually Labelled Multi-turn Dialogue Dataset'
  url: https://www.aclweb.org/anthology/I17-1099
  year: '2017'
I17-1100:
  abstract: "We propose to unify a variety of existing semantic classification tasks,\
    \ such as semantic role labeling, anaphora resolution, and paraphrase detection,\
    \ under the heading of Recognizing Textual Entailment (RTE). We present a general\
    \ strategy to automatically generate one or more sentential hypotheses based on\
    \ an input sentence and pre-existing manual semantic annotations. The resulting\
    \ suite of datasets enables us to probe a statistical RTE model\u2019s performance\
    \ on different aspects of semantics. We demonstrate the value of this approach\
    \ by investigating the behavior of a popular neural network RTE model."
  address: Taipei, Taiwan
  author:
  - first: Aaron Steven
    full: Aaron Steven White
    id: aaron-steven-white
    last: White
  - first: Pushpendre
    full: Pushpendre Rastogi
    id: pushpendre-rastogi
    last: Rastogi
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  author_string: Aaron Steven White, Pushpendre Rastogi, Kevin Duh, Benjamin Van Durme
  bibkey: white-etal-2017-inference
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '996'
  page_last: '1005'
  pages: "996\u20131005"
  paper_id: '100'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1100.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1100.jpg
  title: 'Inference is Everything: Recasting Semantic Resources into a Unified Evaluation
    Framework'
  title_html: 'Inference is Everything: Recasting Semantic Resources into a Unified
    Evaluation Framework'
  url: https://www.aclweb.org/anthology/I17-1100
  year: '2017'
I17-1101:
  abstract: In this paper we present a novel approach to the automatic correction
    of OCR-induced orthographic errors in a given text. While current systems depend
    heavily on large training corpora or external information, such as domain-specific
    lexicons or confidence scores from the OCR process, our system only requires a
    small amount of (relatively) clean training data from a representative corpus
    to learn a character-based statistical language model using Bidirectional Long
    Short-Term Memory Networks (biLSTMs). We demonstrate the versatility and adaptability
    of our system on different text corpora with varying degrees of textual noise,
    including a real-life OCR corpus in the medical domain.
  address: Taipei, Taiwan
  author:
  - first: Eva
    full: "Eva D\u2019hondt"
    id: eva-dhondt
    last: "D\u2019hondt"
  - first: Cyril
    full: Cyril Grouin
    id: cyril-grouin
    last: Grouin
  - first: Brigitte
    full: Brigitte Grau
    id: brigitte-grau
    last: Grau
  author_string: "Eva D\u2019hondt, Cyril Grouin, Brigitte Grau"
  bibkey: dhondt-etal-2017-generating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '1006'
  page_last: '1014'
  pages: "1006\u20131014"
  paper_id: '101'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1101.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1101.jpg
  title: Generating a Training Corpus for OCR Post-Correction Using Encoder-Decoder
    Model
  title_html: Generating a Training Corpus for <span class="acl-fixed-case">OCR</span>
    Post-Correction Using Encoder-Decoder Model
  url: https://www.aclweb.org/anthology/I17-1101
  year: '2017'
I17-1102:
  abstract: Hierarchical attention networks have recently achieved remarkable performance
    for document classification in a given language. However, when multilingual document
    collections are considered, training such models separately for each language
    entails linear parameter growth and lack of cross-language transfer. Learning
    a single multilingual model with fewer parameters is therefore a challenging but
    potentially beneficial objective. To this end, we propose multilingual hierarchical
    attention networks for learning document structures, with shared encoders and/or
    shared attention mechanisms across languages, using multi-task learning and an
    aligned semantic space as input. We evaluate the proposed models on multilingual
    document classification with disjoint label sets, on a large dataset which we
    provide, with 600k news documents in 8 languages, and 5k labels. The multilingual
    models outperform monolingual ones in low-resource as well as full-resource settings,
    and use fewer parameters, thus confirming their computational efficiency and the
    utility of cross-language transfer.
  address: Taipei, Taiwan
  author:
  - first: Nikolaos
    full: Nikolaos Pappas
    id: nikolaos-pappas
    last: Pappas
  - first: Andrei
    full: Andrei Popescu-Belis
    id: andrei-popescu-belis
    last: Popescu-Belis
  author_string: Nikolaos Pappas, Andrei Popescu-Belis
  bibkey: pappas-popescu-belis-2017-multilingual
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '1015'
  page_last: '1025'
  pages: "1015\u20131025"
  paper_id: '102'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1102.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1102.jpg
  title: Multilingual Hierarchical Attention Networks for Document Classification
  title_html: Multilingual Hierarchical Attention Networks for Document Classification
  url: https://www.aclweb.org/anthology/I17-1102
  year: '2017'
I17-1103:
  abstract: In this work we investigate how role-based behavior profiles of a Wikipedia
    editor, considered against the backdrop of roles taken up by other editors in
    discussions, predict the success of the editor at achieving an impact on the associated
    article. We first contribute a new public dataset including a task predicting
    the success of Wikipedia editors involved in discussion, measured by an operationalization
    of the lasting impact of their edits in the article. We then propose a probabilistic
    graphical model that advances earlier work inducing latent discussion roles using
    the light supervision of success in the negotiation task. We evaluate the performance
    of the model and interpret findings of roles and group configurations that lead
    to certain outcomes on Wikipedia.
  address: Taipei, Taiwan
  author:
  - first: Keith
    full: Keith Maki
    id: keith-maki
    last: Maki
  - first: Michael
    full: Michael Yoder
    id: michael-yoder
    last: Yoder
  - first: Yohan
    full: Yohan Jo
    id: yohan-jo
    last: Jo
  - first: Carolyn
    full: "Carolyn Ros\xE9"
    id: carolyn-rose
    last: "Ros\xE9"
  author_string: "Keith Maki, Michael Yoder, Yohan Jo, Carolyn Ros\xE9"
  bibkey: maki-etal-2017-roles
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)'
  month: November
  page_first: '1026'
  page_last: '1035'
  pages: "1026\u20131035"
  paper_id: '103'
  parent_volume_id: I17-1
  pdf: https://www.aclweb.org/anthology/I17-1103.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-1103.jpg
  title: 'Roles and Success in Wikipedia Talk Pages: Identifying Latent Patterns of
    Behavior'
  title_html: 'Roles and Success in <span class="acl-fixed-case">W</span>ikipedia
    Talk Pages: Identifying Latent Patterns of Behavior'
  url: https://www.aclweb.org/anthology/I17-1103
  year: '2017'
I17-2000:
  address: Taipei, Taiwan
  author:
  - first: Greg
    full: Greg Kondrak
    id: greg-kondrak
    last: Kondrak
  - first: Taro
    full: Taro Watanabe
    id: taro-watanabe
    last: Watanabe
  author_string: Greg Kondrak, Taro Watanabe
  bibkey: ijcnlp-2017-international-joint
  bibtype: proceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  paper_id: '0'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2000.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2000.jpg
  title: 'Proceedings of the Eighth International Joint Conference on Natural Language
    Processing (Volume 2: Short Papers)'
  title_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  url: https://www.aclweb.org/anthology/I17-2000
  year: '2017'
I17-2001:
  abstract: This paper proposes a new attention mechanism for neural machine translation
    (NMT) based on convolutional neural networks (CNNs), which is inspired by the
    CKY algorithm. The proposed attention represents every possible combination of
    source words (e.g., phrases and structures) through CNNs, which imitates the CKY
    table in the algorithm. NMT, incorporating the proposed attention, decodes a target
    sentence on the basis of the attention scores of the hidden states of CNNs. The
    proposed attention enables NMT to capture alignments from underlying structures
    of a source sentence without sentence parsing. The evaluations on the Asian Scientific
    Paper Excerpt Corpus (ASPEC) English-Japanese translation task show that the proposed
    attention gains 0.66 points in BLEU.
  address: Taipei, Taiwan
  author:
  - first: Taiki
    full: Taiki Watanabe
    id: taiki-watanabe
    last: Watanabe
  - first: Akihiro
    full: Akihiro Tamura
    id: akihiro-tamura
    last: Tamura
  - first: Takashi
    full: Takashi Ninomiya
    id: takashi-ninomiya
    last: Ninomiya
  author_string: Taiki Watanabe, Akihiro Tamura, Takashi Ninomiya
  bibkey: watanabe-etal-2017-cky
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '1'
  page_last: '6'
  pages: "1\u20136"
  paper_id: '1'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2001.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2001.jpg
  title: CKY-based Convolutional Attention for Neural Machine Translation
  title_html: <span class="acl-fixed-case">CKY</span>-based Convolutional Attention
    for Neural Machine Translation
  url: https://www.aclweb.org/anthology/I17-2001
  year: '2017'
I17-2002:
  abstract: The sequence-to-sequence (Seq2Seq) model has been successfully applied
    to machine translation (MT). Recently, MT performances were improved by incorporating
    supervised attention into the model. In this paper, we introduce supervised attention
    to constituency parsing that can be regarded as another translation task. Evaluation
    results on the PTB corpus showed that the bracketing F-measure was improved by
    supervised attention.
  address: Taipei, Taiwan
  author:
  - first: Hidetaka
    full: Hidetaka Kamigaito
    id: hidetaka-kamigaito
    last: Kamigaito
  - first: Katsuhiko
    full: Katsuhiko Hayashi
    id: katsuhiko-hayashi
    last: Hayashi
  - first: Tsutomu
    full: Tsutomu Hirao
    id: tsutomu-hirao
    last: Hirao
  - first: Hiroya
    full: Hiroya Takamura
    id: hiroya-takamura
    last: Takamura
  - first: Manabu
    full: Manabu Okumura
    id: manabu-okumura
    last: Okumura
  - first: Masaaki
    full: Masaaki Nagata
    id: masaaki-nagata
    last: Nagata
  author_string: Hidetaka Kamigaito, Katsuhiko Hayashi, Tsutomu Hirao, Hiroya Takamura,
    Manabu Okumura, Masaaki Nagata
  bibkey: kamigaito-etal-2017-supervised
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '7'
  page_last: '12'
  pages: "7\u201312"
  paper_id: '2'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2002.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2002.jpg
  title: Supervised Attention for Sequence-to-Sequence Constituency Parsing
  title_html: Supervised Attention for Sequence-to-Sequence Constituency Parsing
  url: https://www.aclweb.org/anthology/I17-2002
  year: '2017'
I17-2003:
  abstract: Our paper addresses the problem of annotation projection for semantic
    role labeling for resource-poor languages using supervised annotations from a
    resource-rich language through parallel data. We propose a transfer method that
    employs information from source and target syntactic dependencies as well as word
    alignment density to improve the quality of an iterative bootstrapping method.
    Our experiments yield a 3.5 absolute labeled F-score improvement over a standard
    annotation projection method.
  address: Taipei, Taiwan
  author:
  - first: Maryam
    full: Maryam Aminian
    id: maryam-aminian
    last: Aminian
  - first: Mohammad Sadegh
    full: Mohammad Sadegh Rasooli
    id: mohammad-sadegh-rasooli
    last: Rasooli
  - first: Mona
    full: Mona Diab
    id: mona-diab
    last: Diab
  author_string: Maryam Aminian, Mohammad Sadegh Rasooli, Mona Diab
  bibkey: aminian-etal-2017-transferring
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '13'
  page_last: '19'
  pages: "13\u201319"
  paper_id: '3'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2003.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2003.jpg
  title: Transferring Semantic Roles Using Translation and Syntactic Information
  title_html: Transferring Semantic Roles Using Translation and Syntactic Information
  url: https://www.aclweb.org/anthology/I17-2003
  year: '2017'
I17-2004:
  abstract: Domain adaptation is a major challenge for neural machine translation
    (NMT). Given unknown words or new domains, NMT systems tend to generate fluent
    translations at the expense of adequacy. We present a stack-based lattice search
    algorithm for NMT and show that constraining its search space with lattices generated
    by phrase-based machine translation (PBMT) improves robustness. We report consistent
    BLEU score gains across four diverse domain adaptation tasks involving medical,
    IT, Koran, or subtitles texts.
  address: Taipei, Taiwan
  author:
  - first: Huda
    full: Huda Khayrallah
    id: huda-khayrallah
    last: Khayrallah
  - first: Gaurav
    full: Gaurav Kumar
    id: gaurav-kumar
    last: Kumar
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  - first: Matt
    full: Matt Post
    id: matt-post
    last: Post
  - first: Philipp
    full: Philipp Koehn
    id: philipp-koehn
    last: Koehn
  author_string: Huda Khayrallah, Gaurav Kumar, Kevin Duh, Matt Post, Philipp Koehn
  bibkey: khayrallah-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '20'
  page_last: '25'
  pages: "20\u201325"
  paper_id: '4'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2004.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2004.jpg
  title: Neural Lattice Search for Domain Adaptation in Machine Translation
  title_html: Neural Lattice Search for Domain Adaptation in Machine Translation
  url: https://www.aclweb.org/anthology/I17-2004
  year: '2017'
I17-2005:
  abstract: This paper tackles a problem of analyzing the well-formedness of syllables
    in Japanese Sign Language (JSL). We formulate the problem as a classification
    problem that classifies syllables into well-formed or ill-formed. We build a data
    set that contains hand-coded syllables and their well-formedness. We define a
    fine-grained feature set based on the hand-coded syllables and train a logistic
    regression classifier on labeled syllables, expecting to find the discriminative
    features from the trained classifier. We also perform pseudo active learning to
    investigate the applicability of active learning in analyzing syllables. In the
    experiments, the best classifier with our combinatorial features achieved the
    accuracy of 87.0%. The pseudo active learning is also shown to be effective showing
    that it could reduce about 84% of training instances to achieve the accuracy of
    82.0% when compared to the model without active learning.
  address: Taipei, Taiwan
  author:
  - first: Satoshi
    full: Satoshi Yawata
    id: satoshi-yawata
    last: Yawata
  - first: Makoto
    full: Makoto Miwa
    id: makoto-miwa
    last: Miwa
  - first: Yutaka
    full: Yutaka Sasaki
    id: yutaka-sasaki
    last: Sasaki
  - first: Daisuke
    full: Daisuke Hara
    id: daisuke-hara
    last: Hara
  author_string: Satoshi Yawata, Makoto Miwa, Yutaka Sasaki, Daisuke Hara
  bibkey: yawata-etal-2017-analyzing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '26'
  page_last: '30'
  pages: "26\u201330"
  paper_id: '5'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2005.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2005.jpg
  title: Analyzing Well-Formedness of Syllables in Japanese Sign Language
  title_html: Analyzing Well-Formedness of Syllables in <span class="acl-fixed-case">J</span>apanese
    Sign Language
  url: https://www.aclweb.org/anthology/I17-2005
  year: '2017'
I17-2006:
  abstract: "Word embeddings are a relatively new addition to the modern NLP researcher\u2019\
    s toolkit. However, unlike other tools, word embeddings are used in a black box\
    \ manner. There are very few studies regarding various hyperparameters. One such\
    \ hyperparameter is the dimension of word embeddings. They are rather decided\
    \ based on a rule of thumb: in the range 50 to 300. In this paper, we show that\
    \ the dimension should instead be chosen based on corpus statistics. More specifically,\
    \ we show that the number of pairwise equidistant words of the corpus vocabulary\
    \ (as defined by some distance/similarity metric) gives a lower bound on the the\
    \ number of dimensions , and going below this bound results in degradation of\
    \ quality of learned word embeddings. Through our evaluations on standard word\
    \ embedding evaluation tasks, we show that for dimensions higher than or equal\
    \ to the bound, we get better results as compared to the ones below it."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2006.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2006.Notes.pdf
  author:
  - first: Kevin
    full: Kevin Patel
    id: kevin-patel
    last: Patel
  - first: Pushpak
    full: Pushpak Bhattacharyya
    id: pushpak-bhattacharyya
    last: Bhattacharyya
  author_string: Kevin Patel, Pushpak Bhattacharyya
  bibkey: patel-bhattacharyya-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '31'
  page_last: '36'
  pages: "31\u201336"
  paper_id: '6'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2006.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2006.jpg
  title: Towards Lower Bounds on Number of Dimensions for Word Embeddings
  title_html: Towards Lower Bounds on Number of Dimensions for Word Embeddings
  url: https://www.aclweb.org/anthology/I17-2006
  year: '2017'
I17-2007:
  abstract: This paper presents an approach to the task of predicting an event description
    from a preceding sentence in a text. Our approach explores sequence-to-sequence
    learning using a bidirectional multi-layer recurrent neural network. Our approach
    substantially outperforms previous work in terms of the BLEU score on two datasets
    derived from WikiHow and DeScript respectively. Since the BLEU score is not easy
    to interpret as a measure of event prediction, we complement our study with a
    second evaluation that exploits the rich linguistic annotation of gold paraphrase
    sets of events.
  address: Taipei, Taiwan
  author:
  - first: Dai Quoc
    full: Dai Quoc Nguyen
    id: dai-quoc-nguyen
    last: Nguyen
  - first: Dat Quoc
    full: Dat Quoc Nguyen
    id: dat-quoc-nguyen
    last: Nguyen
  - first: Cuong Xuan
    full: Cuong Xuan Chu
    id: cuong-xuan-chu
    last: Chu
  - first: Stefan
    full: Stefan Thater
    id: stefan-thater
    last: Thater
  - first: Manfred
    full: Manfred Pinkal
    id: manfred-pinkal
    last: Pinkal
  author_string: Dai Quoc Nguyen, Dat Quoc Nguyen, Cuong Xuan Chu, Stefan Thater,
    Manfred Pinkal
  bibkey: nguyen-etal-2017-sequence
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '37'
  page_last: '42'
  pages: "37\u201342"
  paper_id: '7'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2007.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2007.jpg
  title: Sequence to Sequence Learning for Event Prediction
  title_html: Sequence to Sequence Learning for Event Prediction
  url: https://www.aclweb.org/anthology/I17-2007
  year: '2017'
I17-2008:
  abstract: This paper proposes a reinforcing method that refines the output layers
    of existing Recurrent Neural Network (RNN) language models. We refer to our proposed
    method as Input-to-Output Gate (IOG). IOG has an extremely simple structure, and
    thus, can be easily combined with any RNN language models. Our experiments on
    the Penn Treebank and WikiText-2 datasets demonstrate that IOG consistently boosts
    the performance of several different types of current topline RNN language models.
  address: Taipei, Taiwan
  author:
  - first: Sho
    full: Sho Takase
    id: sho-takase
    last: Takase
  - first: Jun
    full: Jun Suzuki
    id: jun-suzuki
    last: Suzuki
  - first: Masaaki
    full: Masaaki Nagata
    id: masaaki-nagata
    last: Nagata
  author_string: Sho Takase, Jun Suzuki, Masaaki Nagata
  bibkey: takase-etal-2017-input
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '43'
  page_last: '48'
  pages: "43\u201348"
  paper_id: '8'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2008.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2008.jpg
  title: Input-to-Output Gate to Improve RNN Language Models
  title_html: Input-to-Output Gate to Improve <span class="acl-fixed-case">RNN</span>
    Language Models
  url: https://www.aclweb.org/anthology/I17-2008
  year: '2017'
I17-2009:
  abstract: Mobile devices use language models to suggest words and phrases for use
    in text entry. Traditional language models are based on contextual word frequency
    in a static corpus of text. However, certain types of phrases, when offered to
    writers as suggestions, may be systematically chosen more often than their frequency
    would predict. In this paper, we propose the task of generating suggestions that
    writers accept, a related but distinct task to making accurate predictions. Although
    this task is fundamentally interactive, we propose a counterfactual setting that
    permits offline training and evaluation. We find that even a simple language model
    can capture text characteristics that improve acceptability.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2009.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2009.Notes.pdf
  author:
  - first: Kenneth
    full: Kenneth Arnold
    id: kenneth-arnold
    last: Arnold
  - first: Kai-Wei
    full: Kai-Wei Chang
    id: kai-wei-chang
    last: Chang
  - first: Adam
    full: Adam Kalai
    id: adam-kalai
    last: Kalai
  author_string: Kenneth Arnold, Kai-Wei Chang, Adam Kalai
  bibkey: arnold-etal-2017-counterfactual
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '49'
  page_last: '54'
  pages: "49\u201354"
  paper_id: '9'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2009.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2009.jpg
  title: Counterfactual Language Model Adaptation for Suggesting Phrases
  title_html: Counterfactual Language Model Adaptation for Suggesting Phrases
  url: https://www.aclweb.org/anthology/I17-2009
  year: '2017'
I17-2010:
  abstract: Multi-task learning (MTL) has recently contributed to learning better
    representations in service of various NLP tasks. MTL aims at improving the performance
    of a primary task by jointly training on a secondary task. This paper introduces
    automated tasks, which exploit the sequential nature of the input data, as secondary
    tasks in an MTL model. We explore next word prediction, next character prediction,
    and missing word completion as potential automated tasks. Our results show that
    training on a primary task in parallel with a secondary automated task improves
    both the convergence speed and accuracy for the primary task. We suggest two methods
    for augmenting an existing network with automated tasks and establish better performance
    in topic prediction, sentiment analysis, and hashtag recommendation. Finally,
    we show that the MTL models can perform well on datasets that are small and colloquial
    by nature.
  address: Taipei, Taiwan
  author:
  - first: Davis
    full: Davis Liang
    id: davis-liang
    last: Liang
  - first: Yan
    full: Yan Shu
    id: yan-shu
    last: Shu
  author_string: Davis Liang, Yan Shu
  bibkey: liang-shu-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '55'
  page_last: '60'
  pages: "55\u201360"
  paper_id: '10'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2010.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2010.jpg
  title: Deep Automated Multi-task Learning
  title_html: Deep Automated Multi-task Learning
  url: https://www.aclweb.org/anthology/I17-2010
  year: '2017'
I17-2011:
  abstract: "In Multilabel Learning (MLL) each training instance is associated with\
    \ a set of labels and the task is to learn a function that maps an unseen instance\
    \ to its corresponding label set. In this paper, we present a suite of \u2013\
    \ MLL algorithm independent \u2013 post-processing techniques that utilize the\
    \ conditional and directional label-dependences in order to make the predictions\
    \ from any MLL approach more coherent and precise. We solve constraint optimization\
    \ problem over the output produced by any MLL approach and the result is a refined\
    \ version of the input predicted label set. Using proposed techniques, we show\
    \ absolute improvement of 3% on English News and 10% on Chinese E-commerce datasets\
    \ for P@K metric."
  address: Taipei, Taiwan
  author:
  - first: Akshay
    full: Akshay Soni
    id: akshay-soni
    last: Soni
  - first: Aasish
    full: Aasish Pappu
    id: aasish-pappu
    last: Pappu
  - first: Jerry Chia-mau
    full: Jerry Chia-mau Ni
    id: jerry-chia-mau-ni
    last: Ni
  - first: Troy
    full: Troy Chevalier
    id: troy-chevalier
    last: Chevalier
  author_string: Akshay Soni, Aasish Pappu, Jerry Chia-mau Ni, Troy Chevalier
  bibkey: soni-etal-2017-post
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '61'
  page_last: '66'
  pages: "61\u201366"
  paper_id: '11'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2011.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2011.jpg
  title: Post-Processing Techniques for Improving Predictions of Multilabel Learning
    Approaches
  title_html: Post-Processing Techniques for Improving Predictions of Multilabel Learning
    Approaches
  url: https://www.aclweb.org/anthology/I17-2011
  year: '2017'
I17-2012:
  abstract: Non-contiguous word sequences are widely known to be important in modelling
    natural language. However they not explicitly encoded in common text representations.
    In this work we propose a model for text processing using string kernels, capable
    of flexibly representing non-contiguous sequences. Specifically, we derive a vectorised
    version of the string kernel algorithm and their gradients, allowing efficient
    hyperparameter optimisation as part of a Gaussian Process framework. Experiments
    on synthetic data and text regression for emotion analysis show the promise of
    this technique.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2012.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2012.Notes.pdf
  author:
  - first: Daniel
    full: Daniel Beck
    id: daniel-beck
    last: Beck
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  author_string: Daniel Beck, Trevor Cohn
  bibkey: beck-cohn-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '67'
  page_last: '73'
  pages: "67\u201373"
  paper_id: '12'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2012.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2012.jpg
  title: Learning Kernels over Strings using Gaussian Processes
  title_html: Learning Kernels over Strings using <span class="acl-fixed-case">G</span>aussian
    Processes
  url: https://www.aclweb.org/anthology/I17-2012
  year: '2017'
I17-2013:
  abstract: Word segmentation is crucial in natural language processing tasks for
    unsegmented languages. In Japanese, many out-of-vocabulary words appear in the
    phonetic syllabary katakana, making segmentation more difficult due to the lack
    of clues found in mixed script settings. In this paper, we propose a straightforward
    approach based on a variant of tf-idf and apply it to the problem of word segmentation
    in Japanese. Even though our method uses only an unlabeled corpus, experimental
    results show that it achieves performance comparable to existing methods that
    use manually labeled corpora. Furthermore, it improves performance of simple word
    segmentation models trained on a manually labeled corpus.
  address: Taipei, Taiwan
  author:
  - first: Yoshinari
    full: Yoshinari Fujinuma
    id: yoshinari-fujinuma
    last: Fujinuma
  - first: Alvin
    full: Alvin Grissom II
    id: alvin-grissom-ii
    last: Grissom II
  author_string: Yoshinari Fujinuma, Alvin Grissom II
  bibkey: fujinuma-grissom-ii-2017-substring
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '74'
  page_last: '79'
  pages: "74\u201379"
  paper_id: '13'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2013.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2013.jpg
  title: Substring Frequency Features for Segmentation of Japanese Katakana Words
    with Unlabeled Corpora
  title_html: Substring Frequency Features for Segmentation of <span class="acl-fixed-case">J</span>apanese
    Katakana Words with Unlabeled Corpora
  url: https://www.aclweb.org/anthology/I17-2013
  year: '2017'
I17-2014:
  abstract: Part-of-speech (POS) tagging and named entity recognition (NER) are crucial
    steps in natural language processing. In addition, the difficulty of word segmentation
    places additional burden on those who intend to deal with languages such as Chinese,
    and pipelined systems often suffer from error propagation. This work proposes
    an end-to-end model using character-based recurrent neural network (RNN) to jointly
    accomplish segmentation, POS tagging and NER of a Chinese sentence. Experiments
    on previous word segmentation and NER datasets show that a single model with the
    proposed architecture is comparable to those trained specifically for each task,
    and outperforms freely-available softwares. Moreover, we provide a web-based interface
    for the public to easily access this resource.
  address: Taipei, Taiwan
  author:
  - first: Yu-Lun
    full: Yu-Lun Hsieh
    id: yu-lun-hsieh
    last: Hsieh
  - first: Yung-Chun
    full: Yung-Chun Chang
    id: yung-chun-chang
    last: Chang
  - first: Yi-Jie
    full: Yi-Jie Huang
    id: yi-jie-huang
    last: Huang
  - first: Shu-Hao
    full: Shu-Hao Yeh
    id: shu-hao-yeh
    last: Yeh
  - first: Chun-Hung
    full: Chun-Hung Chen
    id: chun-hung-chen
    last: Chen
  - first: Wen-Lian
    full: Wen-Lian Hsu
    id: wen-lian-hsu
    last: Hsu
  author_string: Yu-Lun Hsieh, Yung-Chun Chang, Yi-Jie Huang, Shu-Hao Yeh, Chun-Hung
    Chen, Wen-Lian Hsu
  bibkey: hsieh-etal-2017-monpa
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '80'
  page_last: '85'
  pages: "80\u201385"
  paper_id: '14'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2014.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2014.jpg
  title: 'MONPA: Multi-objective Named-entity and Part-of-speech Annotator for Chinese
    using Recurrent Neural Network'
  title_html: '<span class="acl-fixed-case">MONPA</span>: Multi-objective Named-entity
    and Part-of-speech Annotator for <span class="acl-fixed-case">C</span>hinese using
    Recurrent Neural Network'
  url: https://www.aclweb.org/anthology/I17-2014
  year: '2017'
I17-2015:
  abstract: We extensively analyse the correlations and drawbacks of conventionally
    employed evaluation metrics for word segmentation. Unlike in standard information
    retrieval, precision favours under-splitting systems and therefore can be misleading
    in word segmentation. Overall, based on both theoretical and experimental analysis,
    we propose that precision should be excluded from the standard evaluation metrics
    and that the evaluation score obtained by using only recall is sufficient and
    better correlated with the performance of word segmentation systems.
  address: Taipei, Taiwan
  author:
  - first: Yan
    full: Yan Shao
    id: yan-shao
    last: Shao
  - first: Christian
    full: Christian Hardmeier
    id: christian-hardmeier
    last: Hardmeier
  - first: Joakim
    full: Joakim Nivre
    id: joakim-nivre
    last: Nivre
  author_string: Yan Shao, Christian Hardmeier, Joakim Nivre
  bibkey: shao-etal-2017-recall
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '86'
  page_last: '90'
  pages: "86\u201390"
  paper_id: '15'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2015.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2015.jpg
  title: Recall is the Proper Evaluation Metric for Word Segmentation
  title_html: Recall is the Proper Evaluation Metric for Word Segmentation
  url: https://www.aclweb.org/anthology/I17-2015
  year: '2017'
I17-2016:
  abstract: "Low-resource named entity recognition is still an open problem in NLP.\
    \ Most state-of-the-art systems require tens of thousands of annotated sentences\
    \ in order to obtain high performance. However, for most of the world\u2019s languages\
    \ it is unfeasible to obtain such annotation. In this paper, we present a transfer\
    \ learning scheme, whereby we train character-level neural CRFs to predict named\
    \ entities for both high-resource languages and low-resource languages jointly.\
    \ Learning character representations for multiple related languages allows knowledge\
    \ transfer from the high-resource languages to the low-resource ones, improving\
    \ F1 by up to 9.8 points."
  address: Taipei, Taiwan
  author:
  - first: Ryan
    full: Ryan Cotterell
    id: ryan-cotterell
    last: Cotterell
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  author_string: Ryan Cotterell, Kevin Duh
  bibkey: cotterell-duh-2017-low
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '91'
  page_last: '96'
  pages: "91\u201396"
  paper_id: '16'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2016.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2016.jpg
  title: Low-Resource Named Entity Recognition with Cross-lingual, Character-Level
    Neural Conditional Random Fields
  title_html: Low-Resource Named Entity Recognition with Cross-lingual, Character-Level
    Neural Conditional Random Fields
  url: https://www.aclweb.org/anthology/I17-2016
  year: '2017'
I17-2017:
  abstract: We present Segment-level Neural CRF, which combines neural networks with
    a linear chain CRF for segment-level sequence modeling tasks such as named entity
    recognition (NER) and syntactic chunking. Our segment-level CRF can consider higher-order
    label dependencies compared with conventional word-level CRF. Since it is difficult
    to consider all possible variable length segments, our method uses segment lattice
    constructed from the word-level tagging model to reduce the search space. Performing
    experiments on NER and chunking, we demonstrate that our method outperforms conventional
    word-level CRF with neural networks.
  address: Taipei, Taiwan
  author:
  - first: Motoki
    full: Motoki Sato
    id: motoki-sano
    last: Sato
  - first: Hiroyuki
    full: Hiroyuki Shindo
    id: hiroyuki-shindo
    last: Shindo
  - first: Ikuya
    full: Ikuya Yamada
    id: ikuya-yamada
    last: Yamada
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Motoki Sato, Hiroyuki Shindo, Ikuya Yamada, Yuji Matsumoto
  bibkey: sato-etal-2017-segment
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '97'
  page_last: '102'
  pages: "97\u2013102"
  paper_id: '17'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2017.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2017.jpg
  title: Segment-Level Neural Conditional Random Fields for Named Entity Recognition
  title_html: Segment-Level Neural Conditional Random Fields for Named Entity Recognition
  url: https://www.aclweb.org/anthology/I17-2017
  year: '2017'
I17-2018:
  abstract: We present and take advantage of the inherent visualizability properties
    of words in visual corpora (the textual components of vision-language datasets)
    to compute concreteness scores for words. Our simple method does not require hand-annotated
    concreteness score lists for training, and yields state-of-the-art results when
    evaluated against concreteness scores lists and previously derived scores, as
    well as when used for metaphor detection.
  address: Taipei, Taiwan
  author:
  - first: Gitit
    full: Gitit Kehat
    id: gitit-kehat
    last: Kehat
  - first: James
    full: James Pustejovsky
    id: james-pustejovsky
    last: Pustejovsky
  author_string: Gitit Kehat, James Pustejovsky
  bibkey: kehat-pustejovsky-2017-integrating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '103'
  page_last: '108'
  pages: "103\u2013108"
  paper_id: '18'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2018.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2018.jpg
  title: Integrating Vision and Language Datasets to Measure Word Concreteness
  title_html: Integrating Vision and Language Datasets to Measure Word Concreteness
  url: https://www.aclweb.org/anthology/I17-2018
  year: '2017'
I17-2019:
  abstract: This paper examines the usefulness of semantic features based on word
    alignments for estimating the quality of text simplification. Specifically, we
    introduce seven types of alignment-based features computed on the basis of word
    embeddings and paraphrase lexicons. Through an empirical experiment using the
    QATS dataset, we confirm that we can achieve the state-of-the-art performance
    only with these features.
  address: Taipei, Taiwan
  author:
  - first: Tomoyuki
    full: Tomoyuki Kajiwara
    id: tomoyuki-kajiwara
    last: Kajiwara
  - first: Atsushi
    full: Atsushi Fujita
    id: atsushi-fujita
    last: Fujita
  author_string: Tomoyuki Kajiwara, Atsushi Fujita
  bibkey: kajiwara-fujita-2017-semantic
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '109'
  page_last: '115'
  pages: "109\u2013115"
  paper_id: '19'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2019.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2019.jpg
  title: Semantic Features Based on Word Alignments for Estimating Quality of Text
    Simplification
  title_html: Semantic Features Based on Word Alignments for Estimating Quality of
    Text Simplification
  url: https://www.aclweb.org/anthology/I17-2019
  year: '2017'
I17-2020:
  abstract: Word embeddings learned from text corpus can be improved by injecting
    knowledge from external resources, while at the same time also specializing them
    for similarity or relatedness. These knowledge resources (like WordNet, Paraphrase
    Database) may not exist for all languages. In this work we introduce a method
    to inject word embeddings of a language with knowledge resource of another language
    by leveraging bilingual embeddings. First we improve word embeddings of German,
    Italian, French and Spanish using resources of English and test them on variety
    of word similarity tasks. Then we demonstrate the utility of our method by creating
    improved embeddings for Urdu and Telugu languages using Hindi WordNet, beating
    the previously established baseline for Urdu.
  address: Taipei, Taiwan
  author:
  - first: Prakhar
    full: Prakhar Pandey
    id: prakhar-pandey
    last: Pandey
  - first: Vikram
    full: Vikram Pudi
    id: vikram-pudi
    last: Pudi
  - first: Manish
    full: Manish Shrivastava
    id: manish-shrivastava
    last: Shrivastava
  author_string: Prakhar Pandey, Vikram Pudi, Manish Shrivastava
  bibkey: pandey-etal-2017-injecting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '116'
  page_last: '121'
  pages: "116\u2013121"
  paper_id: '20'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2020.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2020.jpg
  title: "Injecting Word Embeddings with Another Language\u2019s Resource : An Application\
    \ of Bilingual Embeddings"
  title_html: "Injecting Word Embeddings with Another Language\u2019s Resource : An\
    \ Application of Bilingual Embeddings"
  url: https://www.aclweb.org/anthology/I17-2020
  year: '2017'
I17-2021:
  abstract: "Speech is a natural channel for human-computer interaction in robotics\
    \ and consumer applications. Natural language understanding pipelines that start\
    \ with speech can have trouble recovering from speech recognition errors. Black-box\
    \ automatic speech recognition (ASR) systems, built for general purpose use, are\
    \ unable to take advantage of in-domain language models that could otherwise ameliorate\
    \ these errors. In this work, we present a method for re-ranking black-box ASR\
    \ hypotheses using an in-domain language model and semantic parser trained for\
    \ a particular task. Our re-ranking method significantly improves both transcription\
    \ accuracy and semantic understanding over a state-of-the-art ASR\u2019s vanilla\
    \ output."
  address: Taipei, Taiwan
  author:
  - first: Rodolfo
    full: Rodolfo Corona
    id: rodolfo-corona
    last: Corona
  - first: Jesse
    full: Jesse Thomason
    id: jesse-thomason
    last: Thomason
  - first: Raymond
    full: Raymond Mooney
    id: raymond-mooney
    last: Mooney
  author_string: Rodolfo Corona, Jesse Thomason, Raymond Mooney
  bibkey: corona-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '122'
  page_last: '127'
  pages: "122\u2013127"
  paper_id: '21'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2021.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2021.jpg
  title: Improving Black-box Speech Recognition using Semantic Parsing
  title_html: Improving Black-box Speech Recognition using Semantic Parsing
  url: https://www.aclweb.org/anthology/I17-2021
  year: '2017'
I17-2022:
  abstract: The research trend in Japanese predicate-argument structure (PAS) analysis
    is shifting from pointwise prediction models with local features to global models
    designed to search for globally optimal solutions. However, the existing global
    models tend to employ only relatively simple local features; therefore, the overall
    performance gains are rather limited. The importance of designing a local model
    is demonstrated in this study by showing that the performance of a sophisticated
    local model can be considerably improved with recent feature embedding methods
    and a feature combination learning based on a neural network, outperforming the
    state-of-the-art global models in F1 on a common benchmark dataset.
  address: Taipei, Taiwan
  author:
  - first: Yuichiroh
    full: Yuichiroh Matsubayashi
    id: yuichiroh-matsubayashi
    last: Matsubayashi
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Yuichiroh Matsubayashi, Kentaro Inui
  bibkey: matsubayashi-inui-2017-revisiting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '128'
  page_last: '133'
  pages: "128\u2013133"
  paper_id: '22'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2022.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2022.jpg
  title: Revisiting the Design Issues of Local Models for Japanese Predicate-Argument
    Structure Analysis
  title_html: Revisiting the Design Issues of Local Models for <span class="acl-fixed-case">J</span>apanese
    Predicate-Argument Structure Analysis
  url: https://www.aclweb.org/anthology/I17-2022
  year: '2017'
I17-2023:
  abstract: "When giving descriptions, speakers often signify object shape or size\
    \ with hand gestures. Such so-called \u2018iconic\u2019 gestures represent their\
    \ meaning through their relevance to referents in the verbal content, rather than\
    \ having a conventional form. The gesture form on its own is often ambiguous,\
    \ and the aspect of the referent that it highlights is constrained by what the\
    \ language makes salient. We show how the verbal content guides gesture interpretation\
    \ through a computational model that frames the task as a multi-label classification\
    \ task that maps multimodal utterances to semantic categories, using annotated\
    \ human-human data."
  address: Taipei, Taiwan
  author:
  - first: Ting
    full: Ting Han
    id: ting-han
    last: Han
  - first: Julian
    full: Julian Hough
    id: julian-hough
    last: Hough
  - first: David
    full: David Schlangen
    id: david-schlangen
    last: Schlangen
  author_string: Ting Han, Julian Hough, David Schlangen
  bibkey: han-etal-2017-natural
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '134'
  page_last: '139'
  pages: "134\u2013139"
  paper_id: '23'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2023.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2023.jpg
  title: 'Natural Language Informs the Interpretation of Iconic Gestures: A Computational
    Approach'
  title_html: 'Natural Language Informs the Interpretation of Iconic Gestures: A Computational
    Approach'
  url: https://www.aclweb.org/anthology/I17-2023
  year: '2017'
I17-2024:
  abstract: Emotion Analysis is the task of modelling latent emotions present in natural
    language. Labelled datasets for this task are scarce so learning good input text
    representations is not trivial. Using averaged word embeddings is a simple way
    to leverage unlabelled corpora to build text representations but this approach
    can be prone to noise either coming from the embedding themselves or the averaging
    procedure. In this paper we propose a model for Emotion Analysis using Gaussian
    Processes and kernels that are better suitable for functions that exhibit noisy
    behaviour. Empirical evaluations in a emotion prediction task show that our model
    outperforms commonly used baselines for regression.
  address: Taipei, Taiwan
  author:
  - first: Daniel
    full: Daniel Beck
    id: daniel-beck
    last: Beck
  author_string: Daniel Beck
  bibkey: beck-2017-modelling
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '140'
  page_last: '145'
  pages: "140\u2013145"
  paper_id: '24'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2024.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2024.jpg
  title: Modelling Representation Noise in Emotion Analysis using Gaussian Processes
  title_html: Modelling Representation Noise in Emotion Analysis using <span class="acl-fixed-case">G</span>aussian
    Processes
  url: https://www.aclweb.org/anthology/I17-2024
  year: '2017'
I17-2025:
  abstract: In this paper, we investigate the effectiveness of different affective
    lexicons through sentiment analysis of phrases. We examine how phrases can be
    represented through manually prepared lexicons, extended lexicons using computational
    methods, or word embedding. Comparative studies clearly show that word embedding
    using unsupervised distributional method outperforms manually prepared lexicons
    no matter what affective models are used in the lexicons. Our conclusion is that
    although different affective lexicons are cognitively backed by theories, they
    do not show any advantage over the automatically obtained word embedding.
  address: Taipei, Taiwan
  author:
  - first: Minglei
    full: Minglei Li
    id: minglei-li
    last: Li
  - first: Qin
    full: Qin Lu
    id: qin-lu
    last: Lu
  - first: Yunfei
    full: Yunfei Long
    id: yunfei-long
    last: Long
  author_string: Minglei Li, Qin Lu, Yunfei Long
  bibkey: li-etal-2017-manually
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '146'
  page_last: '150'
  pages: "146\u2013150"
  paper_id: '25'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2025.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2025.jpg
  title: Are Manually Prepared Affective Lexicons Really Useful for Sentiment Analysis
  title_html: Are Manually Prepared Affective Lexicons Really Useful for Sentiment
    Analysis
  url: https://www.aclweb.org/anthology/I17-2025
  year: '2017'
I17-2026:
  abstract: Online reviews are valuable resources not only for consumers to make decisions
    before purchase, but also for providers to get feedbacks for their services or
    commodities. In Aspect Based Sentiment Analysis (ABSA), it is critical to identify
    aspect categories and extract aspect terms from the sentences of user-generated
    reviews. However, the two tasks are often treated independently, even though they
    are closely related. Intuitively, the learned knowledge of one task should inform
    the other learning task. In this paper, we propose a multi-task learning model
    based on neural networks to solve them together. We demonstrate the improved performance
    of our multi-task learning model over the models trained separately on three public
    dataset released by SemEval workshops.
  address: Taipei, Taiwan
  author:
  - first: Wei
    full: Wei Xue
    id: wei-xue
    last: Xue
  - first: Wubai
    full: Wubai Zhou
    id: wubai-zhou
    last: Zhou
  - first: Tao
    full: Tao Li
    id: tao-li
    last: Li
  - first: Qing
    full: Qing Wang
    id: qing-wang
    last: Wang
  author_string: Wei Xue, Wubai Zhou, Tao Li, Qing Wang
  bibkey: xue-etal-2017-mtna
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '151'
  page_last: '156'
  pages: "151\u2013156"
  paper_id: '26'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2026.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2026.jpg
  title: 'MTNA: A Neural Multi-task Model for Aspect Category Classification and Aspect
    Term Extraction On Restaurant Reviews'
  title_html: '<span class="acl-fixed-case">MTNA</span>: A Neural Multi-task Model
    for Aspect Category Classification and Aspect Term Extraction On Restaurant Reviews'
  url: https://www.aclweb.org/anthology/I17-2026
  year: '2017'
I17-2027:
  abstract: "Humans process language word by word and construct partial linguistic\
    \ structures on the fly before the end of the sentence is perceived. Inspired\
    \ by this cognitive ability, incremental algorithms for natural language processing\
    \ tasks have been proposed and demonstrated promising performance. For discourse\
    \ relation (DR) parsing, however, it is not yet clear to what extent humans can\
    \ recognize DRs incrementally, because the latent \u2018nodes\u2019 of discourse\
    \ structure can span clauses and sentences. To answer this question, this work\
    \ investigates incrementality in discourse processing based on a corpus annotated\
    \ with DR signals. We find that DRs are dominantly signaled at the boundary between\
    \ the two constituent discourse units. The findings complement existing psycholinguistic\
    \ theories on expectation in discourse processing and provide direction for incremental\
    \ discourse parsing."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2027.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2027.Notes.pdf
  - filename: I17-2027.Datasets.tgz
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-2027.Datasets.tgz
  author:
  - first: Frances
    full: Frances Yung
    id: frances-yung
    last: Yung
  - first: Hiroshi
    full: Hiroshi Noji
    id: hiroshi-noji
    last: Noji
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Frances Yung, Hiroshi Noji, Yuji Matsumoto
  bibkey: yung-etal-2017-discourse
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '157'
  page_last: '162'
  pages: "157\u2013162"
  paper_id: '27'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2027.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2027.jpg
  title: Can Discourse Relations be Identified Incrementally?
  title_html: Can Discourse Relations be Identified Incrementally?
  url: https://www.aclweb.org/anthology/I17-2027
  year: '2017'
I17-2028:
  abstract: Language understanding (LU) and dialogue policy learning are two essential
    components in conversational systems. Human-human dialogues are not well-controlled
    and often random and unpredictable due to their own goals and speaking habits.
    This paper proposes a role-based contextual model to consider different speaker
    roles independently based on the various speaking patterns in the multi-turn dialogues.
    The experiments on the benchmark dataset show that the proposed role-based model
    successfully learns role-specific behavioral patterns for contextual encoding
    and then significantly improves language understanding and dialogue policy learning
    tasks.
  address: Taipei, Taiwan
  author:
  - first: Ta-Chung
    full: Ta-Chung Chi
    id: ta-chung-chi
    last: Chi
  - first: Po-Chun
    full: Po-Chun Chen
    id: po-chun-chen
    last: Chen
  - first: Shang-Yu
    full: Shang-Yu Su
    id: shang-yu-su
    last: Su
  - first: Yun-Nung
    full: Yun-Nung Chen
    id: yun-nung-chen
    last: Chen
  author_string: Ta-Chung Chi, Po-Chun Chen, Shang-Yu Su, Yun-Nung Chen
  bibkey: chi-etal-2017-speaker
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '163'
  page_last: '168'
  pages: "163\u2013168"
  paper_id: '28'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2028.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2028.jpg
  title: Speaker Role Contextual Modeling for Language Understanding and Dialogue
    Policy Learning
  title_html: Speaker Role Contextual Modeling for Language Understanding and Dialogue
    Policy Learning
  url: https://www.aclweb.org/anthology/I17-2028
  year: '2017'
I17-2029:
  abstract: 'Neural conversation systems, typically using sequence-to-sequence (seq2seq)
    models, are showing promising progress recently. However, traditional seq2seq
    suffer from a severe weakness: during beam search decoding, they tend to rank
    universal replies at the top of the candidate list, resulting in the lack of diversity
    among candidate replies. Maximum Marginal Relevance (MMR) is a ranking algorithm
    that has been widely used for subset selection. In this paper, we propose the
    MMR-BS decoding method, which incorporates MMR into the beam search (BS) process
    of seq2seq. The MMR-BS method improves the diversity of generated replies without
    sacrificing their high relevance with the user-issued query. Experiments show
    that our proposed model achieves the best performance among other comparison methods.'
  address: Taipei, Taiwan
  author:
  - first: Yiping
    full: Yiping Song
    id: yiping-song
    last: Song
  - first: Zhiliang
    full: Zhiliang Tian
    id: zhiliang-tian
    last: Tian
  - first: Dongyan
    full: Dongyan Zhao
    id: dongyan-zhao
    last: Zhao
  - first: Ming
    full: Ming Zhang
    id: ming-zhang
    last: Zhang
  - first: Rui
    full: Rui Yan
    id: rui-yan
    last: Yan
  author_string: Yiping Song, Zhiliang Tian, Dongyan Zhao, Ming Zhang, Rui Yan
  bibkey: song-etal-2017-diversifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '169'
  page_last: '174'
  pages: "169\u2013174"
  paper_id: '29'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2029.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2029.jpg
  title: Diversifying Neural Conversation Model with Maximal Marginal Relevance
  title_html: Diversifying Neural Conversation Model with Maximal Marginal Relevance
  url: https://www.aclweb.org/anthology/I17-2029
  year: '2017'
I17-2030:
  abstract: Generating computer code from natural language descriptions has been a
    long-standing problem. Prior work in this domain has restricted itself to generating
    code in one shot from a single description. To overcome this limitation, we propose
    a system that can engage users in a dialog to clarify their intent until it has
    all the information to produce correct code. To evaluate the efficacy of dialog
    in code generation, we focus on synthesizing conditional statements in the form
    of IFTTT recipes.
  address: Taipei, Taiwan
  author:
  - first: Shobhit
    full: Shobhit Chaurasia
    id: shobhit-chaurasia
    last: Chaurasia
  - first: Raymond J.
    full: Raymond J. Mooney
    id: raymond-mooney
    last: Mooney
  author_string: Shobhit Chaurasia, Raymond J. Mooney
  bibkey: chaurasia-mooney-2017-dialog
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '175'
  page_last: '180'
  pages: "175\u2013180"
  paper_id: '30'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2030.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2030.jpg
  title: Dialog for Language to Code
  title_html: Dialog for Language to Code
  url: https://www.aclweb.org/anthology/I17-2030
  year: '2017'
I17-2031:
  abstract: Assessing summaries is a demanding, yet useful task which provides valuable
    information on language competence, especially for second language learners. We
    consider automated scoring of college-level summary writing task in English as
    a second language (EL2). We adopt the Reading-for-Understanding (RU) cognitive
    framework, extended with the Reading-to-Write (RW) element, and use analytic scoring
    with six rubrics covering content and writing quality. We show that regression
    models with reference-based and linguistic features considerably outperform the
    baselines across all the rubrics. Moreover, we find interesting correlations between
    summary features and analytic rubrics, revealing the links between the RU and
    RW constructs.
  address: Taipei, Taiwan
  author:
  - first: Tamara
    full: Tamara Sladoljev-Agejev
    id: tamara-sladoljev-agejev
    last: Sladoljev-Agejev
  - first: Jan
    full: "Jan \u0160najder"
    id: jan-snajder
    last: "\u0160najder"
  author_string: "Tamara Sladoljev-Agejev, Jan \u0160najder"
  bibkey: sladoljev-agejev-snajder-2017-using
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '181'
  page_last: '186'
  pages: "181\u2013186"
  paper_id: '31'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2031.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2031.jpg
  title: Using Analytic Scoring Rubrics in the Automatic Assessment of College-Level
    Summary Writing Tasks in L2
  title_html: Using Analytic Scoring Rubrics in the Automatic Assessment of College-Level
    Summary Writing Tasks in <span class="acl-fixed-case">L</span>2
  url: https://www.aclweb.org/anthology/I17-2031
  year: '2017'
I17-2032:
  abstract: We present in this paper a statistical framework that generates accurate
    and fluent product description from product attributes. Specifically, after extracting
    templates and learning writing knowledge from attribute-description parallel data,
    we use the learned knowledge to decide what to say and how to say for product
    description generation. To evaluate accuracy and fluency for the generated descriptions,
    in addition to BLEU and Recall, we propose to measure what to say (in terms of
    attribute coverage) and to measure how to say (by attribute-specified generation)
    separately. Experimental results show that our framework is effective.
  address: Taipei, Taiwan
  author:
  - first: Jinpeng
    full: Jinpeng Wang
    id: jinpeng-wang
    last: Wang
  - first: Yutai
    full: Yutai Hou
    id: yutai-hou
    last: Hou
  - first: Jing
    full: Jing Liu
    id: jing-liu
    last: Liu
  - first: Yunbo
    full: Yunbo Cao
    id: yunbo-cao
    last: Cao
  - first: Chin-Yew
    full: Chin-Yew Lin
    id: chin-yew-lin
    last: Lin
  author_string: Jinpeng Wang, Yutai Hou, Jing Liu, Yunbo Cao, Chin-Yew Lin
  bibkey: wang-etal-2017-statistical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '187'
  page_last: '192'
  pages: "187\u2013192"
  paper_id: '32'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2032.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2032.jpg
  title: A Statistical Framework for Product Description Generation
  title_html: A Statistical Framework for Product Description Generation
  url: https://www.aclweb.org/anthology/I17-2032
  year: '2017'
I17-2033:
  abstract: An automatic text summarization system can automatically generate a short
    and brief summary that contains a main concept of an original document. In this
    work, we explore the advantages of simple embedding features in Reinforcement
    leaning approach to automatic text summarization tasks. In addition, we propose
    a novel deep learning network for estimating Q-values used in Reinforcement learning.
    We evaluate our model by using ROUGE scores with DUC 2001, 2002, Wikipedia, ACL-ARC
    data. Evaluation results show that our model is competitive with the previous
    models.
  address: Taipei, Taiwan
  author:
  - first: Gyoung Ho
    full: Gyoung Ho Lee
    id: gyoung-ho-lee
    last: Lee
  - first: Kong Joo
    full: Kong Joo Lee
    id: kong-joo-lee
    last: Lee
  author_string: Gyoung Ho Lee, Kong Joo Lee
  bibkey: lee-lee-2017-automatic
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '193'
  page_last: '197'
  pages: "193\u2013197"
  paper_id: '33'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2033.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2033.jpg
  title: Automatic Text Summarization Using Reinforcement Learning with Embedding
    Features
  title_html: Automatic Text Summarization Using Reinforcement Learning with Embedding
    Features
  url: https://www.aclweb.org/anthology/I17-2033
  year: '2017'
I17-2034:
  abstract: Ideally a metric evaluating an abstract system summary should represent
    the extent to which the system-generated summary approximates the semantic inference
    conceived by the reader using a human-written reference summary. Most of the previous
    approaches relied upon word or syntactic sub-sequence overlap to evaluate system-generated
    summaries. Such metrics cannot evaluate the summary at semantic inference level.
    Through this work we introduce the metric of Semantic Similarity for Abstractive
    Summarization (SSAS), which leverages natural language inference and paraphrasing
    techniques to frame a novel approach to evaluate system summaries at semantic
    inference level. SSAS is based upon a weighted composition of quantities representing
    the level of agreement, contradiction, independence, paraphrasing, and optionally
    ROUGE score between a system-generated and a human-written summary.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2034.Datasets.txt
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-2034.Datasets.txt
  author:
  - first: Raghuram
    full: Raghuram Vadapalli
    id: raghuram-vadapalli
    last: Vadapalli
  - first: Litton
    full: Litton J Kurisinkel
    id: litton-j-kurisinkel
    last: J Kurisinkel
  - first: Manish
    full: Manish Gupta
    id: manish-gupta
    last: Gupta
  - first: Vasudeva
    full: Vasudeva Varma
    id: vasudeva-varma
    last: Varma
  author_string: Raghuram Vadapalli, Litton J Kurisinkel, Manish Gupta, Vasudeva Varma
  bibkey: vadapalli-etal-2017-ssas
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '198'
  page_last: '203'
  pages: "198\u2013203"
  paper_id: '34'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2034.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2034.jpg
  title: 'SSAS: Semantic Similarity for Abstractive Summarization'
  title_html: '<span class="acl-fixed-case">SSAS</span>: Semantic Similarity for Abstractive
    Summarization'
  url: https://www.aclweb.org/anthology/I17-2034
  year: '2017'
I17-2035:
  abstract: 'Following Gillick and Favre (2009), a lot of work about extractive summarization
    has modeled this task by associating two contrary constraints: one aims at maximizing
    the coverage of the summary with respect to its information content while the
    other represents its size limit. In this context, the notion of redundancy is
    only implicitly taken into account. In this article, we extend the framework defined
    by Gillick and Favre (2009) by examining how and to what extent integrating semantic
    sentence similarity into an update summarization system can improve its results.
    We show more precisely the impact of this strategy through evaluations performed
    on DUC 2007 and TAC 2008 and 2009 datasets.'
  address: Taipei, Taiwan
  author:
  - first: "Ma\xE2li"
    full: "Ma\xE2li Mnasri"
    id: maali-mnasri
    last: Mnasri
  - first: "Ga\xEBl"
    full: "Ga\xEBl de Chalendar"
    id: gael-de-chalendar
    last: de Chalendar
  - first: Olivier
    full: Olivier Ferret
    id: olivier-ferret
    last: Ferret
  author_string: "Ma\xE2li Mnasri, Ga\xEBl de Chalendar, Olivier Ferret"
  bibkey: mnasri-etal-2017-taking
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '204'
  page_last: '209'
  pages: "204\u2013209"
  paper_id: '35'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2035.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2035.jpg
  title: Taking into account Inter-sentence Similarity for Update Summarization
  title_html: Taking into account Inter-sentence Similarity for Update Summarization
  url: https://www.aclweb.org/anthology/I17-2035
  year: '2017'
I17-2036:
  abstract: This paper presents an initial study on hyperspherical query likelihood
    models (QLMs) for information retrieval (IR). Our motivation is to naturally utilize
    pre-trained word embeddings for probabilistic IR. To this end, key idea is to
    directly leverage the word embeddings as random variables for directional probabilistic
    models based on von Mises-Fisher distributions which are familiar to cosine distances.
    The proposed method enables us to theoretically take semantic similarities between
    document and target queries into consideration without introducing heuristic expansion
    techniques. In addition, this paper reveals relationships between hyperspherical
    QLMs and conventional QLMs. Experiments show document retrieval evaluation results
    in which a hyperspherical QLM is compared to conventional QLMs and document distance
    metrics using word or document embeddings.
  address: Taipei, Taiwan
  author:
  - first: Ryo
    full: Ryo Masumura
    id: ryo-masumura
    last: Masumura
  - first: Taichi
    full: Taichi Asami
    id: taichi-asami
    last: Asami
  - first: Hirokazu
    full: Hirokazu Masataki
    id: hirokazu-masataki
    last: Masataki
  - first: Kugatsu
    full: Kugatsu Sadamitsu
    id: kugatsu-sadamitsu
    last: Sadamitsu
  - first: Kyosuke
    full: Kyosuke Nishida
    id: kyosuke-nishida
    last: Nishida
  - first: Ryuichiro
    full: Ryuichiro Higashinaka
    id: ryuichiro-higashinaka
    last: Higashinaka
  author_string: Ryo Masumura, Taichi Asami, Hirokazu Masataki, Kugatsu Sadamitsu,
    Kyosuke Nishida, Ryuichiro Higashinaka
  bibkey: masumura-etal-2017-hyperspherical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '210'
  page_last: '216'
  pages: "210\u2013216"
  paper_id: '36'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2036.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2036.jpg
  title: Hyperspherical Query Likelihood Models with Word Embeddings
  title_html: Hyperspherical Query Likelihood Models with Word Embeddings
  url: https://www.aclweb.org/anthology/I17-2036
  year: '2017'
I17-2037:
  abstract: Embedding based approaches are shown to be effective for solving simple
    Question Answering (QA) problems in recent works. The major drawback of current
    approaches is that they look only at the similarity (constraint) between a question
    and a head, relation pair. Due to the absence of tail (answer) in the questions,
    these models often require paraphrase datasets to obtain adequate embeddings.
    In this paper, we propose a dual constraint model which exploits the embeddings
    obtained by Trans* family of algorithms to solve the simple QA problem without
    using any additional resources such as paraphrase datasets. The results obtained
    prove that the embeddings learned using dual constraints are better than those
    with single constraint models having similar architecture.
  address: Taipei, Taiwan
  author:
  - first: Kaustubh
    full: Kaustubh Kulkarni
    id: kaustubh-kulkarni
    last: Kulkarni
  - first: Riku
    full: Riku Togashi
    id: riku-togashi
    last: Togashi
  - first: Hideyuki
    full: Hideyuki Maeda
    id: hideyuki-maeda
    last: Maeda
  - first: Sumio
    full: Sumio Fujita
    id: sumio-fujita
    last: Fujita
  author_string: Kaustubh Kulkarni, Riku Togashi, Hideyuki Maeda, Sumio Fujita
  bibkey: kulkarni-etal-2017-dual
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '217'
  page_last: '221'
  pages: "217\u2013221"
  paper_id: '37'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2037.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2037.jpg
  title: Dual Constrained Question Embeddings with Relational Knowledge Bases for
    Simple Question Answering
  title_html: Dual Constrained Question Embeddings with Relational Knowledge Bases
    for Simple Question Answering
  url: https://www.aclweb.org/anthology/I17-2037
  year: '2017'
I17-2038:
  abstract: "This paper investigates the problem of answering compositional factoid\
    \ questions over knowledge bases (KB) under efficiency constraints. The method,\
    \ called TIPI, (i) decomposes compositional questions, (ii) predicts answer types\
    \ for individual sub-questions, (iii) reasons over the compatibility of joint\
    \ types, and finally, (iv) formulates compositional SPARQL queries respecting\
    \ type constraints. TIPI\u2019s answer type predictor is trained using distant\
    \ supervision, and exploits lexical, syntactic and embedding-based features to\
    \ compute context- and hierarchy-aware candidate answer types for an input question.\
    \ Experiments on a recent benchmark show that TIPI results in state-of-the-art\
    \ performance under the real-world assumption that only a single SPARQL query\
    \ can be executed over the KB, and substantial reduction in the number of queries\
    \ in the more general case."
  address: Taipei, Taiwan
  author:
  - first: David
    full: David Ziegler
    id: david-ziegler
    last: Ziegler
  - first: Abdalghani
    full: Abdalghani Abujabal
    id: abdalghani-abujabal
    last: Abujabal
  - first: Rishiraj
    full: Rishiraj Saha Roy
    id: rishiraj-saha-roy
    last: Saha Roy
  - first: Gerhard
    full: Gerhard Weikum
    id: gerhard-weikum
    last: Weikum
  author_string: David Ziegler, Abdalghani Abujabal, Rishiraj Saha Roy, Gerhard Weikum
  bibkey: ziegler-etal-2017-efficiency
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '222'
  page_last: '227'
  pages: "222\u2013227"
  paper_id: '38'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2038.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2038.jpg
  title: Efficiency-aware Answering of Compositional Questions using Answer Type Prediction
  title_html: Efficiency-aware Answering of Compositional Questions using Answer Type
    Prediction
  url: https://www.aclweb.org/anthology/I17-2038
  year: '2017'
I17-2039:
  abstract: 'Relation Discovery discovers predicates (relation types) from a text
    corpus relying on the co-occurrence of two named entities in the same sentence.
    This is a very narrowing constraint: it represents only a small fraction of all
    relation mentions in practice. In this paper we propose a high recall approach
    for Open IE, which enables covering up to 16 times more sentences in a large corpus.
    Comparison against OpenIE systems shows that our proposed approach achieves 28%
    improvement over the highest recall OpenIE system and 6% improvement in precision
    than the same system.'
  address: Taipei, Taiwan
  author:
  - first: Hady
    full: Hady Elsahar
    id: hady-elsahar
    last: Elsahar
  - first: Christophe
    full: Christophe Gravier
    id: christophe-gravier
    last: Gravier
  - first: Frederique
    full: Frederique Laforest
    id: frederique-laforest
    last: Laforest
  author_string: Hady Elsahar, Christophe Gravier, Frederique Laforest
  bibkey: elsahar-etal-2017-high
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '228'
  page_last: '233'
  pages: "228\u2013233"
  paper_id: '39'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2039.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2039.jpg
  title: High Recall Open IE for Relation Discovery
  title_html: High Recall Open <span class="acl-fixed-case">IE</span> for Relation
    Discovery
  url: https://www.aclweb.org/anthology/I17-2039
  year: '2017'
I17-2040:
  abstract: Focusing on the task of identifying event temporal status, we find that
    events directly or indirectly governing the target event in a dependency tree
    are most important contexts. Therefore, we extract dependency chains containing
    context events and use them as input in neural network models, which consistently
    outperform previous models using local context words as input. Visualization verifies
    that the dependency chain representation can effectively capture the context events
    which are closely related to the target event and play key roles in predicting
    event temporal status.
  address: Taipei, Taiwan
  author:
  - first: Zeyu
    full: Zeyu Dai
    id: zeyu-dai
    last: Dai
  - first: Wenlin
    full: Wenlin Yao
    id: wenlin-yao
    last: Yao
  - first: Ruihong
    full: Ruihong Huang
    id: ruihong-huang
    last: Huang
  author_string: Zeyu Dai, Wenlin Yao, Ruihong Huang
  bibkey: dai-etal-2017-using
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '234'
  page_last: '239'
  pages: "234\u2013239"
  paper_id: '40'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2040.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2040.jpg
  title: Using Context Events in Neural Network Models for Event Temporal Status Identification
  title_html: Using Context Events in Neural Network Models for Event Temporal Status
    Identification
  url: https://www.aclweb.org/anthology/I17-2040
  year: '2017'
I17-2041:
  abstract: In this paper, we propose a recurrent neural network model for identifying
    protein-protein interactions in biomedical literature. Experiments on two largest
    public benchmark datasets, AIMed and BioInfer, demonstrate that our approach significantly
    surpasses state-of-the-art methods with relative improvements of 10% and 18%,
    respectively. Cross-corpus evaluation also demonstrate that the proposed model
    remains robust despite using different training data. These results suggest that
    RNN can effectively capture semantic relationships among proteins as well as generalizes
    over different corpora, without any feature engineering.
  address: Taipei, Taiwan
  author:
  - first: Yu-Lun
    full: Yu-Lun Hsieh
    id: yu-lun-hsieh
    last: Hsieh
  - first: Yung-Chun
    full: Yung-Chun Chang
    id: yung-chun-chang
    last: Chang
  - first: Nai-Wen
    full: Nai-Wen Chang
    id: nai-wen-chang
    last: Chang
  - first: Wen-Lian
    full: Wen-Lian Hsu
    id: wen-lian-hsu
    last: Hsu
  author_string: Yu-Lun Hsieh, Yung-Chun Chang, Nai-Wen Chang, Wen-Lian Hsu
  bibkey: hsieh-etal-2017-identifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '240'
  page_last: '245'
  pages: "240\u2013245"
  paper_id: '41'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2041.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2041.jpg
  title: Identifying Protein-protein Interactions in Biomedical Literature using Recurrent
    Neural Networks with Long Short-Term Memory
  title_html: Identifying Protein-protein Interactions in Biomedical Literature using
    Recurrent Neural Networks with Long Short-Term Memory
  url: https://www.aclweb.org/anthology/I17-2041
  year: '2017'
I17-2042:
  abstract: "Empathy captures one\u2019s ability to correlate with and understand\
    \ others\u2019 emotional states and experiences. Messages with empathetic content\
    \ are considered as one of the main advantages for joining online health communities\
    \ due to their potential to improve people\u2019s moods. Unfortunately, to this\
    \ date, no computational studies exist that automatically identify empathetic\
    \ messages in online health communities. We propose a combination of Convolutional\
    \ Neural Networks (CNN) and Long Short Term Memory (LSTM) networks, and show that\
    \ the proposed model outperforms each individual model (CNN and LSTM) as well\
    \ as several baselines."
  address: Taipei, Taiwan
  author:
  - first: Hamed
    full: Hamed Khanpour
    id: hamed-khanpour
    last: Khanpour
  - first: Cornelia
    full: Cornelia Caragea
    id: cornelia-caragea
    last: Caragea
  - first: Prakhar
    full: Prakhar Biyani
    id: prakhar-biyani
    last: Biyani
  author_string: Hamed Khanpour, Cornelia Caragea, Prakhar Biyani
  bibkey: khanpour-etal-2017-identifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '246'
  page_last: '251'
  pages: "246\u2013251"
  paper_id: '42'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2042.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2042.jpg
  title: Identifying Empathetic Messages in Online Health Communities
  title_html: Identifying Empathetic Messages in Online Health Communities
  url: https://www.aclweb.org/anthology/I17-2042
  year: '2017'
I17-2043:
  abstract: Automatic fake news detection is an important, yet very challenging topic.
    Traditional methods using lexical features have only very limited success. This
    paper proposes a novel method to incorporate speaker profiles into an attention
    based LSTM model for fake news detection. Speaker profiles contribute to the model
    in two ways. One is to include them in the attention model. The other includes
    them as additional input data. By adding speaker profiles such as party affiliation,
    speaker title, location and credit history, our model outperforms the state-of-the-art
    method by 14.5% in accuracy using a benchmark fake news detection dataset. This
    proves that speaker profiles provide valuable information to validate the credibility
    of news articles.
  address: Taipei, Taiwan
  author:
  - first: Yunfei
    full: Yunfei Long
    id: yunfei-long
    last: Long
  - first: Qin
    full: Qin Lu
    id: qin-lu
    last: Lu
  - first: Rong
    full: Rong Xiang
    id: rong-xiang
    last: Xiang
  - first: Minglei
    full: Minglei Li
    id: minglei-li
    last: Li
  - first: Chu-Ren
    full: Chu-Ren Huang
    id: chu-ren-huang
    last: Huang
  author_string: Yunfei Long, Qin Lu, Rong Xiang, Minglei Li, Chu-Ren Huang
  bibkey: long-etal-2017-fake
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '252'
  page_last: '256'
  pages: "252\u2013256"
  paper_id: '43'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2043.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2043.jpg
  title: Fake News Detection Through Multi-Perspective Speaker Profiles
  title_html: Fake News Detection Through Multi-Perspective Speaker Profiles
  url: https://www.aclweb.org/anthology/I17-2043
  year: '2017'
I17-2044:
  abstract: In this study, we investigated the effectiveness of augmented data for
    encoder-decoder-based neural normalization models. Attention based encoder-decoder
    models are greatly effective in generating many natural languages. % such as machine
    translation or machine summarization. In general, we have to prepare for a large
    amount of training data to train an encoder-decoder model. Unlike machine translation,
    there are few training data for text-normalization tasks. In this paper, we propose
    two methods for generating augmented data. The experimental results with Japanese
    dialect normalization indicate that our methods are effective for an encoder-decoder
    model and achieve higher BLEU score than that of baselines. We also investigated
    the oracle performance and revealed that there is sufficient room for improving
    an encoder-decoder model.
  address: Taipei, Taiwan
  author:
  - first: Itsumi
    full: Itsumi Saito
    id: itsumi-saito
    last: Saito
  - first: Jun
    full: Jun Suzuki
    id: jun-suzuki
    last: Suzuki
  - first: Kyosuke
    full: Kyosuke Nishida
    id: kyosuke-nishida
    last: Nishida
  - first: Kugatsu
    full: Kugatsu Sadamitsu
    id: kugatsu-sadamitsu
    last: Sadamitsu
  - first: Satoshi
    full: Satoshi Kobashikawa
    id: satoshi-kobashikawa
    last: Kobashikawa
  - first: Ryo
    full: Ryo Masumura
    id: ryo-masumura
    last: Masumura
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  - first: Junji
    full: Junji Tomita
    id: junji-tomita
    last: Tomita
  author_string: Itsumi Saito, Jun Suzuki, Kyosuke Nishida, Kugatsu Sadamitsu, Satoshi
    Kobashikawa, Ryo Masumura, Yuji Matsumoto, Junji Tomita
  bibkey: saito-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '257'
  page_last: '262'
  pages: "257\u2013262"
  paper_id: '44'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2044.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2044.jpg
  title: Improving Neural Text Normalization with Data Augmentation at Character-
    and Morphological Levels
  title_html: Improving Neural Text Normalization with Data Augmentation at Character-
    and Morphological Levels
  url: https://www.aclweb.org/anthology/I17-2044
  year: '2017'
I17-2045:
  abstract: We propose a hierarchical neural network model for language variety identification
    that integrates information from a social network. Recently, language variety
    identification has enjoyed heightened popularity as an advanced task of language
    identification. The proposed model uses additional texts from a social network
    to improve language variety identification from two perspectives. First, they
    are used to introduce the effects of homophily. Secondly, they are used as expanded
    training data for shared layers of the proposed model. By introducing information
    from social networks, the model improved its accuracy by 1.67-5.56. Compared to
    state-of-the-art baselines, these improved performances are better in English
    and comparable in Spanish. Furthermore, we analyzed the cases of Portuguese and
    Arabic when the model showed weak performances, and found that the effect of homophily
    is likely to be weak due to sparsity and noises compared to languages with the
    strong performances.
  address: Taipei, Taiwan
  author:
  - first: Yasuhide
    full: Yasuhide Miura
    id: yasuhide-miura
    last: Miura
  - first: Tomoki
    full: Tomoki Taniguchi
    id: tomoki-taniguchi
    last: Taniguchi
  - first: Motoki
    full: Motoki Taniguchi
    id: motoki-taniguchi
    last: Taniguchi
  - first: Shotaro
    full: Shotaro Misawa
    id: shotaro-misawa
    last: Misawa
  - first: Tomoko
    full: Tomoko Ohkuma
    id: tomoko-ohkuma
    last: Ohkuma
  author_string: Yasuhide Miura, Tomoki Taniguchi, Motoki Taniguchi, Shotaro Misawa,
    Tomoko Ohkuma
  bibkey: miura-etal-2017-using
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '263'
  page_last: '270'
  pages: "263\u2013270"
  paper_id: '45'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2045.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2045.jpg
  title: Using Social Networks to Improve Language Variety Identification with Neural
    Networks
  title_html: Using Social Networks to Improve Language Variety Identification with
    Neural Networks
  url: https://www.aclweb.org/anthology/I17-2045
  year: '2017'
I17-2046:
  abstract: "Training efficiency is one of the main problems for Neural Machine Translation\
    \ (NMT). Deep networks need for very large data as well as many training iterations\
    \ to achieve state-of-the-art performance. This results in very high computation\
    \ cost, slowing down research and industrialisation. In this paper, we propose\
    \ to alleviate this problem with several training methods based on data boosting\
    \ and bootstrap with no modifications to the neural network. It imitates the learning\
    \ process of humans, which typically spend more time when learning \u201Cdifficult\u201D\
    \ concepts than easier ones. We experiment on an English-French translation task\
    \ showing accuracy improvements of up to 1.63 BLEU while saving 20% of training\
    \ time."
  address: Taipei, Taiwan
  author:
  - first: Dakun
    full: Dakun Zhang
    id: dakun-zhang
    last: Zhang
  - first: Jungi
    full: Jungi Kim
    id: jungi-kim
    last: Kim
  - first: Josep
    full: Josep Crego
    id: josep-m-crego
    last: Crego
  - first: Jean
    full: Jean Senellart
    id: jean-senellart
    last: Senellart
  author_string: Dakun Zhang, Jungi Kim, Josep Crego, Jean Senellart
  bibkey: zhang-etal-2017-boosting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '271'
  page_last: '276'
  pages: "271\u2013276"
  paper_id: '46'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2046.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2046.jpg
  title: Boosting Neural Machine Translation
  title_html: Boosting Neural Machine Translation
  url: https://www.aclweb.org/anthology/I17-2046
  year: '2017'
I17-2047:
  abstract: This study reports an attempt to predict the voice of reference using
    the information from the input sentences or previous input/output sentences. Our
    previous study presented a voice controlling method to generate sentences for
    neural machine translation, wherein it was demonstrated that the BLEU score improved
    when the voice of generated sentence was controlled relative to that of the reference.
    However, it is impractical to use the reference information because we cannot
    discern the voice of the correct translation in advance. Thus, this study presents
    a voice prediction method for generated sentences for neural machine translation.
    While evaluating on Japanese-to-English translation, we obtain a 0.70-improvement
    in the BLEU using the predicted voice.
  address: Taipei, Taiwan
  author:
  - first: Hayahide
    full: Hayahide Yamagishi
    id: hayahide-yamagishi
    last: Yamagishi
  - first: Shin
    full: Shin Kanouchi
    id: shin-kanouchi
    last: Kanouchi
  - first: Takayuki
    full: Takayuki Sato
    id: takayuki-sato
    last: Sato
  - first: Mamoru
    full: Mamoru Komachi
    id: mamoru-komachi
    last: Komachi
  author_string: Hayahide Yamagishi, Shin Kanouchi, Takayuki Sato, Mamoru Komachi
  bibkey: yamagishi-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '277'
  page_last: '282'
  pages: "277\u2013282"
  paper_id: '47'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2047.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2047.jpg
  title: Improving Japanese-to-English Neural Machine Translation by Voice Prediction
  title_html: Improving <span class="acl-fixed-case">J</span>apanese-to-<span class="acl-fixed-case">E</span>nglish
    Neural Machine Translation by Voice Prediction
  url: https://www.aclweb.org/anthology/I17-2047
  year: '2017'
I17-2048:
  abstract: We investigate pivot-based translation between related languages in a
    low resource, phrase-based SMT setting. We show that a subword-level pivot-based
    SMT model using a related pivot language is substantially better than word and
    morpheme-level pivot models. It is also highly competitive with the best direct
    translation model, which is encouraging as no direct source-target training corpus
    is used. We also show that combining multiple related language pivot models can
    rival a direct translation model. Thus, the use of subwords as translation units
    coupled with multiple related pivot languages can compensate for the lack of a
    direct parallel corpus.
  address: Taipei, Taiwan
  author:
  - first: Anoop
    full: Anoop Kunchukuttan
    id: anoop-kunchukuttan
    last: Kunchukuttan
  - first: Maulik
    full: Maulik Shah
    id: maulik-shah
    last: Shah
  - first: Pradyot
    full: Pradyot Prakash
    id: pradyot-prakash
    last: Prakash
  - first: Pushpak
    full: Pushpak Bhattacharyya
    id: pushpak-bhattacharyya
    last: Bhattacharyya
  author_string: Anoop Kunchukuttan, Maulik Shah, Pradyot Prakash, Pushpak Bhattacharyya
  bibkey: kunchukuttan-etal-2017-utilizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '283'
  page_last: '289'
  pages: "283\u2013289"
  paper_id: '48'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2048.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2048.jpg
  title: Utilizing Lexical Similarity between Related, Low-resource Languages for
    Pivot-based SMT
  title_html: Utilizing Lexical Similarity between Related, Low-resource Languages
    for Pivot-based <span class="acl-fixed-case">SMT</span>
  url: https://www.aclweb.org/anthology/I17-2048
  year: '2017'
I17-2049:
  abstract: In this paper, we propose a neural machine translation (NMT) with a key-value
    attention mechanism on the source-side encoder. The key-value attention mechanism
    separates the source-side content vector into two types of memory known as the
    key and the value. The key is used for calculating the attention distribution,
    and the value is used for encoding the context representation. Experiments on
    three different tasks indicate that our model outperforms an NMT model with a
    conventional attention mechanism. Furthermore, we perform experiments with a conventional
    NMT framework, in which a part of the initial value of a weight matrix is set
    to zero so that the matrix is as the same initial-state as the key-value attention
    mechanism. As a result, we obtain comparable results with the key-value attention
    mechanism without changing the network structure.
  address: Taipei, Taiwan
  author:
  - first: Hideya
    full: Hideya Mino
    id: hideya-mino
    last: Mino
  - first: Masao
    full: Masao Utiyama
    id: masao-utiyama
    last: Utiyama
  - first: Eiichiro
    full: Eiichiro Sumita
    id: eiichiro-sumita
    last: Sumita
  - first: Takenobu
    full: Takenobu Tokunaga
    id: takenobu-tokunaga
    last: Tokunaga
  author_string: Hideya Mino, Masao Utiyama, Eiichiro Sumita, Takenobu Tokunaga
  bibkey: mino-etal-2017-key
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '290'
  page_last: '295'
  pages: "290\u2013295"
  paper_id: '49'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2049.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2049.jpg
  title: Key-value Attention Mechanism for Neural Machine Translation
  title_html: Key-value Attention Mechanism for Neural Machine Translation
  url: https://www.aclweb.org/anthology/I17-2049
  year: '2017'
I17-2050:
  abstract: We present a simple method to improve neural translation of a low-resource
    language pair using parallel data from a related, also low-resource, language
    pair. The method is based on the transfer method of Zoph et al., but whereas their
    method ignores any source vocabulary overlap, ours exploits it. First, we split
    words using Byte Pair Encoding (BPE) to increase vocabulary overlap. Then, we
    train a model on the first language pair and transfer its parameters, including
    its source word embeddings, to another model and continue training on the second
    language pair. Our experiments show that transfer learning helps word-based translation
    only slightly, but when used on top of a much stronger BPE baseline, it yields
    larger improvements of up to 4.3 BLEU.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2050.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/I17-2050.Software.zip
  author:
  - first: Toan Q.
    full: Toan Q. Nguyen
    id: toan-q-nguyen
    last: Nguyen
  - first: David
    full: David Chiang
    id: david-chiang
    last: Chiang
  author_string: Toan Q. Nguyen, David Chiang
  bibkey: nguyen-chiang-2017-transfer
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '296'
  page_last: '301'
  pages: "296\u2013301"
  paper_id: '50'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2050.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2050.jpg
  title: Transfer Learning across Low-Resource, Related Languages for Neural Machine
    Translation
  title_html: Transfer Learning across Low-Resource, Related Languages for Neural
    Machine Translation
  url: https://www.aclweb.org/anthology/I17-2050
  year: '2017'
I17-2051:
  abstract: Neural machine translation decoders are usually conditional language models
    to sequentially generate words for target sentences. This approach is limited
    to find the best word composition and requires help of explicit methods as beam
    search. To help learning correct compositional mechanisms in NMTs, we propose
    concept equalization using direct mapping distributed representations of source
    and target sentences. In a translation experiment from English to French, the
    concept equalization significantly improved translation quality by 3.00 BLEU points
    compared to a state-of-the-art NMT model.
  address: Taipei, Taiwan
  author:
  - first: Kangil
    full: Kangil Kim
    id: kangil-kim
    last: Kim
  - first: Jong-Hun
    full: Jong-Hun Shin
    id: jong-hun-shin
    last: Shin
  - first: Seung-Hoon
    full: Seung-Hoon Na
    id: seung-hoon-na
    last: Na
  - first: SangKeun
    full: SangKeun Jung
    id: sangkeun-jung
    last: Jung
  author_string: Kangil Kim, Jong-Hun Shin, Seung-Hoon Na, SangKeun Jung
  bibkey: kim-etal-2017-concept
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '302'
  page_last: '307'
  pages: "302\u2013307"
  paper_id: '51'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2051.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2051.jpg
  title: Concept Equalization to Guide Correct Training of Neural Machine Translation
  title_html: Concept Equalization to Guide Correct Training of Neural Machine Translation
  url: https://www.aclweb.org/anthology/I17-2051
  year: '2017'
I17-2052:
  abstract: 'We present PubMed 200k RCT, a new dataset based on PubMed for sequential
    sentence classification. The dataset consists of approximately 200,000 abstracts
    of randomized controlled trials, totaling 2.3 million sentences. Each sentence
    of each abstract is labeled with their role in the abstract using one of the following
    classes: background, objective, method, result, or conclusion. The purpose of
    releasing this dataset is twofold. First, the majority of datasets for sequential
    short-text classification (i.e., classification of short texts that appear in
    sequences) are small: we hope that releasing a new large dataset will help develop
    more accurate algorithms for this task. Second, from an application perspective,
    researchers need better tools to efficiently skim through the literature. Automatically
    classifying each sentence in an abstract would help researchers read abstracts
    more efficiently, especially in fields where abstracts may be long, such as the
    medical field.'
  address: Taipei, Taiwan
  author:
  - first: Franck
    full: Franck Dernoncourt
    id: franck-dernoncourt
    last: Dernoncourt
  - first: Ji Young
    full: Ji Young Lee
    id: ji-young-lee
    last: Lee
  author_string: Franck Dernoncourt, Ji Young Lee
  bibkey: dernoncourt-lee-2017-pubmed
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '308'
  page_last: '313'
  pages: "308\u2013313"
  paper_id: '52'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2052.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2052.jpg
  title: 'PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical
    Abstracts'
  title_html: '<span class="acl-fixed-case">P</span>ub<span class="acl-fixed-case">M</span>ed
    200k <span class="acl-fixed-case">RCT</span>: a Dataset for Sequential Sentence
    Classification in Medical Abstracts'
  url: https://www.aclweb.org/anthology/I17-2052
  year: '2017'
I17-2053:
  abstract: "Automated documentation of programming source code and automated code\
    \ generation from natural language are challenging tasks of both practical and\
    \ scientific interest. Progress in these areas has been limited by the low availability\
    \ of parallel corpora of code and natural language descriptions, which tend to\
    \ be small and constrained to specific domains. In this work we introduce a large\
    \ and diverse parallel corpus of a hundred thousands Python functions with their\
    \ documentation strings (\u201Cdocstrings\u201D) generated by scraping open source\
    \ repositories on GitHub. We describe baseline results for the code documentation\
    \ and code generation tasks obtained by neural machine translation. We also experiment\
    \ with data augmentation techniques to further increase the amount of training\
    \ data. We release our datasets and processing scripts in order to stimulate research\
    \ in these areas."
  address: Taipei, Taiwan
  author:
  - first: Antonio Valerio
    full: Antonio Valerio Miceli Barone
    id: antonio-valerio-miceli-barone
    last: Miceli Barone
  - first: Rico
    full: Rico Sennrich
    id: rico-sennrich
    last: Sennrich
  author_string: Antonio Valerio Miceli Barone, Rico Sennrich
  bibkey: miceli-barone-sennrich-2017-parallel
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '314'
  page_last: '319'
  pages: "314\u2013319"
  paper_id: '53'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2053.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2053.jpg
  title: A Parallel Corpus of Python Functions and Documentation Strings for Automated
    Code Documentation and Code Generation
  title_html: A Parallel Corpus of Python Functions and Documentation Strings for
    Automated Code Documentation and Code Generation
  url: https://www.aclweb.org/anthology/I17-2053
  year: '2017'
I17-2054:
  abstract: Corpus is a valuable resource for information retrieval and data-driven
    natural language processing systems,especially for spoken dialogue research in
    specific domains. However,there is little non-English corpora, particular for
    ones in Chinese. Spoken by the nation with the largest population in the world,
    Chinese become increasingly prevalent and popular among millions of people worldwide.
    In this paper, we build a large-scale and high-quality Chinese corpus, called
    CSDC (Chinese Spoken Dialogue Corpus). It contains five domains and more than
    140 thousand dialogues in all. Each sentence in this corpus is annotated with
    slot information additionally compared to other corpora. To our best knowledge,
    this is the largest Chinese spoken dialogue corpus, as well as the first one with
    slot information. With this corpus, we proposed a method and did a well-designed
    experiment. The indicative result is reported at last.
  address: Taipei, Taiwan
  author:
  - first: Changliang
    full: Changliang Li
    id: changliang-li
    last: Li
  - first: Xiuying
    full: Xiuying Wang
    id: xiuying-wang
    last: Wang
  author_string: Changliang Li, Xiuying Wang
  bibkey: li-wang-2017-building
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '320'
  page_last: '324'
  pages: "320\u2013324"
  paper_id: '54'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2054.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2054.jpg
  title: Building Large Chinese Corpus for Spoken Dialogue Research in Specific Domains
  title_html: Building Large <span class="acl-fixed-case">C</span>hinese Corpus for
    Spoken Dialogue Research in Specific Domains
  url: https://www.aclweb.org/anthology/I17-2054
  year: '2017'
I17-2055:
  abstract: 'We present the first study that evaluates both speaker and listener identification
    for direct speech in literary texts. Our approach consists of two steps: identification
    of speakers and listeners near the quotes, and dialogue chain segmentation. Evaluation
    results show that this approach outperforms a rule-based approach that is state-of-the-art
    on a corpus of literary texts.'
  address: Taipei, Taiwan
  author:
  - first: Chak Yan
    full: Chak Yan Yeung
    id: chak-yan-yeung
    last: Yeung
  - first: John
    full: John Lee
    id: john-s-y-lee
    last: Lee
  author_string: Chak Yan Yeung, John Lee
  bibkey: yeung-lee-2017-identifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '325'
  page_last: '329'
  pages: "325\u2013329"
  paper_id: '55'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2055.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2055.jpg
  title: Identifying Speakers and Listeners of Quoted Speech in Literary Works
  title_html: Identifying Speakers and Listeners of Quoted Speech in Literary Works
  url: https://www.aclweb.org/anthology/I17-2055
  year: '2017'
I17-2056:
  abstract: The psycholinguistic properties of words, namely, word familiarity, age
    of acquisition, concreteness, and imagery, have been reported to be effective
    for educational natural language-processing tasks. Previous studies on predicting
    the values of these properties rely on language-dependent features. This paper
    is the first to propose a practical language-independent method for predicting
    such values by using only a large raw corpus in a language. Through experiments,
    our method successfully predicted the values of these properties in two languages.
    The results for English were competitive with the reported accuracy achieved using
    features specific to English.
  address: Taipei, Taiwan
  author:
  - first: Yo
    full: Yo Ehara
    id: yo-ehara
    last: Ehara
  author_string: Yo Ehara
  bibkey: ehara-2017-language
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '330'
  page_last: '336'
  pages: "330\u2013336"
  paper_id: '56'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2056.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2056.jpg
  title: Language-Independent Prediction of Psycholinguistic Properties of Words
  title_html: Language-Independent Prediction of Psycholinguistic Properties of Words
  url: https://www.aclweb.org/anthology/I17-2056
  year: '2017'
I17-2057:
  abstract: It is very costly and time consuming to find new biomarkers for specific
    diseases in clinical laboratories. In this study, to find new biomarkers most
    closely related to Chronic Obstructive Pulmonary Disease (COPD), which is widely
    known as respiratory disease, biomarkers known to be associated with respiratory
    diseases and COPD itself were converted into word embedding. And their similarities
    were measured. We used Word2Vec, Canonical Correlation Analysis (CCA), and Global
    Vector (GloVe) for word embedding. In order to replace the clinical evaluation,
    the titles and abstracts of papers retrieved from Google Scholars were analyzed
    and quantified to estimate the performance of the word em-bedding models.
  address: Taipei, Taiwan
  author:
  - first: Byeong-Hun
    full: Byeong-Hun Yoon
    id: byeong-hun-yoon
    last: Yoon
  - first: Yu-Seop
    full: Yu-Seop Kim
    id: yu-seop-kim
    last: Kim
  author_string: Byeong-Hun Yoon, Yu-Seop Kim
  bibkey: yoon-kim-2017-correlation
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '337'
  page_last: '342'
  pages: "337\u2013342"
  paper_id: '57'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2057.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2057.jpg
  title: Correlation Analysis of Chronic Obstructive Pulmonary Disease (COPD) and
    its Biomarkers Using the Word Embeddings
  title_html: Correlation Analysis of Chronic Obstructive Pulmonary Disease (<span
    class="acl-fixed-case">COPD</span>) and its Biomarkers Using the Word Embeddings
  url: https://www.aclweb.org/anthology/I17-2057
  year: '2017'
I17-2058:
  abstract: In grammatical error correction (GEC), automatically evaluating system
    outputs requires gold-standard references, which must be created manually and
    thus tend to be both expensive and limited in coverage. To address this problem,
    a reference-less approach has recently emerged; however, previous reference-less
    metrics that only consider the criterion of grammaticality, have not worked as
    well as reference-based metrics. This study explores the potential of extending
    a prior grammaticality-based method to establish a reference-less evaluation method
    for GEC systems. Further, we empirically show that a reference-less metric that
    combines fluency and meaning preservation with grammaticality provides a better
    estimate of manual scores than that of commonly used reference-based metrics.
    To our knowledge, this is the first study that provides empirical evidence that
    a reference-less metric can replace reference-based metrics in evaluating GEC
    systems.
  address: Taipei, Taiwan
  author:
  - first: Hiroki
    full: Hiroki Asano
    id: hiroki-asano
    last: Asano
  - first: Tomoya
    full: Tomoya Mizumoto
    id: tomoya-mizumoto
    last: Mizumoto
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Hiroki Asano, Tomoya Mizumoto, Kentaro Inui
  bibkey: asano-etal-2017-reference
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '343'
  page_last: '348'
  pages: "343\u2013348"
  paper_id: '58'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2058.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2058.jpg
  title: Reference-based Metrics can be Replaced with Reference-less Metrics in Evaluating
    Grammatical Error Correction Systems
  title_html: Reference-based Metrics can be Replaced with Reference-less Metrics
    in Evaluating Grammatical Error Correction Systems
  url: https://www.aclweb.org/anthology/I17-2058
  year: '2017'
I17-2059:
  abstract: Automatic analysis of curriculum vitae (CVs) of applicants is of tremendous
    importance in recruitment scenarios. The semi-structuredness of CVs, however,
    makes CV processing a challenging task. We propose a solution towards transforming
    CVs to follow a unified structure, thereby, paving ways for smoother CV analysis.
    The problem of restructuring is posed as a section relabeling problem, where each
    section of a given CV gets reassigned to a predefined label. Our relabeling method
    relies on semantic relatedness computed between section header, content and labels,
    based on phrase-embeddings learned from a large pool of CVs. We follow different
    heuristics to measure semantic relatedness. Our best heuristic achieves an F-score
    of 93.17% on a test dataset with gold-standard labels obtained using manual annotation.
  address: Taipei, Taiwan
  author:
  - first: Shweta
    full: Shweta Garg
    id: shweta-garg
    last: Garg
  - first: Sudhanshu S
    full: Sudhanshu S Singh
    id: sudhanshu-s-singh
    last: Singh
  - first: Abhijit
    full: Abhijit Mishra
    id: abhijit-mishra
    last: Mishra
  - first: Kuntal
    full: Kuntal Dey
    id: kuntal-dey
    last: Dey
  author_string: Shweta Garg, Sudhanshu S Singh, Abhijit Mishra, Kuntal Dey
  bibkey: garg-etal-2017-cvbed
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '349'
  page_last: '354'
  pages: "349\u2013354"
  paper_id: '59'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2059.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2059.jpg
  title: 'CVBed: Structuring CVs usingWord Embeddings'
  title_html: '<span class="acl-fixed-case">CVB</span>ed: Structuring <span class="acl-fixed-case">CV</span>s
    using<span class="acl-fixed-case">W</span>ord Embeddings'
  url: https://www.aclweb.org/anthology/I17-2059
  year: '2017'
I17-2060:
  abstract: In this work we study the challenging task of automatically constructing
    essays for Chinese college entrance examination where the topic is specified in
    advance. We explore a sentence extraction framework based on diversified lexical
    chains to capture coherence and richness. Experimental analysis shows the effectiveness
    of our approach and reveals the importance of information richness in essay writing.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2060.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2060.Notes.pdf
  - filename: I17-2060.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/I17-2060.Datasets.zip
  author:
  - first: Liunian
    full: Liunian Li
    id: liunian-li
    last: Li
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  - first: Jin-ge
    full: Jin-ge Yao
    id: jin-ge-yao
    last: Yao
  - first: Siming
    full: Siming Yan
    id: siming-yan
    last: Yan
  author_string: Liunian Li, Xiaojun Wan, Jin-ge Yao, Siming Yan
  bibkey: li-etal-2017-leveraging-diverse
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '355'
  page_last: '360'
  pages: "355\u2013360"
  paper_id: '60'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2060.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2060.jpg
  title: Leveraging Diverse Lexical Chains to Construct Essays for Chinese College
    Entrance Examination
  title_html: Leveraging Diverse Lexical Chains to Construct Essays for <span class="acl-fixed-case">C</span>hinese
    College Entrance Examination
  url: https://www.aclweb.org/anthology/I17-2060
  year: '2017'
I17-2061:
  abstract: 'While language conveys meaning largely symbolically, actual communication
    acts typically contain iconic elements as well: People gesture while they speak,
    or may even draw sketches while explaining something. Image retrieval prima facie
    seems like a task that could profit from combined symbolic and iconic reference,
    but it is typically set up to work either from language only, or via (iconic)
    sketches with no verbal contribution. Using a model of grounded language semantics
    and a model of sketch-to-image mapping, we show that adding even very reduced
    iconic information to a verbal image description improves recall. Verbal descriptions
    paired with fully detailed sketches still perform better than these sketches alone.
    We see these results as supporting the assumption that natural user interfaces
    should respond to multimodal input, where possible, rather than just language
    alone.'
  address: Taipei, Taiwan
  author:
  - first: Ting
    full: Ting Han
    id: ting-han
    last: Han
  - first: David
    full: David Schlangen
    id: david-schlangen
    last: Schlangen
  author_string: Ting Han, David Schlangen
  bibkey: han-schlangen-2017-draw
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '361'
  page_last: '365'
  pages: "361\u2013365"
  paper_id: '61'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2061.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2061.jpg
  title: 'Draw and Tell: Multimodal Descriptions Outperform Verbal- or Sketch-Only
    Descriptions in an Image Retrieval Task'
  title_html: 'Draw and Tell: Multimodal Descriptions Outperform Verbal- or Sketch-Only
    Descriptions in an Image Retrieval Task'
  url: https://www.aclweb.org/anthology/I17-2061
  year: '2017'
I17-2062:
  abstract: We propose a neural encoder-decoder model with reinforcement learning
    (NRL) for grammatical error correction (GEC). Unlike conventional maximum likelihood
    estimation (MLE), the model directly optimizes towards an objective that considers
    a sentence-level, task-specific evaluation metric, avoiding the exposure bias
    issue in MLE. We demonstrate that NRL outperforms MLE both in human and automated
    evaluation metrics, achieving the state-of-the-art on a fluency-oriented GEC corpus.
  address: Taipei, Taiwan
  author:
  - first: Keisuke
    full: Keisuke Sakaguchi
    id: keisuke-sakaguchi
    last: Sakaguchi
  - first: Matt
    full: Matt Post
    id: matt-post
    last: Post
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  author_string: Keisuke Sakaguchi, Matt Post, Benjamin Van Durme
  bibkey: sakaguchi-etal-2017-grammatical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '366'
  page_last: '372'
  pages: "366\u2013372"
  paper_id: '62'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2062.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2062.jpg
  title: Grammatical Error Correction with Neural Reinforcement Learning
  title_html: Grammatical Error Correction with Neural Reinforcement Learning
  url: https://www.aclweb.org/anthology/I17-2062
  year: '2017'
I17-2063:
  abstract: This paper describes a coreference resolution system for math problem
    text. Case frame dictionaries and a math taxonomy are utilized for supplying domain
    knowledge. The system deals with various anaphoric phenomena beyond well-studied
    entity coreferences.
  address: Taipei, Taiwan
  author:
  - first: Takumi
    full: Takumi Ito
    id: takumi-ito
    last: Ito
  - first: Takuya
    full: Takuya Matsuzaki
    id: takuya-matsuzaki
    last: Matsuzaki
  - first: Satoshi
    full: Satoshi Sato
    id: satoshi-sato
    last: Sato
  author_string: Takumi Ito, Takuya Matsuzaki, Satoshi Sato
  bibkey: ito-etal-2017-coreference
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '373'
  page_last: '377'
  pages: "373\u2013377"
  paper_id: '63'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2063.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2063.jpg
  title: Coreference Resolution on Math Problem Text in Japanese
  title_html: Coreference Resolution on Math Problem Text in <span class="acl-fixed-case">J</span>apanese
  url: https://www.aclweb.org/anthology/I17-2063
  year: '2017'
I17-2064:
  abstract: We propose a novel method that exploits visual information of ideograms
    and logograms in analyzing Japanese review documents. Our method first converts
    font images of Japanese characters into character embeddings using convolutional
    neural networks. It then constructs document embeddings from the character embeddings
    based on Hierarchical Attention Networks, which represent the documents based
    on attention mechanisms from a character level to a sentence level. The document
    embeddings are finally used to predict the labels of documents. Our method provides
    a way to exploit visual features of characters in languages with ideograms and
    logograms. In the experiments, our method achieved an accuracy comparable to a
    character embedding-based model while our method has much fewer parameters since
    it does not need to keep embeddings of thousands of characters.
  address: Taipei, Taiwan
  author:
  - first: Yota
    full: Yota Toyama
    id: yota-toyama
    last: Toyama
  - first: Makoto
    full: Makoto Miwa
    id: makoto-miwa
    last: Miwa
  - first: Yutaka
    full: Yutaka Sasaki
    id: yutaka-sasaki
    last: Sasaki
  author_string: Yota Toyama, Makoto Miwa, Yutaka Sasaki
  bibkey: toyama-etal-2017-utilizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '378'
  page_last: '382'
  pages: "378\u2013382"
  paper_id: '64'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2064.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2064.jpg
  title: Utilizing Visual Forms of Japanese Characters for Neural Review Classification
  title_html: Utilizing Visual Forms of <span class="acl-fixed-case">J</span>apanese
    Characters for Neural Review Classification
  url: https://www.aclweb.org/anthology/I17-2064
  year: '2017'
I17-2065:
  abstract: "We show how to adapt bilingual word embeddings (BWE\u2019s) to bootstrap\
    \ a cross-lingual name-entity recognition (NER) system in a language with no labeled\
    \ data. We assume a setting where we are given a comparable corpus with NER labels\
    \ for the source language only; our goal is to build a NER model for the target\
    \ language. The proposed multi-task model jointly trains bilingual word embeddings\
    \ while optimizing a NER objective. This creates word embeddings that are both\
    \ shared between languages and fine-tuned for the NER task."
  address: Taipei, Taiwan
  author:
  - first: Dingquan
    full: Dingquan Wang
    id: dingquan-wang
    last: Wang
  - first: Nanyun
    full: Nanyun Peng
    id: nanyun-peng
    last: Peng
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  author_string: Dingquan Wang, Nanyun Peng, Kevin Duh
  bibkey: wang-etal-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '383'
  page_last: '388'
  pages: "383\u2013388"
  paper_id: '65'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2065.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2065.jpg
  title: A Multi-task Learning Approach to Adapting Bilingual Word Embeddings for
    Cross-lingual Named Entity Recognition
  title_html: A Multi-task Learning Approach to Adapting Bilingual Word Embeddings
    for Cross-lingual Named Entity Recognition
  url: https://www.aclweb.org/anthology/I17-2065
  year: '2017'
I17-2066:
  abstract: "In dialogue systems, conveying understanding results of user utterances\
    \ is important because it enables users to feel understood by the system. However,\
    \ it is not clear what types of understanding results should be conveyed to users;\
    \ some utterances may be offensive and some may be too commonsensical. In this\
    \ paper, we explored the effect of conveying understanding results of user utterances\
    \ in a chat-oriented dialogue system by an experiment using human subjects. As\
    \ a result, we found that only certain types of understanding results, such as\
    \ those related to a user\u2019s permanent state, are effective to improve user\
    \ satisfaction. This paper clarifies the types of understanding results that can\
    \ be safely uttered by a system."
  address: Taipei, Taiwan
  author:
  - first: Koh
    full: Koh Mitsuda
    id: koh-mitsuda
    last: Mitsuda
  - first: Ryuichiro
    full: Ryuichiro Higashinaka
    id: ryuichiro-higashinaka
    last: Higashinaka
  - first: Junji
    full: Junji Tomita
    id: junji-tomita
    last: Tomita
  author_string: Koh Mitsuda, Ryuichiro Higashinaka, Junji Tomita
  bibkey: mitsuda-etal-2017-investigating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '389'
  page_last: '394'
  pages: "389\u2013394"
  paper_id: '66'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2066.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2066.jpg
  title: Investigating the Effect of Conveying Understanding Results in Chat-Oriented
    Dialogue Systems
  title_html: Investigating the Effect of Conveying Understanding Results in Chat-Oriented
    Dialogue Systems
  url: https://www.aclweb.org/anthology/I17-2066
  year: '2017'
I17-2067:
  abstract: Contrastive opinion mining is essential in identifying, extracting and
    organising opinions from user generated texts. Most existing studies separate
    input data into respective collections. In addition, the relationships between
    the topics extracted and the sentences in the corpus which express the topics
    are opaque, hindering our understanding of the opinions expressed in the corpus.
    We propose a novel unified latent variable model (contraLDA) which addresses the
    above matters. Experimental results show the effectiveness of our model in mining
    contrasted opinions, outperforming our baselines.
  address: Taipei, Taiwan
  author:
  - first: Ebuka
    full: Ebuka Ibeke
    id: ebuka-ibeke
    last: Ibeke
  - first: Chenghua
    full: Chenghua Lin
    id: chenghua-lin
    last: Lin
  - first: Adam
    full: Adam Wyner
    id: adam-wyner
    last: Wyner
  - first: Mohamad Hardyman
    full: Mohamad Hardyman Barawi
    id: mohamad-hardyman-barawi
    last: Barawi
  author_string: Ebuka Ibeke, Chenghua Lin, Adam Wyner, Mohamad Hardyman Barawi
  bibkey: ibeke-etal-2017-extracting
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '395'
  page_last: '400'
  pages: "395\u2013400"
  paper_id: '67'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2067.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2067.jpg
  title: Extracting and Understanding Contrastive Opinion through Topic Relevant Sentences
  title_html: Extracting and Understanding Contrastive Opinion through Topic Relevant
    Sentences
  url: https://www.aclweb.org/anthology/I17-2067
  year: '2017'
I17-2068:
  abstract: Complex word identification (CWI) is an important task in text accessibility.
    However, due to the scarcity of CWI datasets, previous studies have only addressed
    this problem on Wikipedia sentences and have solely taken into account the needs
    of non-native English speakers. We collect a new CWI dataset (CWIG3G2) covering
    three text genres News, WikiNews, and Wikipedia) annotated by both native and
    non-native English speakers. Unlike previous datasets, we cover single words,
    as well as complex phrases, and present them for judgment in a paragraph context.
    We present the first study on cross-genre and cross-group CWI, showing measurable
    influences in native language and genre types.
  address: Taipei, Taiwan
  author:
  - first: Seid Muhie
    full: Seid Muhie Yimam
    id: seid-muhie-yimam
    last: Yimam
  - first: Sanja
    full: "Sanja \u0160tajner"
    id: sanja-stajner
    last: "\u0160tajner"
  - first: Martin
    full: Martin Riedl
    id: martin-riedl
    last: Riedl
  - first: Chris
    full: Chris Biemann
    id: chris-biemann
    last: Biemann
  author_string: "Seid Muhie Yimam, Sanja \u0160tajner, Martin Riedl, Chris Biemann"
  bibkey: yimam-etal-2017-cwig3g2
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '401'
  page_last: '407'
  pages: "401\u2013407"
  paper_id: '68'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2068.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2068.jpg
  title: CWIG3G2 - Complex Word Identification Task across Three Text Genres and Two
    User Groups
  title_html: <span class="acl-fixed-case">CWIG</span>3<span class="acl-fixed-case">G</span>2
    - Complex Word Identification Task across Three Text Genres and Two User Groups
  url: https://www.aclweb.org/anthology/I17-2068
  year: '2017'
I17-2069:
  abstract: We propose a novel, data-driven, and stylistically consistent dialog response
    generation system. To create a user-friendly system, it is crucial to make generated
    responses not only appropriate but also stylistically consistent. For leaning
    both the properties effectively, our proposed framework has two training stages
    inspired by transfer learning. First, we train the model to generate appropriate
    responses, and then we ensure that the responses have a specific style. Experimental
    results demonstrate that the proposed method produces stylistically consistent
    responses while maintaining the appropriateness of the responses learned in a
    general domain.
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2069.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2069.Notes.pdf
  author:
  - first: Reina
    full: Reina Akama
    id: reina-akama
    last: Akama
  - first: Kazuaki
    full: Kazuaki Inada
    id: kazuaki-inada
    last: Inada
  - first: Naoya
    full: Naoya Inoue
    id: naoya-inoue
    last: Inoue
  - first: Sosuke
    full: Sosuke Kobayashi
    id: sosuke-kobayashi
    last: Kobayashi
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Reina Akama, Kazuaki Inada, Naoya Inoue, Sosuke Kobayashi, Kentaro
    Inui
  bibkey: akama-etal-2017-generating
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '408'
  page_last: '412'
  pages: "408\u2013412"
  paper_id: '69'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2069.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2069.jpg
  title: Generating Stylistically Consistent Dialog Responses with Transfer Learning
  title_html: Generating Stylistically Consistent Dialog Responses with Transfer Learning
  url: https://www.aclweb.org/anthology/I17-2069
  year: '2017'
I17-2070:
  abstract: "We describe a data-driven approach for automatically explaining new,\
    \ non-standard English expressions in a given sentence, building on a large dataset\
    \ that includes 15 years of crowdsourced examples from UrbanDictionary.com. Unlike\
    \ prior studies that focus on matching keywords from a slang dictionary, we investigate\
    \ the possibility of learning a neural sequence-to-sequence model that generates\
    \ explanations of unseen non-standard English expressions given context. We propose\
    \ a dual encoder approach\u2014a word-level encoder learns the representation\
    \ of context, and a second character-level encoder to learn the hidden representation\
    \ of the target non-standard expression. Our model can produce reasonable definitions\
    \ of new non-standard English expressions given their context with certain confidence."
  address: Taipei, Taiwan
  author:
  - first: Ke
    full: Ke Ni
    id: ke-ni
    last: Ni
  - first: William Yang
    full: William Yang Wang
    id: william-yang-wang
    last: Wang
  author_string: Ke Ni, William Yang Wang
  bibkey: ni-wang-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '413'
  page_last: '417'
  pages: "413\u2013417"
  paper_id: '70'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2070.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2070.jpg
  title: Learning to Explain Non-Standard English Words and Phrases
  title_html: Learning to Explain Non-Standard <span class="acl-fixed-case">E</span>nglish
    Words and Phrases
  url: https://www.aclweb.org/anthology/I17-2070
  year: '2017'
I17-2071:
  abstract: We propose a submodular function-based summarization system which integrates
    three important measures namely importance, coverage, and non-redundancy to detect
    the important sentences for the summary. We design monotone and submodular functions
    which allow us to apply an efficient and scalable greedy algorithm to obtain informative
    and well-covered summaries. In addition, we integrate two abstraction-based methods
    namely sentence compression and merging for generating an abstractive sentence
    set. We design our summarization models for both generic and query-focused summarization.
    Experimental results on DUC-2004 and DUC-2007 datasets show that our generic and
    query-focused summarizers have outperformed the state-of-the-art summarization
    systems in terms of ROUGE-1 and ROUGE-2 recall and F-measure.
  address: Taipei, Taiwan
  author:
  - first: Yllias
    full: Yllias Chali
    id: yllias-chali
    last: Chali
  - first: Moin
    full: Moin Tanvee
    id: moin-tanvee
    last: Tanvee
  - first: Mir Tafseer
    full: Mir Tafseer Nayeem
    id: mir-tafseer-nayeem
    last: Nayeem
  author_string: Yllias Chali, Moin Tanvee, Mir Tafseer Nayeem
  bibkey: chali-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '418'
  page_last: '424'
  pages: "418\u2013424"
  paper_id: '71'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2071.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2071.jpg
  title: Towards Abstractive Multi-Document Summarization Using Submodular Function-Based
    Framework, Sentence Compression and Merging
  title_html: Towards Abstractive Multi-Document Summarization Using Submodular Function-Based
    Framework, Sentence Compression and Merging
  url: https://www.aclweb.org/anthology/I17-2071
  year: '2017'
I17-2072:
  abstract: "Relations are expressed in many domains such as newswire, weblogs and\
    \ phone conversations. Trained on a source domain, a relation extractor\u2019\
    s performance degrades when applied to target domains other than the source. A\
    \ common yet labor-intensive method for domain adaptation is to construct a target-domain-specific\
    \ labeled dataset for adapting the extractor. In response, we present an unsupervised\
    \ domain adaptation method which only requires labels from the source domain.\
    \ Our method is a joint model consisting of a CNN-based relation classifier and\
    \ a domain-adversarial classifier. The two components are optimized jointly to\
    \ learn a domain-independent representation for prediction on the target domain.\
    \ Our model outperforms the state-of-the-art on all three test domains of ACE\
    \ 2005."
  address: Taipei, Taiwan
  author:
  - first: Lisheng
    full: Lisheng Fu
    id: lisheng-fu
    last: Fu
  - first: Thien Huu
    full: Thien Huu Nguyen
    id: thien-huu-nguyen
    last: Nguyen
  - first: Bonan
    full: Bonan Min
    id: bonan-min
    last: Min
  - first: Ralph
    full: Ralph Grishman
    id: ralph-grishman
    last: Grishman
  author_string: Lisheng Fu, Thien Huu Nguyen, Bonan Min, Ralph Grishman
  bibkey: fu-etal-2017-domain
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '425'
  page_last: '429'
  pages: "425\u2013429"
  paper_id: '72'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2072.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2072.jpg
  title: Domain Adaptation for Relation Extraction with Domain Adversarial Neural
    Network
  title_html: Domain Adaptation for Relation Extraction with Domain Adversarial Neural
    Network
  url: https://www.aclweb.org/anthology/I17-2072
  year: '2017'
I17-2073:
  abstract: We explore the application of a Deep Structured Similarity Model (DSSM)
    to ranking in lexical simplification. Our results show that the DSSM can effectively
    capture fine-grained features to perform semantic matching when ranking substitution
    candidates, outperforming the state-of-the-art on two standard datasets used for
    the task.
  address: Taipei, Taiwan
  author:
  - first: Lis
    full: Lis Pereira
    id: lis-pereira
    last: Pereira
  - first: Xiaodong
    full: Xiaodong Liu
    id: xiaodong-liu
    last: Liu
  - first: John
    full: John Lee
    id: john-s-y-lee
    last: Lee
  author_string: Lis Pereira, Xiaodong Liu, John Lee
  bibkey: pereira-etal-2017-lexical
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '430'
  page_last: '435'
  pages: "430\u2013435"
  paper_id: '73'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2073.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2073.jpg
  title: Lexical Simplification with the Deep Structured Similarity Model
  title_html: Lexical Simplification with the Deep Structured Similarity Model
  url: https://www.aclweb.org/anthology/I17-2073
  year: '2017'
I17-2074:
  abstract: This paper explores the idea of robot editors, automated proofreaders
    that enable journalists to improve the quality of their articles. We propose a
    novel neural model of multi-task learning that both generates proofread sentences
    and predicts the editing operations required to rewrite the source sentences and
    create the proofread ones. The model is trained using logs of the revisions made
    professional editors revising draft newspaper articles written by journalists.
    Experiments demonstrate the effectiveness of our multi-task learning approach
    and the potential value of using revision logs for this task.
  address: Taipei, Taiwan
  author:
  - first: Yuta
    full: Yuta Hitomi
    id: yuta-hitomi
    last: Hitomi
  - first: Hideaki
    full: Hideaki Tamori
    id: hideaki-tamori
    last: Tamori
  - first: Naoaki
    full: Naoaki Okazaki
    id: naoaki-okazaki
    last: Okazaki
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Yuta Hitomi, Hideaki Tamori, Naoaki Okazaki, Kentaro Inui
  bibkey: hitomi-etal-2017-proofread
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '436'
  page_last: '441'
  pages: "436\u2013441"
  paper_id: '74'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2074.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2074.jpg
  title: Proofread Sentence Generation as Multi-Task Learning with Editing Operation
    Prediction
  title_html: Proofread Sentence Generation as Multi-Task Learning with Editing Operation
    Prediction
  url: https://www.aclweb.org/anthology/I17-2074
  year: '2017'
I17-2075:
  abstract: 'The automation of tasks in community question answering (cQA) is dominated
    by machine learning approaches, whose performance is often limited by the number
    of training examples. Starting from a neural sequence learning approach with attention,
    we explore the impact of two data augmentation techniques on question ranking
    performance: a method that swaps reference questions with their paraphrases, and
    training on examples automatically selected from external datasets. Both methods
    are shown to lead to substantial gains in accuracy over a strong baseline. Further
    improvements are obtained by changing the model architecture to mirror the structure
    seen in the data.'
  address: Taipei, Taiwan
  author:
  - first: Charles
    full: Charles Chen
    id: charles-chen-jr
    last: Chen
  - first: Razvan
    full: Razvan Bunescu
    id: razvan-bunescu
    last: Bunescu
  author_string: Charles Chen, Razvan Bunescu
  bibkey: chen-bunescu-2017-exploration
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '442'
  page_last: '447'
  pages: "442\u2013447"
  paper_id: '75'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2075.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2075.jpg
  title: An Exploration of Data Augmentation and RNN Architectures for Question Ranking
    in Community Question Answering
  title_html: An Exploration of Data Augmentation and <span class="acl-fixed-case">RNN</span>
    Architectures for Question Ranking in Community Question Answering
  url: https://www.aclweb.org/anthology/I17-2075
  year: '2017'
I17-2076:
  abstract: "What can you do with multiple noisy versions of the same text? We present\
    \ a method which generates a single consensus between multi-parallel corpora.\
    \ By maximizing a function of linguistic features between word pairs, we jointly\
    \ learn a single corpus-wide multiway alignment: a consensus between 27 versions\
    \ of the English Bible. We additionally produce English paraphrases, word-level\
    \ distributions of tags, and consensus dependency parses. Our method is language\
    \ independent and applicable to any multi-parallel corpora. Given the Bible\u2019\
    s unique role as alignable bitext for over 800 of the world\u2019s languages,\
    \ this consensus alignment and resulting resources offer value for multilingual\
    \ annotation projection, and also shed potential insights into the Bible itself."
  address: Taipei, Taiwan
  attachment:
  - filename: I17-2076.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/I17-2076.Notes.pdf
  author:
  - first: Patrick
    full: Patrick Xia
    id: patrick-xia
    last: Xia
  - first: David
    full: David Yarowsky
    id: david-yarowsky
    last: Yarowsky
  author_string: Patrick Xia, David Yarowsky
  bibkey: xia-yarowsky-2017-deriving
  bibtype: inproceedings
  booktitle: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the Eighth International Joint Conference on Natural
    Language Processing (Volume 2: Short Papers)'
  month: November
  page_first: '448'
  page_last: '453'
  pages: "448\u2013453"
  paper_id: '76'
  parent_volume_id: I17-2
  pdf: https://www.aclweb.org/anthology/I17-2076.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-2076.jpg
  title: 'Deriving Consensus for Multi-Parallel Corpora: an English Bible Study'
  title_html: 'Deriving Consensus for Multi-Parallel Corpora: an <span class="acl-fixed-case">E</span>nglish
    <span class="acl-fixed-case">B</span>ible Study'
  url: https://www.aclweb.org/anthology/I17-2076
  year: '2017'
I17-3000:
  address: Tapei, Taiwan
  author:
  - first: Seong-Bae
    full: Seong-Bae Park
    id: seong-bae-park
    last: Park
  - first: Thepchai
    full: Thepchai Supnithi
    id: thepchai-supnithi
    last: Supnithi
  author_string: Seong-Bae Park, Thepchai Supnithi
  bibkey: ijcnlp-2017-ijcnlp
  bibtype: proceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  month: November
  paper_id: '0'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3000.jpg
  title: Proceedings of the IJCNLP 2017, System Demonstrations
  title_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  url: https://www.aclweb.org/anthology/I17-3000
  year: '2017'
I17-3001:
  abstract: 'We introduce MASSAlign: a Python library for the alignment and annotation
    of monolingual comparable documents. MASSAlign offers easy-to-use access to state
    of the art algorithms for paragraph and sentence-level alignment, as well as novel
    algorithms for word-level annotation of transformation operations between aligned
    sentences. In addition, MASSAlign provides a visualization module to display and
    analyze the alignments and annotations performed.'
  address: Tapei, Taiwan
  author:
  - first: Gustavo
    full: Gustavo Paetzold
    id: gustavo-paetzold
    last: Paetzold
  - first: Fernando
    full: Fernando Alva-Manchego
    id: fernando-alva-manchego
    last: Alva-Manchego
  - first: Lucia
    full: Lucia Specia
    id: lucia-specia
    last: Specia
  author_string: Gustavo Paetzold, Fernando Alva-Manchego, Lucia Specia
  bibkey: paetzold-etal-2017-massalign
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '1'
  page_last: '4'
  pages: "1\u20134"
  paper_id: '1'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3001.jpg
  title: 'MASSAlign: Alignment and Annotation of Comparable Documents'
  title_html: '<span class="acl-fixed-case">MASSA</span>lign: Alignment and Annotation
    of Comparable Documents'
  url: https://www.aclweb.org/anthology/I17-3001
  year: '2017'
I17-3002:
  abstract: Computer Assisted Discovery Extraction and Translation (CADET) is a workbench
    for helping knowledge workers find, label, and translate documents of interest.
    It combines a multitude of analytics together with a flexible environment for
    customizing the workflow for different users. This open-source framework allows
    for easy development of new research prototypes using a micro-service architecture
    based atop Docker and Apache Thrift.
  address: Tapei, Taiwan
  author:
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  - first: Tom
    full: Tom Lippincott
    id: tom-lippincott
    last: Lippincott
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  - first: Deana
    full: Deana Burchfield
    id: deana-burchfield
    last: Burchfield
  - first: Adam
    full: Adam Poliak
    id: adam-poliak
    last: Poliak
  - first: Cash
    full: Cash Costello
    id: cash-costello
    last: Costello
  - first: Tim
    full: Tim Finin
    id: tim-finin
    last: Finin
  - first: Scott
    full: Scott Miller
    id: scott-miller
    last: Miller
  - first: James
    full: James Mayfield
    id: james-mayfield
    last: Mayfield
  - first: Philipp
    full: Philipp Koehn
    id: philipp-koehn
    last: Koehn
  - first: Craig
    full: Craig Harman
    id: craig-harman
    last: Harman
  - first: Dawn
    full: Dawn Lawrie
    id: dawn-lawrie
    last: Lawrie
  - first: Chandler
    full: Chandler May
    id: chandler-may
    last: May
  - first: Max
    full: Max Thomas
    id: max-thomas
    last: Thomas
  - first: Annabelle
    full: Annabelle Carrell
    id: annabelle-carrell
    last: Carrell
  - first: Julianne
    full: Julianne Chaloux
    id: julianne-chaloux
    last: Chaloux
  - first: Tongfei
    full: Tongfei Chen
    id: tongfei-chen
    last: Chen
  - first: Alex
    full: Alex Comerford
    id: alex-comerford
    last: Comerford
  - first: Mark
    full: Mark Dredze
    id: mark-dredze
    last: Dredze
  - first: Benjamin
    full: Benjamin Glass
    id: benjamin-glass
    last: Glass
  - first: Shudong
    full: Shudong Hao
    id: shudong-hao
    last: Hao
  - first: Patrick
    full: Patrick Martin
    id: m-patrick-martin
    last: Martin
  - first: Pushpendre
    full: Pushpendre Rastogi
    id: pushpendre-rastogi
    last: Rastogi
  - first: Rashmi
    full: Rashmi Sankepally
    id: rashmi-sankepally
    last: Sankepally
  - first: Travis
    full: Travis Wolfe
    id: travis-wolfe
    last: Wolfe
  - first: Ying-Ying
    full: Ying-Ying Tran
    id: ying-ying-tran
    last: Tran
  - first: Ted
    full: Ted Zhang
    id: ted-zhang
    last: Zhang
  author_string: Benjamin Van Durme, Tom Lippincott, Kevin Duh, Deana Burchfield,
    Adam Poliak, Cash Costello, Tim Finin, Scott Miller, James Mayfield, Philipp Koehn,
    Craig Harman, Dawn Lawrie, Chandler May, Max Thomas, Annabelle Carrell, Julianne
    Chaloux, Tongfei Chen, Alex Comerford, Mark Dredze, Benjamin Glass, Shudong Hao,
    Patrick Martin, Pushpendre Rastogi, Rashmi Sankepally, Travis Wolfe, Ying-Ying
    Tran, Ted Zhang
  bibkey: van-durme-etal-2017-cadet
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '5'
  page_last: '8'
  pages: "5\u20138"
  paper_id: '2'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3002.jpg
  title: 'CADET: Computer Assisted Discovery Extraction and Translation'
  title_html: '<span class="acl-fixed-case">CADET</span>: Computer Assisted Discovery
    Extraction and Translation'
  url: https://www.aclweb.org/anthology/I17-3002
  year: '2017'
I17-3003:
  abstract: We demonstrate a report generation system called WiseReporter. The WiseReporter
    generates a text report of a specific topic which is usually given as a keyword
    by verbalizing knowledge base facts involving the topic. This demonstration does
    not demonstate only the report itself, but also the processes how the sentences
    for the report are generated. We are planning to enhance WiseReporter in the future
    by adding data analysis based on deep learning architecture and text summarization.
  address: Tapei, Taiwan
  author:
  - first: Yunseok
    full: Yunseok Noh
    id: yunseok-noh
    last: Noh
  - first: Su Jeong
    full: Su Jeong Choi
    id: su-jeong-choi
    last: Choi
  - first: Seong-Bae
    full: Seong-Bae Park
    id: seong-bae-park
    last: Park
  - first: Se-Young
    full: Se-Young Park
    id: se-young-park
    last: Park
  author_string: Yunseok Noh, Su Jeong Choi, Seong-Bae Park, Se-Young Park
  bibkey: noh-etal-2017-wisereporter
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '9'
  page_last: '12'
  pages: "9\u201312"
  paper_id: '3'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3003.jpg
  title: 'WiseReporter: A Korean Report Generation System'
  title_html: '<span class="acl-fixed-case">W</span>ise<span class="acl-fixed-case">R</span>eporter:
    A <span class="acl-fixed-case">K</span>orean Report Generation System'
  url: https://www.aclweb.org/anthology/I17-3003
  year: '2017'
I17-3004:
  abstract: Cross-language article linking (CLAL) is the task of finding corresponding
    article pairs across encyclopedias of different languages. In this paper, we present
    Encyclolink, a web-based CLAL search interface designed to help users find equivalent
    encyclopedia articles in Baidu Baike for a given English Wikipedia article title
    query. Encyclolink is powered by our cross-encyclopedia entity embedding CLAL
    system (0.8 MRR). The browser-based Interface provides users with a clear and
    easily readable preview of the contents of retrieved articles for comparison.
  address: Tapei, Taiwan
  author:
  - first: Yu-Chun
    full: Yu-Chun Wang
    id: yu-chun-wang
    last: Wang
  - first: Ka Ming
    full: Ka Ming Wong
    id: ka-ming-wong
    last: Wong
  - first: Chun-Kai
    full: Chun-Kai Wu
    id: chun-kai-wu
    last: Wu
  - first: Chao-Lin
    full: Chao-Lin Pan
    id: chao-lin-pan
    last: Pan
  - first: Richard Tzong-Han
    full: Richard Tzong-Han Tsai
    id: richard-tzong-han-tsai
    last: Tsai
  author_string: Yu-Chun Wang, Ka Ming Wong, Chun-Kai Wu, Chao-Lin Pan, Richard Tzong-Han
    Tsai
  bibkey: wang-etal-2017-encyclolink
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '13'
  page_last: '16'
  pages: "13\u201316"
  paper_id: '4'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3004.jpg
  title: 'Encyclolink: A Cross-Encyclopedia,Cross-language Article-Linking System
    and Web-based Search Interface'
  title_html: '<span class="acl-fixed-case">E</span>ncyclolink: A Cross-Encyclopedia,Cross-language
    Article-Linking System and Web-based Search Interface'
  url: https://www.aclweb.org/anthology/I17-3004
  year: '2017'
I17-3005:
  abstract: In the paper, we propose an information retrieval based (IR-based) Question
    Answering (QA) system to assist online customer service staffs respond users in
    the telecom domain. When user asks a question, the system retrieves a set of relevant
    answers and ranks them. Moreover, our system uses a novel reranker to enhance
    the ranking result of information retrieval.It employs the word2vec model to represent
    the sentences as vectors. It also uses a sub-category feature, predicted by the
    k-nearest neighbor algorithm. Finally, the system returns the top five candidate
    answers, making online staffs find answers much more efficiently.
  address: Tapei, Taiwan
  author:
  - first: Jui-Yang
    full: Jui-Yang Wang
    id: jui-yang-wang
    last: Wang
  - first: Min-Feng
    full: Min-Feng Kuo
    id: min-feng-kuo
    last: Kuo
  - first: Jen-Chieh
    full: Jen-Chieh Han
    id: jen-chieh-han
    last: Han
  - first: Chao-Chuang
    full: Chao-Chuang Shih
    id: chao-chuang-shih
    last: Shih
  - first: Chun-Hsun
    full: Chun-Hsun Chen
    id: chun-hsun-chen
    last: Chen
  - first: Po-Ching
    full: Po-Ching Lee
    id: po-ching-lee
    last: Lee
  - first: Richard Tzong-Han
    full: Richard Tzong-Han Tsai
    id: richard-tzong-han-tsai
    last: Tsai
  author_string: Jui-Yang Wang, Min-Feng Kuo, Jen-Chieh Han, Chao-Chuang Shih, Chun-Hsun
    Chen, Po-Ching Lee, Richard Tzong-Han Tsai
  bibkey: wang-etal-2017-telecom
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '17'
  page_last: '20'
  pages: "17\u201320"
  paper_id: '5'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3005.jpg
  title: A Telecom-Domain Online Customer Service Assistant Based on Question Answering
    with Word Embedding and Intent Classification
  title_html: A Telecom-Domain Online Customer Service Assistant Based on Question
    Answering with Word Embedding and Intent Classification
  url: https://www.aclweb.org/anthology/I17-3005
  year: '2017'
I17-3006:
  abstract: We present a system for time sensitive, topic based summarisation of the
    sentiment around target entities and topics in collections of tweets. We describe
    the main elements of the system and illustrate its functionality with two examples
    of sentiment analysis of topics related to the 2017 UK general election.
  address: Tapei, Taiwan
  author:
  - first: Bo
    full: Bo Wang
    id: bo-wang
    last: Wang
  - first: Maria
    full: Maria Liakata
    id: maria-liakata
    last: Liakata
  - first: Adam
    full: Adam Tsakalidis
    id: adam-tsakalidis
    last: Tsakalidis
  - first: Spiros
    full: Spiros Georgakopoulos Kolaitis
    id: spiros-georgakopoulos-kolaitis
    last: Georgakopoulos Kolaitis
  - first: Symeon
    full: Symeon Papadopoulos
    id: symeon-papadopoulos
    last: Papadopoulos
  - first: Lazaros
    full: Lazaros Apostolidis
    id: lazaros-apostolidis
    last: Apostolidis
  - first: Arkaitz
    full: Arkaitz Zubiaga
    id: arkaitz-zubiaga
    last: Zubiaga
  - first: Rob
    full: Rob Procter
    id: rob-procter
    last: Procter
  - first: Yiannis
    full: Yiannis Kompatsiaris
    id: yiannis-kompatsiaris
    last: Kompatsiaris
  author_string: Bo Wang, Maria Liakata, Adam Tsakalidis, Spiros Georgakopoulos Kolaitis,
    Symeon Papadopoulos, Lazaros Apostolidis, Arkaitz Zubiaga, Rob Procter, Yiannis
    Kompatsiaris
  bibkey: wang-etal-2017-totemss
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '21'
  page_last: '24'
  pages: "21\u201324"
  paper_id: '6'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3006.jpg
  title: 'TOTEMSS: Topic-based, Temporal Sentiment Summarisation for Twitter'
  title_html: '<span class="acl-fixed-case">TOTEMSS</span>: Topic-based, Temporal
    Sentiment Summarisation for Twitter'
  url: https://www.aclweb.org/anthology/I17-3006
  year: '2017'
I17-3007:
  abstract: We describe MUSST, a multilingual syntactic simplification tool. The tool
    supports sentence simplifications for English, Italian and Spanish, and can be
    easily extended to other languages. Our implementation includes a set of general-purpose
    simplification rules, as well as a sentence selection module (to select sentences
    to be simplified) and a confidence model (to select only promising simplifications).
    The tool was implemented in the context of the European project SIMPATICO on text
    simplification for Public Administration (PA) texts. Our evaluation on sentences
    in the PA domain shows that we obtain correct simplifications for 76% of the simplified
    cases in English, 71% of the cases in Spanish. For Italian, the results are lower
    (38%) but the tool is still under development.
  address: Tapei, Taiwan
  author:
  - first: Carolina
    full: Carolina Scarton
    id: carolina-scarton
    last: Scarton
  - first: Alessio
    full: Alessio Palmero Aprosio
    id: alessio-palmero-aprosio
    last: Palmero Aprosio
  - first: Sara
    full: Sara Tonelli
    id: sara-tonelli
    last: Tonelli
  - first: Tamara
    full: "Tamara Mart\xEDn Wanton"
    id: tamara-martin-wanton
    last: "Mart\xEDn Wanton"
  - first: Lucia
    full: Lucia Specia
    id: lucia-specia
    last: Specia
  author_string: "Carolina Scarton, Alessio Palmero Aprosio, Sara Tonelli, Tamara\
    \ Mart\xEDn Wanton, Lucia Specia"
  bibkey: scarton-etal-2017-musst
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '25'
  page_last: '28'
  pages: "25\u201328"
  paper_id: '7'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3007.jpg
  title: 'MUSST: A Multilingual Syntactic Simplification Tool'
  title_html: '<span class="acl-fixed-case">MUSST</span>: A Multilingual Syntactic
    Simplification Tool'
  url: https://www.aclweb.org/anthology/I17-3007
  year: '2017'
I17-3008:
  abstract: We demonstrate a neural machine translation web service. Our NMT service
    provides web-based translation interfaces for a variety of language pairs. We
    describe the architecture of NMT runtime pipeline and the training details of
    NMT models. We also show several applications of our online translation interfaces.
  address: Tapei, Taiwan
  author:
  - first: Boli
    full: Boli Wang
    id: boli-wang
    last: Wang
  - first: Zhixing
    full: Zhixing Tan
    id: zhixing-tan
    last: Tan
  - first: Jinming
    full: Jinming Hu
    id: jinming-hu
    last: Hu
  - first: Yidong
    full: Yidong Chen
    id: yidong-chen
    last: Chen
  - first: Xiaodong
    full: Xiaodong Shi
    id: xiaodong-shi
    last: Shi
  author_string: Boli Wang, Zhixing Tan, Jinming Hu, Yidong Chen, Xiaodong Shi
  bibkey: wang-etal-2017-xmu-neural
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '29'
  page_last: '32'
  pages: "29\u201332"
  paper_id: '8'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3008.jpg
  title: XMU Neural Machine Translation Online Service
  title_html: <span class="acl-fixed-case">XMU</span> Neural Machine Translation Online
    Service
  url: https://www.aclweb.org/anthology/I17-3008
  year: '2017'
I17-3009:
  abstract: 'We showcase TODAY, a semantics-enhanced task-oriented dialogue translation
    system, whose novelties are: (i) task-oriented named entity (NE) definition and
    a hybrid strategy for NE recognition and translation; and (ii) a novel grounded
    semantic method for dialogue understanding and task-order management. TODAY is
    a case-study demo which can efficiently and accurately assist customers and agents
    in different languages to reach an agreement in a dialogue for the hotel booking.'
  address: Tapei, Taiwan
  author:
  - first: Longyue
    full: Longyue Wang
    id: longyue-wang
    last: Wang
  - first: Jinhua
    full: Jinhua Du
    id: jinhua-du
    last: Du
  - first: Liangyou
    full: Liangyou Li
    id: liangyou-li
    last: Li
  - first: Zhaopeng
    full: Zhaopeng Tu
    id: zhaopeng-tu
    last: Tu
  - first: Andy
    full: Andy Way
    id: andy-way
    last: Way
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  author_string: Longyue Wang, Jinhua Du, Liangyou Li, Zhaopeng Tu, Andy Way, Qun
    Liu
  bibkey: wang-etal-2017-semantics
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '33'
  page_last: '36'
  pages: "33\u201336"
  paper_id: '9'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3009.jpg
  title: 'Semantics-Enhanced Task-Oriented Dialogue Translation: A Case Study on Hotel
    Booking'
  title_html: 'Semantics-Enhanced Task-Oriented Dialogue Translation: A Case Study
    on Hotel Booking'
  url: https://www.aclweb.org/anthology/I17-3009
  year: '2017'
I17-3010:
  abstract: This paper demonstrates neural network-based toolkit namely NNVLP for
    essential Vietnamese language processing tasks including part-of-speech (POS)
    tagging, chunking, Named Entity Recognition (NER). Our toolkit is a combination
    of bidirectional Long Short-Term Memory (Bi-LSTM), Convolutional Neural Network
    (CNN), Conditional Random Field (CRF), using pre-trained word embeddings as input,
    which outperforms previously published toolkits on these three tasks. We provide
    both of API and web demo for this toolkit.
  address: Tapei, Taiwan
  author:
  - first: Thai-Hoang
    full: Thai-Hoang Pham
    id: thai-hoang-pham
    last: Pham
  - first: Xuan-Khoai
    full: Xuan-Khoai Pham
    id: xuan-khoai-pham
    last: Pham
  - first: Tuan-Anh
    full: Tuan-Anh Nguyen
    id: tuan-anh-nguyen
    last: Nguyen
  - first: Phuong
    full: Phuong Le-Hong
    id: phuong-le-hong
    last: Le-Hong
  author_string: Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh Nguyen, Phuong Le-Hong
  bibkey: pham-etal-2017-nnvlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '37'
  page_last: '40'
  pages: "37\u201340"
  paper_id: '10'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3010.jpg
  title: 'NNVLP: A Neural Network-Based Vietnamese Language Processing Toolkit'
  title_html: '<span class="acl-fixed-case">NNVLP</span>: A Neural Network-Based <span
    class="acl-fixed-case">V</span>ietnamese Language Processing Toolkit'
  url: https://www.aclweb.org/anthology/I17-3010
  year: '2017'
I17-3011:
  abstract: Classifiers are function words that are used to express quantities in
    Chinese and are especially difficult for language learners. In contrast to previous
    studies, we argue that the choice of classifiers is highly contextual and train
    context-aware machine learning models based on a novel publicly available dataset,
    outperforming previous baselines. We further present use cases for our database
    and models in an interactive demo system.
  address: Tapei, Taiwan
  author:
  - first: Nicole
    full: Nicole Peinelt
    id: nicole-peinelt
    last: Peinelt
  - first: Maria
    full: Maria Liakata
    id: maria-liakata
    last: Liakata
  - first: Shu-Kai
    full: Shu-Kai Hsieh
    id: shu-kai-hsieh
    last: Hsieh
  author_string: Nicole Peinelt, Maria Liakata, Shu-Kai Hsieh
  bibkey: peinelt-etal-2017-classifierguesser
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '41'
  page_last: '44'
  pages: "41\u201344"
  paper_id: '11'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3011.jpg
  title: 'ClassifierGuesser: A Context-based Classifier Prediction System for Chinese
    Language Learners'
  title_html: '<span class="acl-fixed-case">C</span>lassifier<span class="acl-fixed-case">G</span>uesser:
    A Context-based Classifier Prediction System for <span class="acl-fixed-case">C</span>hinese
    Language Learners'
  url: https://www.aclweb.org/anthology/I17-3011
  year: '2017'
I17-3012:
  abstract: We present a web-based interface that automatically assesses reading difficulty
    of Chinese texts. The system performs word segmentation, part-of-speech tagging
    and dependency parsing on the input text, and then determines the difficulty levels
    of the vocabulary items and grammatical constructions in the text. Furthermore,
    the system highlights the words and phrases that must be simplified or re-written
    in order to conform to the user-specified target difficulty level. Evaluation
    results show that the system accurately identifies the vocabulary level of 89.9%
    of the words, and detects grammar points at 0.79 precision and 0.83 recall.
  address: Tapei, Taiwan
  author:
  - first: John
    full: John Lee
    id: john-s-y-lee
    last: Lee
  - first: Meichun
    full: Meichun Liu
    id: meichun-liu
    last: Liu
  - first: Chun Yin
    full: Chun Yin Lam
    id: chun-yin-lam
    last: Lam
  - first: Tak On
    full: Tak On Lau
    id: tak-on-lau
    last: Lau
  - first: Bing
    full: Bing Li
    id: bing-li
    last: Li
  - first: Keying
    full: Keying Li
    id: keying-li
    last: Li
  author_string: John Lee, Meichun Liu, Chun Yin Lam, Tak On Lau, Bing Li, Keying
    Li
  bibkey: lee-etal-2017-automatic
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '45'
  page_last: '48'
  pages: "45\u201348"
  paper_id: '12'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3012.jpg
  title: Automatic Difficulty Assessment for Chinese Texts
  title_html: Automatic Difficulty Assessment for <span class="acl-fixed-case">C</span>hinese
    Texts
  url: https://www.aclweb.org/anthology/I17-3012
  year: '2017'
I17-3013:
  abstract: According to the analysis of Cambridge Learner Corpus, using a wrong verb
    is the most common type of grammatical errors. This paper describes Verb Replacer,
    a system for detecting and correcting potential verb errors in a given sentence.
    In our approach, alternative verbs are considered to replace the verb based on
    an error-annotated corpus and verb-object collocations. The method involves applying
    regression on channel models, parsing the sentence, identifying the verbs, retrieving
    a small set of alternative verbs, and evaluating each alternative. Our method
    combines and improves channel and language models, resulting in high recall of
    detecting and correcting verb misuse.
  address: Tapei, Taiwan
  author:
  - first: Yu-Hsuan
    full: Yu-Hsuan Wu
    id: yu-hsuan-wu
    last: Wu
  - first: Jhih-Jie
    full: Jhih-Jie Chen
    id: jhih-jie-chen
    last: Chen
  - first: Jason
    full: Jason Chang
    id: jason-s-chang
    last: Chang
  author_string: Yu-Hsuan Wu, Jhih-Jie Chen, Jason Chang
  bibkey: wu-etal-2017-verb
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '49'
  page_last: '52'
  pages: "49\u201352"
  paper_id: '13'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3013.jpg
  title: 'Verb Replacer: An English Verb Error Correction System'
  title_html: 'Verb Replacer: An <span class="acl-fixed-case">E</span>nglish Verb
    Error Correction System'
  url: https://www.aclweb.org/anthology/I17-3013
  year: '2017'
I17-3014:
  abstract: In this paper, we present a method for extracting Synchronous Grammar
    Patterns (SGPs) from a given parallel corpus in order to assisted second language
    learners in writing. A grammar pattern consists of a head word (verb, noun, or
    adjective) and its syntactic environment. A synchronous grammar pattern describes
    a grammar pattern in the target language (e.g., English) and its counterpart in
    an other language (e.g., Mandarin), serving the purpose of native language support.
    Our method involves identifying the grammar patterns in the target language, aligning
    these patterns with the target language patterns, and finally filtering valid
    SGPs. The extracted SGPs with examples are then used to develop a prototype writing
    assistant system, called WriteAhead/bilingual. Evaluation on a set of randomly
    selected SGPs shows that our system provides satisfactory writing suggestions
    for English as a Second Language (ESL) learners.
  address: Tapei, Taiwan
  author:
  - first: Chi-En
    full: Chi-En Wu
    id: chi-en-wu
    last: Wu
  - first: Jhih-Jie
    full: Jhih-Jie Chen
    id: jhih-jie-chen
    last: Chen
  - first: Jim
    full: Jim Chang
    id: jim-chang
    last: Chang
  - first: Jason
    full: Jason Chang
    id: jason-s-chang
    last: Chang
  author_string: Chi-En Wu, Jhih-Jie Chen, Jim Chang, Jason Chang
  bibkey: wu-etal-2017-learning
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '53'
  page_last: '56'
  pages: "53\u201356"
  paper_id: '14'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3014.jpg
  title: Learning Synchronous Grammar Patterns for Assisted Writing for Second Language
    Learners
  title_html: Learning Synchronous Grammar Patterns for Assisted Writing for Second
    Language Learners
  url: https://www.aclweb.org/anthology/I17-3014
  year: '2017'
I17-3015:
  abstract: "In this paper, we propose an idea of ondemand knowledge validation and\
    \ fulfill the idea through an interactive Question-Answering (QA) game system,\
    \ which is named Guess What. An object (e.g. dog) is first randomly chosen by\
    \ the system, and then a user can repeatedly ask the system questions in natural\
    \ language to guess what the object is. The system would respond with yes/no along\
    \ with a confidence score. Some useful hints can also be given if needed. The\
    \ proposed framework provides a pioneering example of on-demand knowledge validation\
    \ in dialog environment to address such needs in AI agents/chatbots. Moreover,\
    \ the released log data that the system gathered can be used to identify the most\
    \ critical concepts/attributes of an existing knowledge base, which reflects human\u2019\
    s cognition about the world."
  address: Tapei, Taiwan
  author:
  - first: Yu-Sheng
    full: Yu-Sheng Li
    id: yu-sheng-li
    last: Li
  - first: Chien-Hui
    full: Chien-Hui Tseng
    id: chien-hui-tseng
    last: Tseng
  - first: Chian-Yun
    full: Chian-Yun Huang
    id: chian-yun-huang
    last: Huang
  - first: Wei-Yun
    full: Wei-Yun Ma
    id: wei-yun-ma
    last: Ma
  author_string: Yu-Sheng Li, Chien-Hui Tseng, Chian-Yun Huang, Wei-Yun Ma
  bibkey: li-etal-2017-guess
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '57'
  page_last: '60'
  pages: "57\u201360"
  paper_id: '15'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3015.jpg
  title: 'Guess What: A Question Answering Game via On-demand Knowledge Validation'
  title_html: 'Guess What: A Question Answering Game via On-demand Knowledge Validation'
  url: https://www.aclweb.org/anthology/I17-3015
  year: '2017'
I17-3016:
  abstract: This paper aims to provide an effective tool for conversion between Simplified
    Chinese and Traditional Chinese. We present STCP, a customizable system comprising
    statistical conversion model, and proofreading web interface. Experiments show
    that our system achieves comparable character-level conversion performance with
    the state-of-art systems. In addition, our proofreading interface can effectively
    support diagnostics and data annotation. STCP is available at http://lagos.lti.cs.cmu.edu:8002/
  address: Tapei, Taiwan
  author:
  - first: Jiarui
    full: Jiarui Xu
    id: jiarui-xu
    last: Xu
  - first: Xuezhe
    full: Xuezhe Ma
    id: xuezhe-ma
    last: Ma
  - first: Chen-Tse
    full: Chen-Tse Tsai
    id: chen-tse-tsai
    last: Tsai
  - first: Eduard
    full: Eduard Hovy
    id: eduard-hovy
    last: Hovy
  author_string: Jiarui Xu, Xuezhe Ma, Chen-Tse Tsai, Eduard Hovy
  bibkey: xu-etal-2017-stcp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '61'
  page_last: '64'
  pages: "61\u201364"
  paper_id: '16'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3016.jpg
  title: 'STCP: Simplified-Traditional Chinese Conversion and Proofreading'
  title_html: '<span class="acl-fixed-case">STCP</span>: Simplified-Traditional <span
    class="acl-fixed-case">C</span>hinese Conversion and Proofreading'
  url: https://www.aclweb.org/anthology/I17-3016
  year: '2017'
I17-3017:
  abstract: This paper presents DILTON a system which solves simple arithmetic word
    problems. DILTON uses a Deep Neural based model to solve math word problems. DILTON
    divides the question into two parts - worldstate and query. The worldstate and
    the query are processed separately in two different networks and finally, the
    networks are merged to predict the final operation. We report the first deep learning
    approach for the prediction of operation between two numbers. DILTON learns to
    predict operations with 88.81% accuracy in a corpus of primary school questions.
  address: Tapei, Taiwan
  author:
  - first: Purvanshi
    full: Purvanshi Mehta
    id: purvanshi-mehta
    last: Mehta
  - first: Pruthwik
    full: Pruthwik Mishra
    id: pruthwik-mishra
    last: Mishra
  - first: Vinayak
    full: Vinayak Athavale
    id: vinayak-athavale
    last: Athavale
  - first: Manish
    full: Manish Shrivastava
    id: manish-shrivastava
    last: Shrivastava
  - first: Dipti
    full: Dipti Sharma
    id: dipti-misra-sharma
    last: Sharma
  author_string: Purvanshi Mehta, Pruthwik Mishra, Vinayak Athavale, Manish Shrivastava,
    Dipti Sharma
  bibkey: mehta-etal-2017-deep
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, System Demonstrations
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    System Demonstrations
  month: November
  page_first: '65'
  page_last: '68'
  pages: "65\u201368"
  paper_id: '17'
  parent_volume_id: I17-3
  pdf: https://www.aclweb.org/anthology/I17-3017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-3017.jpg
  title: Deep Neural Network based system for solving Arithmetic Word problems
  title_html: Deep Neural Network based system for solving Arithmetic Word problems
  url: https://www.aclweb.org/anthology/I17-3017
  year: '2017'
I17-4000:
  address: Taipei, Taiwan
  author:
  - first: Chao-Hong
    full: Chao-Hong Liu
    id: chao-hong-liu
    last: Liu
  - first: Preslav
    full: Preslav Nakov
    id: preslav-nakov
    last: Nakov
  - first: Nianwen
    full: Nianwen Xue
    id: nianwen-xue
    last: Xue
  author_string: Chao-Hong Liu, Preslav Nakov, Nianwen Xue
  bibkey: ijcnlp-2017-ijcnlp-2017
  bibtype: proceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  month: December
  paper_id: '0'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4000.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4000.jpg
  title: Proceedings of the IJCNLP 2017, Shared Tasks
  title_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  url: https://www.aclweb.org/anthology/I17-4000
  year: '2017'
I17-4001:
  abstract: This paper presents the IJCNLP 2017 shared task for Chinese grammatical
    error diagnosis (CGED) which seeks to identify grammatical error types and their
    range of occurrence within sentences written by learners of Chinese as foreign
    language. We describe the task definition, data preparation, performance metrics,
    and evaluation results. Of the 13 teams registered for this shared task, 5 teams
    developed the system and submitted a total of 13 runs. We expected this evaluation
    campaign could lead to the development of more advanced NLP techniques for educational
    applications, especially for Chinese error detection. All data sets with gold
    standards and scoring scripts are made publicly available to researchers.
  address: Taipei, Taiwan
  author:
  - first: Gaoqi
    full: Gaoqi Rao
    id: gaoqi-rao
    last: Rao
  - first: Baolin
    full: Baolin Zhang
    id: baolin-zhang
    last: Zhang
  - first: Endong
    full: Endong Xun
    id: endong-xun
    last: Xun
  - first: Lung-Hao
    full: Lung-Hao Lee
    id: lung-hao-lee
    last: Lee
  author_string: Gaoqi Rao, Baolin Zhang, Endong Xun, Lung-Hao Lee
  bibkey: rao-etal-2017-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '1'
  page_last: '8'
  pages: "1\u20138"
  paper_id: '1'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4001.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4001.jpg
  title: 'IJCNLP-2017 Task 1: Chinese Grammatical Error Diagnosis'
  title_html: '<span class="acl-fixed-case">IJCNLP</span>-2017 Task 1: <span class="acl-fixed-case">C</span>hinese
    Grammatical Error Diagnosis'
  url: https://www.aclweb.org/anthology/I17-4001
  year: '2017'
I17-4002:
  abstract: This paper presents the IJCNLP 2017 shared task on Dimensional Sentiment
    Analysis for Chinese Phrases (DSAP) which seeks to identify a real-value sentiment
    score of Chinese single words and multi-word phrases in the both valence and arousal
    dimensions. Valence represents the degree of pleasant and unpleasant (or positive
    and negative) feelings, and arousal represents the degree of excitement and calm.
    Of the 19 teams registered for this shared task for two-dimensional sentiment
    analysis, 13 submitted results. We expected that this evaluation campaign could
    produce more advanced dimensional sentiment analysis techniques, especially for
    Chinese affective computing. All data sets with gold standards and scoring script
    are made publicly available to researchers.
  address: Taipei, Taiwan
  author:
  - first: Liang-Chih
    full: Liang-Chih Yu
    id: liang-chih-yu
    last: Yu
  - first: Lung-Hao
    full: Lung-Hao Lee
    id: lung-hao-lee
    last: Lee
  - first: Jin
    full: Jin Wang
    id: jin-wang
    last: Wang
  - first: Kam-Fai
    full: Kam-Fai Wong
    id: kam-fai-wong
    last: Wong
  author_string: Liang-Chih Yu, Lung-Hao Lee, Jin Wang, Kam-Fai Wong
  bibkey: yu-etal-2017-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '9'
  page_last: '16'
  pages: "9\u201316"
  paper_id: '2'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4002.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4002.jpg
  title: 'IJCNLP-2017 Task 2: Dimensional Sentiment Analysis for Chinese Phrases'
  title_html: '<span class="acl-fixed-case">IJCNLP</span>-2017 Task 2: Dimensional
    Sentiment Analysis for <span class="acl-fixed-case">C</span>hinese Phrases'
  url: https://www.aclweb.org/anthology/I17-4002
  year: '2017'
I17-4003:
  abstract: Unlike Entity Disambiguation in web search results, Opinion Disambiguation
    is a relatively unexplored topic. RevOpiD shared task at IJCNLP-2107 aimed to
    attract attention towards this research problem. In this paper, we summarize the
    first run of this task and introduce a new dataset that we have annotated for
    the purpose of evaluating Opinion Mining, Summarization and Disambiguation methods.
  address: Taipei, Taiwan
  author:
  - first: Anil
    full: Anil Kumar Singh
    id: anil-kumar-singh
    last: Kumar Singh
  - first: Avijit
    full: Avijit Thawani
    id: avijit-thawani
    last: Thawani
  - first: Mayank
    full: Mayank Panchal
    id: mayank-panchal
    last: Panchal
  - first: Anubhav
    full: Anubhav Gupta
    id: anubhav-gupta
    last: Gupta
  - first: Julian
    full: Julian McAuley
    id: julian-mcauley
    last: McAuley
  author_string: Anil Kumar Singh, Avijit Thawani, Mayank Panchal, Anubhav Gupta,
    Julian McAuley
  bibkey: kumar-singh-etal-2017-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '17'
  page_last: '25'
  pages: "17\u201325"
  paper_id: '3'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4003.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4003.jpg
  title: 'IJCNLP-2017 Task 3: Review Opinion Diversification (RevOpiD-2017)'
  title_html: 'IJCNLP-2017 Task 3: Review Opinion Diversification (RevOpiD-2017)'
  url: https://www.aclweb.org/anthology/I17-4003
  year: '2017'
I17-4004:
  abstract: This document introduces the IJCNLP 2017 Shared Task on Customer Feedback
    Analysis. In this shared task we have prepared corpora of customer feedback in
    four languages, i.e. English, French, Spanish and Japanese. They were annotated
    in a common meanings categorization, which was improved from an ADAPT-Microsoft
    pivot study on customer feedback. Twenty teams participated in the shared task
    and twelve of them have submitted prediction results. The results show that performance
    of prediction meanings of customer feedback is reasonable well in four languages.
    Nine system description papers are archived in the shared tasks proceeding.
  address: Taipei, Taiwan
  author:
  - first: Chao-Hong
    full: Chao-Hong Liu
    id: chao-hong-liu
    last: Liu
  - first: Yasufumi
    full: Yasufumi Moriya
    id: yasufumi-moriya
    last: Moriya
  - first: Alberto
    full: Alberto Poncelas
    id: alberto-poncelas
    last: Poncelas
  - first: Declan
    full: Declan Groves
    id: declan-groves
    last: Groves
  author_string: Chao-Hong Liu, Yasufumi Moriya, Alberto Poncelas, Declan Groves
  bibkey: liu-etal-2017-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '26'
  page_last: '33'
  pages: "26\u201333"
  paper_id: '4'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4004.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4004.jpg
  title: 'IJCNLP-2017 Task 4: Customer Feedback Analysis'
  title_html: '<span class="acl-fixed-case">IJCNLP</span>-2017 Task 4: Customer Feedback
    Analysis'
  url: https://www.aclweb.org/anthology/I17-4004
  year: '2017'
I17-4005:
  abstract: The IJCNLP-2017 Multi-choice Question Answering(MCQA) task aims at exploring
    the performance of current Question Answering(QA) techniques via the realworld
    complex questions collected from Chinese Senior High School Entrance Examination
    papers and CK12 website1. The questions are all 4-way multi-choice questions writing
    in Chinese and English respectively that cover a wide range of subjects, e.g.
    Biology, History, Life Science and etc. And, all questions are restrained within
    the elementary and middle school level. During the whole procedure of this task,
    7 teams submitted 323 runs in total. This paper describes the collected data,
    the format and size of these questions, formal run statistics and results, overview
    and performance statistics of different methods
  address: Taipei, Taiwan
  author:
  - first: Shangmin
    full: Shangmin Guo
    id: shangmin-guo
    last: Guo
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Shizhu
    full: Shizhu He
    id: shizhu-he
    last: He
  - first: Cao
    full: Cao Liu
    id: cao-liu
    last: Liu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  - first: Zhuoyu
    full: Zhuoyu Wei
    id: zhuoyu-wei
    last: Wei
  author_string: Shangmin Guo, Kang Liu, Shizhu He, Cao Liu, Jun Zhao, Zhuoyu Wei
  bibkey: guo-etal-2017-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '34'
  page_last: '40'
  pages: "34\u201340"
  paper_id: '5'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4005.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4005.jpg
  title: 'IJCNLP-2017 Task 5: Multi-choice Question Answering in Examinations'
  title_html: '<span class="acl-fixed-case">IJCNLP</span>-2017 Task 5: Multi-choice
    Question Answering in Examinations'
  url: https://www.aclweb.org/anthology/I17-4005
  year: '2017'
I17-4006:
  abstract: This paper introduces Alibaba NLP team system on IJCNLP 2017 shared task
    No. 1 Chinese Grammatical Error Diagnosis (CGED). The task is to diagnose four
    types of grammatical errors which are redundant words (R), missing words (M),
    bad word selection (S) and disordered words (W). We treat the task as a sequence
    tagging problem and design some handcraft features to solve it. Our system is
    mainly based on the LSTM-CRF model and 3 ensemble strategies are applied to improve
    the performance. At the identification level and the position level our system
    gets the highest F1 scores. At the position level, which is the most difficult
    level, we perform best on all metrics.
  address: Taipei, Taiwan
  author:
  - first: Yi
    full: Yi Yang
    id: yi-yang
    last: Yang
  - first: Pengjun
    full: Pengjun Xie
    id: pengjun-xie
    last: Xie
  - first: Jun
    full: Jun Tao
    id: jun-tao
    last: Tao
  - first: Guangwei
    full: Guangwei Xu
    id: guangwei-xu
    last: Xu
  - first: Linlin
    full: Linlin Li
    id: linlin-li
    last: Li
  - first: Luo
    full: Luo Si
    id: luo-si
    last: Si
  author_string: Yi Yang, Pengjun Xie, Jun Tao, Guangwei Xu, Linlin Li, Luo Si
  bibkey: yang-etal-2017-alibaba
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '41'
  page_last: '46'
  pages: "41\u201346"
  paper_id: '6'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4006.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4006.jpg
  title: 'Alibaba at IJCNLP-2017 Task 1: Embedding Grammatical Features into LSTMs
    for Chinese Grammatical Error Diagnosis Task'
  title_html: '<span class="acl-fixed-case">A</span>libaba at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 1: Embedding Grammatical Features into <span class="acl-fixed-case">LSTM</span>s
    for <span class="acl-fixed-case">C</span>hinese Grammatical Error Diagnosis Task'
  url: https://www.aclweb.org/anthology/I17-4006
  year: '2017'
I17-4007:
  abstract: Predicting valence-arousal ratings for words and phrases is very useful
    for constructing affective resources for dimensional sentiment analysis. Since
    the existing valence-arousal resources of Chinese are mainly in word-level and
    there is a lack of phrase-level ones, the Dimensional Sentiment Analysis for Chinese
    Phrases (DSAP) task aims to predict the valence-arousal ratings for Chinese affective
    words and phrases automatically. In this task, we propose an approach using a
    densely connected LSTM network and word features to identify dimensional sentiment
    on valence and arousal for words and phrases jointly. We use word embedding as
    major feature and choose part of speech (POS) and word clusters as additional
    features to train the dense LSTM network. The evaluation results of our submissions
    (1st and 2nd in average performance) validate the effectiveness of our system
    to predict valence and arousal dimensions for Chinese words and phrases.
  address: Taipei, Taiwan
  author:
  - first: Chuhan
    full: Chuhan Wu
    id: chuhan-wu
    last: Wu
  - first: Fangzhao
    full: Fangzhao Wu
    id: fangzhao-wu
    last: Wu
  - first: Yongfeng
    full: Yongfeng Huang
    id: yongfeng-huang
    last: Huang
  - first: Sixing
    full: Sixing Wu
    id: sixing-wu
    last: Wu
  - first: Zhigang
    full: Zhigang Yuan
    id: zhigang-yuan
    last: Yuan
  author_string: Chuhan Wu, Fangzhao Wu, Yongfeng Huang, Sixing Wu, Zhigang Yuan
  bibkey: wu-etal-2017-thu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '47'
  page_last: '52'
  pages: "47\u201352"
  paper_id: '7'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4007.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4007.jpg
  title: 'THU_NGN at IJCNLP-2017 Task 2: Dimensional Sentiment Analysis for Chinese
    Phrases with Deep LSTM'
  title_html: '<span class="acl-fixed-case">THU</span>_<span class="acl-fixed-case">NGN</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 2: Dimensional Sentiment
    Analysis for <span class="acl-fixed-case">C</span>hinese Phrases with Deep <span
    class="acl-fixed-case">LSTM</span>'
  url: https://www.aclweb.org/anthology/I17-4007
  year: '2017'
I17-4008:
  abstract: The Review Opinion Diversification (Revopid-2017) shared task focuses
    on selecting top-k reviews from a set of reviews for a particular product based
    on a specific criteria. In this paper, we describe our approaches and results
    for modeling the ranking of reviews based on their usefulness score, this being
    the first of the three subtasks under this shared task. Instead of posing this
    as a regression problem, we modeled this as a classification task where we want
    to identify whether a review is useful or not. We employed a bi-directional LSTM
    to represent each review and is used with a softmax layer to predict the usefulness
    score. We chose the review with highest usefulness score, then find its cosine
    similarity score with rest of the reviews. This is done in order to ensure diversity
    in the selection of top-k reviews. On the top-5 list prediction, we finished 3rd
    while in top-10 list one, we are placed 2nd in the shared task. We have discussed
    the model and the results in detail in the paper.
  address: Taipei, Taiwan
  author:
  - first: Pruthwik
    full: Pruthwik Mishra
    id: pruthwik-mishra
    last: Mishra
  - first: Prathyusha
    full: Prathyusha Danda
    id: prathyusha-danda
    last: Danda
  - first: Silpa
    full: Silpa Kanneganti
    id: silpa-kanneganti
    last: Kanneganti
  - first: Soujanya
    full: Soujanya Lanka
    id: soujanya-lanka
    last: Lanka
  author_string: Pruthwik Mishra, Prathyusha Danda, Silpa Kanneganti, Soujanya Lanka
  bibkey: mishra-etal-2017-iiit
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '53'
  page_last: '58'
  pages: "53\u201358"
  paper_id: '8'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4008.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4008.jpg
  title: 'IIIT-H at IJCNLP-2017 Task 3: A Bidirectional-LSTM Approach for Review Opinion
    Diversification'
  title_html: '<span class="acl-fixed-case">IIIT</span>-H at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 3: A Bidirectional-<span class="acl-fixed-case">LSTM</span> Approach for
    Review Opinion Diversification'
  url: https://www.aclweb.org/anthology/I17-4008
  year: '2017'
I17-4009:
  abstract: "The ability to automatically and accurately process customer feedback\
    \ is a necessity in the private sector. Unfortunately, customer feedback can be\
    \ one of the most difficult types of data to work with due to the sheer volume\
    \ and variety of services, products, languages, and cultures that comprise the\
    \ customer experience. In order to address this issue, our team built a suite\
    \ of classifiers trained on a four-language, multi-label corpus released as part\
    \ of the shared task on \u201CCustomer Feedback Analysis\u201D at IJCNLP 2017.\
    \ In addition to standard text preprocessing, we translated each dataset into\
    \ each other language to increase the size of the training datasets. Additionally,\
    \ we also used word embeddings in our feature engineering step. Ultimately, we\
    \ trained classifiers using Logistic Regression, Random Forest, and Long Short-Term\
    \ Memory (LSTM) Recurrent Neural Networks. Overall, we achieved a Macro-Average\
    \ F-score between 48.7% and 56.0% for the four languages and ranked 3/12 for English,\
    \ 3/7 for Spanish, 1/8 for French, and 2/7 for Japanese."
  address: Taipei, Taiwan
  author:
  - first: Heba
    full: Heba Elfardy
    id: heba-elfardy
    last: Elfardy
  - first: Manisha
    full: Manisha Srivastava
    id: manisha-srivastava
    last: Srivastava
  - first: Wei
    full: Wei Xiao
    id: wei-xiao
    last: Xiao
  - first: Jared
    full: Jared Kramer
    id: jared-kramer
    last: Kramer
  - first: Tarun
    full: Tarun Agarwal
    id: tarun-agarwal
    last: Agarwal
  author_string: Heba Elfardy, Manisha Srivastava, Wei Xiao, Jared Kramer, Tarun Agarwal
  bibkey: elfardy-etal-2017-bingo
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '59'
  page_last: '66'
  pages: "59\u201366"
  paper_id: '9'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4009.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4009.jpg
  title: 'Bingo at IJCNLP-2017 Task 4: Augmenting Data using Machine Translation for
    Cross-linguistic Customer Feedback Classification'
  title_html: 'Bingo at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 4: Augmenting
    Data using Machine Translation for Cross-linguistic Customer Feedback Classification'
  url: https://www.aclweb.org/anthology/I17-4009
  year: '2017'
I17-4010:
  abstract: 'We describe the work of a team from the ADAPT Centre in Ireland in addressing
    automatic answer selection for the Multi-choice Question Answering in Examinations
    shared task. The system is based on a logistic regression over the string similarities
    between question, answer, and additional text. We obtain the highest grade out
    of six systems: 48.7% accuracy on a validation set (vs. a baseline of 29.45%)
    and 45.6% on a test set.'
  address: Taipei, Taiwan
  author:
  - first: Daria
    full: Daria Dzendzik
    id: daria-dzendzik
    last: Dzendzik
  - first: Alberto
    full: Alberto Poncelas
    id: alberto-poncelas
    last: Poncelas
  - first: Carl
    full: Carl Vogel
    id: carl-vogel
    last: Vogel
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  author_string: Daria Dzendzik, Alberto Poncelas, Carl Vogel, Qun Liu
  bibkey: dzendzik-etal-2017-adapt
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '67'
  page_last: '72'
  pages: "67\u201372"
  paper_id: '10'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4010.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4010.jpg
  title: 'ADAPT Centre Cone Team at IJCNLP-2017 Task 5: A Similarity-Based Logistic
    Regression Approach to Multi-choice Question Answering in an Examinations Shared
    Task'
  title_html: '<span class="acl-fixed-case">ADAPT</span> Centre Cone Team at <span
    class="acl-fixed-case">IJCNLP</span>-2017 Task 5: A Similarity-Based Logistic
    Regression Approach to Multi-choice Question Answering in an Examinations Shared
    Task'
  url: https://www.aclweb.org/anthology/I17-4010
  year: '2017'
I17-4011:
  abstract: Building a system to detect Chinese grammatical errors is a challenge
    for natural-language processing researchers. As Chinese learners are increasing,
    developing such a system can help them study Chinese more easily. This paper introduces
    a bi-directional long short-term memory (BiLSTM) - conditional random field (CRF)
    model to produce the sequences that indicate an error type for every position
    of a sentence, since we regard Chinese grammatical error diagnosis (CGED) as a
    sequence-labeling problem.
  address: Taipei, Taiwan
  author:
  - first: Quanlei
    full: Quanlei Liao
    id: quanlei-liao
    last: Liao
  - first: Jin
    full: Jin Wang
    id: jin-wang
    last: Wang
  - first: Jinnan
    full: Jinnan Yang
    id: jinnan-yang
    last: Yang
  - first: Xuejie
    full: Xuejie Zhang
    id: xuejie-zhang
    last: Zhang
  author_string: Quanlei Liao, Jin Wang, Jinnan Yang, Xuejie Zhang
  bibkey: liao-etal-2017-ynu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '73'
  page_last: '77'
  pages: "73\u201377"
  paper_id: '11'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4011.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4011.jpg
  title: 'YNU-HPCC at IJCNLP-2017 Task 1: Chinese Grammatical Error Diagnosis Using
    a Bi-directional LSTM-CRF Model'
  title_html: '<span class="acl-fixed-case">YNU</span>-<span class="acl-fixed-case">HPCC</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 1: <span class="acl-fixed-case">C</span>hinese
    Grammatical Error Diagnosis Using a Bi-directional <span class="acl-fixed-case">LSTM</span>-<span
    class="acl-fixed-case">CRF</span> Model'
  url: https://www.aclweb.org/anthology/I17-4011
  year: '2017'
I17-4012:
  abstract: Grammatical error diagnosis is an important task in natural language processing.
    This paper introduces CVTE Character Checking System in the NLP-TEA-4 shared task
    for CGED 2017, we use Bi-LSTM to generate the probability of every character,
    then take two kinds of strategies to decide whether a character is correct or
    not. This system is probably more suitable to deal with the error type of bad
    word selection, which is one of four types of errors, and the rest are words re-dundancy,
    words missing and words disorder. Finally the second strategy achieves better
    F1 score than the first one at all of detection level, identification level, position
    level.
  address: Taipei, Taiwan
  author:
  - first: Xian
    full: Xian Li
    id: xian-li
    last: Li
  - first: Peng
    full: Peng Wang
    id: peng-wang
    last: Wang
  - first: Suixue
    full: Suixue Wang
    id: suixue-wang
    last: Wang
  - first: Guanyu
    full: Guanyu Jiang
    id: guanyu-jiang
    last: Jiang
  - first: Tianyuan
    full: Tianyuan You
    id: tianyuan-you
    last: You
  author_string: Xian Li, Peng Wang, Suixue Wang, Guanyu Jiang, Tianyuan You
  bibkey: li-etal-2017-cvte
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '78'
  page_last: '83'
  pages: "78\u201383"
  paper_id: '12'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4012.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4012.jpg
  title: 'CVTE at IJCNLP-2017 Task 1: Character Checking System for Chinese Grammatical
    Error Diagnosis Task'
  title_html: '<span class="acl-fixed-case">CVTE</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 1: Character Checking System for <span class="acl-fixed-case">C</span>hinese
    Grammatical Error Diagnosis Task'
  url: https://www.aclweb.org/anthology/I17-4012
  year: '2017'
I17-4013:
  abstract: Sentiment analysis on Chinese text has intensively studied. The basic
    task for related research is to construct an affective lexicon and thereby predict
    emotional scores of different levels. However, finite lexicon resources make it
    difficult to effectively and automatically distinguish between various types of
    sentiment information in Chinese texts. This IJCNLP2017-Task2 competition seeks
    to automatically calculate Valence and Arousal ratings within the hierarchies
    of vocabulary and phrases in Chinese. We introduce a regression methodology to
    automatically recognize continuous emotional values, and incorporate a word embedding
    technique. In our system, the MAE predictive values of Valence and Arousal were
    0.811 and 0.996, respectively, for the sentiment dimension prediction of words
    in Chinese. In phrase prediction, the corresponding results were 0.822 and 0.489,
    ranking sixth among all teams.
  address: Taipei, Taiwan
  author:
  - first: Peng
    full: Peng Zhong
    id: peng-zhong
    last: Zhong
  - first: Jingbin
    full: Jingbin Wang
    id: jingbin-wang
    last: Wang
  author_string: Peng Zhong, Jingbin Wang
  bibkey: zhong-wang-2017-ldccnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '84'
  page_last: '88'
  pages: "84\u201388"
  paper_id: '13'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4013.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4013.jpg
  title: 'LDCCNLP at IJCNLP-2017 Task 2: Dimensional Sentiment Analysis for Chinese
    Phrases Using Machine Learning'
  title_html: '<span class="acl-fixed-case">LDCCNLP</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: Dimensional Sentiment Analysis for <span class="acl-fixed-case">C</span>hinese
    Phrases Using Machine Learning'
  url: https://www.aclweb.org/anthology/I17-4013
  year: '2017'
I17-4014:
  abstract: CKIP takes part in solving the Dimensional Sentiment Analysis for Chinese
    Phrases (DSAP) share task of IJCNLP 2017. This task calls for systems that can
    predict the valence and the arousal of Chinese phrases, which are real values
    between 1 and 9. To achieve this, functions mapping Chinese character sequences
    to real numbers are built by regression techniques. In addition, the CKIP phrase
    Valence-Arousal (VA) predictor depends on knowledge of modifier words and head
    words. This includes the types of known modifier words, VA of head words, and
    distributional semantics of both these words. The predictor took the second place
    out of 13 teams on phrase VA prediction, with 0.444 MAE and 0.935 PCC on valence,
    and 0.395 MAE and 0.904 PCC on arousal.
  address: Taipei, Taiwan
  author:
  - first: Peng-Hsuan
    full: Peng-Hsuan Li
    id: peng-hsuan-li
    last: Li
  - first: Wei-Yun
    full: Wei-Yun Ma
    id: wei-yun-ma
    last: Ma
  - first: Hsin-Yang
    full: Hsin-Yang Wang
    id: hsin-yang-wang
    last: Wang
  author_string: Peng-Hsuan Li, Wei-Yun Ma, Hsin-Yang Wang
  bibkey: li-etal-2017-ckip
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '89'
  page_last: '94'
  pages: "89\u201394"
  paper_id: '14'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4014.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4014.jpg
  title: 'CKIP at IJCNLP-2017 Task 2: Neural Valence-Arousal Prediction for Phrases'
  title_html: '<span class="acl-fixed-case">CKIP</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: Neural Valence-Arousal Prediction for Phrases'
  url: https://www.aclweb.org/anthology/I17-4014
  year: '2017'
I17-4015:
  abstract: "Sentiment lexicon is very helpful in dimensional sentiment applications.\
    \ Because of countless Chinese words, developing a method to predict unseen Chinese\
    \ words is required. The proposed method can handle both words and phrases by\
    \ using an ADVWeight List for word prediction, which in turn improves our performance\
    \ at phrase level. The evaluation results demonstrate that our system is effective\
    \ in dimensional sentiment analysis for Chinese phrases. The Mean Absolute Error\
    \ (MAE) and Pearson\u2019s Correlation Coefficient (PCC) for Valence are 0.723\
    \ and 0.835, respectively, and those for Arousal are 0.914 and 0.756, respectively."
  address: Taipei, Taiwan
  author:
  - first: Zheng-Wen
    full: Zheng-Wen Lin
    id: zheng-wen-lin
    last: Lin
  - first: Yung-Chun
    full: Yung-Chun Chang
    id: yung-chun-chang
    last: Chang
  - first: Chen-Ann
    full: Chen-Ann Wang
    id: chen-ann-wang
    last: Wang
  - first: Yu-Lun
    full: Yu-Lun Hsieh
    id: yu-lun-hsieh
    last: Hsieh
  - first: Wen-Lian
    full: Wen-Lian Hsu
    id: wen-lian-hsu
    last: Hsu
  author_string: Zheng-Wen Lin, Yung-Chun Chang, Chen-Ann Wang, Yu-Lun Hsieh, Wen-Lian
    Hsu
  bibkey: lin-etal-2017-cial
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '95'
  page_last: '99'
  pages: "95\u201399"
  paper_id: '15'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4015.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4015.jpg
  title: 'CIAL at IJCNLP-2017 Task 2: An Ensemble Valence-Arousal Analysis System
    for Chinese Words and Phrases'
  title_html: '<span class="acl-fixed-case">CIAL</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: An Ensemble Valence-Arousal Analysis System for <span class="acl-fixed-case">C</span>hinese
    Words and Phrases'
  url: https://www.aclweb.org/anthology/I17-4015
  year: '2017'
I17-4016:
  abstract: "This paper introduces Team Alibaba\u2019s systems participating IJCNLP\
    \ 2017 shared task No. 2 Dimensional Sentiment Analysis for Chinese Phrases (DSAP).\
    \ The systems mainly utilize a multi-layer neural networks, with multiple features\
    \ input such as word embedding, part-of-speech-tagging (POST), word clustering,\
    \ prefix type, character embedding, cross sentiment input, and AdaBoost method\
    \ for model training. For word level task our best run achieved MAE 0.545 (ranked\
    \ 2nd), PCC 0.892 (ranked 2nd) in valence prediction and MAE 0.857 (ranked 1st),\
    \ PCC 0.678 (ranked 2nd) in arousal prediction. For average performance of word\
    \ and phrase task we achieved MAE 0.5355 (ranked 3rd), PCC 0.8965 (ranked 3rd)\
    \ in valence prediction and MAE 0.661 (ranked 3rd), PCC 0.766 (ranked 2nd) in\
    \ arousal prediction. In the final our submitted system achieved 2nd in mean rank."
  address: Taipei, Taiwan
  author:
  - first: Xin
    full: Xin Zhou
    id: xin-zhou
    last: Zhou
  - first: Jian
    full: Jian Wang
    id: jian-wang
    last: Wang
  - first: Xu
    full: Xu Xie
    id: xu-xie
    last: Xie
  - first: Changlong
    full: Changlong Sun
    id: changlong-sun
    last: Sun
  - first: Luo
    full: Luo Si
    id: luo-si
    last: Si
  author_string: Xin Zhou, Jian Wang, Xu Xie, Changlong Sun, Luo Si
  bibkey: zhou-etal-2017-alibaba
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '100'
  page_last: '104'
  pages: "100\u2013104"
  paper_id: '16'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4016.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4016.jpg
  title: 'Alibaba at IJCNLP-2017 Task 2: A Boosted Deep System for Dimensional Sentiment
    Analysis of Chinese Phrases'
  title_html: '<span class="acl-fixed-case">A</span>libaba at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: A Boosted Deep System for Dimensional Sentiment Analysis of <span class="acl-fixed-case">C</span>hinese
    Phrases'
  url: https://www.aclweb.org/anthology/I17-4016
  year: '2017'
I17-4017:
  abstract: "Categorical sentiment classification has drawn much attention in the\
    \ field of NLP, while less work has been conducted for dimensional sentiment analysis\
    \ (DSA). Recent works for DSA utilize either word embedding, knowledge base features,\
    \ or bilingual language resources. In this paper, we propose our model for IJCNLP\
    \ 2017 Dimensional Sentiment Analysis for Chinese Phrases shared task. Our model\
    \ incorporates word embedding as well as image features, attempting to simulate\
    \ human\u2019s imaging behavior toward sentiment analysis. Though the performance\
    \ is not comparable to others in the end, we conduct several experiments with\
    \ possible reasons discussed, and analyze the drawbacks of our model."
  address: Taipei, Taiwan
  author:
  - first: Szu-Min
    full: Szu-Min Chen
    id: szu-min-chen
    last: Chen
  - first: Zi-Yuan
    full: Zi-Yuan Chen
    id: zi-yuan-chen
    last: Chen
  - first: Lun-Wei
    full: Lun-Wei Ku
    id: lun-wei-ku
    last: Ku
  author_string: Szu-Min Chen, Zi-Yuan Chen, Lun-Wei Ku
  bibkey: chen-etal-2017-nlpsa
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '105'
  page_last: '111'
  pages: "105\u2013111"
  paper_id: '17'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4017.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4017.jpg
  title: 'NLPSA at IJCNLP-2017 Task 2: Imagine Scenario: Leveraging Supportive Images
    for Dimensional Sentiment Analysis'
  title_html: '<span class="acl-fixed-case">NLPSA</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: Imagine Scenario: Leveraging Supportive Images for Dimensional Sentiment
    Analysis'
  url: https://www.aclweb.org/anthology/I17-4017
  year: '2017'
I17-4018:
  abstract: This paper presents two vector representations proposed by National Chiayi
    University (NCYU) about phrased-based sentiment detection which was used to compete
    in dimensional sentiment analysis for Chinese phrases (DSACP) at IJCNLP 2017.
    The vector-based sentiment phraselike unit analysis models are proposed in this
    article. E-HowNet-based clustering is used to obtain the values of valence and
    arousal for sentiment words first. An out-of-vocabulary function is also defined
    in this article to measure the dimensional emotion values for unknown words. For
    predicting the corresponding values of sentiment phrase-like unit, a vectorbased
    approach is proposed here. According to the experimental results, we can find
    the proposed approach is efficacious.
  address: Taipei, Taiwan
  author:
  - first: Jui-Feng
    full: Jui-Feng Yeh
    id: jui-feng-yeh
    last: Yeh
  - first: Jian-Cheng
    full: Jian-Cheng Tsai
    id: jian-cheng-tsai
    last: Tsai
  - first: Bo-Wei
    full: Bo-Wei Wu
    id: bo-wei-wu
    last: Wu
  - first: Tai-You
    full: Tai-You Kuang
    id: tai-you-kuang
    last: Kuang
  author_string: Jui-Feng Yeh, Jian-Cheng Tsai, Bo-Wei Wu, Tai-You Kuang
  bibkey: yeh-etal-2017-ncyu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '112'
  page_last: '117'
  pages: "112\u2013117"
  paper_id: '18'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4018.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4018.jpg
  title: 'NCYU at IJCNLP-2017 Task 2: Dimensional Sentiment Analysis for Chinese Phrases
    using Vector Representations'
  title_html: '<span class="acl-fixed-case">NCYU</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: Dimensional Sentiment Analysis for <span class="acl-fixed-case">C</span>hinese
    Phrases using Vector Representations'
  url: https://www.aclweb.org/anthology/I17-4018
  year: '2017'
I17-4019:
  abstract: This paper introduces Mainiway AI Labs submitted system for the IJCNLP
    2017 shared task on Dimensional Sentiment Analysis of Chinese Phrases (DSAP),
    and related experiments. Our approach consists of deep neural networks with various
    architectures, and our best system is a voted ensemble of networks. We achieve
    a Mean Absolute Error of 0.64 in valence prediction and 0.68 in arousal prediction
    on the test set, both placing us as the 5th ranked team in the competition.
  address: Taipei, Taiwan
  author:
  - first: Yassine
    full: Yassine Benajiba
    id: yassine-benajiba
    last: Benajiba
  - first: Jin
    full: Jin Sun
    id: jin-sun
    last: Sun
  - first: Yong
    full: Yong Zhang
    id: yong-zhang
    last: Zhang
  - first: Zhiliang
    full: Zhiliang Weng
    id: zhiliang-weng
    last: Weng
  - first: Or
    full: Or Biran
    id: or-biran
    last: Biran
  author_string: Yassine Benajiba, Jin Sun, Yong Zhang, Zhiliang Weng, Or Biran
  bibkey: benajiba-etal-2017-mainiwayai
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '118'
  page_last: '123'
  pages: "118\u2013123"
  paper_id: '19'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4019.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4019.jpg
  title: 'MainiwayAI at IJCNLP-2017 Task 2: Ensembles of Deep Architectures for Valence-Arousal
    Prediction'
  title_html: '<span class="acl-fixed-case">M</span>ainiway<span class="acl-fixed-case">AI</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 2: Ensembles of Deep Architectures
    for Valence-Arousal Prediction'
  url: https://www.aclweb.org/anthology/I17-4019
  year: '2017'
I17-4020:
  abstract: In this paper, a deep phrase embedding approach using bi-directional long
    short-term memory (Bi-LSTM) is proposed to predict the valence-arousal ratings
    of Chinese words and phrases. It adopts a Chinese word segmentation frontend,
    a local order-aware word, a global phrase embedding representations and a deep
    regression neural network (DRNN) model. The performance of the proposed method
    was benchmarked by the IJCNLP 2017 shared task 2. According the official evaluation
    results, our best system achieved mean rank 6.5 among all 24 submissions.
  address: Taipei, Taiwan
  author:
  - first: Yen-Hsuan
    full: Yen-Hsuan Lee
    id: yen-hsuan-lee
    last: Lee
  - first: Han-Yun
    full: Han-Yun Yeh
    id: han-yun-yeh
    last: Yeh
  - first: Yih-Ru
    full: Yih-Ru Wang
    id: yih-ru-wang
    last: Wang
  - first: Yuan-Fu
    full: Yuan-Fu Liao
    id: yuan-fu-liao
    last: Liao
  author_string: Yen-Hsuan Lee, Han-Yun Yeh, Yih-Ru Wang, Yuan-Fu Liao
  bibkey: lee-etal-2017-nctu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '124'
  page_last: '129'
  pages: "124\u2013129"
  paper_id: '20'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4020.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4020.jpg
  title: 'NCTU-NTUT at IJCNLP-2017 Task 2: Deep Phrase Embedding using bi-LSTMs for
    Valence-Arousal Ratings Prediction of Chinese Phrases'
  title_html: '<span class="acl-fixed-case">NCTU</span>-<span class="acl-fixed-case">NTUT</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 2: Deep Phrase Embedding
    using bi-<span class="acl-fixed-case">LSTM</span>s for Valence-Arousal Ratings
    Prediction of <span class="acl-fixed-case">C</span>hinese Phrases'
  url: https://www.aclweb.org/anthology/I17-4020
  year: '2017'
I17-4021:
  abstract: This paper describes the approaches of sentimental score prediction in
    the NTOU DSA system participating in DSAP this year. The modules to predict scores
    for words are adapted from our system last year. The approach to predict scores
    for phrases is keyword-based machine learning method. The performance of our system
    is good in predicting scores of phrases.
  address: Taipei, Taiwan
  author:
  - first: Chuan-Jie
    full: Chuan-Jie Lin
    id: chuan-jie-lin
    last: Lin
  - first: Hao-Tsung
    full: Hao-Tsung Chang
    id: hao-tsung-chang
    last: Chang
  author_string: Chuan-Jie Lin, Hao-Tsung Chang
  bibkey: lin-chang-2017-ntoua
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '130'
  page_last: '133'
  pages: "130\u2013133"
  paper_id: '21'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4021.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4021.jpg
  title: 'NTOUA at IJCNLP-2017 Task 2: Predicting Sentiment Scores of Chinese Words
    and Phrases'
  title_html: '<span class="acl-fixed-case">NTOUA</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 2: Predicting Sentiment Scores of <span class="acl-fixed-case">C</span>hinese
    Words and Phrases'
  url: https://www.aclweb.org/anthology/I17-4021
  year: '2017'
I17-4022:
  abstract: 'Review Opinion Diversification (RevOpiD) 2017 is a shared task which
    is held in International Joint Conference on Natural Language Processing (IJCNLP).
    The shared task aims at selecting top-k reviews, as a summary, from a set of re-views.
    There are three subtasks in RevOpiD: helpfulness ranking, rep-resentativeness
    ranking, and ex-haustive coverage ranking. This year, our team submitted runs
    by three models. We focus on ranking reviews based on the helpfulness of the reviews.
    In the first two models, we use linear regression with two different loss functions.
    First one is least squares, and second one is cross entropy. The third run is
    a random baseline. For both k=5 and k=10, our second model gets the best scores
    in the official evaluation metrics.'
  address: Taipei, Taiwan
  author:
  - first: Shih-Hung
    full: Shih-Hung Wu
    id: shih-hung-wu
    last: Wu
  - first: Su-Yu
    full: Su-Yu Chang
    id: su-yu-chang
    last: Chang
  - first: Liang-Pu
    full: Liang-Pu Chen
    id: liang-pu-chen
    last: Chen
  author_string: Shih-Hung Wu, Su-Yu Chang, Liang-Pu Chen
  bibkey: wu-etal-2017-cyut
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '134'
  page_last: '137'
  pages: "134\u2013137"
  paper_id: '22'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4022.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4022.jpg
  title: 'CYUT at IJCNLP-2017 Task 3: System Report for Review Opinion Diversification'
  title_html: '<span class="acl-fixed-case">CYUT</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 3: System Report for Review Opinion Diversification'
  url: https://www.aclweb.org/anthology/I17-4022
  year: '2017'
I17-4023:
  abstract: "IJCNLP-17 Review Opinion Diversification (RevOpiD-2017) task has been\
    \ designed for ranking the top-k reviews of a product from a set of reviews, which\
    \ assists in identifying a summarized output to express the opinion of the entire\
    \ review set. The task is divided into three independent subtasks as subtask-A,subtask-B,\
    \ and subtask-C. Each of these three subtasks selects the top-k reviews based\
    \ on helpfulness, representativeness, and exhaustiveness of the opinions expressed\
    \ in the review set individually. In order to develop the modules and predict\
    \ the rank of reviews for all three subtasks, we have employed two well-known\
    \ supervised classifiers namely, Na\xEFve Bayes and Logistic Regression on the\
    \ top of several extracted features such as the number of nouns, number of verbs,\
    \ and number of sentiment words etc from the provided datasets. Finally, the organizers\
    \ have helped to validate the predicted outputs for all three subtasks by using\
    \ their evaluation metrics. The metrics provide the scores of list size 5 as (0.80\
    \ (mth)) for subtask-A, (0.86 (cos), 0.87 (cos d), 0.71 (cpr), 4.98 (a-dcg), and\
    \ 556.94 (wt)) for subtask B, and (10.94 (unwt) and 0.67 (recall)) for subtask\
    \ C individually."
  address: Taipei, Taiwan
  author:
  - first: Monalisa
    full: Monalisa Dey
    id: monalisa-dey
    last: Dey
  - first: Anupam
    full: Anupam Mondal
    id: anupam-mondal
    last: Mondal
  - first: Dipankar
    full: Dipankar Das
    id: dipankar-das
    last: Das
  author_string: Monalisa Dey, Anupam Mondal, Dipankar Das
  bibkey: dey-etal-2017-junlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '138'
  page_last: '142'
  pages: "138\u2013142"
  paper_id: '23'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4023.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4023.jpg
  title: 'JUNLP at IJCNLP-2017 Task 3: A Rank Prediction Model for Review Opinion
    Diversification'
  title_html: '<span class="acl-fixed-case">JUNLP</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 3: A Rank Prediction Model for Review Opinion Diversification'
  url: https://www.aclweb.org/anthology/I17-4023
  year: '2017'
I17-4024:
  abstract: 'We present All-In-1, a simple model for multilingual text classification
    that does not require any parallel data. It is based on a traditional Support
    Vector Machine classifier exploiting multilingual word embeddings and character
    n-grams. Our model is simple, easily extendable yet very effective, overall ranking
    1st (out of 12 teams) in the IJCNLP 2017 shared task on customer feedback analysis
    in four languages: English, French, Japanese and Spanish.'
  address: Taipei, Taiwan
  author:
  - first: Barbara
    full: Barbara Plank
    id: barbara-plank
    last: Plank
  author_string: Barbara Plank
  bibkey: plank-2017-1
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '143'
  page_last: '148'
  pages: "143\u2013148"
  paper_id: '24'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4024.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4024.jpg
  title: 'All-In-1 at IJCNLP-2017 Task 4: Short Text Classification with One Model
    for All Languages'
  title_html: 'All-In-1 at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 4:
    Short Text Classification with One Model for All Languages'
  url: https://www.aclweb.org/anthology/I17-4024
  year: '2017'
I17-4025:
  abstract: The analysis of customer feedback is useful to provide good customer service.
    There are a lot of online customer feedback are produced. Manual classification
    is impractical because the high volume of data. Therefore, the automatic classification
    of the customer feedback is of importance for the analysis system to identify
    meanings or intentions that the customer express. The aim of shared Task 4 of
    IJCNLP 2017 is to classify the customer feedback into six tags categorization.
    In this paper, we present a system that uses word embeddings to express the feature
    of the sentence in the corpus and the neural network as the classifier to complete
    the shared task. And then the ensemble method is used to get final predictive
    result. The proposed method get ranked first among twelve teams in terms of micro-averaged
    F1 and second for accura-cy metric.
  address: Taipei, Taiwan
  author:
  - first: Shuying
    full: Shuying Lin
    id: shuying-lin
    last: Lin
  - first: Huosheng
    full: Huosheng Xie
    id: huosheng-xie
    last: Xie
  - first: Liang-Chih
    full: Liang-Chih Yu
    id: liang-chih-yu
    last: Yu
  - first: K. Robert
    full: K. Robert Lai
    id: k-robert-lai
    last: Lai
  author_string: Shuying Lin, Huosheng Xie, Liang-Chih Yu, K. Robert Lai
  bibkey: lin-etal-2017-sentinlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '149'
  page_last: '154'
  pages: "149\u2013154"
  paper_id: '25'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4025.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4025.jpg
  title: 'SentiNLP at IJCNLP-2017 Task 4: Customer Feedback Analysis Using a Bi-LSTM-CNN
    Model'
  title_html: '<span class="acl-fixed-case">S</span>enti<span class="acl-fixed-case">NLP</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 4: Customer Feedback Analysis
    Using a Bi-<span class="acl-fixed-case">LSTM</span>-<span class="acl-fixed-case">CNN</span>
    Model'
  url: https://www.aclweb.org/anthology/I17-4025
  year: '2017'
I17-4026:
  abstract: The IJCNLP 2017 shared task on Customer Feedback Analysis focuses on classifying
    customer feedback into one of a predefined set of categories or classes. In this
    paper, we describe our approach to this problem and the results on four languages,
    i.e. English, French, Japanese and Spanish. Our system implemented a bidirectional
    LSTM (Graves and Schmidhuber, 2005) using pre-trained glove (Pennington et al.,
    2014) and fastText (Joulin et al., 2016) embeddings, and SVM (Cortes and Vapnik,
    1995) with TF-IDF vectors for classifying the feedback data which is described
    in the later sections. We also tried different machine learning techniques and
    compared the results in this paper. Out of the 12 participating teams, our systems
    obtained 0.65, 0.86, 0.70 and 0.56 exact accuracy score in English, Spanish, French
    and Japanese respectively. We observed that our systems perform better than the
    baseline systems in three languages while we match the baseline accuracy for Japanese
    on our submitted systems. We noticed significant improvements in Japanese in later
    experiments, matching the highest performing system that was submitted in the
    shared task, which we will discuss in this paper.
  address: Taipei, Taiwan
  author:
  - first: Prathyusha
    full: Prathyusha Danda
    id: prathyusha-danda
    last: Danda
  - first: Pruthwik
    full: Pruthwik Mishra
    id: pruthwik-mishra
    last: Mishra
  - first: Silpa
    full: Silpa Kanneganti
    id: silpa-kanneganti
    last: Kanneganti
  - first: Soujanya
    full: Soujanya Lanka
    id: soujanya-lanka
    last: Lanka
  author_string: Prathyusha Danda, Pruthwik Mishra, Silpa Kanneganti, Soujanya Lanka
  bibkey: danda-etal-2017-iiit
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '155'
  page_last: '160'
  pages: "155\u2013160"
  paper_id: '26'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4026.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4026.jpg
  title: 'IIIT-H at IJCNLP-2017 Task 4: Customer Feedback Analysis using Machine Learning
    and Neural Network Approaches'
  title_html: '<span class="acl-fixed-case">IIIT</span>-H at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 4: Customer Feedback Analysis using Machine Learning and Neural Network Approaches'
  url: https://www.aclweb.org/anthology/I17-4026
  year: '2017'
I17-4027:
  abstract: 'In this age of the digital economy, promoting organisations attempt their
    best to engage the customers in the feedback provisioning process. With the assistance
    of customer insights, an organisation can develop a better product and provide
    a better service to its customer. In this paper, we analyse the real world samples
    of customer feedback from Microsoft Office customers in four languages, i.e.,
    English, French, Spanish and Japanese and conclude a five-plus-one-classes categorisation
    (comment, request, bug, complaint, meaningless and undetermined) for meaning classification.
    The task is to %access multilingual corpora annotated by the proposed meaning
    categorization scheme and develop a system to determine what class(es) the customer
    feedback sentences should be annotated as in four languages. We propose following
    approaches to accomplish this task: (i) a multinomial naive bayes (MNB) approach
    for multi-label classification, (ii) MNB with one-vs-rest classifier approach,
    and (iii) the combination of the multilabel classification-based and the sentiment
    classification-based approach. Our best system produces F-scores of 0.67, 0.83,
    0.72 and 0.7 for English, Spanish, French and Japanese, respectively. The results
    are competitive to the best ones for all languages and secure 3rd and 5th position
    for Japanese and French, respectively, among all submitted systems.'
  address: Taipei, Taiwan
  author:
  - first: Pintu
    full: Pintu Lohar
    id: pintu-lohar
    last: Lohar
  - first: Koel
    full: Koel Dutta Chowdhury
    id: koel-dutta-chowdhury
    last: Dutta Chowdhury
  - first: Haithem
    full: Haithem Afli
    id: haithem-afli
    last: Afli
  - first: Mohammed
    full: Mohammed Hasanuzzaman
    id: mohammed-hasanuzzaman
    last: Hasanuzzaman
  - first: Andy
    full: Andy Way
    id: andy-way
    last: Way
  author_string: Pintu Lohar, Koel Dutta Chowdhury, Haithem Afli, Mohammed Hasanuzzaman,
    Andy Way
  bibkey: lohar-etal-2017-adapt
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '161'
  page_last: '169'
  pages: "161\u2013169"
  paper_id: '27'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4027.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4027.jpg
  title: 'ADAPT at IJCNLP-2017 Task 4: A Multinomial Naive Bayes Classification Approach
    for Customer Feedback Analysis task'
  title_html: '<span class="acl-fixed-case">ADAPT</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 4: A Multinomial Naive <span class="acl-fixed-case">B</span>ayes Classification
    Approach for Customer Feedback Analysis task'
  url: https://www.aclweb.org/anthology/I17-4027
  year: '2017'
I17-4028:
  abstract: "This paper describes our systems for IJCNLP 2017 Shared Task on Customer\
    \ Feedback Analysis. We experimented with simple neural architectures that gave\
    \ competitive performance on certain tasks. This includes shallow CNN and Bi-Directional\
    \ LSTM architectures with Facebook\u2019s Fasttext as a baseline model. Our best\
    \ performing model was in the Top 5 systems using the Exact-Accuracy and Micro-Average-F1\
    \ metrics for the Spanish (85.28% for both) and French (70% and 73.17% respectively)\
    \ task, and outperformed all the other models on comment (87.28%) and meaningless\
    \ (51.85%) tags using Micro Average F1 by Tags metric for the French task."
  address: Taipei, Taiwan
  author:
  - first: Dushyanta
    full: Dushyanta Dhyani
    id: dushyanta-dhyani
    last: Dhyani
  author_string: Dushyanta Dhyani
  bibkey: dhyani-2017-ohiostate
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '170'
  page_last: '173'
  pages: "170\u2013173"
  paper_id: '28'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4028.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4028.jpg
  title: 'OhioState at IJCNLP-2017 Task 4: Exploring Neural Architectures for Multilingual
    Customer Feedback Analysis'
  title_html: '<span class="acl-fixed-case">O</span>hio<span class="acl-fixed-case">S</span>tate
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 4: Exploring Neural Architectures
    for Multilingual Customer Feedback Analysis'
  url: https://www.aclweb.org/anthology/I17-4028
  year: '2017'
I17-4029:
  abstract: This paper describes our submission to IJCNLP 2017 shared task 4, for
    predicting the tags of unseen customer feedback sentences, such as comments, complaints,
    bugs, requests, and meaningless and undetermined statements. With the use of a
    neural network, a large number of deep learning methods have been developed, which
    perform very well on text classification. Our ensemble classification model is
    based on a bi-directional gated recurrent unit and an attention mechanism which
    shows a 3.8% improvement in classification accuracy. To enhance the model performance,
    we also compared it with several word-embedding models. The comparative results
    show that a combination of both word2vec and GloVe achieves the best performance.
  address: Taipei, Taiwan
  author:
  - first: Nan
    full: Nan Wang
    id: nan-wang
    last: Wang
  - first: Jin
    full: Jin Wang
    id: jin-wang
    last: Wang
  - first: Xuejie
    full: Xuejie Zhang
    id: xuejie-zhang
    last: Zhang
  author_string: Nan Wang, Jin Wang, Xuejie Zhang
  bibkey: wang-etal-2017-ynu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '174'
  page_last: '179'
  pages: "174\u2013179"
  paper_id: '29'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4029.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4029.jpg
  title: 'YNU-HPCC at IJCNLP-2017 Task 4: Attention-based Bi-directional GRU Model
    for Customer Feedback Analysis Task of English'
  title_html: '<span class="acl-fixed-case">YNU</span>-<span class="acl-fixed-case">HPCC</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 4: Attention-based Bi-directional
    <span class="acl-fixed-case">GRU</span> Model for Customer Feedback Analysis Task
    of <span class="acl-fixed-case">E</span>nglish'
  url: https://www.aclweb.org/anthology/I17-4029
  year: '2017'
I17-4030:
  abstract: In this paper, we describe a deep learning framework for analyzing the
    customer feedback as part of our participation in the shared task on Customer
    Feedback Analysis at the 8th International Joint Conference on Natural Language
    Processing (IJCNLP 2017). A Convolutional Neural Network (CNN) based deep neural
    network model was employed for the customer feedback task. The proposed system
    was evaluated on two languages, namely, English and French.
  address: Taipei, Taiwan
  author:
  - first: Somnath
    full: Somnath Banerjee
    id: somnath-banerjee
    last: Banerjee
  - first: Partha
    full: Partha Pakray
    id: partha-pakray
    last: Pakray
  - first: Riyanka
    full: Riyanka Manna
    id: riyanka-manna
    last: Manna
  - first: Dipankar
    full: Dipankar Das
    id: dipankar-das
    last: Das
  - first: Alexander
    full: Alexander Gelbukh
    id: alexander-gelbukh
    last: Gelbukh
  author_string: Somnath Banerjee, Partha Pakray, Riyanka Manna, Dipankar Das, Alexander
    Gelbukh
  bibkey: banerjee-etal-2017-nitmz
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '180'
  page_last: '183'
  pages: "180\u2013183"
  paper_id: '30'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4030.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4030.jpg
  title: 'NITMZ-JU at IJCNLP-2017 Task 4: Customer Feedback Analysis'
  title_html: 'NITMZ-JU at IJCNLP-2017 Task 4: Customer Feedback Analysis'
  url: https://www.aclweb.org/anthology/I17-4030
  year: '2017'
I17-4031:
  abstract: Analyzing customer feedback is the best way to channelize the data into
    new marketing strategies that benefit entrepreneurs as well as customers. Therefore
    an automated system which can analyze the customer behavior is in great demand.
    Users may write feedbacks in any language, and hence mining appropriate information
    often becomes intractable. Especially in a traditional feature-based supervised
    model, it is difficult to build a generic system as one has to understand the
    concerned language for finding the relevant features. In order to overcome this,
    we propose deep Convolutional Neural Network (CNN) and Recurrent Neural Network
    (RNN) based approaches that do not require handcrafting of features. We evaluate
    these techniques for analyzing customer feedback sentences on four languages,
    namely English, French, Japanese and Spanish. Our empirical analysis shows that
    our models perform well in all the four languages on the setups of IJCNLP Shared
    Task on Customer Feedback Analysis. Our model achieved the second rank in French,
    with an accuracy of 71.75% and third ranks for all the other languages.
  address: Taipei, Taiwan
  author:
  - first: Deepak
    full: Deepak Gupta
    id: deepak-gupta
    last: Gupta
  - first: Pabitra
    full: Pabitra Lenka
    id: pabitra-lenka
    last: Lenka
  - first: Harsimran
    full: Harsimran Bedi
    id: harsimran-bedi
    last: Bedi
  - first: Asif
    full: Asif Ekbal
    id: asif-ekbal
    last: Ekbal
  - first: Pushpak
    full: Pushpak Bhattacharyya
    id: pushpak-bhattacharyya
    last: Bhattacharyya
  author_string: Deepak Gupta, Pabitra Lenka, Harsimran Bedi, Asif Ekbal, Pushpak
    Bhattacharyya
  bibkey: gupta-etal-2017-iitp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '184'
  page_last: '193'
  pages: "184\u2013193"
  paper_id: '31'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4031.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4031.jpg
  title: 'IITP at IJCNLP-2017 Task 4: Auto Analysis of Customer Feedback using CNN
    and GRU Network'
  title_html: '<span class="acl-fixed-case">IITP</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 4: Auto Analysis of Customer Feedback using <span class="acl-fixed-case">CNN</span>
    and <span class="acl-fixed-case">GRU</span> Network'
  url: https://www.aclweb.org/anthology/I17-4031
  year: '2017'
I17-4032:
  abstract: In this paper, we perform convolutional neural networks (CNN) to learn
    the joint representations of question-answer pairs first, then use the joint representations
    as the inputs of the long short-term memory (LSTM) with attention to learn the
    answer sequence of a question for labeling the matching quality of each answer.
    We also incorporating external knowledge by training Word2Vec on Flashcards data,
    thus we get more compact embedding. Experimental results show that our method
    achieves better or comparable performance compared with the baseline system. The
    proposed approach achieves the accuracy of 0.39, 0.42 in English valid set, test
    set, respectively.
  address: Taipei, Taiwan
  author:
  - first: Min
    full: Min Wang
    id: min-wang
    last: Wang
  - first: Qingxun
    full: Qingxun Liu
    id: qingxun-liu
    last: Liu
  - first: Peng
    full: Peng Ding
    id: peng-ding
    last: Ding
  - first: Yongbin
    full: Yongbin Li
    id: yongbin-li
    last: Li
  - first: Xiaobing
    full: Xiaobing Zhou
    id: xiaobing-zhou
    last: Zhou
  author_string: Min Wang, Qingxun Liu, Peng Ding, Yongbin Li, Xiaobing Zhou
  bibkey: wang-etal-2017-ynudlg-ijcnlp
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '194'
  page_last: '198'
  pages: "194\u2013198"
  paper_id: '32'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4032.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4032.jpg
  title: 'YNUDLG at IJCNLP-2017 Task 5: A CNN-LSTM Model with Attention for Multi-choice
    Question Answering in Examinations'
  title_html: '<span class="acl-fixed-case">YNUDLG</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 5: A <span class="acl-fixed-case">CNN</span>-<span class="acl-fixed-case">LSTM</span>
    Model with Attention for Multi-choice Question Answering in Examinations'
  url: https://www.aclweb.org/anthology/I17-4032
  year: '2017'
I17-4033:
  abstract: Multi-choice question answering in exams is a typical QA task. To accomplish
    this task, we present an answer localization method to locate answers shown in
    web pages, considering structural information and semantic information both. Using
    this method as basis, we analyze sentences and paragraphs appeared on web pages
    to get predictions. With this answer localization system, we get effective results
    on both validation dataset and test dataset.
  address: Taipei, Taiwan
  author:
  - first: Changliang
    full: Changliang Li
    id: changliang-li
    last: Li
  - first: Cunliang
    full: Cunliang Kong
    id: cunliang-kong
    last: Kong
  author_string: Changliang Li, Cunliang Kong
  bibkey: li-kong-2017-als
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '199'
  page_last: '202'
  pages: "199\u2013202"
  paper_id: '33'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4033.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4033.jpg
  title: 'ALS at IJCNLP-2017 Task 5: Answer Localization System for Multi-Choice Question
    Answering in Exams'
  title_html: '<span class="acl-fixed-case">ALS</span> at <span class="acl-fixed-case">IJCNLP</span>-2017
    Task 5: Answer Localization System for Multi-Choice Question Answering in Exams'
  url: https://www.aclweb.org/anthology/I17-4033
  year: '2017'
I17-4034:
  abstract: In this paper we present MappSent, a textual similarity approach that
    we applied to the multi-choice question answering in exams shared task. MappSent
    has initially been proposed for question-to-question similarity hazem2017. In
    this work, we present the results of two adaptations of MappSent for the question
    answering task on the English dataset.
  address: Taipei, Taiwan
  author:
  - first: Amir
    full: Amir Hazem
    id: amir-hazem
    last: Hazem
  author_string: Amir Hazem
  bibkey: hazem-2017-mappsent
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '203'
  page_last: '207'
  pages: "203\u2013207"
  paper_id: '34'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4034.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4034.jpg
  title: 'MappSent at IJCNLP-2017 Task 5: A Textual Similarity Approach Applied to
    Multi-choice Question Answering in Examinations'
  title_html: '<span class="acl-fixed-case">M</span>app<span class="acl-fixed-case">S</span>ent
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 5: A Textual Similarity
    Approach Applied to Multi-choice Question Answering in Examinations'
  url: https://www.aclweb.org/anthology/I17-4034
  year: '2017'
I17-4035:
  abstract: A shared task is a typical question answering task that aims to test how
    accurately the participants can answer the questions in exams. Typically, for
    each question, there are four candidate answers, and only one of the answers is
    correct. The existing methods for such a task usually implement a recurrent neural
    network (RNN) or long short-term memory (LSTM). However, both RNN and LSTM are
    biased models in which the words in the tail of a sentence are more dominant than
    the words in the header. In this paper, we propose the use of an attention-based
    LSTM (AT-LSTM) model for these tasks. By adding an attention mechanism to the
    standard LSTM, this model can more easily capture long contextual information.
  address: Taipei, Taiwan
  author:
  - first: Hang
    full: Hang Yuan
    id: hang-yuan
    last: Yuan
  - first: You
    full: You Zhang
    id: you-zhang
    last: Zhang
  - first: Jin
    full: Jin Wang
    id: jin-wang
    last: Wang
  - first: Xuejie
    full: Xuejie Zhang
    id: xuejie-zhang
    last: Zhang
  author_string: Hang Yuan, You Zhang, Jin Wang, Xuejie Zhang
  bibkey: yuan-etal-2017-ynu
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '208'
  page_last: '212'
  pages: "208\u2013212"
  paper_id: '35'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4035.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4035.jpg
  title: 'YNU-HPCC at IJCNLP-2017 Task 5: Multi-choice Question Answering in Exams
    Using an Attention-based LSTM Model'
  title_html: '<span class="acl-fixed-case">YNU</span>-<span class="acl-fixed-case">HPCC</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 5: Multi-choice Question
    Answering in Exams Using an Attention-based <span class="acl-fixed-case">LSTM</span>
    Model'
  url: https://www.aclweb.org/anthology/I17-4035
  year: '2017'
I17-4036:
  abstract: "This paper describes the participation of the JU NITM team in IJCNLP-2017\
    \ Task 5: \u201CMulti-choice Question Answering in Examinations\u201D. The main\
    \ aim of this shared task is to choose the correct option for each multi-choice\
    \ question. Our proposed model includes vector representations as feature and\
    \ machine learning for classification. At first we represent question and answer\
    \ in vector space and after that find the cosine similarity between those two\
    \ vectors. Finally we apply classification approach to find the correct answer.\
    \ Our system was only developed for the English language, and it obtained an accuracy\
    \ of 40.07% for test dataset and 40.06% for valid dataset."
  address: Taipei, Taiwan
  author:
  - first: Sandip
    full: Sandip Sarkar
    id: sandip-sarkar
    last: Sarkar
  - first: Dipankar
    full: Dipankar Das
    id: dipankar-das
    last: Das
  - first: Partha
    full: Partha Pakray
    id: partha-pakray
    last: Pakray
  author_string: Sandip Sarkar, Dipankar Das, Partha Pakray
  bibkey: sarkar-etal-2017-ju
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Shared Tasks
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Shared Tasks
  month: December
  page_first: '213'
  page_last: '216'
  pages: "213\u2013216"
  paper_id: '36'
  parent_volume_id: I17-4
  pdf: https://www.aclweb.org/anthology/I17-4036.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-4036.jpg
  title: 'JU NITM at IJCNLP-2017 Task 5: A Classification Approach for Answer Selection
    in Multi-choice Question Answering System'
  title_html: '<span class="acl-fixed-case">JU</span> <span class="acl-fixed-case">NITM</span>
    at <span class="acl-fixed-case">IJCNLP</span>-2017 Task 5: A Classification Approach
    for Answer Selection in Multi-choice Question Answering System'
  url: https://www.aclweb.org/anthology/I17-4036
  year: '2017'
I17-5000:
  address: Taipei, Taiwan
  author:
  - first: Sadao
    full: Sadao Kurohashi
    id: sadao-kurohashi
    last: Kurohashi
  - first: Michael
    full: Michael Strube
    id: michael-strube
    last: Strube
  author_string: Sadao Kurohashi, Michael Strube
  bibkey: ijcnlp-2017-ijcnlp-2017-tutorial
  bibtype: proceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  month: November
  paper_id: '0'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5000.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5000.jpg
  title: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  title_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  url: https://www.aclweb.org/anthology/I17-5000
  year: '2017'
I17-5001:
  abstract: "Neural networks, also with a fancy name deep learning, just right can\
    \ overcome the above \u201Cfeature engineering\u201D problem. In theory, they\
    \ can use non-linear activation functions and multiple layers to automatically\
    \ find useful features. The novel network structures, such as convolutional or\
    \ recurrent, help to reduce the difficulty further. These deep learning models\
    \ have been successfully used for lexical analysis and parsing. In this tutorial,\
    \ we will give a review of each line of work, by contrasting them with traditional\
    \ statistical methods, and organizing them in consistent orders."
  address: Taipei, Taiwan
  author:
  - first: Wanxiang
    full: Wanxiang Che
    id: wanxiang-che
    last: Che
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  author_string: Wanxiang Che, Yue Zhang
  bibkey: che-zhang-2017-deep
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '1'
  page_last: '2'
  pages: "1\u20132"
  paper_id: '1'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5001.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5001.jpg
  title: Deep Learning in Lexical Analysis and Parsing
  title_html: Deep Learning in Lexical Analysis and Parsing
  url: https://www.aclweb.org/anthology/I17-5001
  year: '2017'
I17-5002:
  abstract: Neural vector representations are now ubiquitous in all subfields of natural
    language processing and text mining. While methods such as word2vec and GloVe
    are well-known, this tutorial focuses on multilingual and cross-lingual vector
    representations, of words, but also of sentences and documents as well.
  address: Taipei, Taiwan
  author:
  - first: Gerard
    full: Gerard de Melo
    id: gerard-de-melo
    last: de Melo
  author_string: Gerard de Melo
  bibkey: de-melo-2017-multilingual
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '3'
  page_last: '5'
  pages: "3\u20135"
  paper_id: '2'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5002.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5002.jpg
  title: Multilingual Vector Representations of Words, Sentences, and Documents
  title_html: Multilingual Vector Representations of Words, Sentences, and Documents
  url: https://www.aclweb.org/anthology/I17-5002
  year: '2017'
I17-5003:
  abstract: "In the past decade, spoken dialogue systems have been the most prominent\
    \ component in today\u2019s personal assistants. A lot of devices have incorporated\
    \ dialogue system modules, which allow users to speak naturally in order to finish\
    \ tasks more efficiently. The traditional conversational systems have rather complex\
    \ and/or modular pipelines. The advance of deep learning technologies has recently\
    \ risen the applications of neural models to dialogue modeling. Nevertheless,\
    \ applying deep learning technologies for building robust and scalable dialogue\
    \ systems is still a challenging task and an open research area as it requires\
    \ deeper understanding of the classic pipelines as well as detailed knowledge\
    \ on the benchmark of the models of the prior work and the recent state-of-the-art\
    \ work. Therefore, this tutorial is designed to focus on an overview of the dialogue\
    \ system development while describing most recent research for building task-oriented\
    \ and chit-chat dialogue systems, and summarizing the challenges. We target the\
    \ audience of students and practitioners who have some deep learning background,\
    \ who want to get more familiar with conversational dialogue systems."
  address: Taipei, Taiwan
  author:
  - first: Yun-Nung
    full: Yun-Nung Chen
    id: yun-nung-chen
    last: Chen
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  author_string: Yun-Nung Chen, Jianfeng Gao
  bibkey: chen-gao-2017-open
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '6'
  page_last: '10'
  pages: "6\u201310"
  paper_id: '3'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5003.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5003.jpg
  title: Open-Domain Neural Dialogue Systems
  title_html: Open-Domain Neural Dialogue Systems
  url: https://www.aclweb.org/anthology/I17-5003
  year: '2017'
I17-5004:
  abstract: Machine Translation (MT) is a sub-field of NLP which has experienced a
    number of paradigm shifts since its inception. Up until 2014, Phrase Based Statistical
    Machine Translation (PBSMT) approaches used to be the state of the art. In late
    2014, Neural Machine Translation (NMT) was introduced and was proven to outperform
    all PBSMT approaches by a significant margin. Since then, the NMT approaches have
    undergone several transformations which have pushed the state of the art even
    further. This tutorial is primarily aimed at researchers who are either interested
    in or are fairly new to the world of NMT and want to obtain a deep understanding
    of NMT fundamentals. Because it will also cover the latest developments in NMT,
    it should also be useful to attendees with some experience in NMT.
  address: Taipei, Taiwan
  author:
  - first: Fabien
    full: Fabien Cromieres
    id: fabien-cromieres
    last: Cromieres
  - first: Toshiaki
    full: Toshiaki Nakazawa
    id: toshiaki-nakazawa
    last: Nakazawa
  - first: Raj
    full: Raj Dabre
    id: raj-dabre
    last: Dabre
  author_string: Fabien Cromieres, Toshiaki Nakazawa, Raj Dabre
  bibkey: cromieres-etal-2017-neural
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '11'
  page_last: '13'
  pages: "11\u201313"
  paper_id: '4'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5004.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5004.jpg
  title: 'Neural Machine Translation: Basics, Practical Aspects and Recent Trends'
  title_html: 'Neural Machine Translation: Basics, Practical Aspects and Recent Trends'
  url: https://www.aclweb.org/anthology/I17-5004
  year: '2017'
I17-5005:
  abstract: "There is no question that our research community have, and still has\
    \ been producing an insurmountable amount of interesting strategies, models and\
    \ tools to a wide array of problems and challenges in diverse areas of knowledge.\
    \ But for as long as interesting work has existed, we\u2019ve been plagued by\
    \ a great unsolved mystery: how come there is so much interesting work being published\
    \ in conferences, but not as many interesting and engaging posters and presentations\
    \ being featured in them? In this tutorial, we present practical step-by-step\
    \ makeup solutions for poster, slides and oral presentations in order to help\
    \ researchers who feel like they are not able to convey the importance of their\
    \ research to the community in conferences."
  address: Taipei, Taiwan
  author:
  - first: Gustavo
    full: Gustavo Paetzold
    id: gustavo-paetzold
    last: Paetzold
  - first: Lucia
    full: Lucia Specia
    id: lucia-specia
    last: Specia
  author_string: Gustavo Paetzold, Lucia Specia
  bibkey: paetzold-specia-2017-ultimate
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '14'
  page_last: '15'
  pages: "14\u201315"
  paper_id: '5'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5005.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5005.jpg
  title: 'The Ultimate Presentation Makeup Tutorial: How to Polish your Posters, Slides
    and Presentations Skills'
  title_html: 'The Ultimate Presentation Makeup Tutorial: How to Polish your Posters,
    Slides and Presentations Skills'
  url: https://www.aclweb.org/anthology/I17-5005
  year: '2017'
I17-5006:
  abstract: "This is tutorial proposal. Abstract is as follows: The principle of compositionality\
    \ states that the meaning of a complete sentence must be explained in terms of\
    \ the meanings of its subsentential parts; in other words, each syntactic operation\
    \ should have a corresponding semantic operation. In recent years, it has been\
    \ increasingly evident that distributional and formal semantics are complementary\
    \ in addressing composition; while the distributional/vector-based approach can\
    \ naturally measure semantic similarity (Mitchell and Lapata, 2010), the formal/symbolic\
    \ approach has a long tradition within logic-based semantic frameworks (Montague,\
    \ 1974) and can readily be connected to theorem provers or databases to perform\
    \ complicated tasks. In this tutorial, we will cover recent efforts in extending\
    \ word vectors to account for composition and reasoning, the various challenging\
    \ phenomena observed in composition and addressed by formal semantics, and a hybrid\
    \ approach that combines merits of the two. Outline and introduction to instructors\
    \ are found in the submission. Ran Tian has taught a tutorial at the Annual Meeting\
    \ of the Association for Natural Language Processing in Japan, 2015. The estimated\
    \ audience size was about one hundred. Only a limited part of the contents in\
    \ this tutorial is drawn from the previous one. Koji Mineshima has taught a one-week\
    \ course at the 28th European Summer School in Logic, Language and Information\
    \ (ESSLLI2016), together with Prof. Daisuke Bekki. Only a few contents are the\
    \ same with this tutorial. Tutorials on \u201CCCG Semantic Parsing\u201D have\
    \ been given in ACL2013, EMNLP2014, and AAAI2015. A coming tutorial on \u201C\
    Deep Learning for Semantic Composition\u201D will be given in ACL2017. Contents\
    \ in these tutorials are somehow related to but not overlapping with our proposal."
  address: Taipei, Taiwan
  author:
  - first: Ran
    full: Ran Tian
    id: ran-tian
    last: Tian
  - first: Koji
    full: Koji Mineshima
    id: koji-mineshima
    last: Mineshima
  - first: Pascual
    full: "Pascual Mart\xEDnez-G\xF3mez"
    id: pascual-martinez-gomez
    last: "Mart\xEDnez-G\xF3mez"
  author_string: "Ran Tian, Koji Mineshima, Pascual Mart\xEDnez-G\xF3mez"
  bibkey: tian-etal-2017-challenge
  bibtype: inproceedings
  booktitle: Proceedings of the IJCNLP 2017, Tutorial Abstracts
  booktitle_html: Proceedings of the <span class="acl-fixed-case">IJCNLP</span> 2017,
    Tutorial Abstracts
  month: November
  page_first: '16'
  page_last: '17'
  pages: "16\u201317"
  paper_id: '6'
  parent_volume_id: I17-5
  pdf: https://www.aclweb.org/anthology/I17-5006.pdf
  publisher: Asian Federation of Natural Language Processing
  thumbnail: https://www.aclweb.org/anthology/thumb/I17-5006.jpg
  title: The Challenge of Composition in Distributional and Formal Semantics
  title_html: The Challenge of Composition in Distributional and Formal Semantics
  url: https://www.aclweb.org/anthology/I17-5006
  year: '2017'
