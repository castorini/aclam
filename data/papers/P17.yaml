P17-1000:
  address: Vancouver, Canada
  author:
  - first: Regina
    full: Regina Barzilay
    id: regina-barzilay
    last: Barzilay
  - first: Min-Yen
    full: Min-Yen Kan
    id: min-yen-kan
    last: Kan
  author_string: Regina Barzilay, Min-Yen Kan
  bibkey: acl-2017-association
  bibtype: proceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1
  month: July
  paper_id: '0'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1000.jpg
  title: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  title_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  url: https://www.aclweb.org/anthology/P17-1000
  year: '2017'
P17-1001:
  abstract: Neural network models have shown their promising opportunities for multi-task
    learning, which focus on learning the shared layers to extract the common and
    task-invariant features. However, in most existing approaches, the extracted shared
    features are prone to be contaminated by task-specific features or the noise brought
    by other tasks. In this paper, we propose an adversarial multi-task learning framework,
    alleviating the shared and private latent feature spaces from interfering with
    each other. We conduct extensive experiments on 16 different text classification
    tasks, which demonstrates the benefits of our approach. Besides, we show that
    the shared knowledge learned by our proposed model can be regarded as off-the-shelf
    knowledge and easily transferred to new tasks. The datasets of all 16 tasks are
    publicly available at http://nlp.fudan.edu.cn/data/.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952967
    type: video
    url: https://vimeo.com/234952967
  author:
  - first: Pengfei
    full: Pengfei Liu
    id: pengfei-liu
    last: Liu
  - first: Xipeng
    full: Xipeng Qiu
    id: xipeng-qiu
    last: Qiu
  - first: Xuanjing
    full: Xuanjing Huang
    id: xuan-jing-huang
    last: Huang
  author_string: Pengfei Liu, Xipeng Qiu, Xuanjing Huang
  bibkey: liu-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1001
  month: July
  page_first: '1'
  page_last: '10'
  pages: "1\u201310"
  paper_id: '1'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1001.jpg
  title: Adversarial Multi-task Learning for Text Classification
  title_html: Adversarial Multi-task Learning for Text Classification
  url: https://www.aclweb.org/anthology/P17-1001
  year: '2017'
P17-1002:
  abstract: "We investigate neural techniques for end-to-end computational argumentation\
    \ mining (AM). We frame AM both as a token-based dependency parsing and as a token-based\
    \ sequence tagging problem, including a multi-task learning setup. Contrary to\
    \ models that operate on the argument component level, we find that framing AM\
    \ as dependency parsing leads to subpar performance results. In contrast, less\
    \ complex (local) tagging models based on BiLSTMs perform robustly across classification\
    \ scenarios, being able to catch long-range dependencies inherent to the AM problem.\
    \ Moreover, we find that jointly learning \u2018natural\u2019 subtasks, in a multi-task\
    \ learning setup, improves performance."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1002.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1002.Notes.pdf
  - filename: https://vimeo.com/234953034
    type: video
    url: https://vimeo.com/234953034
  author:
  - first: Steffen
    full: Steffen Eger
    id: steffen-eger
    last: Eger
  - first: Johannes
    full: Johannes Daxenberger
    id: johannes-daxenberger
    last: Daxenberger
  - first: Iryna
    full: Iryna Gurevych
    id: iryna-gurevych
    last: Gurevych
  author_string: Steffen Eger, Johannes Daxenberger, Iryna Gurevych
  bibkey: eger-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1002
  month: July
  page_first: '11'
  page_last: '22'
  pages: "11\u201322"
  paper_id: '2'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1002.jpg
  title: Neural End-to-End Learning for Computational Argumentation Mining
  title_html: Neural End-to-End Learning for Computational Argumentation Mining
  url: https://www.aclweb.org/anthology/P17-1002
  year: '2017'
P17-1003:
  abstract: "Harnessing the statistical power of neural networks to perform language\
    \ understanding and symbolic reasoning is difficult, when it requires executing\
    \ efficient discrete operations against a large knowledge-base. In this work,\
    \ we introduce a Neural Symbolic Machine, which contains (a) a neural \u201Cprogrammer\u201D\
    , i.e., a sequence-to-sequence model that maps language utterances to programs\
    \ and utilizes a key-variable memory to handle compositionality (b) a symbolic\
    \ \u201Ccomputer\u201D, i.e., a Lisp interpreter that performs program execution,\
    \ and helps find good programs by pruning the search space. We apply REINFORCE\
    \ to directly optimize the task reward of this structured prediction problem.\
    \ To train with weak supervision and improve the stability of REINFORCE, we augment\
    \ it with an iterative maximum-likelihood training process. NSM outperforms the\
    \ state-of-the-art on the WebQuestionsSP dataset when trained from question-answer\
    \ pairs only, without requiring any feature engineering or domain-specific knowledge."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1003.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1003.Notes.pdf
  - filename: https://vimeo.com/234953110
    type: video
    url: https://vimeo.com/234953110
  author:
  - first: Chen
    full: Chen Liang
    id: chen-liang
    last: Liang
  - first: Jonathan
    full: Jonathan Berant
    id: jonathan-berant
    last: Berant
  - first: Quoc
    full: Quoc Le
    id: quoc-le
    last: Le
  - first: Kenneth D.
    full: Kenneth D. Forbus
    id: kenneth-forbus
    last: Forbus
  - first: Ni
    full: Ni Lao
    id: ni-lao
    last: Lao
  author_string: Chen Liang, Jonathan Berant, Quoc Le, Kenneth D. Forbus, Ni Lao
  bibkey: liang-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1003
  month: July
  page_first: '23'
  page_last: '33'
  pages: "23\u201333"
  paper_id: '3'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1003.jpg
  title: 'Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak
    Supervision'
  title_html: 'Neural Symbolic Machines: Learning Semantic Parsers on <span class="acl-fixed-case">F</span>reebase
    with Weak Supervision'
  url: https://www.aclweb.org/anthology/P17-1003
  year: '2017'
P17-1004:
  abstract: Relation extraction has been widely used for finding unknown relational
    facts from plain text. Most existing methods focus on exploiting mono-lingual
    data for relation extraction, ignoring massive information from the texts in various
    languages. To address this issue, we introduce a multi-lingual neural relation
    extraction framework, which employs mono-lingual attention to utilize the information
    within mono-lingual texts and further proposes cross-lingual attention to consider
    the information consistency and complementarity among cross-lingual texts. Experimental
    results on real-world datasets show that, our model can take advantage of multi-lingual
    texts and consistently achieve significant improvements on relation extraction
    as compared with baselines.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953158
    type: video
    url: https://vimeo.com/234953158
  author:
  - first: Yankai
    full: Yankai Lin
    id: yankai-lin
    last: Lin
  - first: Zhiyuan
    full: Zhiyuan Liu
    id: zhiyuan-liu
    last: Liu
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Yankai Lin, Zhiyuan Liu, Maosong Sun
  bibkey: lin-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1004
  month: July
  page_first: '34'
  page_last: '43'
  pages: "34\u201343"
  paper_id: '4'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1004.jpg
  title: Neural Relation Extraction with Multi-lingual Attention
  title_html: Neural Relation Extraction with Multi-lingual Attention
  url: https://www.aclweb.org/anthology/P17-1004
  year: '2017'
P17-1005:
  abstract: We introduce a neural semantic parser which is interpretable and scalable.
    Our model converts natural language utterances to intermediate, domain-general
    natural language representations in the form of predicate-argument structures,
    which are induced with a transition system and subsequently mapped to target domains.
    The semantic parser is trained end-to-end using annotated logical forms or their
    denotations. We achieve the state of the art on SPADES and GRAPHQUESTIONS and
    obtain competitive results on GEOQUERY and WEBQUESTIONS. The induced predicate-argument
    structures shed light on the types of representations useful for semantic parsing
    and how these are different from linguistically motivated ones.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954083
    type: video
    url: https://vimeo.com/234954083
  author:
  - first: Jianpeng
    full: Jianpeng Cheng
    id: jianpeng-cheng
    last: Cheng
  - first: Siva
    full: Siva Reddy
    id: siva-reddy
    last: Reddy
  - first: Vijay
    full: Vijay Saraswat
    id: vijay-saraswat
    last: Saraswat
  - first: Mirella
    full: Mirella Lapata
    id: mirella-lapata
    last: Lapata
  author_string: Jianpeng Cheng, Siva Reddy, Vijay Saraswat, Mirella Lapata
  bibkey: cheng-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1005
  month: July
  page_first: '44'
  page_last: '55'
  pages: "44\u201355"
  paper_id: '5'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1005.jpg
  title: Learning Structured Natural Language Representations for Semantic Parsing
  title_html: Learning Structured Natural Language Representations for Semantic Parsing
  url: https://www.aclweb.org/anthology/P17-1005
  year: '2017'
P17-1006:
  abstract: "Morphologically rich languages accentuate two properties of distributional\
    \ vector space models: 1) the difficulty of inducing accurate representations\
    \ for low-frequency word forms; and 2) insensitivity to distinct lexical relations\
    \ that have similar distributional signatures. These effects are detrimental for\
    \ language understanding systems, which may infer that \u2018inexpensive\u2019\
    \ is a rephrasing for \u2018expensive\u2019 or may not associate \u2018acquire\u2019\
    \ with \u2018acquires\u2019. In this work, we propose a novel morph-fitting procedure\
    \ which moves past the use of curated semantic lexicons for improving distributional\
    \ vector spaces. Instead, our method injects morphological constraints generated\
    \ using simple language-specific rules, pulling inflectional forms of the same\
    \ word close together and pushing derivational antonyms far apart. In intrinsic\
    \ evaluation over four languages, we show that our approach: 1) improves low-frequency\
    \ word estimates; and 2) boosts the semantic quality of the entire word vector\
    \ collection. Finally, we show that morph-fitted vectors yield large gains in\
    \ the downstream task of dialogue state tracking, highlighting the importance\
    \ of morphology for tackling long-tail phenomena in language understanding tasks."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1006.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1006.Notes.zip
  - filename: https://vimeo.com/234954143
    type: video
    url: https://vimeo.com/234954143
  author:
  - first: Ivan
    full: "Ivan Vuli\u0107"
    id: ivan-vulic
    last: "Vuli\u0107"
  - first: Nikola
    full: "Nikola Mrk\u0161i\u0107"
    id: nikola-mrksic
    last: "Mrk\u0161i\u0107"
  - first: Roi
    full: Roi Reichart
    id: roi-reichart
    last: Reichart
  - first: Diarmuid
    full: "Diarmuid \xD3 S\xE9aghdha"
    id: diarmuid-o-seaghdha
    last: "\xD3 S\xE9aghdha"
  - first: Steve
    full: Steve Young
    id: steve-young
    last: Young
  - first: Anna
    full: Anna Korhonen
    id: anna-korhonen
    last: Korhonen
  author_string: "Ivan Vuli\u0107, Nikola Mrk\u0161i\u0107, Roi Reichart, Diarmuid\
    \ \xD3 S\xE9aghdha, Steve Young, Anna Korhonen"
  bibkey: vulic-etal-2017-morph
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1006
  month: July
  page_first: '56'
  page_last: '68'
  pages: "56\u201368"
  paper_id: '6'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1006.jpg
  title: 'Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific
    Rules'
  title_html: 'Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific
    Rules'
  url: https://www.aclweb.org/anthology/P17-1006
  year: '2017'
P17-1007:
  abstract: "In recent years word-embedding models have gained great popularity due\
    \ to their remarkable performance on several tasks, including word analogy questions\
    \ and caption generation. An unexpected \u201Cside-effect\u201D of such models\
    \ is that their vectors often exhibit compositionality, i.e., addingtwo word-vectors\
    \ results in a vector that is only a small angle away from the vector of a word\
    \ representing the semantic composite of the original words, e.g., \u201Cman\u201D\
    \ + \u201Croyal\u201D = \u201Cking\u201D. This work provides a theoretical justification\
    \ for the presence of additive compositionality in word vectors learned using\
    \ the Skip-Gram model. In particular, it shows that additive compositionality\
    \ holds in an even stricter sense (small distance rather than small angle) under\
    \ certain assumptions on the process generating the corpus. As a corollary, it\
    \ explains the success of vector calculus in solving word analogies. When these\
    \ assumptions do not hold, this work describes the correct non-linear composition\
    \ operator. Finally, this work establishes a connection between the Skip-Gram\
    \ model and the Sufficient Dimensionality Reduction (SDR) framework of Globerson\
    \ and Tishby: the parameters of SDR models can be obtained from those of Skip-Gram\
    \ models simply by adding information on symbol frequencies. This shows that Skip-Gram\
    \ embeddings are optimal in the sense of Globerson and Tishby and, further, implies\
    \ that the heuristics commonly used to approximately fit Skip-Gram models can\
    \ be used to fit SDR models."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954195
    type: video
    url: https://vimeo.com/234954195
  author:
  - first: Alex
    full: Alex Gittens
    id: alex-gittens
    last: Gittens
  - first: Dimitris
    full: Dimitris Achlioptas
    id: dimitris-achlioptas
    last: Achlioptas
  - first: Michael W.
    full: Michael W. Mahoney
    id: michael-w-mahoney
    last: Mahoney
  author_string: Alex Gittens, Dimitris Achlioptas, Michael W. Mahoney
  bibkey: gittens-etal-2017-skip
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1007
  month: July
  page_first: '69'
  page_last: '76'
  pages: "69\u201376"
  paper_id: '7'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1007.jpg
  title: "Skip-Gram \u2212 Zipf + Uniform = Vector Additivity"
  title_html: "Skip-Gram \u2212 <span class=\"acl-fixed-case\">Z</span>ipf + Uniform\
    \ = Vector Additivity"
  url: https://www.aclweb.org/anthology/P17-1007
  year: '2017'
P17-1008:
  abstract: Semantic representation is receiving growing attention in NLP in the past
    few years, and many proposals for semantic schemes (e.g., AMR, UCCA, GMB, UDS)
    have been put forth. Yet, little has been done to assess the achievements and
    the shortcomings of these new contenders, compare them with syntactic schemes,
    and clarify the general goals of research on semantic representation. We address
    these gaps by critically surveying the state of the art in the field.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954248
    type: video
    url: https://vimeo.com/234954248
  author:
  - first: Omri
    full: Omri Abend
    id: omri-abend
    last: Abend
  - first: Ari
    full: Ari Rappoport
    id: ari-rappoport
    last: Rappoport
  author_string: Omri Abend, Ari Rappoport
  bibkey: abend-rappoport-2017-state
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1008
  month: July
  page_first: '77'
  page_last: '89'
  pages: "77\u201389"
  paper_id: '8'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1008.jpg
  title: The State of the Art in Semantic Representation
  title_html: The State of the Art in Semantic Representation
  url: https://www.aclweb.org/anthology/P17-1008
  year: '2017'
P17-1009:
  abstract: While joint models have been developed for many NLP tasks, the vast majority
    of event coreference resolvers, including the top-performing resolvers competing
    in the recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipeline-based,
    where the propagation of errors from the trigger detection component to the event
    coreference component is a major performance limiting factor. To address this
    problem, we propose a model for jointly learning event coreference, trigger detection,
    and event anaphoricity. Our joint model is novel in its choice of tasks and its
    features for capturing cross-task interactions. To our knowledge, this is the
    first attempt to train a mention-ranking model and employ event anaphoricity for
    event coreference. Our model achieves the best results to date on the KBP 2016
    English and Chinese datasets.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953264
    type: video
    url: https://vimeo.com/234953264
  author:
  - first: Jing
    full: Jing Lu
    id: jing-lu
    last: Lu
  - first: Vincent
    full: Vincent Ng
    id: vincent-ng
    last: Ng
  author_string: Jing Lu, Vincent Ng
  bibkey: lu-ng-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1009
  month: July
  page_first: '90'
  page_last: '101'
  pages: "90\u2013101"
  paper_id: '9'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1009.jpg
  title: Joint Learning for Event Coreference Resolution
  title_html: Joint Learning for Event Coreference Resolution
  url: https://www.aclweb.org/anthology/P17-1009
  year: '2017'
P17-1010:
  abstract: Most existing approaches for zero pronoun resolution are heavily relying
    on annotated data, which is often released by shared task organizers. Therefore,
    the lack of annotated data becomes a major obstacle in the progress of zero pronoun
    resolution task. Also, it is expensive to spend manpower on labeling the data
    for better performance. To alleviate the problem above, in this paper, we propose
    a simple but novel approach to automatically generate large-scale pseudo training
    data for zero pronoun resolution. Furthermore, we successfully transfer the cloze-style
    reading comprehension neural network model into zero pronoun resolution task and
    propose a two-step training mechanism to overcome the gap between the pseudo training
    data and the real one. Experimental results show that the proposed approach significantly
    outperforms the state-of-the-art systems with an absolute improvements of 3.1%
    F-score on OntoNotes 5.0 data.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953310
    type: video
    url: https://vimeo.com/234953310
  author:
  - first: Ting
    full: Ting Liu
    id: ting-liu
    last: Liu
  - first: Yiming
    full: Yiming Cui
    id: yiming-cui
    last: Cui
  - first: Qingyu
    full: Qingyu Yin
    id: qingyu-yin
    last: Yin
  - first: Wei-Nan
    full: Wei-Nan Zhang
    id: weinan-zhang
    last: Zhang
  - first: Shijin
    full: Shijin Wang
    id: shijin-wang
    last: Wang
  - first: Guoping
    full: Guoping Hu
    id: guoping-hu
    last: Hu
  author_string: Ting Liu, Yiming Cui, Qingyu Yin, Wei-Nan Zhang, Shijin Wang, Guoping
    Hu
  bibkey: liu-etal-2017-generating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1010
  month: July
  page_first: '102'
  page_last: '111'
  pages: "102\u2013111"
  paper_id: '10'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1010.jpg
  title: Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun
    Resolution
  title_html: Generating and Exploiting Large-scale Pseudo Training Data for Zero
    Pronoun Resolution
  url: https://www.aclweb.org/anthology/P17-1010
  year: '2017'
P17-1011:
  abstract: Discourse modes play an important role in writing composition and evaluation.
    This paper presents a study on the manual and automatic identification of narration,exposition,
    description, argument and emotion expressing sentences in narrative essays. We
    annotate a corpus to study the characteristics of discourse modes and describe
    a neural sequence labeling model for identification. Evaluation results show that
    discourse modes can be identified automatically with an average F1-score of 0.7.
    We further demonstrate that discourse modes can be used as features that improve
    automatic essay scoring (AES). The impacts of discourse modes for AES are also
    discussed.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953346
    type: video
    url: https://vimeo.com/234953346
  author:
  - first: Wei
    full: Wei Song
    id: wei-song
    last: Song
  - first: Dong
    full: Dong Wang
    id: dong-wang
    last: Wang
  - first: Ruiji
    full: Ruiji Fu
    id: ruiji-fu
    last: Fu
  - first: Lizhen
    full: Lizhen Liu
    id: lizhen-liu
    last: Liu
  - first: Ting
    full: Ting Liu
    id: ting-liu
    last: Liu
  - first: Guoping
    full: Guoping Hu
    id: guoping-hu
    last: Hu
  author_string: Wei Song, Dong Wang, Ruiji Fu, Lizhen Liu, Ting Liu, Guoping Hu
  bibkey: song-etal-2017-discourse
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1011
  month: July
  page_first: '112'
  page_last: '122'
  pages: "112\u2013122"
  paper_id: '11'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1011.jpg
  title: Discourse Mode Identification in Essays
  title_html: Discourse Mode Identification in Essays
  url: https://www.aclweb.org/anthology/P17-1011
  year: '2017'
P17-1012:
  abstract: "The prevalent approach to neural machine translation relies on bi-directional\
    \ LSTMs to encode the source sentence. We present a faster and simpler architecture\
    \ based on a succession of convolutional layers. This allows to encode the source\
    \ sentence simultaneously compared to recurrent networks for which computation\
    \ is constrained by temporal dependencies. On WMT\u201916 English-Romanian translation\
    \ we achieve competitive accuracy to the state-of-the-art and on WMT\u201915 English-German\
    \ we outperform several recently published results. Our models obtain almost the\
    \ same accuracy as a very deep LSTM setup on WMT\u201914 English-French translation.\
    \ We speed up CPU decoding by more than two times at the same or higher accuracy\
    \ as a strong bi-directional LSTM."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951320
    type: video
    url: https://vimeo.com/234951320
  author:
  - first: Jonas
    full: Jonas Gehring
    id: jonas-gehring
    last: Gehring
  - first: Michael
    full: Michael Auli
    id: michael-auli
    last: Auli
  - first: David
    full: David Grangier
    id: david-grangier
    last: Grangier
  - first: Yann
    full: Yann Dauphin
    id: yann-dauphin
    last: Dauphin
  author_string: Jonas Gehring, Michael Auli, David Grangier, Yann Dauphin
  bibkey: gehring-etal-2017-convolutional
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1012
  month: July
  page_first: '123'
  page_last: '135'
  pages: "123\u2013135"
  paper_id: '12'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1012.jpg
  title: A Convolutional Encoder Model for Neural Machine Translation
  title_html: A Convolutional Encoder Model for Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1012
  year: '2017'
P17-1013:
  abstract: Deep Neural Networks (DNNs) have provably enhanced the state-of-the-art
    Neural Machine Translation (NMT) with its capability in modeling complex functions
    and capturing complex linguistic structures. However NMT with deep architecture
    in its encoder or decoder RNNs often suffer from severe gradient diffusion due
    to the non-linear recurrent activations, which often makes the optimization much
    more difficult. To address this problem we propose a novel linear associative
    units (LAU) to reduce the gradient propagation path inside the recurrent unit.
    Different from conventional approaches (LSTM unit and GRU), LAUs uses linear associative
    connections between input and output of the recurrent unit, which allows unimpeded
    information flow through both space and time The model is quite simple, but it
    is surprisingly effective. Our empirical study on Chinese-English translation
    shows that our model with proper configuration can improve by 11.7 BLEU upon Groundhog
    and the best reported on results in the same setting. On WMT14 English-German
    task and a larger WMT14 English-French task, our model achieves comparable results
    with the state-of-the-art.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951392
    type: video
    url: https://vimeo.com/234951392
  author:
  - first: Mingxuan
    full: Mingxuan Wang
    id: mingxuan-wang
    last: Wang
  - first: Zhengdong
    full: Zhengdong Lu
    id: zhengdong-lu
    last: Lu
  - first: Jie
    full: Jie Zhou
    id: jie-zhou
    last: Zhou
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  author_string: Mingxuan Wang, Zhengdong Lu, Jie Zhou, Qun Liu
  bibkey: wang-etal-2017-deep-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1013
  month: July
  page_first: '136'
  page_last: '145'
  pages: "136\u2013145"
  paper_id: '13'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1013.jpg
  title: Deep Neural Machine Translation with Linear Associative Unit
  title_html: Deep Neural Machine Translation with Linear Associative Unit
  url: https://www.aclweb.org/anthology/P17-1013
  year: '2017'
P17-1014:
  abstract: Sequence-to-sequence models have shown strong performance across a broad
    range of applications. However, their application to parsing and generating text
    using Abstract Meaning Representation (AMR) has been limited, due to the relatively
    limited amount of labeled data and the non-sequential nature of the AMR graphs.
    We present a novel training procedure that can lift this limitation using millions
    of unlabeled sentences and careful preprocessing of the AMR graphs. For AMR parsing,
    our model achieves competitive results of 62.1 SMATCH, the current best score
    reported without significant use of external semantic resources. For AMR generation,
    our model establishes a new state-of-the-art performance of BLEU 33.8. We present
    extensive ablative and qualitative analysis including strong evidence that sequence-based
    AMR models are robust against ordering variations of graph-to-sequence conversions.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1014.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1014.Presentation.pdf
  - filename: https://vimeo.com/234952236
    type: video
    url: https://vimeo.com/234952236
  author:
  - first: Ioannis
    full: Ioannis Konstas
    id: ioannis-konstas
    last: Konstas
  - first: Srinivasan
    full: Srinivasan Iyer
    id: srinivasan-iyer
    last: Iyer
  - first: Mark
    full: Mark Yatskar
    id: mark-yatskar
    last: Yatskar
  - first: Yejin
    full: Yejin Choi
    id: yejin-choi
    last: Choi
  - first: Luke
    full: Luke Zettlemoyer
    id: luke-zettlemoyer
    last: Zettlemoyer
  author_string: Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, Luke
    Zettlemoyer
  bibkey: konstas-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1014
  month: July
  page_first: '146'
  page_last: '157'
  pages: "146\u2013157"
  paper_id: '14'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1014.jpg
  title: 'Neural AMR: Sequence-to-Sequence Models for Parsing and Generation'
  title_html: 'Neural <span class="acl-fixed-case">AMR</span>: Sequence-to-Sequence
    Models for Parsing and Generation'
  url: https://www.aclweb.org/anthology/P17-1014
  year: '2017'
P17-1015:
  abstract: "Solving algebraic word problems requires executing a series of arithmetic\
    \ operations\u2014a program\u2014to obtain a final answer. However, since programs\
    \ can be arbitrarily complicated, inducing them directly from question-answer\
    \ pairs is a formidable challenge. To make this task more feasible, we solve these\
    \ problems by generating answer rationales, sequences of natural language and\
    \ human-readable mathematical expressions that derive the final answer through\
    \ a series of small steps. Although rationales do not explicitly specify programs,\
    \ they provide a scaffolding for their structure via intermediate milestones.\
    \ To evaluate our approach, we have created a new 100,000-sample dataset of questions,\
    \ answers and rationales. Experimental results show that indirect supervision\
    \ of program learning via answer rationales is a promising strategy for inducing\
    \ arithmetic programs."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952264
    type: video
    url: https://vimeo.com/234952264
  author:
  - first: Wang
    full: Wang Ling
    id: wang-ling
    last: Ling
  - first: Dani
    full: Dani Yogatama
    id: dani-yogatama
    last: Yogatama
  - first: Chris
    full: Chris Dyer
    id: chris-dyer
    last: Dyer
  - first: Phil
    full: Phil Blunsom
    id: phil-blunsom
    last: Blunsom
  author_string: Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom
  bibkey: ling-etal-2017-program
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1015
  month: July
  page_first: '158'
  page_last: '167'
  pages: "158\u2013167"
  paper_id: '15'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1015.jpg
  title: 'Program Induction by Rationale Generation: Learning to Solve and Explain
    Algebraic Word Problems'
  title_html: 'Program Induction by Rationale Generation: Learning to Solve and Explain
    Algebraic Word Problems'
  url: https://www.aclweb.org/anthology/P17-1015
  year: '2017'
P17-1016:
  abstract: We propose two novel methodologies for the automatic generation of rhythmic
    poetry in a variety of forms. The first approach uses a neural language model
    trained on a phonetic encoding to learn an implicit representation of both the
    form and content of English poetry. This model can effectively learn common poetic
    devices such as rhyme, rhythm and alliteration. The second approach considers
    poetry generation as a constraint satisfaction problem where a generative neural
    language model is tasked with learning a representation of content, and a discriminative
    weighted finite state machine constrains it on the basis of form. By manipulating
    the constraints of the latter model, we can generate coherent poetry with arbitrary
    forms and themes. A large-scale extrinsic evaluation demonstrated that participants
    consider machine-generated poems to be written by humans 54% of the time. In addition,
    participants rated a machine-generated poem to be the best amongst all evaluated.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1016.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1016.Notes.pdf
  - filename: https://vimeo.com/234952320
    type: video
    url: https://vimeo.com/234952320
  author:
  - first: Jack
    full: Jack Hopkins
    id: jack-hopkins
    last: Hopkins
  - first: Douwe
    full: Douwe Kiela
    id: douwe-kiela
    last: Kiela
  author_string: Jack Hopkins, Douwe Kiela
  bibkey: hopkins-kiela-2017-automatically
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1016
  month: July
  page_first: '168'
  page_last: '178'
  pages: "168\u2013178"
  paper_id: '16'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1016.jpg
  title: Automatically Generating Rhythmic Verse with Neural Networks
  title_html: Automatically Generating Rhythmic Verse with Neural Networks
  url: https://www.aclweb.org/anthology/P17-1016
  year: '2017'
P17-1017:
  abstract: "In this paper, we present a novel framework for semi-automatically creating\
    \ linguistically challenging micro-planning data-to-text corpora from existing\
    \ Knowledge Bases. Because our method pairs data of varying size and shape with\
    \ texts ranging from simple clauses to short texts, a dataset created using this\
    \ framework provides a challenging benchmark for microplanning. Another feature\
    \ of this framework is that it can be applied to any large scale knowledge base\
    \ and can therefore be used to train and learn KB verbalisers. We apply our framework\
    \ to DBpedia data and compare the resulting dataset with Wen et al. 2016\u2019\
    s. We show that while Wen et al.\u2019s dataset is more than twice larger than\
    \ ours, it is less diverse both in terms of input and in terms of text. We thus\
    \ propose our corpus generation framework as a novel method for creating challenging\
    \ data sets from which NLG models can be learned which are capable of handling\
    \ the complex interactions occurring during in micro-planning between lexicalisation,\
    \ aggregation, surface realisation, referring expression generation and sentence\
    \ segmentation. To encourage researchers to take up this challenge, we made available\
    \ a dataset of 21,855 data/text pairs created using this framework in the context\
    \ of the WebNLG shared task."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952361
    type: video
    url: https://vimeo.com/234952361
  author:
  - first: Claire
    full: Claire Gardent
    id: claire-gardent
    last: Gardent
  - first: Anastasia
    full: Anastasia Shimorina
    id: anastasia-shimorina
    last: Shimorina
  - first: Shashi
    full: Shashi Narayan
    id: shashi-narayan
    last: Narayan
  - first: Laura
    full: Laura Perez-Beltrachini
    id: laura-perez-beltrachini
    last: Perez-Beltrachini
  author_string: Claire Gardent, Anastasia Shimorina, Shashi Narayan, Laura Perez-Beltrachini
  bibkey: gardent-etal-2017-creating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1017
  month: July
  page_first: '179'
  page_last: '188'
  pages: "179\u2013188"
  paper_id: '17'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1017.jpg
  title: Creating Training Corpora for NLG Micro-Planners
  title_html: Creating Training Corpora for <span class="acl-fixed-case">NLG</span>
    Micro-Planners
  url: https://www.aclweb.org/anthology/P17-1017
  year: '2017'
P17-1018:
  abstract: In this paper, we present the gated self-matching networks for reading
    comprehension style question answering, which aims to answer questions from a
    given passage. We first match the question and passage with gated attention-based
    recurrent networks to obtain the question-aware passage representation. Then we
    propose a self-matching attention mechanism to refine the representation by matching
    the passage against itself, which effectively encodes information from the whole
    passage. We finally employ the pointer networks to locate the positions of answers
    from the passages. We conduct extensive experiments on the SQuAD dataset. The
    single model achieves 71.3% on the evaluation metrics of exact match on the hidden
    test set, while the ensemble model further boosts the results to 75.9%. At the
    time of submission of the paper, our model holds the first place on the SQuAD
    leaderboard for both single and ensemble model.
  address: Vancouver, Canada
  author:
  - first: Wenhui
    full: Wenhui Wang
    id: wenhui-wang
    last: Wang
  - first: Nan
    full: Nan Yang
    id: nan-yang
    last: Yang
  - first: Furu
    full: Furu Wei
    id: furu-wei
    last: Wei
  - first: Baobao
    full: Baobao Chang
    id: baobao-chang
    last: Chang
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  author_string: Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, Ming Zhou
  bibkey: wang-etal-2017-gated
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1018
  month: July
  page_first: '189'
  page_last: '198'
  pages: "189\u2013198"
  paper_id: '18'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1018.jpg
  title: Gated Self-Matching Networks for Reading Comprehension and Question Answering
  title_html: Gated Self-Matching Networks for Reading Comprehension and Question
    Answering
  url: https://www.aclweb.org/anthology/P17-1018
  year: '2017'
P17-1019:
  abstract: Generating answer with natural language sentence is very important in
    real-world question answering systems, which needs to obtain a right answer as
    well as a coherent natural response. In this paper, we propose an end-to-end question
    answering system called COREQA in sequence-to-sequence learning, which incorporates
    copying and retrieving mechanisms to generate natural answers within an encoder-decoder
    framework. Specifically, in COREQA, the semantic units (words, phrases and entities)
    in a natural answer are dynamically predicted from the vocabulary, copied from
    the given question and/or retrieved from the corresponding knowledge base jointly.
    Our empirical study on both synthetic and real-world datasets demonstrates the
    efficiency of COREQA, which is able to generate correct, coherent and natural
    answers for knowledge inquired questions.
  address: Vancouver, Canada
  author:
  - first: Shizhu
    full: Shizhu He
    id: shizhu-he
    last: He
  - first: Cao
    full: Cao Liu
    id: cao-liu
    last: Liu
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  author_string: Shizhu He, Cao Liu, Kang Liu, Jun Zhao
  bibkey: he-etal-2017-generating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1019
  month: July
  page_first: '199'
  page_last: '208'
  pages: "199\u2013208"
  paper_id: '19'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1019.jpg
  title: Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms
    in Sequence-to-Sequence Learning
  title_html: Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms
    in Sequence-to-Sequence Learning
  url: https://www.aclweb.org/anthology/P17-1019
  year: '2017'
P17-1020:
  abstract: We present a framework for question answering that can efficiently scale
    to longer documents while maintaining or even improving performance of state-of-the-art
    models. While most successful approaches for reading comprehension rely on recurrent
    neural networks (RNNs), running them over long documents is prohibitively slow
    because it is difficult to parallelize over sequences. Inspired by how people
    first skim the document, identify relevant parts, and carefully read these parts
    to produce an answer, we combine a coarse, fast model for selecting relevant sentences
    and a more expensive RNN for producing the answer from those sentences. We treat
    sentence selection as a latent variable trained jointly from the answer only using
    reinforcement learning. Experiments demonstrate state-of-the-art performance on
    a challenging subset of the WikiReading dataset and on a new dataset, while speeding
    up the model by 3.5x-6.7x.
  address: Vancouver, Canada
  author:
  - first: Eunsol
    full: Eunsol Choi
    id: eunsol-choi
    last: Choi
  - first: Daniel
    full: Daniel Hewlett
    id: daniel-hewlett
    last: Hewlett
  - first: Jakob
    full: Jakob Uszkoreit
    id: jakob-uszkoreit
    last: Uszkoreit
  - first: Illia
    full: Illia Polosukhin
    id: illia-polosukhin
    last: Polosukhin
  - first: Alexandre
    full: Alexandre Lacoste
    id: alexandre-lacoste
    last: Lacoste
  - first: Jonathan
    full: Jonathan Berant
    id: jonathan-berant
    last: Berant
  author_string: Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre
    Lacoste, Jonathan Berant
  bibkey: choi-etal-2017-coarse
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1020
  month: July
  page_first: '209'
  page_last: '220'
  pages: "209\u2013220"
  paper_id: '20'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1020.jpg
  title: Coarse-to-Fine Question Answering for Long Documents
  title_html: Coarse-to-Fine Question Answering for Long Documents
  url: https://www.aclweb.org/anthology/P17-1020
  year: '2017'
P17-1021:
  abstract: With the rapid growth of knowledge bases (KBs) on the web, how to take
    full advantage of them becomes increasingly important. Question answering over
    knowledge base (KB-QA) is one of the promising approaches to access the substantial
    knowledge. Meanwhile, as the neural network-based (NN-based) methods develop,
    NN-based KB-QA has already achieved impressive results. However, previous work
    did not put more emphasis on question representation, and the question is converted
    into a fixed vector regardless of its candidate answers. This simple representation
    strategy is not easy to express the proper information in the question. Hence,
    we present an end-to-end neural network model to represent the questions and their
    corresponding scores dynamically according to the various candidate answer aspects
    via cross-attention mechanism. In addition, we leverage the global knowledge inside
    the underlying KB, aiming at integrating the rich KB information into the representation
    of the answers. As a result, it could alleviates the out-of-vocabulary (OOV) problem,
    which helps the cross-attention model to represent the question more precisely.
    The experimental results on WebQuestions demonstrate the effectiveness of the
    proposed approach.
  address: Vancouver, Canada
  author:
  - first: Yanchao
    full: Yanchao Hao
    id: yanchao-hao
    last: Hao
  - first: Yuanzhe
    full: Yuanzhe Zhang
    id: yuanzhe-zhang
    last: Zhang
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Shizhu
    full: Shizhu He
    id: shizhu-he
    last: He
  - first: Zhanyi
    full: Zhanyi Liu
    id: zhanyi-liu
    last: Liu
  - first: Hua
    full: Hua Wu
    id: hua-wu
    last: Wu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  author_string: Yanchao Hao, Yuanzhe Zhang, Kang Liu, Shizhu He, Zhanyi Liu, Hua
    Wu, Jun Zhao
  bibkey: hao-etal-2017-end
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1021
  month: July
  page_first: '221'
  page_last: '231'
  pages: "221\u2013231"
  paper_id: '21'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1021.jpg
  title: An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention
    Combining Global Knowledge
  title_html: An End-to-End Model for Question Answering over Knowledge Base with
    Cross-Attention Combining Global Knowledge
  url: https://www.aclweb.org/anthology/P17-1021
  year: '2017'
P17-1022:
  abstract: "Several approaches have recently been proposed for learning decentralized\
    \ deep multiagent policies that coordinate via a differentiable communication\
    \ channel. While these policies are effective for many tasks, interpretation of\
    \ their induced communication strategies has remained a challenge. Here we propose\
    \ to interpret agents\u2019 messages by translating them. Unlike in typical machine\
    \ translation problems, we have no parallel data to learn from. Instead we develop\
    \ a translation model based on the insight that agent messages and natural language\
    \ strings mean the same thing if they induce the same belief about the world in\
    \ a listener. We present theoretical guarantees and empirical evidence that our\
    \ approach preserves both the semantics and pragmatics of messages by ensuring\
    \ that players communicating through a translation layer do not suffer a substantial\
    \ loss in reward relative to players with a common language."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1022.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1022.Notes.pdf
  - filename: https://vimeo.com/234954361
    type: video
    url: https://vimeo.com/234954361
  author:
  - first: Jacob
    full: Jacob Andreas
    id: jacob-andreas
    last: Andreas
  - first: Anca
    full: Anca Dragan
    id: anca-dragan
    last: Dragan
  - first: Dan
    full: Dan Klein
    id: dan-klein
    last: Klein
  author_string: Jacob Andreas, Anca Dragan, Dan Klein
  bibkey: andreas-etal-2017-translating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1022
  month: July
  page_first: '232'
  page_last: '242'
  pages: "232\u2013242"
  paper_id: '22'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1022.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1022.jpg
  title: Translating Neuralese
  title_html: Translating Neuralese
  url: https://www.aclweb.org/anthology/P17-1022
  year: '2017'
P17-1023:
  abstract: We investigate object naming, which is an important sub-task of referring
    expression generation on real-world images. As opposed to mutually exclusive labels
    used in object recognition, object names are more flexible, subject to communicative
    preferences and semantically related to each other. Therefore, we investigate
    models of referential word meaning that link visual to lexical information which
    we assume to be given through distributional word embeddings. We present a model
    that learns individual predictors for object names that link visual and distributional
    aspects of word meaning during training. We show that this is particularly beneficial
    for zero-shot learning, as compared to projecting visual objects directly into
    the distributional space. In a standard object naming task, we find that different
    ways of combining lexical and visual information achieve very similar performance,
    though experiments on model combination suggest that they capture complementary
    aspects of referential meaning.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954406
    type: video
    url: https://vimeo.com/234954406
  author:
  - first: Sina
    full: "Sina Zarrie\xDF"
    id: sina-zarriess
    last: "Zarrie\xDF"
  - first: David
    full: David Schlangen
    id: david-schlangen
    last: Schlangen
  author_string: "Sina Zarrie\xDF, David Schlangen"
  bibkey: zarriess-schlangen-2017-obtaining
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1023
  month: July
  page_first: '243'
  page_last: '254'
  pages: "243\u2013254"
  paper_id: '23'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1023.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1023.jpg
  title: 'Obtaining referential word meanings from visual and distributional information:
    Experiments on object naming'
  title_html: 'Obtaining referential word meanings from visual and distributional
    information: Experiments on object naming'
  url: https://www.aclweb.org/anthology/P17-1023
  year: '2017'
P17-1024:
  abstract: "In this paper, we aim to understand whether current language and vision\
    \ (LaVi) models truly grasp the interaction between the two modalities. To this\
    \ end, we propose an extension of the MS-COCO dataset, FOIL-COCO, which associates\
    \ images with both correct and \u2018foil\u2019 captions, that is, descriptions\
    \ of the image that are highly similar to the original ones, but contain one single\
    \ mistake (\u2018foil word\u2019). We show that current LaVi models fall into\
    \ the traps of this data and perform badly on three tasks: a) caption classification\
    \ (correct vs. foil); b) foil word detection; c) foil word correction. Humans,\
    \ in contrast, have near-perfect performance on those tasks. We demonstrate that\
    \ merely utilising language cues is not enough to model FOIL-COCO and that it\
    \ challenges the state-of-the-art by requiring a fine-grained understanding of\
    \ the relation between text and image."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954462
    type: video
    url: https://vimeo.com/234954462
  author:
  - first: Ravi
    full: Ravi Shekhar
    id: ravi-shekhar
    last: Shekhar
  - first: Sandro
    full: Sandro Pezzelle
    id: sandro-pezzelle
    last: Pezzelle
  - first: Yauhen
    full: Yauhen Klimovich
    id: yauhen-klimovich
    last: Klimovich
  - first: "Aur\xE9lie"
    full: "Aur\xE9lie Herbelot"
    id: aurelie-herbelot
    last: Herbelot
  - first: Moin
    full: Moin Nabi
    id: moin-nabi
    last: Nabi
  - first: Enver
    full: Enver Sangineto
    id: enver-sangineto
    last: Sangineto
  - first: Raffaella
    full: Raffaella Bernardi
    id: raffaella-bernardi
    last: Bernardi
  author_string: "Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aur\xE9lie Herbelot,\
    \ Moin Nabi, Enver Sangineto, Raffaella Bernardi"
  bibkey: shekhar-etal-2017-foil
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1024
  month: July
  page_first: '255'
  page_last: '265'
  pages: "255\u2013265"
  paper_id: '24'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1024.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1024.jpg
  title: FOIL it! Find One mismatch between Image and Language caption
  title_html: <span class="acl-fixed-case">FOIL</span> it! Find One mismatch between
    Image and Language caption
  url: https://www.aclweb.org/anthology/P17-1024
  year: '2017'
P17-1025:
  abstract: "Learning commonsense knowledge from natural language text is nontrivial\
    \ due to reporting bias: people rarely state the obvious, e.g., \u201CMy house\
    \ is bigger than me.\u201D However, while rarely stated explicitly, this trivial\
    \ everyday knowledge does influence the way people talk about the world, which\
    \ provides indirect clues to reason about the world. For example, a statement\
    \ like, \u201CTyler entered his house\u201D implies that his house is bigger than\
    \ Tyler. In this paper, we present an approach to infer relative physical knowledge\
    \ of actions and objects along five dimensions (e.g., size, weight, and strength)\
    \ from unstructured natural language text. We frame knowledge acquisition as joint\
    \ inference over two closely related problems: learning (1) relative physical\
    \ knowledge of object pairs and (2) physical implications of actions when applied\
    \ to those object pairs. Empirical results demonstrate that it is possible to\
    \ extract knowledge of actions and objects from language and that joint inference\
    \ over different types of knowledge improves performance."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954495
    type: video
    url: https://vimeo.com/234954495
  author:
  - first: Maxwell
    full: Maxwell Forbes
    id: maxwell-forbes
    last: Forbes
  - first: Yejin
    full: Yejin Choi
    id: yejin-choi
    last: Choi
  author_string: Maxwell Forbes, Yejin Choi
  bibkey: forbes-choi-2017-verb
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1025
  month: July
  page_first: '266'
  page_last: '276'
  pages: "266\u2013276"
  paper_id: '25'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1025.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1025.jpg
  title: 'Verb Physics: Relative Physical Knowledge of Actions and Objects'
  title_html: 'Verb Physics: Relative Physical Knowledge of Actions and Objects'
  url: https://www.aclweb.org/anthology/P17-1025
  year: '2017'
P17-1026:
  abstract: We propose a new A* CCG parsing model in which the probability of a tree
    is decomposed into factors of CCG categories and its syntactic dependencies both
    defined on bi-directional LSTMs. Our factored model allows the precomputation
    of all probabilities and runs very efficiently, while modeling sentence structures
    explicitly via dependencies. Our model achieves the state-of-the-art results on
    English and Japanese CCG parsing.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953499
    type: video
    url: https://vimeo.com/234953499
  author:
  - first: Masashi
    full: Masashi Yoshikawa
    id: masashi-yoshikawa
    last: Yoshikawa
  - first: Hiroshi
    full: Hiroshi Noji
    id: hiroshi-noji
    last: Noji
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Masashi Yoshikawa, Hiroshi Noji, Yuji Matsumoto
  bibkey: yoshikawa-etal-2017-ccg
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1026
  month: July
  page_first: '277'
  page_last: '287'
  pages: "277\u2013287"
  paper_id: '26'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1026.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1026.jpg
  title: A* CCG Parsing with a Supertag and Dependency Factored Model
  title_html: <span class="acl-fixed-case">A</span>* <span class="acl-fixed-case">CCG</span>
    Parsing with a Supertag and Dependency Factored Model
  url: https://www.aclweb.org/anthology/P17-1026
  year: '2017'
P17-1027:
  abstract: Restricted non-monotonicity has been shown beneficial for the projective
    arc-eager dependency parser in previous research, as posterior decisions can repair
    mistakes made in previous states due to the lack of information. In this paper,
    we propose a novel, fully non-monotonic transition system based on the non-projective
    Covington algorithm. As a non-monotonic system requires exploration of erroneous
    actions during the training process, we develop several non-monotonic variants
    of the recently defined dynamic oracle for the Covington parser, based on tight
    approximations of the loss. Experiments on datasets from the CoNLL-X and CoNLL-XI
    shared tasks show that a non-monotonic dynamic oracle outperforms the monotonic
    version in the majority of languages.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953567
    type: video
    url: https://vimeo.com/234953567
  author:
  - first: Daniel
    full: "Daniel Fern\xE1ndez-Gonz\xE1lez"
    id: daniel-fernandez-gonzalez
    last: "Fern\xE1ndez-Gonz\xE1lez"
  - first: Carlos
    full: "Carlos G\xF3mez-Rodr\xEDguez"
    id: carlos-gomez-rodriguez
    last: "G\xF3mez-Rodr\xEDguez"
  author_string: "Daniel Fern\xE1ndez-Gonz\xE1lez, Carlos G\xF3mez-Rodr\xEDguez"
  bibkey: fernandez-gonzalez-gomez-rodriguez-2017-full
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1027
  month: July
  page_first: '288'
  page_last: '298'
  pages: "288\u2013298"
  paper_id: '27'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1027.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1027.jpg
  title: A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing
  title_html: A Full Non-Monotonic Transition System for Unrestricted Non-Projective
    Parsing
  url: https://www.aclweb.org/anthology/P17-1027
  year: '2017'
P17-1028:
  abstract: 'Despite sequences being core to NLP, scant work has considered how to
    handle noisy sequence labels from multiple annotators for the same text. Given
    such annotations, we consider two complementary tasks: (1) aggregating sequential
    crowd labels to infer a best single set of consensus annotations; and (2) using
    crowd annotations as training data for a model that can predict sequences in unannotated
    text. For aggregation, we propose a novel Hidden Markov Model variant. To predict
    sequences in unannotated text, we propose a neural approach using Long Short Term
    Memory. We evaluate a suite of methods across two different applications and text
    genres: Named-Entity Recognition in news articles and Information Extraction from
    biomedical abstracts. Results show improvement over strong baselines. Our source
    code and data are available online.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953632
    type: video
    url: https://vimeo.com/234953632
  author:
  - first: An Thanh
    full: An Thanh Nguyen
    id: an-thanh-nguyen
    last: Nguyen
  - first: Byron
    full: Byron Wallace
    id: byron-c-wallace
    last: Wallace
  - first: Junyi Jessy
    full: Junyi Jessy Li
    id: junyi-jessy-li
    last: Li
  - first: Ani
    full: Ani Nenkova
    id: ani-nenkova
    last: Nenkova
  - first: Matthew
    full: Matthew Lease
    id: matthew-lease
    last: Lease
  author_string: An Thanh Nguyen, Byron Wallace, Junyi Jessy Li, Ani Nenkova, Matthew
    Lease
  bibkey: nguyen-etal-2017-aggregating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1028
  month: July
  page_first: '299'
  page_last: '309'
  pages: "299\u2013309"
  paper_id: '28'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1028.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1028.jpg
  title: Aggregating and Predicting Sequence Labels from Crowd Annotations
  title_html: Aggregating and Predicting Sequence Labels from Crowd Annotations
  url: https://www.aclweb.org/anthology/P17-1028
  year: '2017'
P17-1029:
  abstract: Labeled sequence transduction is a task of transforming one sequence into
    another sequence that satisfies desiderata specified by a set of labels. In this
    paper we propose multi-space variational encoder-decoders, a new model for labeled
    sequence transduction with semi-supervised learning. The generative model can
    use neural networks to handle both discrete and continuous latent variables to
    exploit various features of data. Experiments show that our model provides not
    only a powerful supervised framework but also can effectively take advantage of
    the unlabeled data. On the SIGMORPHON morphological inflection benchmark, our
    model outperforms single-model state-of-art results by a large margin for the
    majority of languages.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951631
    type: video
    url: https://vimeo.com/234951631
  author:
  - first: Chunting
    full: Chunting Zhou
    id: chunting-zhou
    last: Zhou
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  author_string: Chunting Zhou, Graham Neubig
  bibkey: zhou-neubig-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1029
  month: July
  page_first: '310'
  page_last: '320'
  pages: "310\u2013320"
  paper_id: '29'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1029.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1029.jpg
  title: Multi-space Variational Encoder-Decoders for Semi-supervised Labeled Sequence
    Transduction
  title_html: Multi-space Variational Encoder-Decoders for Semi-supervised Labeled
    Sequence Transduction
  url: https://www.aclweb.org/anthology/P17-1029
  year: '2017'
P17-1030:
  abstract: Recurrent neural networks (RNNs) have shown promising performance for
    language modeling. However, traditional training of RNNs using back-propagation
    through time often suffers from overfitting. One reason for this is that stochastic
    optimization (used for large training sets) does not provide good estimates of
    model uncertainty. This paper leverages recent advances in stochastic gradient
    Markov Chain Monte Carlo (also appropriate for large training sets) to learn weight
    uncertainty in RNNs. It yields a principled Bayesian learning algorithm, adding
    gradient noise during training (enhancing exploration of the model-parameter space)
    and model averaging when testing. Extensive experiments on various RNN models
    and across a broad range of applications demonstrate the superiority of the proposed
    approach relative to stochastic optimization.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1030.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1030.Notes.pdf
  - filename: https://vimeo.com/234951692
    type: video
    url: https://vimeo.com/234951692
  author:
  - first: Zhe
    full: Zhe Gan
    id: zhe-gan
    last: Gan
  - first: Chunyuan
    full: Chunyuan Li
    id: chunyuan-li
    last: Li
  - first: Changyou
    full: Changyou Chen
    id: changyou-chen
    last: Chen
  - first: Yunchen
    full: Yunchen Pu
    id: yunchen-pu
    last: Pu
  - first: Qinliang
    full: Qinliang Su
    id: qinliang-su
    last: Su
  - first: Lawrence
    full: Lawrence Carin
    id: lawrence-carin
    last: Carin
  author_string: Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence
    Carin
  bibkey: gan-etal-2017-scalable
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1030
  month: July
  page_first: '321'
  page_last: '331'
  pages: "321\u2013331"
  paper_id: '30'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1030.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1030.jpg
  title: Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling
  title_html: Scalable <span class="acl-fixed-case">B</span>ayesian Learning of Recurrent
    Neural Networks for Language Modeling
  url: https://www.aclweb.org/anthology/P17-1030
  year: '2017'
P17-1031:
  abstract: Automated processing of historical texts often relies on pre-normalization
    to modern word forms. Training encoder-decoder architectures to solve such problems
    typically requires a lot of training data, which is not available for the named
    task. We address this problem by using several novel encoder-decoder architectures,
    including a multi-task learning (MTL) architecture using a grapheme-to-phoneme
    dictionary as auxiliary data, pushing the state-of-the-art by an absolute 2% increase
    in performance. We analyze the induced models across 44 different texts from Early
    New High German. Interestingly, we observe that, as previously conjectured, multi-task
    learning can learn to focus attention during decoding, in ways remarkably similar
    to recently proposed attention mechanisms. This, we believe, is an important step
    toward understanding how MTL works.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951752
    type: video
    url: https://vimeo.com/234951752
  - filename: P17-1031.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1031.Presentation.pdf
  author:
  - first: Marcel
    full: Marcel Bollmann
    id: marcel-bollmann
    last: Bollmann
  - first: Joachim
    full: Joachim Bingel
    id: joachim-bingel
    last: Bingel
  - first: Anders
    full: "Anders S\xF8gaard"
    id: anders-sogaard
    last: "S\xF8gaard"
  author_string: "Marcel Bollmann, Joachim Bingel, Anders S\xF8gaard"
  bibkey: bollmann-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1031
  month: July
  page_first: '332'
  page_last: '344'
  pages: "332\u2013344"
  paper_id: '31'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1031.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1031.jpg
  title: Learning attention for historical text normalization by learning to pronounce
  title_html: Learning attention for historical text normalization by learning to
    pronounce
  url: https://www.aclweb.org/anthology/P17-1031
  year: '2017'
P17-1032:
  abstract: "Kernel methods enable the direct usage of structured representations\
    \ of textual data during language learning and inference tasks. Expressive kernels,\
    \ such as Tree Kernels, achieve excellent performance in NLP. On the other side,\
    \ deep neural networks have been demonstrated effective in automatically learning\
    \ feature representations during training. However, their input is tensor data,\
    \ i.e., they can not manage rich structured information. In this paper, we show\
    \ that expressive kernels and deep neural networks can be combined in a common\
    \ framework in order to (i) explicitly model structured information and (ii) learn\
    \ non-linear decision functions. We show that the input layer of a deep architecture\
    \ can be pre-trained through the application of the Nystrom low-rank approximation\
    \ of kernel spaces. The resulting \u201Ckernelized\u201D neural network achieves\
    \ state-of-the-art accuracy in three different tasks."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951827
    type: video
    url: https://vimeo.com/234951827
  author:
  - first: Danilo
    full: Danilo Croce
    id: danilo-croce
    last: Croce
  - first: Simone
    full: Simone Filice
    id: simone-filice
    last: Filice
  - first: Giuseppe
    full: Giuseppe Castellucci
    id: giuseppe-castellucci
    last: Castellucci
  - first: Roberto
    full: Roberto Basili
    id: roberto-basili
    last: Basili
  author_string: Danilo Croce, Simone Filice, Giuseppe Castellucci, Roberto Basili
  bibkey: croce-etal-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1032
  month: July
  page_first: '345'
  page_last: '354'
  pages: "345\u2013354"
  paper_id: '32'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1032.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1032.jpg
  title: Deep Learning in Semantic Kernel Spaces
  title_html: Deep Learning in Semantic Kernel Spaces
  url: https://www.aclweb.org/anthology/P17-1032
  year: '2017'
P17-1033:
  abstract: Language models are typically applied at the sentence level, without access
    to the broader document context. We present a neural language model that incorporates
    document context in the form of a topic model-like architecture, thus providing
    a succinct representation of the broader document context outside of the current
    sentence. Experiments over a range of datasets demonstrate that our model outperforms
    a pure sentence-based model in terms of language model perplexity, and leads to
    topics that are potentially more coherent than those produced by a standard LDA
    topic model. Our model also has the ability to generate related sentences for
    a topic, providing another way to interpret topics.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1033.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1033.Notes.zip
  - filename: https://vimeo.com/234951882
    type: video
    url: https://vimeo.com/234951882
  author:
  - first: Jey Han
    full: Jey Han Lau
    id: jey-han-lau
    last: Lau
  - first: Timothy
    full: Timothy Baldwin
    id: timothy-baldwin
    last: Baldwin
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  author_string: Jey Han Lau, Timothy Baldwin, Trevor Cohn
  bibkey: lau-etal-2017-topically
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1033
  month: July
  page_first: '355'
  page_last: '365'
  pages: "355\u2013365"
  paper_id: '33'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1033.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1033.jpg
  title: Topically Driven Neural Language Model
  title_html: Topically Driven Neural Language Model
  url: https://www.aclweb.org/anthology/P17-1033
  year: '2017'
P17-1034:
  abstract: "Solving cold-start problem in review spam detection is an urgent and\
    \ significant task. It can help the on-line review websites to relieve the damage\
    \ of spammers in time, but has never been investigated by previous work. This\
    \ paper proposes a novel neural network model to detect review spam for cold-start\
    \ problem, by learning to represent the new reviewers\u2019 review with jointly\
    \ embedded textual and behavioral information. Experimental results prove the\
    \ proposed model achieves an effective performance and possesses preferable domain-adaptability.\
    \ It is also applicable to a large scale dataset in an unsupervised way."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952462
    type: video
    url: https://vimeo.com/234952462
  author:
  - first: Xuepeng
    full: Xuepeng Wang
    id: xuepeng-wang
    last: Wang
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  author_string: Xuepeng Wang, Kang Liu, Jun Zhao
  bibkey: wang-etal-2017-handling
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1034
  month: July
  page_first: '366'
  page_last: '376'
  pages: "366\u2013376"
  paper_id: '34'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1034.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1034.jpg
  title: Handling Cold-Start Problem in Review Spam Detection by Jointly Embedding
    Texts and Behaviors
  title_html: Handling Cold-Start Problem in Review Spam Detection by Jointly Embedding
    Texts and Behaviors
  url: https://www.aclweb.org/anthology/P17-1034
  year: '2017'
P17-1035:
  abstract: Cognitive NLP systems- i.e., NLP systems that make use of behavioral data
    - augment traditional text-based features with cognitive features extracted from
    eye-movement patterns, EEG signals, brain-imaging etc. Such extraction of features
    is typically manual. We contend that manual extraction of features may not be
    the best way to tackle text subtleties that characteristically prevail in complex
    classification tasks like Sentiment Analysis and Sarcasm Detection, and that even
    the extraction and choice of features should be delegated to the learning system.
    We introduce a framework to automatically extract cognitive features from the
    eye-movement/gaze data of human readers reading the text and use them as features
    along with textual features for the tasks of sentiment polarity and sarcasm detection.
    Our proposed framework is based on Convolutional Neural Network (CNN). The CNN
    learns features from both gaze and text and uses them to classify the input text.
    We test our technique on published sentiment and sarcasm labeled datasets, enriched
    with gaze information, to show that using a combination of automatically learned
    text and gaze features often yields better classification performance over (i)
    CNN based systems that rely on text input alone and (ii) existing systems that
    rely on handcrafted gaze and textual features.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952512
    type: video
    url: https://vimeo.com/234952512
  author:
  - first: Abhijit
    full: Abhijit Mishra
    id: abhijit-mishra
    last: Mishra
  - first: Kuntal
    full: Kuntal Dey
    id: kuntal-dey
    last: Dey
  - first: Pushpak
    full: Pushpak Bhattacharyya
    id: pushpak-bhattacharyya
    last: Bhattacharyya
  author_string: Abhijit Mishra, Kuntal Dey, Pushpak Bhattacharyya
  bibkey: mishra-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1035
  month: July
  page_first: '377'
  page_last: '387'
  pages: "377\u2013387"
  paper_id: '35'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1035.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1035.jpg
  title: Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification
    using Convolutional Neural Network
  title_html: Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm
    Classification using Convolutional Neural Network
  url: https://www.aclweb.org/anthology/P17-1035
  year: '2017'
P17-1036:
  abstract: Aspect extraction is an important and challenging task in aspect-based
    sentiment analysis. Existing works tend to apply variants of topic models on this
    task. While fairly successful, these methods usually do not produce highly coherent
    aspects. In this paper, we present a novel neural approach with the aim of discovering
    coherent aspects. The model improves coherence by exploiting the distribution
    of word co-occurrences through the use of neural word embeddings. Unlike topic
    models which typically assume independently generated words, word embedding models
    encourage words that appear in similar contexts to be located close to each other
    in the embedding space. In addition, we use an attention mechanism to de-emphasize
    irrelevant words during training, further improving the coherence of aspects.
    Experimental results on real-life datasets demonstrate that our approach discovers
    more meaningful and coherent aspects, and substantially outperforms baseline methods
    on several evaluation tasks.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952560
    type: video
    url: https://vimeo.com/234952560
  author:
  - first: Ruidan
    full: Ruidan He
    id: ruidan-he
    last: He
  - first: Wee Sun
    full: Wee Sun Lee
    id: wee-sun-lee
    last: Lee
  - first: Hwee Tou
    full: Hwee Tou Ng
    id: hwee-tou-ng
    last: Ng
  - first: Daniel
    full: Daniel Dahlmeier
    id: daniel-dahlmeier
    last: Dahlmeier
  author_string: Ruidan He, Wee Sun Lee, Hwee Tou Ng, Daniel Dahlmeier
  bibkey: he-etal-2017-unsupervised
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1036
  month: July
  page_first: '388'
  page_last: '397'
  pages: "388\u2013397"
  paper_id: '36'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1036.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1036.jpg
  title: An Unsupervised Neural Attention Model for Aspect Extraction
  title_html: An Unsupervised Neural Attention Model for Aspect Extraction
  url: https://www.aclweb.org/anthology/P17-1036
  year: '2017'
P17-1037:
  abstract: "We presents in this paper our approach for modeling inter-topic preferences\
    \ of Twitter users: for example, \u201Cthose who agree with the Trans-Pacific\
    \ Partnership (TPP) also agree with free trade\u201D. This kind of knowledge is\
    \ useful not only for stance detection across multiple topics but also for various\
    \ real-world applications including public opinion survey, electoral prediction,\
    \ electoral campaigns, and online debates. In order to extract users\u2019 preferences\
    \ on Twitter, we design linguistic patterns in which people agree and disagree\
    \ about specific topics (e.g., \u201CA is completely wrong\u201D). By applying\
    \ these linguistic patterns to a collection of tweets, we extract statements agreeing\
    \ and disagreeing with various topics. Inspired by previous work on item recommendation,\
    \ we formalize the task of modeling inter-topic preferences as matrix factorization:\
    \ representing users\u2019 preference as a user-topic matrix and mapping both\
    \ users and topics onto a latent feature space that abstracts the preferences.\
    \ Our experimental results demonstrate both that our presented approach is useful\
    \ in predicting missing preferences of users and that the latent vector representations\
    \ of topics successfully encode inter-topic preferences."
  address: Vancouver, Canada
  author:
  - first: Akira
    full: Akira Sasaki
    id: akira-sasaki
    last: Sasaki
  - first: Kazuaki
    full: Kazuaki Hanawa
    id: kazuaki-hanawa
    last: Hanawa
  - first: Naoaki
    full: Naoaki Okazaki
    id: naoaki-okazaki
    last: Okazaki
  - first: Kentaro
    full: Kentaro Inui
    id: kentaro-inui
    last: Inui
  author_string: Akira Sasaki, Kazuaki Hanawa, Naoaki Okazaki, Kentaro Inui
  bibkey: sasaki-etal-2017-topics
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1037
  month: July
  page_first: '398'
  page_last: '408'
  pages: "398\u2013408"
  paper_id: '37'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1037.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1037.jpg
  title: 'Other Topics You May Also Agree or Disagree: Modeling Inter-Topic Preferences
    using Tweets and Matrix Factorization'
  title_html: 'Other Topics You May Also Agree or Disagree: Modeling Inter-Topic Preferences
    using Tweets and Matrix Factorization'
  url: https://www.aclweb.org/anthology/P17-1037
  year: '2017'
P17-1038:
  abstract: Modern models of event extraction for tasks like ACE are based on supervised
    learning of events from small hand-labeled data. However, hand-labeled training
    data is expensive to produce, in low coverage of event types, and limited in size,
    which makes supervised methods hard to extract large scale of events for knowledge
    base population. To solve the data labeling problem, we propose to automatically
    label training data for event extraction via world knowledge and linguistic knowledge,
    which can detect key arguments and trigger words for each event type and employ
    them to label events in texts automatically. The experimental results show that
    the quality of our large scale automatically labeled data is competitive with
    elaborately human-labeled data. And our automatically labeled data can incorporate
    with human-labeled data, then improve the performance of models learned from these
    data.
  address: Vancouver, Canada
  author:
  - first: Yubo
    full: Yubo Chen
    id: yubo-chen
    last: Chen
  - first: Shulin
    full: Shulin Liu
    id: shulin-liu
    last: Liu
  - first: Xiang
    full: Xiang Zhang
    id: xiang-zhang
    last: Zhang
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  author_string: Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, Jun Zhao
  bibkey: chen-etal-2017-automatically
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1038
  month: July
  page_first: '409'
  page_last: '419'
  pages: "409\u2013419"
  paper_id: '38'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1038.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1038.jpg
  title: Automatically Labeled Data Generation for Large Scale Event Extraction
  title_html: Automatically Labeled Data Generation for Large Scale Event Extraction
  url: https://www.aclweb.org/anthology/P17-1038
  year: '2017'
P17-1039:
  abstract: Extracting time expressions from free text is a fundamental task for many
    applications. We analyze the time expressions from four datasets and find that
    only a small group of words are used to express time information, and the words
    in time expressions demonstrate similar syntactic behaviour. Based on the findings,
    we propose a type-based approach, named SynTime, to recognize time expressions.
    Specifically, we define three main syntactic token types, namely time token, modifier,
    and numeral, to group time-related regular expressions over tokens. On the types
    we design general heuristic rules to recognize time expressions. In recognition,
    SynTime first identifies the time tokens from raw text, then searches their surroundings
    for modifiers and numerals to form time segments, and finally merges the time
    segments to time expressions. As a light-weight rule-based tagger, SynTime runs
    in real time, and can be easily expanded by simply adding keywords for the text
    of different types and of different domains. Experiment on benchmark datasets
    and tweets data shows that SynTime outperforms state-of-the-art methods.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1039.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1039.Presentation.pdf
  author:
  - first: Xiaoshi
    full: Xiaoshi Zhong
    id: xiaoshi-zhong
    last: Zhong
  - first: Aixin
    full: Aixin Sun
    id: aixin-sun
    last: Sun
  - first: Erik
    full: Erik Cambria
    id: erik-cambria
    last: Cambria
  author_string: Xiaoshi Zhong, Aixin Sun, Erik Cambria
  bibkey: zhong-etal-2017-time
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1039
  month: July
  page_first: '420'
  page_last: '429'
  pages: "420\u2013429"
  paper_id: '39'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1039.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1039.jpg
  title: Time Expression Analysis and Recognition Using Syntactic Token Types and
    General Heuristic Rules
  title_html: Time Expression Analysis and Recognition Using Syntactic Token Types
    and General Heuristic Rules
  url: https://www.aclweb.org/anthology/P17-1039
  year: '2017'
P17-1040:
  abstract: Distant supervision significantly reduces human efforts in building training
    data for many classification tasks. While promising, this technique often introduces
    noise to the generated training data, which can severely affect the model performance.
    In this paper, we take a deep look at the application of distant supervision in
    relation extraction. We show that the dynamic transition matrix can effectively
    characterize the noise in the training data built by distant supervision. The
    transition matrix can be effectively trained using a novel curriculum learning
    based method without any direct supervision about the noise. We thoroughly evaluate
    our approach under a wide range of extraction scenarios. Experimental results
    show that our approach consistently improves the extraction results and outperforms
    the state-of-the-art in various evaluation scenarios.
  address: Vancouver, Canada
  author:
  - first: Bingfeng
    full: Bingfeng Luo
    id: bingfeng-luo
    last: Luo
  - first: Yansong
    full: Yansong Feng
    id: yansong-feng
    last: Feng
  - first: Zheng
    full: Zheng Wang
    id: zheng-wang
    last: Wang
  - first: Zhanxing
    full: Zhanxing Zhu
    id: zhanxing-zhu
    last: Zhu
  - first: Songfang
    full: Songfang Huang
    id: songfang-huang
    last: Huang
  - first: Rui
    full: Rui Yan
    id: rui-yan
    last: Yan
  - first: Dongyan
    full: Dongyan Zhao
    id: dongyan-zhao
    last: Zhao
  author_string: Bingfeng Luo, Yansong Feng, Zheng Wang, Zhanxing Zhu, Songfang Huang,
    Rui Yan, Dongyan Zhao
  bibkey: luo-etal-2017-learning-noise
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1040
  month: July
  page_first: '430'
  page_last: '439'
  pages: "430\u2013439"
  paper_id: '40'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1040.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1040.jpg
  title: 'Learning with Noise: Enhance Distantly Supervised Relation Extraction with
    Dynamic Transition Matrix'
  title_html: 'Learning with Noise: Enhance Distantly Supervised Relation Extraction
    with Dynamic Transition Matrix'
  url: https://www.aclweb.org/anthology/P17-1040
  year: '2017'
P17-1041:
  abstract: We consider the problem of parsing natural language descriptions into
    source code written in a general-purpose programming language like Python. Existing
    data-driven methods treat this problem as a language generation task without considering
    the underlying syntax of the target programming language. Informed by previous
    work in semantic parsing, in this paper we propose a novel neural architecture
    powered by a grammar model to explicitly capture the target syntax as prior knowledge.
    Experiments find this an effective way to scale up to generation of complex programs
    from natural language descriptions, achieving state-of-the-art results that well
    outperform previous code generation and semantic parsing approaches.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1041.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1041.Notes.pdf
  - filename: https://vimeo.com/234954608
    type: video
    url: https://vimeo.com/234954608
  author:
  - first: Pengcheng
    full: Pengcheng Yin
    id: pengcheng-yin
    last: Yin
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  author_string: Pengcheng Yin, Graham Neubig
  bibkey: yin-neubig-2017-syntactic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1041
  month: July
  page_first: '440'
  page_last: '450'
  pages: "440\u2013450"
  paper_id: '41'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1041.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1041.jpg
  title: A Syntactic Neural Model for General-Purpose Code Generation
  title_html: A Syntactic Neural Model for General-Purpose Code Generation
  url: https://www.aclweb.org/anthology/P17-1041
  year: '2017'
P17-1042:
  abstract: Most methods to learn bilingual word embeddings rely on large parallel
    corpora, which is difficult to obtain for most language pairs. This has motivated
    an active research line to relax this requirement, with methods that use document-aligned
    corpora or bilingual dictionaries of a few thousand words instead. In this work,
    we further reduce the need of bilingual resources using a very simple self-learning
    approach that can be combined with any dictionary-based mapping technique. Our
    method exploits the structural similarity of embedding spaces, and works with
    as little bilingual evidence as a 25 word dictionary or even an automatically
    generated list of numerals, obtaining results comparable to those of systems that
    use richer resources.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1042.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1042.Presentation.pdf
  - filename: https://vimeo.com/234954663
    type: video
    url: https://vimeo.com/234954663
  author:
  - first: Mikel
    full: Mikel Artetxe
    id: mikel-artetxe
    last: Artetxe
  - first: Gorka
    full: Gorka Labaka
    id: gorka-labaka
    last: Labaka
  - first: Eneko
    full: Eneko Agirre
    id: eneko-agirre
    last: Agirre
  author_string: Mikel Artetxe, Gorka Labaka, Eneko Agirre
  bibkey: artetxe-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1042
  month: July
  page_first: '451'
  page_last: '462'
  pages: "451\u2013462"
  paper_id: '42'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1042.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1042.jpg
  title: Learning bilingual word embeddings with (almost) no bilingual data
  title_html: Learning bilingual word embeddings with (almost) no bilingual data
  url: https://www.aclweb.org/anthology/P17-1042
  year: '2017'
P17-1043:
  abstract: We present a system which parses sentences into Abstract Meaning Representations,
    improving state-of-the-art results for this task by more than 5%. AMR graphs represent
    semantic content using linguistic properties such as semantic roles, coreference,
    negation, and more. The AMR parser does not rely on a syntactic pre-parse, or
    heavily engineered features, and uses five recurrent neural networks as the key
    architectural components for inferring AMR graphs.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954715
    type: video
    url: https://vimeo.com/234954715
  author:
  - first: William
    full: William Foland
    id: william-foland
    last: Foland
  - first: James H.
    full: James H. Martin
    id: james-h-martin
    last: Martin
  author_string: William Foland, James H. Martin
  bibkey: foland-martin-2017-abstract
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1043
  month: July
  page_first: '463'
  page_last: '472'
  pages: "463\u2013472"
  paper_id: '43'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1043.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1043.jpg
  title: Abstract Meaning Representation Parsing using LSTM Recurrent Neural Networks
  title_html: Abstract Meaning Representation Parsing using <span class="acl-fixed-case">LSTM</span>
    Recurrent Neural Networks
  url: https://www.aclweb.org/anthology/P17-1043
  year: '2017'
P17-1044:
  abstract: We introduce a new deep learning model for semantic role labeling (SRL)
    that significantly improves the state of the art, along with detailed analyses
    to reveal its strengths and limitations. We use a deep highway BiLSTM architecture
    with constrained decoding, while observing a number of recent best practices for
    initialization and regularization. Our 8-layer ensemble model achieves 83.2 F1
    on theCoNLL 2005 test set and 83.4 F1 on CoNLL 2012, roughly a 10% relative error
    reduction over the previous state of the art. Extensive empirical analysis of
    these gains show that (1) deep models excel at recovering long-distance dependencies
    but can still make surprisingly obvious errors, and (2) that there is still room
    for syntactic parsers to improve these results.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954784
    type: video
    url: https://vimeo.com/234954784
  author:
  - first: Luheng
    full: Luheng He
    id: luheng-he
    last: He
  - first: Kenton
    full: Kenton Lee
    id: kenton-lee
    last: Lee
  - first: Mike
    full: Mike Lewis
    id: mike-lewis
    last: Lewis
  - first: Luke
    full: Luke Zettlemoyer
    id: luke-zettlemoyer
    last: Zettlemoyer
  author_string: Luheng He, Kenton Lee, Mike Lewis, Luke Zettlemoyer
  bibkey: he-etal-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1044
  month: July
  page_first: '473'
  page_last: '483'
  pages: "473\u2013483"
  paper_id: '44'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1044.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1044.jpg
  title: "Deep Semantic Role Labeling: What Works and What\u2019s Next"
  title_html: "Deep Semantic Role Labeling: What Works and What\u2019s Next"
  url: https://www.aclweb.org/anthology/P17-1044
  year: '2017'
P17-1045:
  abstract: "This paper proposes KB-InfoBot - a multi-turn dialogue agent which helps\
    \ users search Knowledge Bases (KBs) without composing complicated queries. Such\
    \ goal-oriented dialogue agents typically need to interact with an external database\
    \ to access real-world knowledge. Previous systems achieved this by issuing a\
    \ symbolic query to the KB to retrieve entries based on their attributes. However,\
    \ such symbolic operations break the differentiability of the system and prevent\
    \ end-to-end training of neural dialogue agents. In this paper, we address this\
    \ limitation by replacing symbolic queries with an induced \u201Csoft\u201D posterior\
    \ distribution over the KB that indicates which entities the user is interested\
    \ in. Integrating the soft retrieval process with a reinforcement learner leads\
    \ to higher task success rate and reward in both simulations and against real\
    \ users. We also present a fully neural end-to-end agent, trained entirely from\
    \ user feedback, and discuss its application towards personalized dialogue agents."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953832
    type: video
    url: https://vimeo.com/234953832
  author:
  - first: Bhuwan
    full: Bhuwan Dhingra
    id: bhuwan-dhingra
    last: Dhingra
  - first: Lihong
    full: Lihong Li
    id: lihong-li
    last: Li
  - first: Xiujun
    full: Xiujun Li
    id: xiujun-li
    last: Li
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  - first: Yun-Nung
    full: Yun-Nung Chen
    id: yun-nung-chen
    last: Chen
  - first: Faisal
    full: Faisal Ahmed
    id: faisal-ahmad
    last: Ahmed
  - first: Li
    full: Li Deng
    id: li-deng
    last: Deng
  author_string: Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen,
    Faisal Ahmed, Li Deng
  bibkey: dhingra-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1045
  month: July
  page_first: '484'
  page_last: '495'
  pages: "484\u2013495"
  paper_id: '45'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1045.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1045.jpg
  title: Towards End-to-End Reinforcement Learning of Dialogue Agents for Information
    Access
  title_html: Towards End-to-End Reinforcement Learning of Dialogue Agents for Information
    Access
  url: https://www.aclweb.org/anthology/P17-1045
  year: '2017'
P17-1046:
  abstract: We study response selection for multi-turn conversation in retrieval based
    chatbots. Existing work either concatenates utterances in context or matches a
    response with a highly abstract context vector finally, which may lose relationships
    among the utterances or important information in the context. We propose a sequential
    matching network (SMN) to address both problems. SMN first matches a response
    with each utterance in the context on multiple levels of granularity, and distills
    important matching information from each pair as a vector with convolution and
    pooling operations. The vectors are then accumulated in a chronological order
    through a recurrent neural network (RNN) which models relationships among the
    utterances. The final matching score is calculated with the hidden states of the
    RNN. Empirical study on two public data sets shows that SMN can significantly
    outperform state-of-the-art methods for response selection in multi-turn conversation.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953894
    type: video
    url: https://vimeo.com/234953894
  author:
  - first: Yu
    full: Yu Wu
    id: yu-wu
    last: Wu
  - first: Wei
    full: Wei Wu
    id: wei-wu
    last: Wu
  - first: Chen
    full: Chen Xing
    id: chen-xing
    last: Xing
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  - first: Zhoujun
    full: Zhoujun Li
    id: zhoujun-li
    last: Li
  author_string: Yu Wu, Wei Wu, Chen Xing, Ming Zhou, Zhoujun Li
  bibkey: wu-etal-2017-sequential
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1046
  month: July
  page_first: '496'
  page_last: '505'
  pages: "496\u2013505"
  paper_id: '46'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1046.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1046.jpg
  title: 'Sequential Matching Network: A New Architecture for Multi-turn Response
    Selection in Retrieval-Based Chatbots'
  title_html: 'Sequential Matching Network: A New Architecture for Multi-turn Response
    Selection in Retrieval-Based Chatbots'
  url: https://www.aclweb.org/anthology/P17-1046
  year: '2017'
P17-1047:
  abstract: "Given a collection of images and spoken audio captions, we present a\
    \ method for discovering word-like acoustic units in the continuous speech signal\
    \ and grounding them to semantically relevant image regions. For example, our\
    \ model is able to detect spoken instances of the word \u2018lighthouse\u2019\
    \ within an utterance and associate them with image regions containing lighthouses.\
    \ We do not use any form of conventional automatic speech recognition, nor do\
    \ we use any text transcriptions or conventional linguistic annotations. Our model\
    \ effectively implements a form of spoken language acquisition, in which the computer\
    \ learns not only to recognize word categories by sound, but also to enrich the\
    \ words it learns with semantics by grounding them in images."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953939
    type: video
    url: https://vimeo.com/234953939
  author:
  - first: David
    full: David Harwath
    id: david-harwath
    last: Harwath
  - first: James
    full: James Glass
    id: james-glass
    last: Glass
  author_string: David Harwath, James Glass
  bibkey: harwath-glass-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1047
  month: July
  page_first: '506'
  page_last: '517'
  pages: "506\u2013517"
  paper_id: '47'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1047.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1047.jpg
  title: Learning Word-Like Units from Joint Audio-Visual Analysis
  title_html: Learning Word-Like Units from Joint Audio-Visual Analysis
  url: https://www.aclweb.org/anthology/P17-1047
  year: '2017'
P17-1048:
  abstract: 'End-to-end automatic speech recognition (ASR) has become a popular alternative
    to conventional DNN/HMM systems because it avoids the need for linguistic resources
    such as pronunciation dictionary, tokenization, and context-dependency trees,
    leading to a greatly simplified model-building process. There are two major types
    of end-to-end architectures for ASR: attention-based methods use an attention
    mechanism to perform alignment between acoustic frames and recognized symbols,
    and connectionist temporal classification (CTC), uses Markov assumptions to efficiently
    solve sequential problems by dynamic programming. This paper proposes joint decoding
    algorithm for end-to-end ASR with a hybrid CTC/attention architecture, which effectively
    utilizes both advantages in decoding. We have applied the proposed method to two
    ASR benchmarks (spontaneous Japanese and Mandarin Chinese), and showing the comparable
    performance to conventional state-of-the-art DNN/HMM ASR systems without linguistic
    resources.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953996
    type: video
    url: https://vimeo.com/234953996
  author:
  - first: Takaaki
    full: Takaaki Hori
    id: takaaki-hori
    last: Hori
  - first: Shinji
    full: Shinji Watanabe
    id: shinji-watanabe
    last: Watanabe
  - first: John
    full: John Hershey
    id: john-r-hershey
    last: Hershey
  author_string: Takaaki Hori, Shinji Watanabe, John Hershey
  bibkey: hori-etal-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1048
  month: July
  page_first: '518'
  page_last: '529'
  pages: "518\u2013529"
  paper_id: '48'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1048.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1048.jpg
  title: Joint CTC/attention decoding for end-to-end speech recognition
  title_html: Joint <span class="acl-fixed-case">CTC</span>/attention decoding for
    end-to-end speech recognition
  url: https://www.aclweb.org/anthology/P17-1048
  year: '2017'
P17-1049:
  abstract: Translation has played an important role in trade, law, commerce, politics,
    and literature for thousands of years. Translators have always tried to be invisible;
    ideal translations should look as if they were written originally in the target
    language. We show that traces of the source language remain in the translation
    product to the extent that it is possible to uncover the history of the source
    language by looking only at the translation. Specifically, we automatically reconstruct
    phylogenetic language trees from monolingual texts (translated from several source
    languages). The signal of the source language is so powerful that it is retained
    even after two phases of translation. This strongly indicates that source language
    interference is the most dominant characteristic of translated texts, overshadowing
    the more subtle signals of universal properties of translation.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1049.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1049.Presentation.pdf
  author:
  - first: Ella
    full: Ella Rabinovich
    id: ella-rabinovich
    last: Rabinovich
  - first: Noam
    full: Noam Ordan
    id: noam-ordan
    last: Ordan
  - first: Shuly
    full: Shuly Wintner
    id: shuly-wintner
    last: Wintner
  author_string: Ella Rabinovich, Noam Ordan, Shuly Wintner
  bibkey: rabinovich-etal-2017-found
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1049
  month: July
  page_first: '530'
  page_last: '540'
  pages: "530\u2013540"
  paper_id: '49'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1049.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1049.jpg
  title: 'Found in Translation: Reconstructing Phylogenetic Language Trees from Translations'
  title_html: 'Found in Translation: Reconstructing Phylogenetic Language Trees from
    Translations'
  url: https://www.aclweb.org/anthology/P17-1049
  year: '2017'
P17-1050:
  abstract: "A fundamental question in language learning concerns the role of a speaker\u2019\
    s first language in second language acquisition. We present a novel methodology\
    \ for studying this question: analysis of eye-movement patterns in second language\
    \ reading of free-form text. Using this methodology, we demonstrate for the first\
    \ time that the native language of English learners can be predicted from their\
    \ gaze fixations when reading English. We provide analysis of classifier uncertainty\
    \ and learned features, which indicates that differences in English reading are\
    \ likely to be rooted in linguistic divergences across native languages. The presented\
    \ framework complements production studies and offers new ground for advancing\
    \ research on multilingualism."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951959
    type: video
    url: https://vimeo.com/234951959
  author:
  - first: Yevgeni
    full: Yevgeni Berzak
    id: yevgeni-berzak
    last: Berzak
  - first: Chie
    full: Chie Nakamura
    id: chie-nakamura
    last: Nakamura
  - first: Suzanne
    full: Suzanne Flynn
    id: suzanne-flynn
    last: Flynn
  - first: Boris
    full: Boris Katz
    id: boris-katz
    last: Katz
  author_string: Yevgeni Berzak, Chie Nakamura, Suzanne Flynn, Boris Katz
  bibkey: berzak-etal-2017-predicting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1050
  month: July
  page_first: '541'
  page_last: '551'
  pages: "541\u2013551"
  paper_id: '50'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1050.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1050.jpg
  title: Predicting Native Language from Gaze
  title_html: Predicting Native Language from Gaze
  url: https://www.aclweb.org/anthology/P17-1050
  year: '2017'
P17-1051:
  abstract: We present in this paper a novel framework for morpheme segmentation which
    uses the morpho-syntactic regularities preserved by word representations, in addition
    to orthographic features, to segment words into morphemes. This framework is the
    first to consider vocabulary-wide syntactico-semantic information for this task.
    We also analyze the deficiencies of available benchmarking datasets and introduce
    our own dataset that was created on the basis of compositionality. We validate
    our algorithm across datasets and present state-of-the-art results.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1051.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1051.Presentation.pdf
  - filename: P17-1051.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1051.Software.zip
  - filename: P17-1051.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1051.Datasets.zip
  - filename: https://vimeo.com/234952666
    type: video
    url: https://vimeo.com/234952666
  author:
  - first: Tarek
    full: Tarek Sakakini
    id: tarek-sakakini
    last: Sakakini
  - first: Suma
    full: Suma Bhat
    id: suma-bhat
    last: Bhat
  - first: Pramod
    full: Pramod Viswanath
    id: pramod-viswanath
    last: Viswanath
  author_string: Tarek Sakakini, Suma Bhat, Pramod Viswanath
  bibkey: sakakini-etal-2017-morse
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1051
  month: July
  page_first: '552'
  page_last: '561'
  pages: "552\u2013561"
  paper_id: '51'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1051.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1051.jpg
  title: 'MORSE: Semantic-ally Drive-n MORpheme SEgment-er'
  title_html: '<span class="acl-fixed-case">MORSE</span>: Semantic-ally Drive-n <span
    class="acl-fixed-case">MOR</span>pheme <span class="acl-fixed-case">SE</span>gment-er'
  url: https://www.aclweb.org/anthology/P17-1051
  year: '2017'
P17-1052:
  abstract: This paper proposes a low-complexity word-level deep convolutional neural
    network (CNN) architecture for text categorization that can efficiently represent
    long-range associations in text. In the literature, several deep and complex neural
    networks have been proposed for this task, assuming availability of relatively
    large amounts of training data. However, the associated computational complexity
    increases as the networks go deeper, which poses serious challenges in practical
    applications. Moreover, it was shown recently that shallow word-level CNNs are
    more accurate and much faster than the state-of-the-art very deep nets such as
    character-level CNNs even in the setting of large training data. Motivated by
    these findings, we carefully studied deepening of word-level CNNs to capture global
    representations of text, and found a simple network architecture with which the
    best accuracy can be obtained by increasing the network depth without increasing
    computational cost by much. We call it deep pyramid CNN. The proposed model with
    15 weight layers outperforms the previous best models on six benchmark datasets
    for sentiment classification and topic categorization.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956392
    type: video
    url: https://vimeo.com/234956392
  author:
  - first: Rie
    full: Rie Johnson
    id: rie-johnson
    last: Johnson
  - first: Tong
    full: Tong Zhang
    id: tong-zhang
    last: Zhang
  author_string: Rie Johnson, Tong Zhang
  bibkey: johnson-zhang-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1052
  month: July
  page_first: '562'
  page_last: '570'
  pages: "562\u2013570"
  paper_id: '52'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1052.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1052.jpg
  title: Deep Pyramid Convolutional Neural Networks for Text Categorization
  title_html: Deep Pyramid Convolutional Neural Networks for Text Categorization
  url: https://www.aclweb.org/anthology/P17-1052
  year: '2017'
P17-1053:
  abstract: Relation detection is a core component of many NLP applications including
    Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical
    recurrent neural network enhanced by residual learning which detects KB relations
    given an input question. Our method uses deep residual bidirectional LSTMs to
    compare questions and relation names via different levels of abstraction. Additionally,
    we propose a simple KBQA system that integrates entity linking and our proposed
    relation detector to make the two components enhance each other. Our experimental
    results show that our approach not only achieves outstanding relation detection
    performance, but more importantly, it helps our KBQA system achieve state-of-the-art
    accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP)
    QA benchmarks.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1053.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1053.Notes.pdf
  - filename: P17-1053.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1053.Datasets.zip
  - filename: https://vimeo.com/234956455
    type: video
    url: https://vimeo.com/234956455
  author:
  - first: Mo
    full: Mo Yu
    id: mo-yu
    last: Yu
  - first: Wenpeng
    full: Wenpeng Yin
    id: wenpeng-yin
    last: Yin
  - first: Kazi Saidul
    full: Kazi Saidul Hasan
    id: kazi-saidul-hasan
    last: Hasan
  - first: Cicero
    full: Cicero dos Santos
    id: cicero-dos-santos
    last: dos Santos
  - first: Bing
    full: Bing Xiang
    id: bing-xiang
    last: Xiang
  - first: Bowen
    full: Bowen Zhou
    id: bowen-zhou
    last: Zhou
  author_string: Mo Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang,
    Bowen Zhou
  bibkey: yu-etal-2017-improved
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1053
  month: July
  page_first: '571'
  page_last: '581'
  pages: "571\u2013581"
  paper_id: '53'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1053.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1053.jpg
  title: Improved Neural Relation Detection for Knowledge Base Question Answering
  title_html: Improved Neural Relation Detection for Knowledge Base Question Answering
  url: https://www.aclweb.org/anthology/P17-1053
  year: '2017'
P17-1054:
  abstract: Keyphrase provides highly-summative information that can be effectively
    used for understanding, organizing and retrieving text content. Though previous
    studies have provided many workable solutions for automated keyphrase extraction,
    they commonly divided the to-be-summarized content into multiple text chunks,
    then ranked and selected the most meaningful ones. These approaches could neither
    identify keyphrases that do not appear in the text, nor capture the real semantic
    meaning behind the text. We propose a generative model for keyphrase prediction
    with an encoder-decoder framework, which can effectively overcome the above drawbacks.
    We name it as deep keyphrase generation since it attempts to capture the deep
    semantic meaning of the content with a deep learning method. Empirical analysis
    on six datasets demonstrates that our proposed model not only achieves a significant
    performance boost on extracting keyphrases that appear in the source text, but
    also can generate absent keyphrases based on the semantic meaning of the text.
    Code and dataset are available at https://github.com/memray/seq2seq-keyphrase.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1054.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1054.Presentation.pdf
  - filename: https://vimeo.com/234956524
    type: video
    url: https://vimeo.com/234956524
  author:
  - first: Rui
    full: Rui Meng
    id: rui-meng
    last: Meng
  - first: Sanqiang
    full: Sanqiang Zhao
    id: sanqiang-zhao
    last: Zhao
  - first: Shuguang
    full: Shuguang Han
    id: shuguang-han
    last: Han
  - first: Daqing
    full: Daqing He
    id: daqing-he
    last: He
  - first: Peter
    full: Peter Brusilovsky
    id: peter-brusilovsky
    last: Brusilovsky
  - first: Yu
    full: Yu Chi
    id: yu-chi
    last: Chi
  author_string: Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky,
    Yu Chi
  bibkey: meng-etal-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1054
  month: July
  page_first: '582'
  page_last: '592'
  pages: "582\u2013592"
  paper_id: '54'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1054.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1054.jpg
  title: Deep Keyphrase Generation
  title_html: Deep Keyphrase Generation
  url: https://www.aclweb.org/anthology/P17-1054
  year: '2017'
P17-1055:
  abstract: "Cloze-style reading comprehension is a representative problem in mining\
    \ relationship between document and query. In this paper, we present a simple\
    \ but novel model called attention-over-attention reader for better solving cloze-style\
    \ reading comprehension task. The proposed model aims to place another attention\
    \ mechanism over the document-level attention and induces \u201Cattended attention\u201D\
    \ for final answer predictions. One advantage of our model is that it is simpler\
    \ than related works while giving excellent performance. In addition to the primary\
    \ model, we also propose an N-best re-ranking strategy to double check the validity\
    \ of the candidates and further improve the performance. Experimental results\
    \ show that the proposed methods significantly outperform various state-of-the-art\
    \ systems by a large margin in public datasets, such as CNN and Children\u2019\
    s Book Test."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956590
    type: video
    url: https://vimeo.com/234956590
  author:
  - first: Yiming
    full: Yiming Cui
    id: yiming-cui
    last: Cui
  - first: Zhipeng
    full: Zhipeng Chen
    id: zhipeng-chen
    last: Chen
  - first: Si
    full: Si Wei
    id: si-wei
    last: Wei
  - first: Shijin
    full: Shijin Wang
    id: shijin-wang
    last: Wang
  - first: Ting
    full: Ting Liu
    id: ting-liu
    last: Liu
  - first: Guoping
    full: Guoping Hu
    id: guoping-hu
    last: Hu
  author_string: Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu, Guoping
    Hu
  bibkey: cui-etal-2017-attention
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1055
  month: July
  page_first: '593'
  page_last: '602'
  pages: "593\u2013602"
  paper_id: '55'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1055.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1055.jpg
  title: Attention-over-Attention Neural Networks for Reading Comprehension
  title_html: Attention-over-Attention Neural Networks for Reading Comprehension
  url: https://www.aclweb.org/anthology/P17-1055
  year: '2017'
P17-1056:
  abstract: "Cultural fit is widely believed to affect the success of individuals\
    \ and the groups to which they belong. Yet it remains an elusive, poorly measured\
    \ construct. Recent research draws on computational linguistics to measure cultural\
    \ fit but overlooks asymmetries in cultural adaptation. By contrast, we develop\
    \ a directed, dynamic measure of cultural fit based on linguistic alignment, which\
    \ estimates the influence of one person\u2019s word use on another\u2019s and\
    \ distinguishes between two enculturation mechanisms: internalization and self-regulation.\
    \ We use this measure to trace employees\u2019 enculturation trajectories over\
    \ a large, multi-year corpus of corporate emails and find that patterns of alignment\
    \ in the first six months of employment are predictive of individuals\u2019 downstream\
    \ outcomes, especially involuntary exit. Further predictive analyses suggest referential\
    \ alignment plays an overlooked role in linguistic alignment."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957958
    type: video
    url: https://vimeo.com/234957958
  author:
  - first: Gabriel
    full: Gabriel Doyle
    id: gabriel-doyle
    last: Doyle
  - first: Amir
    full: Amir Goldberg
    id: amir-goldberg
    last: Goldberg
  - first: Sameer
    full: Sameer Srivastava
    id: sameer-srivastava
    last: Srivastava
  - first: Michael
    full: Michael Frank
    id: michael-c-frank
    last: Frank
  author_string: Gabriel Doyle, Amir Goldberg, Sameer Srivastava, Michael Frank
  bibkey: doyle-etal-2017-alignment
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1056
  month: July
  page_first: '603'
  page_last: '612'
  pages: "603\u2013612"
  paper_id: '56'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1056.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1056.jpg
  title: 'Alignment at Work: Using Language to Distinguish the Internalization and
    Self-Regulation Components of Cultural Fit in Organizations'
  title_html: 'Alignment at Work: Using Language to Distinguish the Internalization
    and Self-Regulation Components of Cultural Fit in Organizations'
  url: https://www.aclweb.org/anthology/P17-1056
  year: '2017'
P17-1057:
  abstract: We present a visually grounded model of speech perception which projects
    spoken utterances and images to a joint semantic space. We use a multi-layer recurrent
    highway network to model the temporal nature of spoken speech, and show that it
    learns to extract both form and meaning-based linguistic knowledge from the input
    signal. We carry out an in-depth analysis of the representations used by different
    components of the trained model and show that encoding of semantic aspects tends
    to become richer as we go up the hierarchy of layers, whereas encoding of form-related
    aspects of the language input tends to initially increase and then plateau or
    decrease.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1057.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1057.Presentation.pdf
  - filename: https://vimeo.com/234958014
    type: video
    url: https://vimeo.com/234958014
  author:
  - first: Grzegorz
    full: "Grzegorz Chrupa\u0142a"
    id: grzegorz-chrupala
    last: "Chrupa\u0142a"
  - first: Lieke
    full: Lieke Gelderloos
    id: lieke-gelderloos
    last: Gelderloos
  - first: Afra
    full: Afra Alishahi
    id: afra-alishahi
    last: Alishahi
  author_string: "Grzegorz Chrupa\u0142a, Lieke Gelderloos, Afra Alishahi"
  bibkey: chrupala-etal-2017-representations
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1057
  month: July
  page_first: '613'
  page_last: '622'
  pages: "613\u2013622"
  paper_id: '57'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1057.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1057.jpg
  title: Representations of language in a model of visually grounded speech signal
  title_html: Representations of language in a model of visually grounded speech signal
  url: https://www.aclweb.org/anthology/P17-1057
  year: '2017'
P17-1058:
  abstract: We propose a perspective on dialogue that focuses on relative information
    contributions of conversation partners as a key to successful communication. We
    predict the success of collaborative task in English and Danish corpora of task-oriented
    dialogue. Two features are extracted from the frequency domain representations
    of the lexical entropy series of each interlocutor, power spectrum overlap (PSO)
    and relative phase (RP). We find that PSO is a negative predictor of task success,
    while RP is a positive one. An SVM with these features significantly improved
    on previous task success prediction models. Our findings suggest that the strategic
    distribution of information density between interlocutors is relevant to task
    success.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958072
    type: video
    url: https://vimeo.com/234958072
  author:
  - first: Yang
    full: Yang Xu
    id: yang-xu
    last: Xu
  - first: David
    full: David Reitter
    id: david-reitter
    last: Reitter
  author_string: Yang Xu, David Reitter
  bibkey: xu-reitter-2017-spectral
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1058
  month: July
  page_first: '623'
  page_last: '633'
  pages: "623\u2013633"
  paper_id: '58'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1058.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1058.jpg
  title: Spectral Analysis of Information Density in Dialogue Predicts Collaborative
    Task Performance
  title_html: Spectral Analysis of Information Density in Dialogue Predicts Collaborative
    Task Performance
  url: https://www.aclweb.org/anthology/P17-1058
  year: '2017'
P17-1059:
  abstract: Human verbal communication includes affective messages which are conveyed
    through use of emotionally colored words. There has been a lot of research effort
    in this direction but the problem of integrating state-of-the-art neural language
    models with affective information remains an area ripe for exploration. In this
    paper, we propose an extension to an LSTM (Long Short-Term Memory) language model
    for generation of conversational text, conditioned on affect categories. Our proposed
    model, Affect-LM enables us to customize the degree of emotional content in generated
    sentences through an additional design parameter. Perception studies conducted
    using Amazon Mechanical Turk show that Affect-LM can generate naturally looking
    emotional sentences without sacrificing grammatical correctness. Affect-LM also
    learns affect-discriminative word representations, and perplexity experiments
    show that additional affective information in conversational text can improve
    language model prediction.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957188
    type: video
    url: https://vimeo.com/234957188
  author:
  - first: Sayan
    full: Sayan Ghosh
    id: sayan-ghosh
    last: Ghosh
  - first: Mathieu
    full: Mathieu Chollet
    id: mathieu-chollet
    last: Chollet
  - first: Eugene
    full: Eugene Laksana
    id: eugene-laksana
    last: Laksana
  - first: Louis-Philippe
    full: Louis-Philippe Morency
    id: louis-philippe-morency
    last: Morency
  - first: Stefan
    full: Stefan Scherer
    id: stefan-scherer
    last: Scherer
  author_string: Sayan Ghosh, Mathieu Chollet, Eugene Laksana, Louis-Philippe Morency,
    Stefan Scherer
  bibkey: ghosh-etal-2017-affect
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1059
  month: July
  page_first: '634'
  page_last: '642'
  pages: "634\u2013642"
  paper_id: '59'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1059.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1059.jpg
  title: 'Affect-LM: A Neural Language Model for Customizable Affective Text Generation'
  title_html: 'Affect-<span class="acl-fixed-case">LM</span>: A Neural Language Model
    for Customizable Affective Text Generation'
  url: https://www.aclweb.org/anthology/P17-1059
  year: '2017'
P17-1060:
  abstract: "An important problem in domain adaptation is to quickly generalize to\
    \ a new domain with limited supervision given K existing domains. One approach\
    \ is to retrain a global model across all K + 1 domains using standard techniques,\
    \ for instance Daum\xE9 III (2009). However, it is desirable to adapt without\
    \ having to re-estimate a global model from scratch each time a new domain with\
    \ potentially new intents and slots is added. We describe a solution based on\
    \ attending an ensemble of domain experts. We assume K domain specific intent\
    \ and slot models trained on respective domains. When given domain K + 1, our\
    \ model uses a weighted combination of the K domain experts\u2019 feedback along\
    \ with its own opinion to make predictions on the new domain. In experiments,\
    \ the model significantly outperforms baselines that do not use domain adaptation\
    \ and also performs better than the full retraining approach."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957265
    type: video
    url: https://vimeo.com/234957265
  author:
  - first: Young-Bum
    full: Young-Bum Kim
    id: young-bum-kim
    last: Kim
  - first: Karl
    full: Karl Stratos
    id: karl-stratos
    last: Stratos
  - first: Dongchan
    full: Dongchan Kim
    id: dongchan-kim
    last: Kim
  author_string: Young-Bum Kim, Karl Stratos, Dongchan Kim
  bibkey: kim-etal-2017-domain
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1060
  month: July
  page_first: '643'
  page_last: '653'
  pages: "643\u2013653"
  paper_id: '60'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1060.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1060.jpg
  title: Domain Attention with an Ensemble of Experts
  title_html: Domain Attention with an Ensemble of Experts
  url: https://www.aclweb.org/anthology/P17-1060
  year: '2017'
P17-1061:
  abstract: While recent neural encoder-decoder models have shown great promise in
    modeling open-domain conversations, they often generate dull and generic responses.
    Unlike past work that has focused on diversifying the output of the decoder from
    word-level to alleviate this problem, we present a novel framework based on conditional
    variational autoencoders that capture the discourse-level diversity in the encoder.
    Our model uses latent variables to learn a distribution over potential conversational
    intents and generates diverse responses using only greedy decoders. We have further
    developed a novel variant that is integrated with linguistic prior knowledge for
    better performance. Finally, the training procedure is improved through introducing
    a bag-of-word loss. Our proposed models have been validated to generate significantly
    more diverse responses than baseline approaches and exhibit competence of discourse-level
    decision-making.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1061.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1061.Presentation.pdf
  - filename: P17-1061.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1061.Datasets.zip
  - filename: https://vimeo.com/234957321
    type: video
    url: https://vimeo.com/234957321
  author:
  - first: Tiancheng
    full: Tiancheng Zhao
    id: tiancheng-zhao
    last: Zhao
  - first: Ran
    full: Ran Zhao
    id: ran-zhao
    last: Zhao
  - first: Maxine
    full: Maxine Eskenazi
    id: maxine-eskenazi
    last: Eskenazi
  author_string: Tiancheng Zhao, Ran Zhao, Maxine Eskenazi
  bibkey: zhao-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1061
  month: July
  page_first: '654'
  page_last: '664'
  pages: "654\u2013664"
  paper_id: '61'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1061.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1061.jpg
  title: Learning Discourse-level Diversity for Neural Dialog Models using Conditional
    Variational Autoencoders
  title_html: Learning Discourse-level Diversity for Neural Dialog Models using Conditional
    Variational Autoencoders
  url: https://www.aclweb.org/anthology/P17-1061
  year: '2017'
P17-1062:
  abstract: End-to-end learning of recurrent neural networks (RNNs) is an attractive
    solution for dialog systems; however, current techniques are data-intensive and
    require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code
    Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as
    software and system action templates. Compared to existing end-to-end approaches,
    HCNs considerably reduce the amount of training data required, while retaining
    the key benefit of inferring a latent representation of dialog state. In addition,
    HCNs can be optimized with supervised learning, reinforcement learning, or a mixture
    of both. HCNs attain state-of-the-art performance on the bAbI dialog dataset (Bordes
    and Weston, 2016), and outperform two commercially deployed customer-facing dialog
    systems at our company.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957373
    type: video
    url: https://vimeo.com/234957373
  author:
  - first: Jason D.
    full: Jason D. Williams
    id: jason-d-williams
    last: Williams
  - first: Kavosh
    full: Kavosh Asadi
    id: kavosh-asadi-atui
    last: Asadi
  - first: Geoffrey
    full: Geoffrey Zweig
    id: geoffrey-zweig
    last: Zweig
  author_string: Jason D. Williams, Kavosh Asadi, Geoffrey Zweig
  bibkey: williams-etal-2017-hybrid
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1062
  month: July
  page_first: '665'
  page_last: '677'
  pages: "665\u2013677"
  paper_id: '62'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1062.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1062.jpg
  title: 'Hybrid Code Networks: practical and efficient end-to-end dialog control
    with supervised and reinforcement learning'
  title_html: 'Hybrid Code Networks: practical and efficient end-to-end dialog control
    with supervised and reinforcement learning'
  url: https://www.aclweb.org/anthology/P17-1062
  year: '2017'
P17-1063:
  abstract: "The referring expressions (REs) produced by a natural language generation\
    \ (NLG) system can be misunderstood by the hearer, even when they are semantically\
    \ correct. In an interactive setting, the NLG system can try to recognize such\
    \ misunderstandings and correct them. We present an algorithm for generating corrective\
    \ REs that use contrastive focus (\u201Cno, the BLUE button\u201D) to emphasize\
    \ the information the hearer most likely misunderstood. We show empirically that\
    \ these contrastive REs are preferred over REs without contrast marking."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1063.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1063.Datasets.zip
  - filename: https://vimeo.com/234957432
    type: video
    url: https://vimeo.com/234957432
  author:
  - first: "Mart\xEDn"
    full: "Mart\xEDn Villalba"
    id: martin-villalba
    last: Villalba
  - first: Christoph
    full: Christoph Teichmann
    id: christoph-teichmann
    last: Teichmann
  - first: Alexander
    full: Alexander Koller
    id: alexander-koller
    last: Koller
  author_string: "Mart\xEDn Villalba, Christoph Teichmann, Alexander Koller"
  bibkey: villalba-etal-2017-generating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1063
  month: July
  page_first: '678'
  page_last: '687'
  pages: "678\u2013687"
  paper_id: '63'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1063.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1063.jpg
  title: Generating Contrastive Referring Expressions
  title_html: Generating Contrastive Referring Expressions
  url: https://www.aclweb.org/anthology/P17-1063
  year: '2017'
P17-1064:
  abstract: 'Even though a linguistics-free sequence to sequence model in neural machine
    translation (NMT) has certain capability of implicitly learning syntactic information
    of source sentences, this paper shows that source syntax can be explicitly incorporated
    into NMT effectively to provide further improvements. Specifically, we linearize
    parse trees of source sentences to obtain structural label sequences. On the basis,
    we propose three different sorts of encoders to incorporate source syntax into
    NMT: 1) Parallel RNN encoder that learns word and label annotation vectors parallelly;
    2) Hierarchical RNN encoder that learns word and label annotation vectors in a
    two-level hierarchy; and 3) Mixed RNN encoder that stitchingly learns word and
    label annotation vectors over sequences where words and labels are mixed. Experimentation
    on Chinese-to-English translation demonstrates that all the three proposed syntactic
    encoders are able to improve translation accuracy. It is interesting to note that
    the simplest RNN encoder, i.e., Mixed RNN encoder yields the best performance
    with an significant improvement of 1.4 BLEU points. Moreover, an in-depth analysis
    from several perspectives is provided to reveal how source syntax benefits NMT.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954880
    type: video
    url: https://vimeo.com/234954880
  author:
  - first: Junhui
    full: Junhui Li
    id: junhui-li
    last: Li
  - first: Deyi
    full: Deyi Xiong
    id: deyi-xiong
    last: Xiong
  - first: Zhaopeng
    full: Zhaopeng Tu
    id: zhaopeng-tu
    last: Tu
  - first: Muhua
    full: Muhua Zhu
    id: muhua-zhu
    last: Zhu
  - first: Min
    full: Min Zhang
    id: min-zhang
    last: Zhang
  - first: Guodong
    full: Guodong Zhou
    id: guodong-zhou
    last: Zhou
  author_string: Junhui Li, Deyi Xiong, Zhaopeng Tu, Muhua Zhu, Min Zhang, Guodong
    Zhou
  bibkey: li-etal-2017-modeling
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1064
  month: July
  page_first: '688'
  page_last: '697'
  pages: "688\u2013697"
  paper_id: '64'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1064.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1064.jpg
  title: Modeling Source Syntax for Neural Machine Translation
  title_html: Modeling Source Syntax for Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1064
  year: '2017'
P17-1065:
  abstract: Nowadays a typical Neural Machine Translation (NMT) model generates translations
    from left to right as a linear sequence, during which latent syntactic structures
    of the target sentences are not explicitly concerned. Inspired by the success
    of using syntactic knowledge of target language for improving statistical machine
    translation, in this paper we propose a novel Sequence-to-Dependency Neural Machine
    Translation (SD-NMT) method, in which the target word sequence and its corresponding
    dependency structure are jointly constructed and modeled, and this structure is
    used as context to facilitate word generations. Experimental results show that
    the proposed method significantly outperforms state-of-the-art baselines on Chinese-English
    and Japanese-English translation tasks.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954926
    type: video
    url: https://vimeo.com/234954926
  author:
  - first: Shuangzhi
    full: Shuangzhi Wu
    id: shuangzhi-wu
    last: Wu
  - first: Dongdong
    full: Dongdong Zhang
    id: dongdong-zhang
    last: Zhang
  - first: Nan
    full: Nan Yang
    id: nan-yang
    last: Yang
  - first: Mu
    full: Mu Li
    id: mu-li
    last: Li
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  author_string: Shuangzhi Wu, Dongdong Zhang, Nan Yang, Mu Li, Ming Zhou
  bibkey: wu-etal-2017-sequence
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1065
  month: July
  page_first: '698'
  page_last: '707'
  pages: "698\u2013707"
  paper_id: '65'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1065.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1065.jpg
  title: Sequence-to-Dependency Neural Machine Translation
  title_html: Sequence-to-Dependency Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1065
  year: '2017'
P17-1066:
  abstract: How fake news goes viral via social media? How does its propagation pattern
    differ from real stories? In this paper, we attempt to address the problem of
    identifying rumors, i.e., fake information, out of microblog posts based on their
    propagation structure. We firstly model microblog posts diffusion with propagation
    trees, which provide valuable clues on how an original message is transmitted
    and developed over time. We then propose a kernel-based method called Propagation
    Tree Kernel, which captures high-order patterns differentiating different types
    of rumors by evaluating the similarities between their propagation tree structures.
    Experimental results on two real-world datasets demonstrate that the proposed
    kernel-based approach can detect rumors more quickly and accurately than state-of-the-art
    rumor detection models.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1066.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1066.Presentation.pdf
  - filename: https://vimeo.com/234955713
    type: video
    url: https://vimeo.com/234955713
  author:
  - first: Jing
    full: Jing Ma
    id: jing-ma
    last: Ma
  - first: Wei
    full: Wei Gao
    id: wei-gao
    last: Gao
  - first: Kam-Fai
    full: Kam-Fai Wong
    id: kam-fai-wong
    last: Wong
  author_string: Jing Ma, Wei Gao, Kam-Fai Wong
  bibkey: ma-etal-2017-detect
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1066
  month: July
  page_first: '708'
  page_last: '717'
  pages: "708\u2013717"
  paper_id: '66'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1066.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1066.jpg
  title: Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning
  title_html: Detect Rumors in Microblog Posts Using Propagation Structure via Kernel
    Learning
  url: https://www.aclweb.org/anthology/P17-1066
  year: '2017'
P17-1067:
  abstract: "Accurate detection of emotion from natural language has applications\
    \ ranging from building emotional chatbots to better understanding individuals\
    \ and their lives. However, progress on emotion detection has been hampered by\
    \ the absence of large labeled datasets. In this work, we build a very large dataset\
    \ for fine-grained emotions and develop deep learning models on it. We achieve\
    \ a new state-of-the-art on 24 fine-grained types of emotions (with an average\
    \ accuracy of 87.58%). We also extend the task beyond emotion types to model Robert\
    \ Plutick\u2019s 8 primary emotion dimensions, acquiring a superior accuracy of\
    \ 95.68%."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955738
    type: video
    url: https://vimeo.com/234955738
  author:
  - first: Muhammad
    full: Muhammad Abdul-Mageed
    id: muhammad-abdul-mageed
    last: Abdul-Mageed
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  author_string: Muhammad Abdul-Mageed, Lyle Ungar
  bibkey: abdul-mageed-ungar-2017-emonet
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1067
  month: July
  page_first: '718'
  page_last: '728'
  pages: "718\u2013728"
  paper_id: '67'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1067.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1067.jpg
  title: 'EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks'
  title_html: '<span class="acl-fixed-case">E</span>mo<span class="acl-fixed-case">N</span>et:
    Fine-Grained Emotion Detection with Gated Recurrent Neural Networks'
  url: https://www.aclweb.org/anthology/P17-1067
  year: '2017'
P17-1068:
  abstract: "Automatic political orientation prediction from social media posts has\
    \ to date proven successful only in distinguishing between publicly declared liberals\
    \ and conservatives in the US. This study examines users\u2019 political ideology\
    \ using a seven-point scale which enables us to identify politically moderate\
    \ and neutral users \u2013 groups which are of particular interest to political\
    \ scientists and pollsters. Using a novel data set with political ideology labels\
    \ self-reported through surveys, our goal is two-fold: a) to characterize the\
    \ groups of politically engaged users through language use on Twitter; b) to build\
    \ a fine-grained model that predicts political ideology of unseen users. Our results\
    \ identify differences in both political leaning and engagement and the extent\
    \ to which each group tweets using political keywords. Finally, we demonstrate\
    \ how to improve ideology prediction accuracy by exploiting the relationships\
    \ between the user groups."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1068.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1068.Presentation.pdf
  - filename: https://vimeo.com/234955801
    type: video
    url: https://vimeo.com/234955801
  author:
  - first: Daniel
    full: "Daniel Preo\u0163iuc-Pietro"
    id: daniel-preotiuc-pietro
    last: "Preo\u0163iuc-Pietro"
  - first: Ye
    full: Ye Liu
    id: ye-liu
    last: Liu
  - first: Daniel
    full: Daniel Hopkins
    id: daniel-hopkins
    last: Hopkins
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  author_string: "Daniel Preo\u0163iuc-Pietro, Ye Liu, Daniel Hopkins, Lyle Ungar"
  bibkey: preotiuc-pietro-etal-2017-beyond
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1068
  month: July
  page_first: '729'
  page_last: '740'
  pages: "729\u2013740"
  paper_id: '68'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1068.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1068.jpg
  title: 'Beyond Binary Labels: Political Ideology Prediction of Twitter Users'
  title_html: 'Beyond Binary Labels: Political Ideology Prediction of Twitter Users'
  url: https://www.aclweb.org/anthology/P17-1068
  year: '2017'
P17-1069:
  abstract: Framing is a political strategy in which politicians carefully word their
    statements in order to control public perception of issues. Previous works exploring
    political framing typically analyze frame usage in longer texts, such as congressional
    speeches. We present a collection of weakly supervised models which harness collective
    classification to predict the frames used in political discourse on the microblogging
    platform, Twitter. Our global probabilistic models show that by combining both
    lexical features of tweets and network-based behavioral features of Twitter, we
    are able to increase the average, unsupervised F1 score by 21.52 points over a
    lexical baseline alone.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955861
    type: video
    url: https://vimeo.com/234955861
  author:
  - first: Kristen
    full: Kristen Johnson
    id: kristen-johnson
    last: Johnson
  - first: Di
    full: Di Jin
    id: di-jin
    last: Jin
  - first: Dan
    full: Dan Goldwasser
    id: dan-goldwasser
    last: Goldwasser
  author_string: Kristen Johnson, Di Jin, Dan Goldwasser
  bibkey: johnson-etal-2017-leveraging
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1069
  month: July
  page_first: '741'
  page_last: '752'
  pages: "741\u2013752"
  paper_id: '69'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1069.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1069.jpg
  title: Leveraging Behavioral and Social Information for Weakly Supervised Collective
    Classification of Political Discourse on Twitter
  title_html: Leveraging Behavioral and Social Information for Weakly Supervised Collective
    Classification of Political Discourse on Twitter
  url: https://www.aclweb.org/anthology/P17-1069
  year: '2017'
P17-1070:
  abstract: Grammatical error correction (GEC) systems strive to correct both global
    errors inword order and usage, and local errors inspelling and inflection. Further
    developing upon recent work on neural machine translation, we propose a new hybrid
    neural model with nested attention layers for GEC.Experiments show that the new
    model can effectively correct errors of both types by incorporating word and character-level
    information, and that the model significantly outperforms previous neural models
    for GEC as measured on the standard CoNLL-14 benchmark dataset.Further analysis
    also shows that the superiority of the proposed model can be largely attributed
    to the use of the nested attention mechanism, which has proven particularly effective
    incorrecting local errors that involve small edits in orthography.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956745
    type: video
    url: https://vimeo.com/234956745
  author:
  - first: Jianshu
    full: Jianshu Ji
    id: jianshu-ji
    last: Ji
  - first: Qinlong
    full: Qinlong Wang
    id: qinlong-wang
    last: Wang
  - first: Kristina
    full: Kristina Toutanova
    id: kristina-toutanova
    last: Toutanova
  - first: Yongen
    full: Yongen Gong
    id: yongen-gong
    last: Gong
  - first: Steven
    full: Steven Truong
    id: steven-truong
    last: Truong
  - first: Jianfeng
    full: Jianfeng Gao
    id: jianfeng-gao
    last: Gao
  author_string: Jianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen Gong, Steven
    Truong, Jianfeng Gao
  bibkey: ji-etal-2017-nested
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1070
  month: July
  page_first: '753'
  page_last: '762'
  pages: "753\u2013762"
  paper_id: '70'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1070.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1070.jpg
  title: A Nested Attention Neural Hybrid Model for Grammatical Error Correction
  title_html: A Nested Attention Neural Hybrid Model for Grammatical Error Correction
  url: https://www.aclweb.org/anthology/P17-1070
  year: '2017'
P17-1071:
  abstract: Text similarity measures are used in multiple tasks such as plagiarism
    detection, information ranking and recognition of paraphrases and textual entailment.
    While recent advances in deep learning highlighted the relevance of sequential
    models in natural language generation, existing similarity measures do not fully
    exploit the sequential nature of language. Examples of such similarity measures
    include n-grams and skip-grams overlap which rely on distinct slices of the input
    texts. In this paper we present a novel text similarity measure inspired from
    a common representation in DNA sequence alignment algorithms. The new measure,
    called TextFlow, represents input text pairs as continuous curves and uses both
    the actual position of the words and sequence matching to compute the similarity
    value. Our experiments on 8 different datasets show very encouraging results in
    paraphrase detection, textual entailment recognition and ranking relevance.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956802
    type: video
    url: https://vimeo.com/234956802
  author:
  - first: Yassine
    full: Yassine Mrabet
    id: yassine-mrabet
    last: Mrabet
  - first: Halil
    full: Halil Kilicoglu
    id: halil-kilicoglu
    last: Kilicoglu
  - first: Dina
    full: Dina Demner-Fushman
    id: dina-demner-fushman
    last: Demner-Fushman
  author_string: Yassine Mrabet, Halil Kilicoglu, Dina Demner-Fushman
  bibkey: mrabet-etal-2017-textflow
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1071
  month: July
  page_first: '763'
  page_last: '772'
  pages: "763\u2013772"
  paper_id: '71'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1071.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1071.jpg
  title: 'TextFlow: A Text Similarity Measure based on Continuous Sequences'
  title_html: '<span class="acl-fixed-case">T</span>ext<span class="acl-fixed-case">F</span>low:
    A Text Similarity Measure based on Continuous Sequences'
  url: https://www.aclweb.org/anthology/P17-1071
  year: '2017'
P17-1072:
  abstract: "Understanding how ideas relate to each other is a fundamental question\
    \ in many domains, ranging from intellectual history to public communication.\
    \ Because ideas are naturally embedded in texts, we propose the first framework\
    \ to systematically characterize the relations between ideas based on their occurrence\
    \ in a corpus of documents, independent of how these ideas are represented. Combining\
    \ two statistics\u2014cooccurrence within documents and prevalence correlation\
    \ over time\u2014our approach reveals a number of different ways in which ideas\
    \ can cooperate and compete. For instance, two ideas can closely track each other\u2019\
    s prevalence over time, and yet rarely cooccur, almost like a \u201Ccold war\u201D\
    \ scenario. We observe that pairwise cooccurrence and prevalence correlation exhibit\
    \ different distributions. We further demonstrate that our approach is able to\
    \ uncover intriguing relations between ideas through in-depth case studies on\
    \ news articles and research papers."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1072.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1072.Presentation.pdf
  - filename: P17-1072.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1072.Notes.pdf
  - filename: https://vimeo.com/234956834
    type: video
    url: https://vimeo.com/234956834
  author:
  - first: Chenhao
    full: Chenhao Tan
    id: chenhao-tan
    last: Tan
  - first: Dallas
    full: Dallas Card
    id: dallas-card
    last: Card
  - first: Noah A.
    full: Noah A. Smith
    id: noah-a-smith
    last: Smith
  author_string: Chenhao Tan, Dallas Card, Noah A. Smith
  bibkey: tan-etal-2017-friendships
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1072
  month: July
  page_first: '773'
  page_last: '783'
  pages: "773\u2013783"
  paper_id: '72'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1072.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1072.jpg
  title: 'Friendships, Rivalries, and Trysts: Characterizing Relations between Ideas
    in Texts'
  title_html: 'Friendships, Rivalries, and Trysts: Characterizing Relations between
    Ideas in Texts'
  url: https://www.aclweb.org/anthology/P17-1072
  year: '2017'
P17-1073:
  abstract: The paper presents a procedure of building an evaluation dataset. for
    the validation of compositional distributional semantics models estimated for
    languages other than English. The procedure generally builds on steps designed
    to assemble the SICK corpus, which contains pairs of English sentences annotated
    for semantic relatedness and entailment, because we aim at building a comparable
    dataset. However, the implementation of particular building steps significantly
    differs from the original SICK design assumptions, which is caused by both lack
    of necessary extraneous resources for an investigated language and the need for
    language-specific transformation rules. The designed procedure is verified on
    Polish, a fusional language with a relatively free word order, and contributes
    to building a Polish evaluation dataset. The resource consists of 10K sentence
    pairs which are human-annotated for semantic relatedness and entailment. The dataset
    may be used for the evaluation of compositional distributional semantics models
    of Polish.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958212
    type: video
    url: https://vimeo.com/234958212
  author:
  - first: Alina
    full: "Alina Wr\xF3blewska"
    id: alina-wroblewska
    last: "Wr\xF3blewska"
  - first: Katarzyna
    full: "Katarzyna Krasnowska-Kiera\u015B"
    id: katarzyna-krasnowska-kieras
    last: "Krasnowska-Kiera\u015B"
  author_string: "Alina Wr\xF3blewska, Katarzyna Krasnowska-Kiera\u015B"
  bibkey: wroblewska-krasnowska-kieras-2017-polish
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1073
  month: July
  page_first: '784'
  page_last: '792'
  pages: "784\u2013792"
  paper_id: '73'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1073.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1073.jpg
  title: Polish evaluation dataset for compositional distributional semantics models
  title_html: Polish evaluation dataset for compositional distributional semantics
    models
  url: https://www.aclweb.org/anthology/P17-1073
  year: '2017'
P17-1074:
  abstract: "Until now, error type performance for Grammatical Error Correction (GEC)\
    \ systems could only be measured in terms of recall because system output is not\
    \ annotated. To overcome this problem, we introduce ERRANT, a grammatical ERRor\
    \ ANnotation Toolkit designed to automatically extract edits from parallel original\
    \ and corrected sentences and classify them according to a new, dataset-agnostic,\
    \ rule-based framework. This not only facilitates error type evaluation at different\
    \ levels of granularity, but can also be used to reduce annotator workload and\
    \ standardise existing GEC datasets. Human experts rated the automatic edits as\
    \ \u201CGood\u201D or \u201CAcceptable\u201D in at least 95% of cases, so we applied\
    \ ERRANT to the system output of the CoNLL-2014 shared task to carry out a detailed\
    \ error type analysis for the first time."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958258
    type: video
    url: https://vimeo.com/234958258
  author:
  - first: Christopher
    full: Christopher Bryant
    id: christopher-bryant
    last: Bryant
  - first: Mariano
    full: Mariano Felice
    id: mariano-felice
    last: Felice
  - first: Ted
    full: Ted Briscoe
    id: ted-briscoe
    last: Briscoe
  author_string: Christopher Bryant, Mariano Felice, Ted Briscoe
  bibkey: bryant-etal-2017-automatic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1074
  month: July
  page_first: '793'
  page_last: '805'
  pages: "793\u2013805"
  paper_id: '74'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1074.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1074.jpg
  title: Automatic Annotation and Evaluation of Error Types for Grammatical Error
    Correction
  title_html: Automatic Annotation and Evaluation of Error Types for Grammatical Error
    Correction
  url: https://www.aclweb.org/anthology/P17-1074
  year: '2017'
P17-1075:
  abstract: 'Knowing the quality of reading comprehension (RC) datasets is important
    for the development of natural-language understanding systems. In this study,
    two classes of metrics were adopted for evaluating RC datasets: prerequisite skills
    and readability. We applied these classes to six existing datasets, including
    MCTest and SQuAD, and highlighted the characteristics of the datasets according
    to each metric and the correlation between the two classes. Our dataset analysis
    suggests that the readability of RC datasets does not directly affect the question
    difficulty and that it is possible to create an RC dataset that is easy to read
    but difficult to answer.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958313
    type: video
    url: https://vimeo.com/234958313
  author:
  - first: Saku
    full: Saku Sugawara
    id: saku-sugawara
    last: Sugawara
  - first: Yusuke
    full: Yusuke Kido
    id: yusuke-kido
    last: Kido
  - first: Hikaru
    full: Hikaru Yokono
    id: hikaru-yokono
    last: Yokono
  - first: Akiko
    full: Akiko Aizawa
    id: akiko-aizawa
    last: Aizawa
  author_string: Saku Sugawara, Yusuke Kido, Hikaru Yokono, Akiko Aizawa
  bibkey: sugawara-etal-2017-evaluation
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1075
  month: July
  page_first: '806'
  page_last: '817'
  pages: "806\u2013817"
  paper_id: '75'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1075.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1075.jpg
  title: 'Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills
    and Readability'
  title_html: 'Evaluation Metrics for Machine Reading Comprehension: Prerequisite
    Skills and Readability'
  url: https://www.aclweb.org/anthology/P17-1075
  year: '2017'
P17-1076:
  abstract: In this work, we present a minimal neural model for constituency parsing
    based on independent scoring of labels and spans. We show that this model is not
    only compatible with classical dynamic programming techniques, but also admits
    a novel greedy top-down inference algorithm based on recursive partitioning of
    the input. We demonstrate empirically that both prediction schemes are competitive
    with recent work, and when combined with basic extensions to the scoring model
    are capable of achieving state-of-the-art single-model performance on the Penn
    Treebank (91.79 F1) and strong performance on the French Treebank (82.23 F1).
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957467
    type: video
    url: https://vimeo.com/234957467
  author:
  - first: Mitchell
    full: Mitchell Stern
    id: mitchell-stern
    last: Stern
  - first: Jacob
    full: Jacob Andreas
    id: jacob-andreas
    last: Andreas
  - first: Dan
    full: Dan Klein
    id: dan-klein
    last: Klein
  author_string: Mitchell Stern, Jacob Andreas, Dan Klein
  bibkey: stern-etal-2017-minimal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1076
  month: July
  page_first: '818'
  page_last: '827'
  pages: "818\u2013827"
  paper_id: '76'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1076.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1076.jpg
  title: A Minimal Span-Based Neural Constituency Parser
  title_html: A Minimal Span-Based Neural Constituency Parser
  url: https://www.aclweb.org/anthology/P17-1076
  year: '2017'
P17-1077:
  abstract: We model a dependency graph as a book, a particular kind of topological
    space, for semantic dependency parsing. The spine of the book is made up of a
    sequence of words, and each page contains a subset of noncrossing arcs. To build
    a semantic graph for a given sentence, we design new Maximum Subgraph algorithms
    to generate noncrossing graphs on each page, and a Lagrangian Relaxation-based
    algorithm tocombine pages into a book. Experiments demonstrate the effectiveness
    of the bookembedding framework across a wide range of conditions. Our parser obtains
    comparable results with a state-of-the-art transition-based parser.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1077.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1077.Notes.pdf
  - filename: P17-1077.Software.tgz
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1077.Software.tgz
  - filename: https://vimeo.com/234957523
    type: video
    url: https://vimeo.com/234957523
  author:
  - first: Weiwei
    full: Weiwei Sun
    id: weiwei-sun
    last: Sun
  - first: Junjie
    full: Junjie Cao
    id: junjie-cao
    last: Cao
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  author_string: Weiwei Sun, Junjie Cao, Xiaojun Wan
  bibkey: sun-etal-2017-semantic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1077
  month: July
  page_first: '828'
  page_last: '838'
  pages: "828\u2013838"
  paper_id: '77'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1077.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1077.jpg
  title: Semantic Dependency Parsing via Book Embedding
  title_html: Semantic Dependency Parsing via Book Embedding
  url: https://www.aclweb.org/anthology/P17-1077
  year: '2017'
P17-1078:
  abstract: Neural word segmentation research has benefited from large-scale raw texts
    by leveraging them for pretraining character and word embeddings. On the other
    hand, statistical segmentation research has exploited richer sources of external
    information, such as punctuation, automatic segmentation and POS. We investigate
    the effectiveness of a range of external training sources for neural word segmentation
    by building a modular segmentation model, pretraining the most important submodule
    using rich external sources. Results show that such pretraining significantly
    improves the model, leading to accuracies competitive to the best methods on six
    benchmarks.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957587
    type: video
    url: https://vimeo.com/234957587
  author:
  - first: Jie
    full: Jie Yang
    id: jie-yang
    last: Yang
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Fei
    full: Fei Dong
    id: fei-dong
    last: Dong
  author_string: Jie Yang, Yue Zhang, Fei Dong
  bibkey: yang-etal-2017-neural-word
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1078
  month: July
  page_first: '839'
  page_last: '849'
  pages: "839\u2013849"
  paper_id: '78'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1078.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1078.jpg
  title: Neural Word Segmentation with Rich Pretraining
  title_html: Neural Word Segmentation with Rich Pretraining
  url: https://www.aclweb.org/anthology/P17-1078
  year: '2017'
P17-1079:
  abstract: 'In this paper, we propose a new method for calculating the output layer
    in neural machine translation systems. The method is based on predicting a binary
    code for each word and can reduce computation time/memory requirements of the
    output layer to be logarithmic in vocabulary size in the best case. In addition,
    we also introduce two advanced approaches to improve the robustness of the proposed
    model: using error-correcting codes and combining softmax and binary codes. Experiments
    on two English-Japanese bidirectional translation tasks show proposed models achieve
    BLEU scores that approach the softmax, while reducing memory usage to the order
    of less than 1/10 and improving decoding speed on CPUs by x5 to x10.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955136
    type: video
    url: https://vimeo.com/234955136
  author:
  - first: Yusuke
    full: Yusuke Oda
    id: yusuke-oda
    last: Oda
  - first: Philip
    full: Philip Arthur
    id: philip-arthur
    last: Arthur
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  - first: Koichiro
    full: Koichiro Yoshino
    id: koichiro-yoshino
    last: Yoshino
  - first: Satoshi
    full: Satoshi Nakamura
    id: satoshi-nakamura
    last: Nakamura
  author_string: Yusuke Oda, Philip Arthur, Graham Neubig, Koichiro Yoshino, Satoshi
    Nakamura
  bibkey: oda-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1079
  month: July
  page_first: '850'
  page_last: '860'
  pages: "850\u2013860"
  paper_id: '79'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1079.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1079.jpg
  title: Neural Machine Translation via Binary Code Prediction
  title_html: Neural Machine Translation via Binary Code Prediction
  url: https://www.aclweb.org/anthology/P17-1079
  year: '2017'
P17-1080:
  abstract: 'Neural machine translation (MT) models obtain state-of-the-art performance
    while maintaining a simple, end-to-end architecture. However, little is known
    about what these models learn about source and target languages during the training
    process. In this work, we analyze the representations learned by neural MT models
    at various levels of granularity and empirically evaluate the quality of the representations
    for learning morphology through extrinsic part-of-speech and morphological tagging
    tasks. We conduct a thorough investigation along several parameters: word-based
    vs. character-based representations, depth of the encoding layer, the identity
    of the target language, and encoder vs. decoder representations. Our data-driven,
    quantitative evaluation sheds light on important aspects in the neural MT system
    and its ability to capture word structure.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955191
    type: video
    url: https://vimeo.com/234955191
  author:
  - first: Yonatan
    full: Yonatan Belinkov
    id: yonatan-belinkov
    last: Belinkov
  - first: Nadir
    full: Nadir Durrani
    id: nadir-durrani
    last: Durrani
  - first: Fahim
    full: Fahim Dalvi
    id: fahim-dalvi
    last: Dalvi
  - first: Hassan
    full: Hassan Sajjad
    id: hassan-sajjad
    last: Sajjad
  - first: James
    full: James Glass
    id: james-glass
    last: Glass
  author_string: Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James
    Glass
  bibkey: belinkov-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1080
  month: July
  page_first: '861'
  page_last: '872'
  pages: "861\u2013872"
  paper_id: '80'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1080.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1080.jpg
  title: What do Neural Machine Translation Models Learn about Morphology?
  title_html: What do Neural Machine Translation Models Learn about Morphology?
  url: https://www.aclweb.org/anthology/P17-1080
  year: '2017'
P17-1081:
  abstract: Multimodal sentiment analysis is a developing area of research, which
    involves the identification of sentiments in videos. Current research considers
    utterances as independent entities, i.e., ignores the interdependencies and relations
    among the utterances of a video. In this paper, we propose a LSTM-based model
    that enables utterances to capture contextual information from their surroundings
    in the same video, thus aiding the classification process. Our method shows 5-10%
    performance improvement over the state of the art and high robustness to generalizability.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955981
    type: video
    url: https://vimeo.com/234955981
  author:
  - first: Soujanya
    full: Soujanya Poria
    id: soujanya-poria
    last: Poria
  - first: Erik
    full: Erik Cambria
    id: erik-cambria
    last: Cambria
  - first: Devamanyu
    full: Devamanyu Hazarika
    id: devamanyu-hazarika
    last: Hazarika
  - first: Navonil
    full: Navonil Majumder
    id: navonil-majumder
    last: Majumder
  - first: Amir
    full: Amir Zadeh
    id: amir-zadeh
    last: Zadeh
  - first: Louis-Philippe
    full: Louis-Philippe Morency
    id: louis-philippe-morency
    last: Morency
  author_string: Soujanya Poria, Erik Cambria, Devamanyu Hazarika, Navonil Majumder,
    Amir Zadeh, Louis-Philippe Morency
  bibkey: poria-etal-2017-context
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1081
  month: July
  page_first: '873'
  page_last: '883'
  pages: "873\u2013883"
  paper_id: '81'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1081.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1081.jpg
  title: Context-Dependent Sentiment Analysis in User-Generated Videos
  title_html: Context-Dependent Sentiment Analysis in User-Generated Videos
  url: https://www.aclweb.org/anthology/P17-1081
  year: '2017'
P17-1082:
  abstract: The sociolinguistic construct of stancetaking describes the activities
    through which discourse participants create and signal relationships to their
    interlocutors, to the topic of discussion, and to the talk itself. Stancetaking
    underlies a wide range of interactional phenomena, relating to formality, politeness,
    affect, and subjectivity. We present a computational approach to stancetaking,
    in which we build a theoretically-motivated lexicon of stance markers, and then
    use multidimensional analysis to identify a set of underlying stance dimensions.
    We validate these dimensions intrinscially and extrinsically, showing that they
    are internally coherent, match pre-registered hypotheses, and correlate with social
    phenomena.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956035
    type: video
    url: https://vimeo.com/234956035
  author:
  - first: Umashanthi
    full: Umashanthi Pavalanathan
    id: umashanthi-pavalanathan
    last: Pavalanathan
  - first: Jim
    full: Jim Fitzpatrick
    id: jim-fitzpatrick
    last: Fitzpatrick
  - first: Scott
    full: Scott Kiesling
    id: scott-f-kiesling
    last: Kiesling
  - first: Jacob
    full: Jacob Eisenstein
    id: jacob-eisenstein
    last: Eisenstein
  author_string: Umashanthi Pavalanathan, Jim Fitzpatrick, Scott Kiesling, Jacob Eisenstein
  bibkey: pavalanathan-etal-2017-multidimensional
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1082
  month: July
  page_first: '884'
  page_last: '895'
  pages: "884\u2013895"
  paper_id: '82'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1082.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1082.jpg
  title: A Multidimensional Lexicon for Interpersonal Stancetaking
  title_html: A Multidimensional Lexicon for Interpersonal Stancetaking
  url: https://www.aclweb.org/anthology/P17-1082
  year: '2017'
P17-1083:
  abstract: "Interactive topic models are powerful tools for those seeking to understand\
    \ large collections of text. However, existing sampling-based interactive topic\
    \ modeling approaches scale poorly to large data sets. Anchor methods, which use\
    \ a single word to uniquely identify a topic, offer the speed needed for interactive\
    \ work but lack both a mechanism to inject prior knowledge and lack the intuitive\
    \ semantics needed for user-facing applications. We propose combinations of words\
    \ as anchors, going beyond existing single word anchor algorithms\u2014an approach\
    \ we call \u201CTandem Anchors\u201D. We begin with a synthetic investigation\
    \ of this approach then apply the approach to interactive topic modeling in a\
    \ user study and compare it to interactive and non-interactive approaches. Tandem\
    \ anchors are faster and more intuitive than existing interactive approaches."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956951
    type: video
    url: https://vimeo.com/234956951
  author:
  - first: Jeffrey
    full: Jeffrey Lund
    id: jeffrey-lund
    last: Lund
  - first: Connor
    full: Connor Cook
    id: connor-cook
    last: Cook
  - first: Kevin
    full: Kevin Seppi
    id: kevin-seppi
    last: Seppi
  - first: Jordan
    full: Jordan Boyd-Graber
    id: jordan-boyd-graber
    last: Boyd-Graber
  author_string: Jeffrey Lund, Connor Cook, Kevin Seppi, Jordan Boyd-Graber
  bibkey: lund-etal-2017-tandem
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1083
  month: July
  page_first: '896'
  page_last: '905'
  pages: "896\u2013905"
  paper_id: '83'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1083.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1083.jpg
  title: 'Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling'
  title_html: 'Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic
    Modeling'
  url: https://www.aclweb.org/anthology/P17-1083
  year: '2017'
P17-1084:
  abstract: 'Understanding common entities and their attributes is a primary requirement
    for any system that comprehends natural language. In order to enable learning
    about common entities, we introduce a novel machine comprehension task, GuessTwo:
    given a short paragraph comparing different aspects of two real-world semantically-similar
    entities, a system should guess what those entities are. Accomplishing this task
    requires deep language understanding which enables inference, connecting each
    comparison paragraph to different levels of knowledge about world entities and
    their attributes. So far we have crowdsourced a dataset of more than 14K comparison
    paragraphs comparing entities from a variety of categories such as fruits and
    animals. We have designed two schemes for evaluation: open-ended, and binary-choice
    prediction. For benchmarking further progress in the task, we have collected a
    set of paragraphs as the test set on which human can accomplish the task with
    an accuracy of 94.2% on open-ended prediction. We have implemented various models
    for tackling the task, ranging from semantic-driven to neural models. The semantic-driven
    approach outperforms the neural models, however, the results indicate that the
    task is very challenging across the models.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956988
    type: video
    url: https://vimeo.com/234956988
  author:
  - first: Omid
    full: Omid Bakhshandeh
    id: omid-bakhshandeh
    last: Bakhshandeh
  - first: James
    full: James Allen
    id: james-allen
    last: Allen
  author_string: Omid Bakhshandeh, James Allen
  bibkey: bakhshandeh-allen-2017-apples
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1084
  month: July
  page_first: '906'
  page_last: '916'
  pages: "906\u2013916"
  paper_id: '84'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1084.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1084.jpg
  title: 'Apples to Apples: Learning Semantics of Common Entities Through a Novel
    Comprehension Task'
  title_html: 'Apples to Apples: Learning Semantics of Common Entities Through a Novel
    Comprehension Task'
  url: https://www.aclweb.org/anthology/P17-1084
  year: '2017'
P17-1085:
  abstract: We present a novel attention-based recurrent neural network for joint
    extraction of entity mentions and relations. We show that attention along with
    long short term memory (LSTM) network can extract semantic relations between entity
    mentions without having access to dependency trees. Experiments on Automatic Content
    Extraction (ACE) corpora show that our model significantly outperforms feature-based
    joint model by Li and Ji (2014). We also compare our model with an end-to-end
    tree-based LSTM model (SPTree) by Miwa and Bansal (2016) and show that our model
    performs within 1% on entity mentions and 2% on relations. Our fine-grained analysis
    also shows that our model performs significantly better on Agent-Artifact relations,
    while SPTree performs better on Physical and Part-Whole relations.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957033
    type: video
    url: https://vimeo.com/234957033
  author:
  - first: Arzoo
    full: Arzoo Katiyar
    id: arzoo-katiyar
    last: Katiyar
  - first: Claire
    full: Claire Cardie
    id: claire-cardie
    last: Cardie
  author_string: Arzoo Katiyar, Claire Cardie
  bibkey: katiyar-cardie-2017-going
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1085
  month: July
  page_first: '917'
  page_last: '928'
  pages: "917\u2013928"
  paper_id: '85'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1085.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1085.jpg
  title: 'Going out on a limb: Joint Extraction of Entity Mentions and Relations without
    Dependency Trees'
  title_html: 'Going out on a limb: Joint Extraction of Entity Mentions and Relations
    without Dependency Trees'
  url: https://www.aclweb.org/anthology/P17-1085
  year: '2017'
P17-1086:
  abstract: "Our goal is to create a convenient natural language interface for performing\
    \ well-specified but complex actions such as analyzing data, manipulating text,\
    \ and querying databases. However, existing natural language interfaces for such\
    \ tasks are quite primitive compared to the power one wields with a programming\
    \ language. To bridge this gap, we start with a core programming language and\
    \ allow users to \u201Cnaturalize\u201D the core language incrementally by defining\
    \ alternative, more natural syntax and increasingly complex concepts in terms\
    \ of compositions of simpler ones. In a voxel world, we show that a community\
    \ of users can simultaneously teach a common system a diverse language and use\
    \ it to build hundreds of complex voxel structures. Over the course of three days,\
    \ these users went from using only the core language to using the naturalized\
    \ language in 85.9% of the last 10K utterances."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958455
    type: video
    url: https://vimeo.com/234958455
  author:
  - first: Sida I.
    full: Sida I. Wang
    id: sida-i-wang
    last: Wang
  - first: Samuel
    full: Samuel Ginn
    id: samuel-ginn
    last: Ginn
  - first: Percy
    full: Percy Liang
    id: percy-liang
    last: Liang
  - first: Christopher D.
    full: Christopher D. Manning
    id: christopher-d-manning
    last: Manning
  author_string: Sida I. Wang, Samuel Ginn, Percy Liang, Christopher D. Manning
  bibkey: wang-etal-2017-naturalizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1086
  month: July
  page_first: '929'
  page_last: '938'
  pages: "929\u2013938"
  paper_id: '86'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1086.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1086.jpg
  title: Naturalizing a Programming Language via Interactive Learning
  title_html: Naturalizing a Programming Language via Interactive Learning
  url: https://www.aclweb.org/anthology/P17-1086
  year: '2017'
P17-1087:
  abstract: Vector space representations of words capture many aspects of word similarity,
    but such methods tend to produce vector spaces in which antonyms (as well as synonyms)
    are close to each other. For spectral clustering using such word embeddings, words
    are points in a vector space where synonyms are linked with positive weights,
    while antonyms are linked with negative weights. We present a new signed spectral
    normalized graph cut algorithm, signed clustering, that overlays existing thesauri
    upon distributionally derived vector representations of words, so that antonym
    relationships between word pairs are represented by negative weights. Our signed
    clustering algorithm produces clusters of words that simultaneously capture distributional
    and synonym relations. By using randomized spectral decomposition (Halko et al.,
    2011) and sparse matrices, our method is both fast and scalable. We validate our
    clusters using datasets containing human judgments of word pair similarities and
    show the benefit of using our word clusters for sentiment prediction.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1087.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1087.Notes.pdf
  - filename: https://vimeo.com/234958514
    type: video
    url: https://vimeo.com/234958514
  author:
  - first: "Jo\xE3o"
    full: "Jo\xE3o Sedoc"
    id: joao-sedoc
    last: Sedoc
  - first: Jean
    full: Jean Gallier
    id: jean-gallier
    last: Gallier
  - first: Dean
    full: Dean Foster
    id: dean-foster
    last: Foster
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  author_string: "Jo\xE3o Sedoc, Jean Gallier, Dean Foster, Lyle Ungar"
  bibkey: sedoc-etal-2017-semantic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1087
  month: July
  page_first: '939'
  page_last: '949'
  pages: "939\u2013949"
  paper_id: '87'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1087.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1087.jpg
  title: Semantic Word Clusters Using Signed Spectral Clustering
  title_html: Semantic Word Clusters Using Signed Spectral Clustering
  url: https://www.aclweb.org/anthology/P17-1087
  year: '2017'
P17-1088:
  abstract: "Knowledge bases are important resources for a variety of natural language\
    \ processing tasks but suffer from incompleteness. We propose a novel embedding\
    \ model, ITransF, to perform knowledge base completion. Equipped with a sparse\
    \ attention mechanism, ITransF discovers hidden concepts of relations and transfer\
    \ statistical strength through the sharing of concepts. Moreover, the learned\
    \ associations between relations and concepts, which are represented by sparse\
    \ attention vectors, can be interpreted easily. We evaluate ITransF on two benchmark\
    \ datasets\u2014WN18 and FB15k for knowledge base completion and obtains improvements\
    \ on both the mean rank and Hits@10 metrics, over all baselines that do not use\
    \ additional information."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958563
    type: video
    url: https://vimeo.com/234958563
  author:
  - first: Qizhe
    full: Qizhe Xie
    id: qizhe-xie
    last: Xie
  - first: Xuezhe
    full: Xuezhe Ma
    id: xuezhe-ma
    last: Ma
  - first: Zihang
    full: Zihang Dai
    id: zihang-dai
    last: Dai
  - first: Eduard
    full: Eduard Hovy
    id: eduard-hovy
    last: Hovy
  author_string: Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard Hovy
  bibkey: xie-etal-2017-interpretable
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1088
  month: July
  page_first: '950'
  page_last: '962'
  pages: "950\u2013962"
  paper_id: '88'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1088.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1088.jpg
  title: An Interpretable Knowledge Transfer Model for Knowledge Base Completion
  title_html: An Interpretable Knowledge Transfer Model for Knowledge Base Completion
  url: https://www.aclweb.org/anthology/P17-1088
  year: '2017'
P17-1089:
  abstract: We present an approach to rapidly and easily build natural language interfaces
    to databases for new domains, whose performance improves over time based on user
    feedback, and requires minimal intervention. To achieve this, we adapt neural
    sequence models to map utterances directly to SQL with its full expressivity,
    bypassing any intermediate meaning representations. These models are immediately
    deployed online to solicit feedback from real users to flag incorrect queries.
    Finally, the popularity of SQL facilitates gathering annotations for incorrect
    predictions using the crowd, which is directly used to improve our models. This
    complete feedback loop, without intermediate representations or database specific
    engineering, opens up new ways of building high quality semantic parsers. Experiments
    suggest that this approach can be deployed quickly for any new target domain,
    as we show by learning a semantic parser for an online academic database from
    scratch.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1089.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1089.Notes.pdf
  - filename: https://vimeo.com/234958614
    type: video
    url: https://vimeo.com/234958614
  author:
  - first: Srinivasan
    full: Srinivasan Iyer
    id: srinivasan-iyer
    last: Iyer
  - first: Ioannis
    full: Ioannis Konstas
    id: ioannis-konstas
    last: Konstas
  - first: Alvin
    full: Alvin Cheung
    id: alvin-cheung
    last: Cheung
  - first: Jayant
    full: Jayant Krishnamurthy
    id: jayant-krishnamurthy
    last: Krishnamurthy
  - first: Luke
    full: Luke Zettlemoyer
    id: luke-zettlemoyer
    last: Zettlemoyer
  author_string: Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy,
    Luke Zettlemoyer
  bibkey: iyer-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1089
  month: July
  page_first: '963'
  page_last: '973'
  pages: "963\u2013973"
  paper_id: '89'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1089.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1089.jpg
  title: Learning a Neural Semantic Parser from User Feedback
  title_html: Learning a Neural Semantic Parser from User Feedback
  url: https://www.aclweb.org/anthology/P17-1089
  year: '2017'
P17-1090:
  abstract: "We present a joint modeling approach to identify salient discussion points\
    \ in spoken meetings as well as to label the discourse relations between speaker\
    \ turns. A variation of our model is also discussed when discourse relations are\
    \ treated as latent variables. Experimental results on two popular meeting corpora\
    \ show that our joint model can outperform state-of-the-art approaches for both\
    \ phrase-based content selection and discourse relation prediction tasks. We also\
    \ evaluate our model on predicting the consistency among team members\u2019 understanding\
    \ of their group decisions. Classifiers trained with features constructed from\
    \ our model achieve significant better predictive performance than the state-of-the-art."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957724
    type: video
    url: https://vimeo.com/234957724
  author:
  - first: Kechen
    full: Kechen Qin
    id: kechen-qin
    last: Qin
  - first: Lu
    full: Lu Wang
    id: lu-wang
    last: Wang
  - first: Joseph
    full: Joseph Kim
    id: joseph-kim
    last: Kim
  author_string: Kechen Qin, Lu Wang, Joseph Kim
  bibkey: qin-etal-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1090
  month: July
  page_first: '974'
  page_last: '984'
  pages: "974\u2013984"
  paper_id: '90'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1090.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1090.jpg
  title: Joint Modeling of Content and Discourse Relations in Dialogues
  title_html: Joint Modeling of Content and Discourse Relations in Dialogues
  url: https://www.aclweb.org/anthology/P17-1090
  year: '2017'
P17-1091:
  abstract: We propose a novel factor graph model for argument mining, designed for
    settings in which the argumentative relations in a document do not necessarily
    form a tree structure. (This is the case in over 20% of the web comments dataset
    we release.) Our model jointly learns elementary unit type classification and
    argumentative relation prediction. Moreover, our model supports SVM and RNN parametrizations,
    can enforce structure constraints (e.g., transitivity), and can express dependencies
    between adjacent relations and propositions. Our approaches outperform unstructured
    baselines in both web comments and argumentative essay datasets.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957758
    type: video
    url: https://vimeo.com/234957758
  author:
  - first: Vlad
    full: Vlad Niculae
    id: vlad-niculae
    last: Niculae
  - first: Joonsuk
    full: Joonsuk Park
    id: joonsuk-park
    last: Park
  - first: Claire
    full: Claire Cardie
    id: claire-cardie
    last: Cardie
  author_string: Vlad Niculae, Joonsuk Park, Claire Cardie
  bibkey: niculae-etal-2017-argument
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1091
  month: July
  page_first: '985'
  page_last: '995'
  pages: "985\u2013995"
  paper_id: '91'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1091.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1091.jpg
  title: Argument Mining with Structured SVMs and RNNs
  title_html: Argument Mining with Structured <span class="acl-fixed-case">SVM</span>s
    and <span class="acl-fixed-case">RNN</span>s
  url: https://www.aclweb.org/anthology/P17-1091
  year: '2017'
P17-1092:
  abstract: We show that discourse structure, as defined by Rhetorical Structure Theory
    and provided by an existing discourse parser, benefits text categorization. Our
    approach uses a recursive neural network and a newly proposed attention mechanism
    to compute a representation of the text that focuses on salient content, from
    the perspective of both RST and the task. Experiments consider variants of the
    approach and illustrate its strengths and weaknesses.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1092.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1092.Notes.pdf
  - filename: https://vimeo.com/234957810
    type: video
    url: https://vimeo.com/234957810
  author:
  - first: Yangfeng
    full: Yangfeng Ji
    id: yangfeng-ji
    last: Ji
  - first: Noah A.
    full: Noah A. Smith
    id: noah-a-smith
    last: Smith
  author_string: Yangfeng Ji, Noah A. Smith
  bibkey: ji-smith-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1092
  month: July
  page_first: '996'
  page_last: '1005'
  pages: "996\u20131005"
  paper_id: '92'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1092.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1092.jpg
  title: Neural Discourse Structure for Text Categorization
  title_html: Neural Discourse Structure for Text Categorization
  url: https://www.aclweb.org/anthology/P17-1092
  year: '2017'
P17-1093:
  abstract: Implicit discourse relation classification is of great challenge due to
    the lack of connectives as strong linguistic cues, which motivates the use of
    annotated implicit connectives to improve the recognition. We propose a feature
    imitation framework in which an implicit relation network is driven to learn from
    another neural network with access to connectives, and thus encouraged to extract
    similarly salient features for accurate classification. We develop an adversarial
    model to enable an adaptive imitation scheme through competition between the implicit
    network and a rival feature discriminator. Our method effectively transfers discriminability
    of connectives to the implicit features, and achieves state-of-the-art performance
    on the PDTB benchmark.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957861
    type: video
    url: https://vimeo.com/234957861
  author:
  - first: Lianhui
    full: Lianhui Qin
    id: lianhui-qin
    last: Qin
  - first: Zhisong
    full: Zhisong Zhang
    id: zhisong-zhang
    last: Zhang
  - first: Hai
    full: Hai Zhao
    id: hai-zhao
    last: Zhao
  - first: Zhiting
    full: Zhiting Hu
    id: zhiting-hu
    last: Hu
  - first: Eric
    full: Eric Xing
    id: eric-xing
    last: Xing
  author_string: Lianhui Qin, Zhisong Zhang, Hai Zhao, Zhiting Hu, Eric Xing
  bibkey: qin-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1093
  month: July
  page_first: '1006'
  page_last: '1017'
  pages: "1006\u20131017"
  paper_id: '93'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1093.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1093.jpg
  title: Adversarial Connective-exploiting Networks for Implicit Discourse Relation
    Classification
  title_html: Adversarial Connective-exploiting Networks for Implicit Discourse Relation
    Classification
  url: https://www.aclweb.org/anthology/P17-1093
  year: '2017'
P17-1094:
  abstract: An interesting aspect of structured prediction is the evaluation of an
    output structure against the gold standard. Especially in the loss-augmented setting,
    the need of finding the max-violating constraint has severely limited the expressivity
    of effective loss functions. In this paper, we trade off exact computation for
    enabling the use and study of more complex loss functions for coreference resolution.
    Most interestingly, we show that such functions can be (i) automatically learned
    also from controversial but commonly accepted coreference measures, e.g., MELA,
    and (ii) successfully used in learning algorithms. The accurate model comparison
    on the standard CoNLL-2012 setting shows the benefit of more expressive loss functions.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957914
    type: video
    url: https://vimeo.com/234957914
  author:
  - first: Iryna
    full: Iryna Haponchyk
    id: iryna-haponchyk
    last: Haponchyk
  - first: Alessandro
    full: Alessandro Moschitti
    id: alessandro-moschitti
    last: Moschitti
  author_string: Iryna Haponchyk, Alessandro Moschitti
  bibkey: haponchyk-moschitti-2017-dont
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1094
  month: July
  page_first: '1018'
  page_last: '1028'
  pages: "1018\u20131028"
  paper_id: '94'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1094.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1094.jpg
  title: "Don\u2019t understand a measure? Learn it: Structured Prediction for Coreference\
    \ Resolution optimizing its measures"
  title_html: "Don\u2019t understand a measure? Learn it: Structured Prediction for\
    \ Coreference Resolution optimizing its measures"
  url: https://www.aclweb.org/anthology/P17-1094
  year: '2017'
P17-1095:
  abstract: 'Lexical resources such as dictionaries and gazetteers are often used
    as auxiliary data for tasks such as part-of-speech induction and named-entity
    recognition. However, discriminative training with lexical features requires annotated
    data to reliably estimate the lexical feature weights and may result in overfitting
    the lexical features at the expense of features which generalize better. In this
    paper, we investigate a more robust approach: we stipulate that the lexicon is
    the result of an assumed generative process. Practically, this means that we may
    treat the lexical resources as observations under the proposed generative model.
    The lexical resources provide training data for the generative model without requiring
    separate data to estimate lexical feature weights. We evaluate the proposed approach
    in two settings: part-of-speech induction and low-resource named-entity recognition.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1095.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1095.Notes.zip
  - filename: https://vimeo.com/234955407
    type: video
    url: https://vimeo.com/234955407
  author:
  - first: Nicholas
    full: Nicholas Andrews
    id: nicholas-andrews
    last: Andrews
  - first: Mark
    full: Mark Dredze
    id: mark-dredze
    last: Dredze
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  - first: Jason
    full: Jason Eisner
    id: jason-eisner
    last: Eisner
  author_string: Nicholas Andrews, Mark Dredze, Benjamin Van Durme, Jason Eisner
  bibkey: andrews-etal-2017-bayesian
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1095
  month: July
  page_first: '1029'
  page_last: '1039'
  pages: "1029\u20131039"
  paper_id: '95'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1095.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1095.jpg
  title: Bayesian Modeling of Lexical Resources for Low-Resource Settings
  title_html: <span class="acl-fixed-case">B</span>ayesian Modeling of Lexical Resources
    for Low-Resource Settings
  url: https://www.aclweb.org/anthology/P17-1095
  year: '2017'
P17-1096:
  abstract: "We study the problem of semi-supervised question answering\u2014utilizing\
    \ unlabeled text to boost the performance of question answering models. We propose\
    \ a novel training framework, the Generative Domain-Adaptive Nets. In this framework,\
    \ we train a generative model to generate questions based on the unlabeled text,\
    \ and combine model-generated questions with human-generated questions for training\
    \ question answering models. We develop novel domain adaptation algorithms, based\
    \ on reinforcement learning, to alleviate the discrepancy between the model-generated\
    \ data distribution and the human-generated data distribution. Experiments show\
    \ that our proposed framework obtains substantial improvement from unlabeled text."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955469
    type: video
    url: https://vimeo.com/234955469
  author:
  - first: Zhilin
    full: Zhilin Yang
    id: zhilin-yang
    last: Yang
  - first: Junjie
    full: Junjie Hu
    id: junjie-hu
    last: Hu
  - first: Ruslan
    full: Ruslan Salakhutdinov
    id: ruslan-salakhutdinov
    last: Salakhutdinov
  - first: William
    full: William Cohen
    id: william-cohen
    last: Cohen
  author_string: Zhilin Yang, Junjie Hu, Ruslan Salakhutdinov, William Cohen
  bibkey: yang-etal-2017-semi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1096
  month: July
  page_first: '1040'
  page_last: '1050'
  pages: "1040\u20131050"
  paper_id: '96'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1096.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1096.jpg
  title: Semi-Supervised QA with Generative Domain-Adaptive Nets
  title_html: Semi-Supervised <span class="acl-fixed-case">QA</span> with Generative
    Domain-Adaptive Nets
  url: https://www.aclweb.org/anthology/P17-1096
  year: '2017'
P17-1097:
  abstract: 'Our goal is to learn a semantic parser that maps natural language utterances
    into executable programs when only indirect supervision is available: examples
    are labeled with the correct execution result, but not the program itself. Consequently,
    we must search the space of programs for those that output the correct result,
    while not being misled by spurious programs: incorrect programs that coincidentally
    output the correct result. We connect two common learning paradigms, reinforcement
    learning (RL) and maximum marginal likelihood (MML), and then present a new learning
    algorithm that combines the strengths of both. The new algorithm guards against
    spurious programs by combining the systematic search traditionally employed in
    MML with the randomized exploration of RL, and by updating parameters such that
    probability is spread more evenly across consistent programs. We apply our learning
    algorithm to a new neural semantic parser and show significant gains over existing
    state-of-the-art results on a recent context-dependent semantic parsing task.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955545
    type: video
    url: https://vimeo.com/234955545
  author:
  - first: Kelvin
    full: Kelvin Guu
    id: kelvin-guu
    last: Guu
  - first: Panupong
    full: Panupong Pasupat
    id: panupong-pasupat
    last: Pasupat
  - first: Evan
    full: Evan Liu
    id: evan-liu
    last: Liu
  - first: Percy
    full: Percy Liang
    id: percy-liang
    last: Liang
  author_string: Kelvin Guu, Panupong Pasupat, Evan Liu, Percy Liang
  bibkey: guu-etal-2017-language
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1097
  month: July
  page_first: '1051'
  page_last: '1062'
  pages: "1051\u20131062"
  paper_id: '97'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1097.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1097.jpg
  title: 'From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal
    Likelihood'
  title_html: 'From Language to Programs: Bridging Reinforcement Learning and Maximum
    Marginal Likelihood'
  url: https://www.aclweb.org/anthology/P17-1097
  year: '2017'
P17-1098:
  abstract: Abstractive summarization aims to generate a shorter version of the document
    covering all the salient points in a compact and coherent fashion. On the other
    hand, query-based summarization highlights those points that are relevant in the
    context of a given query. The encode-attend-decode paradigm has achieved notable
    success in machine translation, extractive summarization, dialog systems, etc.
    But it suffers from the drawback of generation of repeated phrases. In this work
    we propose a model for the query-based summarization task based on the encode-attend-decode
    paradigm with two key additions (i) a query attention model (in addition to document
    attention model) which learns to focus on different portions of the query at different
    time steps (instead of using a static representation for the query) and (ii) a
    new diversity based attention model which aims to alleviate the problem of repeating
    phrases in the summary. In order to enable the testing of this model we introduce
    a new query-based summarization dataset building on debatepedia. Our experiments
    show that with these two additions the proposed model clearly outperforms vanilla
    encode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956203
    type: video
    url: https://vimeo.com/234956203
  author:
  - first: Preksha
    full: Preksha Nema
    id: preksha-nema
    last: Nema
  - first: Mitesh M.
    full: Mitesh M. Khapra
    id: mitesh-m-khapra
    last: Khapra
  - first: Anirban
    full: Anirban Laha
    id: anirban-laha
    last: Laha
  - first: Balaraman
    full: Balaraman Ravindran
    id: balaraman-ravindran
    last: Ravindran
  author_string: Preksha Nema, Mitesh M. Khapra, Anirban Laha, Balaraman Ravindran
  bibkey: nema-etal-2017-diversity
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1098
  month: July
  page_first: '1063'
  page_last: '1072'
  pages: "1063\u20131072"
  paper_id: '98'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1098.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1098.jpg
  title: Diversity driven attention model for query-based abstractive summarization
  title_html: Diversity driven attention model for query-based abstractive summarization
  url: https://www.aclweb.org/anthology/P17-1098
  year: '2017'
P17-1099:
  abstract: 'Neural sequence-to-sequence models have provided a viable new approach
    for abstractive text summarization (meaning they are not restricted to simply
    selecting and rearranging passages from the original text). However, these models
    have two shortcomings: they are liable to reproduce factual details inaccurately,
    and they tend to repeat themselves. In this work we propose a novel architecture
    that augments the standard sequence-to-sequence attentional model in two orthogonal
    ways. First, we use a hybrid pointer-generator network that can copy words from
    the source text via pointing, which aids accurate reproduction of information,
    while retaining the ability to produce novel words through the generator. Second,
    we use coverage to keep track of what has been summarized, which discourages repetition.
    We apply our model to the CNN / Daily Mail summarization task, outperforming the
    current abstractive state-of-the-art by at least 2 ROUGE points.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1099.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1099.Presentation.pdf
  - filename: P17-1099.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1099.Notes.pdf
  - filename: https://vimeo.com/234956256
    type: video
    url: https://vimeo.com/234956256
  author:
  - first: Abigail
    full: Abigail See
    id: abigail-see
    last: See
  - first: Peter J.
    full: Peter J. Liu
    id: peter-j-liu
    last: Liu
  - first: Christopher D.
    full: Christopher D. Manning
    id: christopher-d-manning
    last: Manning
  author_string: Abigail See, Peter J. Liu, Christopher D. Manning
  bibkey: see-etal-2017-get
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1099
  month: July
  page_first: '1073'
  page_last: '1083'
  pages: "1073\u20131083"
  paper_id: '99'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1099.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1099.jpg
  title: 'Get To The Point: Summarization with Pointer-Generator Networks'
  title_html: 'Get To The Point: Summarization with Pointer-Generator Networks'
  url: https://www.aclweb.org/anthology/P17-1099
  year: '2017'
P17-1100:
  abstract: We present a new supervised framework that learns to estimate automatic
    Pyramid scores and uses them for optimization-based extractive multi-document
    summarization. For learning automatic Pyramid scores, we developed a method for
    automatic training data generation which is based on a genetic algorithm using
    automatic Pyramid as the fitness function. Our experimental evaluation shows that
    our new framework significantly outperforms strong baselines regarding automatic
    Pyramid, and that there is much room for improvement in comparison with the upper-bound
    for automatic Pyramid.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956306
    type: video
    url: https://vimeo.com/234956306
  author:
  - first: Maxime
    full: Maxime Peyrard
    id: maxime-peyrard
    last: Peyrard
  - first: Judith
    full: Judith Eckle-Kohler
    id: judith-eckle-kohler
    last: Eckle-Kohler
  author_string: Maxime Peyrard, Judith Eckle-Kohler
  bibkey: peyrard-eckle-kohler-2017-supervised
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1100
  month: July
  page_first: '1084'
  page_last: '1094'
  pages: "1084\u20131094"
  paper_id: '100'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1100.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1100.jpg
  title: Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document
    Summarization
  title_html: Supervised Learning of Automatic Pyramid for Optimization-Based Multi-Document
    Summarization
  url: https://www.aclweb.org/anthology/P17-1100
  year: '2017'
P17-1101:
  abstract: We propose a selective encoding model to extend the sequence-to-sequence
    framework for abstractive sentence summarization. It consists of a sentence encoder,
    a selective gate network, and an attention equipped decoder. The sentence encoder
    and decoder are built with recurrent neural networks. The selective gate network
    constructs a second level sentence representation by controlling the information
    flow from encoder to decoder. The second level representation is tailored for
    sentence summarization task, which leads to better performance. We evaluate our
    model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization
    datasets. The experimental results show that the proposed selective encoding model
    outperforms the state-of-the-art baseline models.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956352
    type: video
    url: https://vimeo.com/234956352
  author:
  - first: Qingyu
    full: Qingyu Zhou
    id: qingyu-zhou
    last: Zhou
  - first: Nan
    full: Nan Yang
    id: nan-yang
    last: Yang
  - first: Furu
    full: Furu Wei
    id: furu-wei
    last: Wei
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  author_string: Qingyu Zhou, Nan Yang, Furu Wei, Ming Zhou
  bibkey: zhou-etal-2017-selective
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1101
  month: July
  page_first: '1095'
  page_last: '1104'
  pages: "1095\u20131104"
  paper_id: '101'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1101.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1101.jpg
  title: Selective Encoding for Abstractive Sentence Summarization
  title_html: Selective Encoding for Abstractive Sentence Summarization
  url: https://www.aclweb.org/anthology/P17-1101
  year: '2017'
P17-1102:
  abstract: "The large and growing amounts of online scholarly data present both challenges\
    \ and opportunities to enhance knowledge discovery. One such challenge is to automatically\
    \ extract a small set of keyphrases from a document that can accurately describe\
    \ the document\u2019s content and can facilitate fast information processing.\
    \ In this paper, we propose PositionRank, an unsupervised model for keyphrase\
    \ extraction from scholarly documents that incorporates information from all positions\
    \ of a word\u2019s occurrences into a biased PageRank. Our model obtains remarkable\
    \ improvements in performance over PageRank models that do not take into account\
    \ word positions as well as over strong baselines for this task. Specifically,\
    \ on several datasets of research papers, PositionRank achieves improvements as\
    \ high as 29.09%."
  address: Vancouver, Canada
  author:
  - first: Corina
    full: Corina Florescu
    id: corina-florescu
    last: Florescu
  - first: Cornelia
    full: Cornelia Caragea
    id: cornelia-caragea
    last: Caragea
  author_string: Corina Florescu, Cornelia Caragea
  bibkey: florescu-caragea-2017-positionrank
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1102
  month: July
  page_first: '1105'
  page_last: '1115'
  pages: "1105\u20131115"
  paper_id: '102'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1102.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1102.jpg
  title: 'PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly
    Documents'
  title_html: '<span class="acl-fixed-case">P</span>osition<span class="acl-fixed-case">R</span>ank:
    An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents'
  url: https://www.aclweb.org/anthology/P17-1102
  year: '2017'
P17-1103:
  abstract: "Automatically evaluating the quality of dialogue responses for unstructured\
    \ domains is a challenging problem. Unfortunately, existing automatic evaluation\
    \ metrics are biased and correlate very poorly with human judgements of response\
    \ quality (Liu et al., 2016). Yet having an accurate automatic evaluation procedure\
    \ is crucial for dialogue research, as it allows rapid prototyping and testing\
    \ of new models with fewer expensive human evaluations. In response to this challenge,\
    \ we formulate automatic dialogue evaluation as a learning problem.We present\
    \ an evaluation model (ADEM)that learns to predict human-like scores to input\
    \ responses, using a new dataset of human response scores. We show that the ADEM\
    \ model\u2019s predictions correlate significantly, and at a level much higher\
    \ than word-overlap metrics such as BLEU, with human judgements at both the utterance\
    \ and system-level. We also show that ADEM can generalize to evaluating dialogue\
    \ mod-els unseen during training, an important step for automatic dialogue evaluation."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1103.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1103.Notes.pdf
  - filename: https://vimeo.com/234958888
    type: video
    url: https://vimeo.com/234958888
  author:
  - first: Ryan
    full: Ryan Lowe
    id: ryan-lowe
    last: Lowe
  - first: Michael
    full: Michael Noseworthy
    id: michael-noseworthy
    last: Noseworthy
  - first: Iulian Vlad
    full: Iulian Vlad Serban
    id: iulian-vlad-serban
    last: Serban
  - first: Nicolas
    full: Nicolas Angelard-Gontier
    id: nicolas-angelard-gontier
    last: Angelard-Gontier
  - first: Yoshua
    full: Yoshua Bengio
    id: yoshua-bengio
    last: Bengio
  - first: Joelle
    full: Joelle Pineau
    id: joelle-pineau
    last: Pineau
  author_string: Ryan Lowe, Michael Noseworthy, Iulian Vlad Serban, Nicolas Angelard-Gontier,
    Yoshua Bengio, Joelle Pineau
  bibkey: lowe-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1103
  month: July
  page_first: '1116'
  page_last: '1126'
  pages: "1116\u20131126"
  paper_id: '103'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1103.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1103.jpg
  title: 'Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses'
  title_html: 'Towards an Automatic <span class="acl-fixed-case">T</span>uring Test:
    Learning to Evaluate Dialogue Responses'
  url: https://www.aclweb.org/anthology/P17-1103
  year: '2017'
P17-1104:
  abstract: 'We present the first parser for UCCA, a cross-linguistically applicable
    framework for semantic representation, which builds on extensive typological work
    and supports rapid annotation. UCCA poses a challenge for existing parsing techniques,
    as it exhibits reentrancy (resulting in DAG structures), discontinuous structures
    and non-terminal nodes corresponding to complex semantic units. To our knowledge,
    the conjunction of these formal properties is not supported by any existing parser.
    Our transition-based parser, which uses a novel transition set and features based
    on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle
    more general graph structures can inform the development of parsers for other
    semantic DAG structures, and in languages that frequently use discontinuous structures.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1104.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1104.Notes.pdf
  - filename: P17-1104.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1104.Presentation.pdf
  - filename: P17-1104.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1104.Software.zip
  - filename: https://vimeo.com/234958945
    type: video
    url: https://vimeo.com/234958945
  author:
  - first: Daniel
    full: Daniel Hershcovich
    id: daniel-hershcovich
    last: Hershcovich
  - first: Omri
    full: Omri Abend
    id: omri-abend
    last: Abend
  - first: Ari
    full: Ari Rappoport
    id: ari-rappoport
    last: Rappoport
  author_string: Daniel Hershcovich, Omri Abend, Ari Rappoport
  bibkey: hershcovich-etal-2017-transition
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1104
  month: July
  page_first: '1127'
  page_last: '1138'
  pages: "1127\u20131138"
  paper_id: '104'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1104.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1104.jpg
  title: A Transition-Based Directed Acyclic Graph Parser for UCCA
  title_html: A Transition-Based Directed Acyclic Graph Parser for <span class="acl-fixed-case">UCCA</span>
  url: https://www.aclweb.org/anthology/P17-1104
  year: '2017'
P17-1105:
  abstract: Tasks like code generation and semantic parsing require mapping unstructured
    (or partially structured) inputs to well-formed, executable outputs. We introduce
    abstract syntax networks, a modeling framework for these problems. The outputs
    are represented as abstract syntax trees (ASTs) and constructed by a decoder with
    a dynamically-determined modular structure paralleling the structure of the output
    tree. On the benchmark Hearthstone dataset for code generation, our model obtains
    79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art
    values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs,
    and Geo semantic parsing datasets with no task-specific engineering.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958993
    type: video
    url: https://vimeo.com/234958993
  author:
  - first: Maxim
    full: Maxim Rabinovich
    id: maxim-rabinovich
    last: Rabinovich
  - first: Mitchell
    full: Mitchell Stern
    id: mitchell-stern
    last: Stern
  - first: Dan
    full: Dan Klein
    id: dan-klein
    last: Klein
  author_string: Maxim Rabinovich, Mitchell Stern, Dan Klein
  bibkey: rabinovich-etal-2017-abstract
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1105
  month: July
  page_first: '1139'
  page_last: '1149'
  pages: "1139\u20131149"
  paper_id: '105'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1105.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1105.jpg
  title: Abstract Syntax Networks for Code Generation and Semantic Parsing
  title_html: Abstract Syntax Networks for Code Generation and Semantic Parsing
  url: https://www.aclweb.org/anthology/P17-1105
  year: '2017'
P17-1106:
  abstract: While neural machine translation (NMT) has made remarkable progress in
    recent years, it is hard to interpret its internal workings due to the continuous
    representations and non-linearity of neural networks. In this work, we propose
    to use layer-wise relevance propagation (LRP) to compute the contribution of each
    contextual word to arbitrary hidden states in the attention-based encoder-decoder
    framework. We show that visualization with LRP helps to interpret the internal
    workings of NMT and analyze translation errors.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234946242
    type: video
    url: https://vimeo.com/234946242
  author:
  - first: Yanzhuo
    full: Yanzhuo Ding
    id: yanzhuo-ding
    last: Ding
  - first: Yang
    full: Yang Liu
    id: yang-liu-ict
    last: Liu
  - first: Huanbo
    full: Huanbo Luan
    id: huanbo-luan
    last: Luan
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Yanzhuo Ding, Yang Liu, Huanbo Luan, Maosong Sun
  bibkey: ding-etal-2017-visualizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1106
  month: July
  page_first: '1150'
  page_last: '1159'
  pages: "1150\u20131159"
  paper_id: '106'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1106.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1106.jpg
  title: Visualizing and Understanding Neural Machine Translation
  title_html: Visualizing and Understanding Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1106
  year: '2017'
P17-1107:
  abstract: We introduce a method for error detection in automatically annotated text,
    aimed at supporting the creation of high-quality language resources at affordable
    cost. Our method combines an unsupervised generative model with human supervision
    from active learning. We test our approach on in-domain and out-of-domain data
    in two languages, in AL simulations and in a real world setting. For all settings,
    the results show that our method is able to detect annotation errors with high
    precision and high recall.
  address: Vancouver, Canada
  author:
  - first: Ines
    full: Ines Rehbein
    id: ines-rehbein
    last: Rehbein
  - first: Josef
    full: Josef Ruppenhofer
    id: josef-ruppenhofer
    last: Ruppenhofer
  author_string: Ines Rehbein, Josef Ruppenhofer
  bibkey: rehbein-ruppenhofer-2017-detecting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1107
  month: July
  page_first: '1160'
  page_last: '1170'
  pages: "1160\u20131170"
  paper_id: '107'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1107.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1107.jpg
  title: Detecting annotation noise in automatically labelled data
  title_html: Detecting annotation noise in automatically labelled data
  url: https://www.aclweb.org/anthology/P17-1107
  year: '2017'
P17-1108:
  abstract: Abstractive summarization is the ultimate goal of document summarization
    research, but previously it is less investigated due to the immaturity of text
    generation techniques. Recently impressive progress has been made to abstractive
    sentence summarization using neural models. Unfortunately, attempts on abstractive
    document summarization are still in a primitive stage, and the evaluation results
    are worse than extractive methods on benchmark datasets. In this paper, we review
    the difficulties of neural abstractive document summarization, and propose a novel
    graph-based attention mechanism in the sequence-to-sequence framework. The intuition
    is to address the saliency factor of summarization, which has been overlooked
    by prior works. Experimental results demonstrate our model is able to achieve
    considerable improvement over previous neural abstractive models. The data-driven
    neural abstractive method is also competitive with state-of-the-art extractive
    methods.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234959124
    type: video
    url: https://vimeo.com/234959124
  author:
  - first: Jiwei
    full: Jiwei Tan
    id: jiwei-tan
    last: Tan
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  - first: Jianguo
    full: Jianguo Xiao
    id: jianguo-xiao
    last: Xiao
  author_string: Jiwei Tan, Xiaojun Wan, Jianguo Xiao
  bibkey: tan-etal-2017-abstractive
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1108
  month: July
  page_first: '1171'
  page_last: '1181'
  pages: "1171\u20131181"
  paper_id: '108'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1108.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1108.jpg
  title: Abstractive Document Summarization with a Graph-Based Attentional Neural
    Model
  title_html: Abstractive Document Summarization with a Graph-Based Attentional Neural
    Model
  url: https://www.aclweb.org/anthology/P17-1108
  year: '2017'
P17-1109:
  abstract: "Linguistic typology studies the range of structures present in human\
    \ language. The main goal of the field is to discover which sets of possible phenomena\
    \ are universal, and which are merely frequent. For example, all languages have\
    \ vowels, while most\u2014but not all\u2014languages have an /u/ sound. In this\
    \ paper we present the first probabilistic treatment of a basic question in phonological\
    \ typology: What makes a natural vowel inventory? We introduce a series of deep\
    \ stochastic point processes, and contrast them with previous computational, simulation-based\
    \ approaches. We provide a comprehensive suite of experiments on over 200 distinct\
    \ languages."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234959176
    type: video
    url: https://vimeo.com/234959176
  author:
  - first: Ryan
    full: Ryan Cotterell
    id: ryan-cotterell
    last: Cotterell
  - first: Jason
    full: Jason Eisner
    id: jason-eisner
    last: Eisner
  author_string: Ryan Cotterell, Jason Eisner
  bibkey: cotterell-eisner-2017-probabilistic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1109
  month: July
  page_first: '1182'
  page_last: '1192'
  pages: "1182\u20131192"
  paper_id: '109'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1109.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1109.jpg
  title: 'Probabilistic Typology: Deep Generative Models of Vowel Inventories'
  title_html: 'Probabilistic Typology: Deep Generative Models of Vowel Inventories'
  url: https://www.aclweb.org/anthology/P17-1109
  year: '2017'
P17-1110:
  abstract: Different linguistic perspectives causes many diverse segmentation criteria
    for Chinese word segmentation (CWS). Most existing methods focus on improve the
    performance for each single criterion. However, it is interesting to exploit these
    different criteria and mining their common underlying knowledge. In this paper,
    we propose adversarial multi-criteria learning for CWS by integrating shared knowledge
    from multiple heterogeneous segmentation criteria. Experiments on eight corpora
    with heterogeneous segmentation criteria show that the performance of each corpus
    obtains a significant improvement, compared to single-criterion learning. Source
    codes of this paper are available on Github.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234944621
    type: video
    url: https://vimeo.com/234944621
  author:
  - first: Xinchi
    full: Xinchi Chen
    id: xinchi-chen
    last: Chen
  - first: Zhan
    full: Zhan Shi
    id: zhan-shi
    last: Shi
  - first: Xipeng
    full: Xipeng Qiu
    id: xipeng-qiu
    last: Qiu
  - first: Xuanjing
    full: Xuanjing Huang
    id: xuan-jing-huang
    last: Huang
  author_string: Xinchi Chen, Zhan Shi, Xipeng Qiu, Xuanjing Huang
  bibkey: chen-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1110
  month: July
  page_first: '1193'
  page_last: '1203'
  pages: "1193\u20131203"
  paper_id: '110'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1110.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1110.jpg
  title: Adversarial Multi-Criteria Learning for Chinese Word Segmentation
  title_html: Adversarial Multi-Criteria Learning for <span class="acl-fixed-case">C</span>hinese
    Word Segmentation
  url: https://www.aclweb.org/anthology/P17-1110
  year: '2017'
P17-1111:
  abstract: We present neural network-based joint models for Chinese word segmentation,
    POS tagging and dependency parsing. Our models are the first neural approaches
    for fully joint Chinese analysis that is known to prevent the error propagation
    problem of pipeline models. Although word embeddings play a key role in dependency
    parsing, they cannot be applied directly to the joint task in the previous work.
    To address this problem, we propose embeddings of character strings, in addition
    to words. Experiments show that our models outperform existing systems in Chinese
    word segmentation and POS tagging, and perform preferable accuracies in dependency
    parsing. We also explore bi-LSTM models with fewer features.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234944928
    type: video
    url: https://vimeo.com/234944928
  author:
  - first: Shuhei
    full: Shuhei Kurita
    id: shuhei-kurita
    last: Kurita
  - first: Daisuke
    full: Daisuke Kawahara
    id: daisuke-kawahara
    last: Kawahara
  - first: Sadao
    full: Sadao Kurohashi
    id: sadao-kurohashi
    last: Kurohashi
  author_string: Shuhei Kurita, Daisuke Kawahara, Sadao Kurohashi
  bibkey: kurita-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1111
  month: July
  page_first: '1204'
  page_last: '1214'
  pages: "1204\u20131214"
  paper_id: '111'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1111.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1111.jpg
  title: Neural Joint Model for Transition-based Chinese Syntactic Analysis
  title_html: Neural Joint Model for Transition-based <span class="acl-fixed-case">C</span>hinese
    Syntactic Analysis
  url: https://www.aclweb.org/anthology/P17-1111
  year: '2017'
P17-1112:
  abstract: Parsing sentences to linguistically-expressive semantic representations
    is a key goal of Natural Language Processing. Yet statistical parsing has focussed
    almost exclusively on bilexical dependencies or domain-specific logical forms.
    We propose a neural encoder-decoder transition-based parser which is the first
    full-coverage semantic graph parser for Minimal Recursion Semantics (MRS). The
    model architecture uses stack-based embedding features, predicting graphs jointly
    with unlexicalized predicates and their token alignments. Our parser is more accurate
    than attention-based baselines on MRS, and on an additional Abstract Meaning Representation
    (AMR) benchmark, and GPU batch processing makes it an order of magnitude faster
    than a high-precision grammar-based parser. Further, the 86.69% Smatch score of
    our MRS parser is higher than the upper-bound on AMR parsing, making MRS an attractive
    choice as a semantic representation.
  address: Vancouver, Canada
  author:
  - first: Jan
    full: Jan Buys
    id: jan-buys
    last: Buys
  - first: Phil
    full: Phil Blunsom
    id: phil-blunsom
    last: Blunsom
  author_string: Jan Buys, Phil Blunsom
  bibkey: buys-blunsom-2017-robust
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1112
  month: July
  page_first: '1215'
  page_last: '1226'
  pages: "1215\u20131226"
  paper_id: '112'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1112.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1112.jpg
  title: Robust Incremental Neural Semantic Graph Parsing
  title_html: Robust Incremental Neural Semantic Graph Parsing
  url: https://www.aclweb.org/anthology/P17-1112
  year: '2017'
P17-1113:
  abstract: "Joint extraction of entities and relations is an important task in information\
    \ extraction. To tackle this problem, we firstly propose a novel tagging scheme\
    \ that can convert the joint extraction task to a tagging problem.. Then, based\
    \ on our tagging scheme, we study different end-to-end models to extract entities\
    \ and their relations directly, without identifying entities and relations separately.\
    \ We conduct experiments on a public dataset produced by distant supervision method\
    \ and the experimental results show that the tagging based methods are better\
    \ than most of the existing pipelined and joint learning methods. What\u2019s\
    \ more, the end-to-end model proposed in this paper, achieves the best results\
    \ on the public dataset."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234945423
    type: video
    url: https://vimeo.com/234945423
  author:
  - first: Suncong
    full: Suncong Zheng
    id: suncong-zheng
    last: Zheng
  - first: Feng
    full: Feng Wang
    id: feng-wang
    last: Wang
  - first: Hongyun
    full: Hongyun Bao
    id: hongyun-bao
    last: Bao
  - first: Yuexing
    full: Yuexing Hao
    id: yuexing-hao
    last: Hao
  - first: Peng
    full: Peng Zhou
    id: peng-zhou
    last: Zhou
  - first: Bo
    full: Bo Xu
    id: bo-xu
    last: Xu
  author_string: Suncong Zheng, Feng Wang, Hongyun Bao, Yuexing Hao, Peng Zhou, Bo
    Xu
  bibkey: zheng-etal-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1113
  month: July
  page_first: '1227'
  page_last: '1236'
  pages: "1227\u20131236"
  paper_id: '113'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1113.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1113.jpg
  title: Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme
  title_html: Joint Extraction of Entities and Relations Based on a Novel Tagging
    Scheme
  url: https://www.aclweb.org/anthology/P17-1113
  year: '2017'
P17-1114:
  abstract: In this paper, we study a novel approach for named entity recognition
    (NER) and mention detection (MD) in natural language processing. Instead of treating
    NER as a sequence labeling problem, we propose a new local detection approach,
    which relies on the recent fixed-size ordinally forgetting encoding (FOFE) method
    to fully encode each sentence fragment and its left/right contexts into a fixed-size
    representation. Subsequently, a simple feedforward neural network (FFNN) is learned
    to either reject or predict entity label for each individual text fragment. The
    proposed method has been evaluated in several popular NER and MD tasks, including
    CoNLL 2003 NER task and TAC-KBP2015 and TAC-KBP2016 Tri-lingual Entity Discovery
    and Linking (EDL) tasks. Our method has yielded pretty strong performance in all
    of these examined tasks. This local detection approach has shown many advantages
    over the traditional sequence labeling methods.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234945176
    type: video
    url: https://vimeo.com/234945176
  author:
  - first: Mingbin
    full: Mingbin Xu
    id: mingbin-xu
    last: Xu
  - first: Hui
    full: Hui Jiang
    id: hui-jiang
    last: Jiang
  - first: Sedtawut
    full: Sedtawut Watcharawittayakul
    id: sedtawut-watcharawittayakul
    last: Watcharawittayakul
  author_string: Mingbin Xu, Hui Jiang, Sedtawut Watcharawittayakul
  bibkey: xu-etal-2017-local
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1114
  month: July
  page_first: '1237'
  page_last: '1247'
  pages: "1237\u20131247"
  paper_id: '114'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1114.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1114.jpg
  title: A Local Detection Approach for Named Entity Recognition and Mention Detection
  title_html: A Local Detection Approach for Named Entity Recognition and Mention
    Detection
  url: https://www.aclweb.org/anthology/P17-1114
  year: '2017'
P17-1115:
  abstract: Named entities are frequently used in a metonymic manner. They serve as
    references to related entities such as people and organisations. Accurate identification
    and interpretation of metonymy can be directly beneficial to various NLP applications,
    such as Named Entity Recognition and Geographical Parsing. Until now, metonymy
    resolution (MR) methods mainly relied on parsers, taggers, dictionaries, external
    word lists and other handcrafted lexical resources. We show how a minimalist neural
    approach combined with a novel predicate window method can achieve competitive
    results on the SemEval 2007 task on Metonymy Resolution. Additionally, we contribute
    with a new Wikipedia-based MR dataset called RelocaR, which is tailored towards
    locations as well as improving previous deficiencies in annotation guidelines.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1115.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1115.Datasets.zip
  - filename: https://vimeo.com/234945689
    type: video
    url: https://vimeo.com/234945689
  author:
  - first: Milan
    full: Milan Gritta
    id: milan-gritta
    last: Gritta
  - first: Mohammad Taher
    full: Mohammad Taher Pilehvar
    id: mohammad-taher-pilehvar
    last: Pilehvar
  - first: Nut
    full: Nut Limsopatham
    id: nut-limsopatham
    last: Limsopatham
  - first: Nigel
    full: Nigel Collier
    id: nigel-collier
    last: Collier
  author_string: Milan Gritta, Mohammad Taher Pilehvar, Nut Limsopatham, Nigel Collier
  bibkey: gritta-etal-2017-vancouver
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1115
  month: July
  page_first: '1248'
  page_last: '1259'
  pages: "1248\u20131259"
  paper_id: '115'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1115.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1115.jpg
  title: Vancouver Welcomes You! Minimalist Location Metonymy Resolution
  title_html: Vancouver Welcomes You! Minimalist Location Metonymy Resolution
  url: https://www.aclweb.org/anthology/P17-1115
  year: '2017'
P17-1116:
  abstract: We propose a novel geolocation prediction model using a complex neural
    network. Geolocation prediction in social media has attracted many researchers
    to use information of various types. Our model unifies text, metadata, and user
    network representations with an attention mechanism to overcome previous ensemble
    approaches. In an evaluation using two open datasets, the proposed model exhibited
    a maximum 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy@161
    against previous models. We further analyzed several intermediate layers of our
    model, which revealed that their states capture some statistical characteristics
    of the datasets.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1116.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1116.Presentation.pdf
  - filename: https://vimeo.com/234945928
    type: video
    url: https://vimeo.com/234945928
  author:
  - first: Yasuhide
    full: Yasuhide Miura
    id: yasuhide-miura
    last: Miura
  - first: Motoki
    full: Motoki Taniguchi
    id: motoki-taniguchi
    last: Taniguchi
  - first: Tomoki
    full: Tomoki Taniguchi
    id: tomoki-taniguchi
    last: Taniguchi
  - first: Tomoko
    full: Tomoko Ohkuma
    id: tomoko-ohkuma
    last: Ohkuma
  author_string: Yasuhide Miura, Motoki Taniguchi, Tomoki Taniguchi, Tomoko Ohkuma
  bibkey: miura-etal-2017-unifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1116
  month: July
  page_first: '1260'
  page_last: '1272'
  pages: "1260\u20131272"
  paper_id: '116'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1116.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1116.jpg
  title: Unifying Text, Metadata, and User Network Representations with a Neural Network
    for Geolocation Prediction
  title_html: Unifying Text, Metadata, and User Network Representations with a Neural
    Network for Geolocation Prediction
  url: https://www.aclweb.org/anthology/P17-1116
  year: '2017'
P17-1117:
  abstract: 'Video captioning, the task of describing the content of a video, has
    seen some promising improvements in recent years with sequence-to-sequence models,
    but accurately learning the temporal and logical dynamics involved in the task
    still remains a challenge, especially given the lack of sufficient annotated data.
    We improve video captioning by sharing knowledge with two related directed-generation
    tasks: a temporally-directed unsupervised video prediction task to learn richer
    context-aware video encoder representations, and a logically-directed language
    entailment generation task to learn better video-entailing caption decoder representations.
    For this, we present a many-to-many multi-task learning model that shares parameters
    across the encoders and decoders of the three tasks. We achieve significant improvements
    and the new state-of-the-art on several standard video captioning datasets using
    diverse automatic and human evaluations. We also show mutual multi-task improvements
    on the entailment generation task.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1117.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1117.Notes.pdf
  - filename: https://vimeo.com/234946056
    type: video
    url: https://vimeo.com/234946056
  author:
  - first: Ramakanth
    full: Ramakanth Pasunuru
    id: ramakanth-pasunuru
    last: Pasunuru
  - first: Mohit
    full: Mohit Bansal
    id: mohit-bansal
    last: Bansal
  author_string: Ramakanth Pasunuru, Mohit Bansal
  bibkey: pasunuru-bansal-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1117
  month: July
  page_first: '1273'
  page_last: '1283'
  pages: "1273\u20131283"
  paper_id: '117'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1117.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1117.jpg
  title: Multi-Task Video Captioning with Video and Entailment Generation
  title_html: Multi-Task Video Captioning with Video and Entailment Generation
  url: https://www.aclweb.org/anthology/P17-1117
  year: '2017'
P17-1118:
  abstract: 'Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose.
    Linguistic features, mainly from parsers, have been used to detect MCI, but this
    is not suitable for large-scale assessments. MCI disfluencies produce non-grammatical
    speech that requires manual or high precision automatic correction of transcripts.
    In this paper, we modeled transcripts into complex networks and enriched them
    with word embedding (CNE) to better represent short texts produced in neuropsychological
    assessments. The network measurements were applied with well-known classifiers
    to automatically identify MCI in transcripts, in a binary classification task.
    A comparison was made with the performance of traditional approaches using Bag
    of Words (BoW) and linguistic features for three datasets: DementiaBank in English,
    and Cinderella and Arizona-Battery in Portuguese. Overall, CNE provided higher
    accuracy than using only complex networks, while Support Vector Machine was superior
    to other classifiers. CNE provided the highest accuracies for DementiaBank and
    Cinderella, but BoW was more efficient for the Arizona-Battery dataset probably
    owing to its short narratives. The approach using linguistic features yielded
    higher accuracy if the transcriptions of the Cinderella dataset were manually
    revised. Taken together, the results indicate that complex networks enriched with
    embedding is promising for detecting MCI in large-scale assessments.'
  address: Vancouver, Canada
  author:
  - first: Leandro
    full: Leandro Santos
    id: leandro-santos
    last: Santos
  - first: Edilson Anselmo
    full: "Edilson Anselmo Corr\xEAa J\xFAnior"
    id: edilson-anselmo-correa-junior
    last: "Corr\xEAa J\xFAnior"
  - first: Osvaldo
    full: Osvaldo Oliveira Jr
    id: osvaldo-novais-oliveira-jr
    last: Oliveira Jr
  - first: Diego
    full: Diego Amancio
    id: diego-raphael-amancio
    last: Amancio
  - first: "Let\xEDcia"
    full: "Let\xEDcia Mansur"
    id: leticia-mansur
    last: Mansur
  - first: Sandra
    full: "Sandra Alu\xEDsio"
    id: sandra-aluisio
    last: "Alu\xEDsio"
  author_string: "Leandro Santos, Edilson Anselmo Corr\xEAa J\xFAnior, Osvaldo Oliveira\
    \ Jr, Diego Amancio, Let\xEDcia Mansur, Sandra Alu\xEDsio"
  bibkey: santos-etal-2017-enriching
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1118
  month: July
  page_first: '1284'
  page_last: '1296'
  pages: "1284\u20131296"
  paper_id: '118'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1118.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1118.jpg
  title: Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive
    Impairment from Speech Transcripts
  title_html: Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive
    Impairment from Speech Transcripts
  url: https://www.aclweb.org/anthology/P17-1118
  year: '2017'
P17-1119:
  abstract: Two types of data shift common in practice are 1. transferring from synthetic
    data to live user data (a deployment shift), and 2. transferring from stale data
    to current data (a temporal shift). Both cause a distribution mismatch between
    training and evaluation, leading to a model that overfits the flawed training
    data and performs poorly on the test data. We propose a solution to this mismatch
    problem by framing it as domain adaptation, treating the flawed training dataset
    as a source domain and the evaluation dataset as a target domain. To this end,
    we use and build on several recent advances in neural domain adaptation such as
    adversarial training (Ganinet al., 2016) and domain separation network (Bousmalis
    et al., 2016), proposing a new effective adversarial training scheme. In both
    supervised and unsupervised adaptation scenarios, our approach yields clear improvement
    over strong baselines.
  address: Vancouver, Canada
  author:
  - first: Young-Bum
    full: Young-Bum Kim
    id: young-bum-kim
    last: Kim
  - first: Karl
    full: Karl Stratos
    id: karl-stratos
    last: Stratos
  - first: Dongchan
    full: Dongchan Kim
    id: dongchan-kim
    last: Kim
  author_string: Young-Bum Kim, Karl Stratos, Dongchan Kim
  bibkey: kim-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1119
  month: July
  page_first: '1297'
  page_last: '1307'
  pages: "1297\u20131307"
  paper_id: '119'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1119.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1119.jpg
  title: Adversarial Adaptation of Synthetic or Stale Data
  title_html: Adversarial Adaptation of Synthetic or Stale Data
  url: https://www.aclweb.org/anthology/P17-1119
  year: '2017'
P17-1120:
  abstract: Recently emerged intelligent assistants on smartphones and home electronics
    (e.g., Siri and Alexa) can be seen as novel hybrids of domain-specific task-oriented
    spoken dialogue systems and open-domain non-task-oriented ones. To realize such
    hybrid dialogue systems, this paper investigates determining whether or not a
    user is going to have a chat with the system. To address the lack of benchmark
    datasets for this task, we construct a new dataset consisting of 15,160 utterances
    collected from the real log data of a commercial intelligent assistant (and will
    release the dataset to facilitate future research activity). In addition, we investigate
    using tweets and Web search queries for handling open-domain user utterances,
    which characterize the task of chat detection. Experimental experiments demonstrated
    that, while simple supervised methods are effective, the use of the tweets and
    search queries further improves the F1-score from 86.21 to 87.53. -score from
    86.21 to 87.53.
  address: Vancouver, Canada
  author:
  - first: Satoshi
    full: Satoshi Akasaki
    id: satoshi-akasaki
    last: Akasaki
  - first: Nobuhiro
    full: Nobuhiro Kaji
    id: nobuhiro-kaji
    last: Kaji
  author_string: Satoshi Akasaki, Nobuhiro Kaji
  bibkey: akasaki-kaji-2017-chat
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1120
  month: July
  page_first: '1308'
  page_last: '1319'
  pages: "1308\u20131319"
  paper_id: '120'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1120.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1120.jpg
  title: 'Chat Detection in an Intelligent Assistant: Combining Task-oriented and
    Non-task-oriented Spoken Dialogue Systems'
  title_html: 'Chat Detection in an Intelligent Assistant: Combining Task-oriented
    and Non-task-oriented Spoken Dialogue Systems'
  url: https://www.aclweb.org/anthology/P17-1120
  year: '2017'
P17-1121:
  abstract: We propose a local coherence model based on a convolutional neural network
    that operates over the entity grid representation of a text. The model captures
    long range entity transitions along with entity-specific features without loosing
    generalization, thanks to the power of distributed representation. We present
    a pairwise ranking method to train the model in an end-to-end fashion on a task
    and learn task-specific high level features. Our evaluation on three different
    coherence assessment tasks demonstrates that our model achieves state of the art
    results outperforming existing models by a good margin.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/306164201
    type: video
    url: https://vimeo.com/306164201
  author:
  - first: Dat
    full: Dat Tien Nguyen
    id: dat-tien-nguyen
    last: Tien Nguyen
  - first: Shafiq
    full: Shafiq Joty
    id: shafiq-joty
    last: Joty
  author_string: Dat Tien Nguyen, Shafiq Joty
  bibkey: tien-nguyen-joty-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1121
  month: July
  page_first: '1320'
  page_last: '1330'
  pages: "1320\u20131330"
  paper_id: '121'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1121.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1121.jpg
  title: A Neural Local Coherence Model
  title_html: A Neural Local Coherence Model
  url: https://www.aclweb.org/anthology/P17-1121
  year: '2017'
P17-1122:
  abstract: "Opinionated Natural Language Generation (ONLG) is a new, challenging,\
    \ task that aims to automatically generate human-like, subjective, responses to\
    \ opinionated articles online. We present a data-driven architecture for ONLG\
    \ that generates subjective responses triggered by users\u2019 agendas, consisting\
    \ of topics and sentiments, and based on wide-coverage automatically-acquired\
    \ generative grammars. We compare three types of grammatical representations that\
    \ we design for ONLG, which interleave different layers of linguistic information\
    \ and are induced from a new, enriched dataset we developed. Our evaluation shows\
    \ that generation with Relational-Realizational (Tsarfaty and Sima\u2019an, 2008)\
    \ inspired grammar gets better language model scores than lexicalized grammars\
    \ \u2018a la Collins (2003), and that the latter gets better human-evaluation\
    \ scores. We also show that conditioning the generation on topic models makes\
    \ generated responses more relevant to the document content."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1122.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1122.Notes.pdf
  author:
  - first: Tomer
    full: Tomer Cagan
    id: tomer-cagan
    last: Cagan
  - first: Stefan L.
    full: Stefan L. Frank
    id: stefan-l-frank
    last: Frank
  - first: Reut
    full: Reut Tsarfaty
    id: reut-tsarfaty
    last: Tsarfaty
  author_string: Tomer Cagan, Stefan L. Frank, Reut Tsarfaty
  bibkey: cagan-etal-2017-data
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1122
  month: July
  page_first: '1331'
  page_last: '1341'
  pages: "1331\u20131341"
  paper_id: '122'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1122.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1122.jpg
  title: Data-Driven Broad-Coverage Grammars for Opinionated Natural Language Generation
    (ONLG)
  title_html: Data-Driven Broad-Coverage Grammars for Opinionated Natural Language
    Generation (<span class="acl-fixed-case">ONLG</span>)
  url: https://www.aclweb.org/anthology/P17-1122
  year: '2017'
P17-1123:
  abstract: We study automatic question generation for sentences from text passages
    in reading comprehension. We introduce an attention-based sequence learning model
    for the task and investigate the effect of encoding sentence- vs. paragraph-level
    information. In contrast to all previous work, our model does not rely on hand-crafted
    rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via
    sequence-to-sequence learning. Automatic evaluation results show that our system
    significantly outperforms the state-of-the-art rule-based system. In human evaluations,
    questions generated by our system are also rated as being more natural (i.e.,,
    grammaticality, fluency) and as more difficult to answer (in terms of syntactic
    and lexical divergence from the original text and reasoning needed to answer).
  address: Vancouver, Canada
  author:
  - first: Xinya
    full: Xinya Du
    id: xinya-du
    last: Du
  - first: Junru
    full: Junru Shao
    id: junru-shao
    last: Shao
  - first: Claire
    full: Claire Cardie
    id: claire-cardie
    last: Cardie
  author_string: Xinya Du, Junru Shao, Claire Cardie
  bibkey: du-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1123
  month: July
  page_first: '1342'
  page_last: '1352'
  pages: "1342\u20131352"
  paper_id: '123'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1123.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1123.jpg
  title: 'Learning to Ask: Neural Question Generation for Reading Comprehension'
  title_html: 'Learning to Ask: Neural Question Generation for Reading Comprehension'
  url: https://www.aclweb.org/anthology/P17-1123
  year: '2017'
P17-1124:
  abstract: In this paper, we propose an extractive multi-document summarization (MDS)
    system using joint optimization and active learning for content selection grounded
    in user feedback. Our method interactively obtains user feedback to gradually
    improve the results of a state-of-the-art integer linear programming (ILP) framework
    for MDS. Our methods complement fully automatic methods in producing high-quality
    summaries with a minimum number of iterations and feedbacks. We conduct multiple
    simulation-based experiments and analyze the effect of feedback-based concept
    selection in the ILP setup in order to maximize the user-desired content in the
    summary.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1124.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1124.Poster.pdf
  author:
  - first: Avinesh
    full: Avinesh P.V.S
    id: avinesh-p-v-s
    last: P.V.S
  - first: Christian M.
    full: Christian M. Meyer
    id: christian-m-meyer
    last: Meyer
  author_string: Avinesh P.V.S, Christian M. Meyer
  bibkey: p-v-s-meyer-2017-joint
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1124
  month: July
  page_first: '1353'
  page_last: '1363'
  pages: "1353\u20131363"
  paper_id: '124'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1124.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1124.jpg
  title: Joint Optimization of User-desired Content in Multi-document Summaries by
    Learning from User Feedback
  title_html: Joint Optimization of User-desired Content in Multi-document Summaries
    by Learning from User Feedback
  url: https://www.aclweb.org/anthology/P17-1124
  year: '2017'
P17-1125:
  abstract: It has been shown that Chinese poems can be successfully generated by
    sequence-to-sequence neural models, particularly with the attention mechanism.
    A potential problem of this approach, however, is that neural models can only
    learn abstract rules, while poem generation is a highly creative process that
    involves not only rules but also innovations for which pure statistical models
    are not appropriate in principle. This work proposes a memory augmented neural
    model for Chinese poem generation, where the neural model and the augmented memory
    work together to balance the requirements of linguistic accordance and aesthetic
    innovation, leading to innovative generations that are still rule-compliant. In
    addition, it is found that the memory mechanism provides interesting flexibility
    that can be used to generate poems with different styles.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1125.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1125.Notes.zip
  author:
  - first: Jiyuan
    full: Jiyuan Zhang
    id: jiyuan-zhang
    last: Zhang
  - first: Yang
    full: Yang Feng
    id: yang-feng
    last: Feng
  - first: Dong
    full: Dong Wang
    id: dong-wang
    last: Wang
  - first: Yang
    full: Yang Wang
    id: yang-wang
    last: Wang
  - first: Andrew
    full: Andrew Abel
    id: andrew-abel
    last: Abel
  - first: Shiyue
    full: Shiyue Zhang
    id: shiyue-zhang
    last: Zhang
  - first: Andi
    full: Andi Zhang
    id: andi-zhang
    last: Zhang
  author_string: Jiyuan Zhang, Yang Feng, Dong Wang, Yang Wang, Andrew Abel, Shiyue
    Zhang, Andi Zhang
  bibkey: zhang-etal-2017-flexible
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1125
  month: July
  page_first: '1364'
  page_last: '1373'
  pages: "1364\u20131373"
  paper_id: '125'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1125.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1125.jpg
  title: Flexible and Creative Chinese Poetry Generation Using Neural Memory
  title_html: Flexible and Creative <span class="acl-fixed-case">C</span>hinese Poetry
    Generation Using Neural Memory
  url: https://www.aclweb.org/anthology/P17-1125
  year: '2017'
P17-1126:
  abstract: This paper presents a novel encoder-decoder model for automatically generating
    market comments from stock prices. The model first encodes both short- and long-term
    series of stock prices so that it can mention short- and long-term changes in
    stock prices. In the decoding phase, our model can also generate a numerical value
    by selecting an appropriate arithmetic operation such as subtraction or rounding,
    and applying it to the input stock prices. Empirical experiments show that our
    best model generates market comments at the fluency and the informativeness approaching
    human-generated reference texts.
  address: Vancouver, Canada
  author:
  - first: Soichiro
    full: Soichiro Murakami
    id: soichiro-murakami
    last: Murakami
  - first: Akihiko
    full: Akihiko Watanabe
    id: akihiko-watanabe
    last: Watanabe
  - first: Akira
    full: Akira Miyazawa
    id: akira-miyazawa
    last: Miyazawa
  - first: Keiichi
    full: Keiichi Goshima
    id: keiichi-goshima
    last: Goshima
  - first: Toshihiko
    full: Toshihiko Yanase
    id: toshihiko-yanase
    last: Yanase
  - first: Hiroya
    full: Hiroya Takamura
    id: hiroya-takamura
    last: Takamura
  - first: Yusuke
    full: Yusuke Miyao
    id: yusuke-miyao
    last: Miyao
  author_string: Soichiro Murakami, Akihiko Watanabe, Akira Miyazawa, Keiichi Goshima,
    Toshihiko Yanase, Hiroya Takamura, Yusuke Miyao
  bibkey: murakami-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1126
  month: July
  page_first: '1374'
  page_last: '1384'
  pages: "1374\u20131384"
  paper_id: '126'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1126.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1126.jpg
  title: Learning to Generate Market Comments from Stock Prices
  title_html: Learning to Generate Market Comments from Stock Prices
  url: https://www.aclweb.org/anthology/P17-1126
  year: '2017'
P17-1127:
  abstract: 'In this paper, we study how to improve the domain adaptability of a deletion-based
    Long Short-Term Memory (LSTM) neural network model for sentence compression. We
    hypothesize that syntactic information helps in making such models more robust
    across domains. We propose two major changes to the model: using explicit syntactic
    features and introducing syntactic constraints through Integer Linear Programming
    (ILP). Our evaluation shows that the proposed model works better than the original
    model as well as a traditional non-neural-network-based model in a cross-domain
    setting.'
  address: Vancouver, Canada
  author:
  - first: Liangguo
    full: Liangguo Wang
    id: liangguo-wang
    last: Wang
  - first: Jing
    full: Jing Jiang
    id: jing-jiang
    last: Jiang
  - first: Hai Leong
    full: Hai Leong Chieu
    id: hai-leong-chieu
    last: Chieu
  - first: Chen Hui
    full: Chen Hui Ong
    id: chen-hui-ong
    last: Ong
  - first: Dandan
    full: Dandan Song
    id: dandan-song
    last: Song
  - first: Lejian
    full: Lejian Liao
    id: lejian-liao
    last: Liao
  author_string: Liangguo Wang, Jing Jiang, Hai Leong Chieu, Chen Hui Ong, Dandan
    Song, Lejian Liao
  bibkey: wang-etal-2017-syntax
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1127
  month: July
  page_first: '1385'
  page_last: '1393'
  pages: "1385\u20131393"
  paper_id: '127'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1127.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1127.jpg
  title: Can Syntax Help? Improving an LSTM-based Sentence Compression Model for New
    Domains
  title_html: Can Syntax Help? Improving an <span class="acl-fixed-case">LSTM</span>-based
    Sentence Compression Model for New Domains
  url: https://www.aclweb.org/anthology/P17-1127
  year: '2017'
P17-1128:
  abstract: Finding the correct hypernyms for entities is essential for taxonomy learning,
    fine-grained entity categorization, query understanding, etc. Due to the flexibility
    of the Chinese language, it is challenging to identify hypernyms in Chinese accurately.
    Rather than extracting hypernyms from texts, in this paper, we present a transductive
    learning approach to establish mappings from entities to hypernyms in the embedding
    space directly. It combines linear and non-linear embedding projection models,
    with the capacity of encoding arbitrary language-specific rules. Experiments on
    real-world datasets illustrate that our approach outperforms previous methods
    for Chinese hypernym prediction.
  address: Vancouver, Canada
  author:
  - first: Chengyu
    full: Chengyu Wang
    id: chengyu-wang
    last: Wang
  - first: Junchi
    full: Junchi Yan
    id: junchi-yan
    last: Yan
  - first: Aoying
    full: Aoying Zhou
    id: aoying-zhou
    last: Zhou
  - first: Xiaofeng
    full: Xiaofeng He
    id: xiaofeng-he
    last: He
  author_string: Chengyu Wang, Junchi Yan, Aoying Zhou, Xiaofeng He
  bibkey: wang-etal-2017-transductive
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1128
  month: July
  page_first: '1394'
  page_last: '1404'
  pages: "1394\u20131404"
  paper_id: '128'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1128.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1128.jpg
  title: Transductive Non-linear Learning for Chinese Hypernym Prediction
  title_html: Transductive Non-linear Learning for <span class="acl-fixed-case">C</span>hinese
    Hypernym Prediction
  url: https://www.aclweb.org/anthology/P17-1128
  year: '2017'
P17-1129:
  abstract: Reading comprehension (RC), aiming to understand natural texts and answer
    questions therein, is a challenging task. In this paper, we study the RC problem
    on the Stanford Question Answering Dataset (SQuAD). Observing from the training
    set that most correct answers are centered around constituents in the parse tree,
    we design a constituent-centric neural architecture where the generation of candidate
    answers and their representation learning are both based on constituents and guided
    by the parse tree. Under this architecture, the search space of candidate answers
    can be greatly reduced without sacrificing the coverage of correct answers and
    the syntactic, hierarchical and compositional structure among constituents can
    be well captured, which contributes to better representation learning of the candidate
    answers. On SQuAD, our method achieves the state of the art performance and the
    ablation study corroborates the effectiveness of individual modules.
  address: Vancouver, Canada
  author:
  - first: Pengtao
    full: Pengtao Xie
    id: pengtao-xie
    last: Xie
  - first: Eric
    full: Eric Xing
    id: eric-xing
    last: Xing
  author_string: Pengtao Xie, Eric Xing
  bibkey: xie-xing-2017-constituent
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1129
  month: July
  page_first: '1405'
  page_last: '1414'
  pages: "1405\u20131414"
  paper_id: '129'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1129.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1129.jpg
  title: A Constituent-Centric Neural Architecture for Reading Comprehension
  title_html: A Constituent-Centric Neural Architecture for Reading Comprehension
  url: https://www.aclweb.org/anthology/P17-1129
  year: '2017'
P17-1130:
  abstract: Cross-lingual text classification(CLTC) is the task of classifying documents
    written in different languages into the same taxonomy of categories. This paper
    presents a novel approach to CLTC that builds on model distillation, which adapts
    and extends a framework originally proposed for model compression. Using soft
    probabilistic predictions for the documents in a label-rich language as the (induced)
    supervisory labels in a parallel corpus of documents, we train classifiers successfully
    for new languages in which labeled training data are not available. An adversarial
    feature adaptation technique is also applied during the model training to reduce
    distribution mismatch. We conducted experiments on two benchmark CLTC datasets,
    treating English as the source language and German, French, Japan and Chinese
    as the unlabeled target languages. The proposed approach had the advantageous
    or comparable performance of the other state-of-art methods.
  address: Vancouver, Canada
  author:
  - first: Ruochen
    full: Ruochen Xu
    id: ruochen-xu
    last: Xu
  - first: Yiming
    full: Yiming Yang
    id: yiming-yang
    last: Yang
  author_string: Ruochen Xu, Yiming Yang
  bibkey: xu-yang-2017-cross
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1130
  month: July
  page_first: '1415'
  page_last: '1425'
  pages: "1415\u20131425"
  paper_id: '130'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1130.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1130.jpg
  title: Cross-lingual Distillation for Text Classification
  title_html: Cross-lingual Distillation for Text Classification
  url: https://www.aclweb.org/anthology/P17-1130
  year: '2017'
P17-1131:
  abstract: "Counselor empathy is associated with better outcomes in psychology and\
    \ behavioral counseling. In this paper, we explore several aspects pertaining\
    \ to counseling interaction dynamics and their relation to counselor empathy during\
    \ motivational interviewing encounters. Particularly, we analyze aspects such\
    \ as participants\u2019 engagement, participants\u2019 verbal and nonverbal accommodation,\
    \ as well as topics being discussed during the conversation, with the final goal\
    \ of identifying linguistic and acoustic markers of counselor empathy. We also\
    \ show how we can use these findings alongside other raw linguistic and acoustic\
    \ features to build accurate counselor empathy classifiers with accuracies of\
    \ up to 80%."
  address: Vancouver, Canada
  author:
  - first: "Ver\xF3nica"
    full: "Ver\xF3nica P\xE9rez-Rosas"
    id: veronica-perez-rosas
    last: "P\xE9rez-Rosas"
  - first: Rada
    full: Rada Mihalcea
    id: rada-mihalcea
    last: Mihalcea
  - first: Kenneth
    full: Kenneth Resnicow
    id: kenneth-resnicow
    last: Resnicow
  - first: Satinder
    full: Satinder Singh
    id: satinder-singh
    last: Singh
  - first: Lawrence
    full: Lawrence An
    id: lawrence-an
    last: An
  author_string: "Ver\xF3nica P\xE9rez-Rosas, Rada Mihalcea, Kenneth Resnicow, Satinder\
    \ Singh, Lawrence An"
  bibkey: perez-rosas-etal-2017-understanding
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1131
  month: July
  page_first: '1426'
  page_last: '1435'
  pages: "1426\u20131435"
  paper_id: '131'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1131.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1131.jpg
  title: Understanding and Predicting Empathic Behavior in Counseling Therapy
  title_html: Understanding and Predicting Empathic Behavior in Counseling Therapy
  url: https://www.aclweb.org/anthology/P17-1131
  year: '2017'
P17-1132:
  abstract: This paper focuses on how to take advantage of external knowledge bases
    (KBs) to improve recurrent neural networks for machine reading. Traditional methods
    that exploit knowledge from KBs encode knowledge as discrete indicator features.
    Not only do these features generalize poorly, but they require task-specific feature
    engineering to achieve good performance. We propose KBLSTM, a novel neural model
    that leverages continuous representations of KBs to enhance the learning of recurrent
    neural networks for machine reading. To effectively integrate background knowledge
    with information from the currently processed text, our model employs an attention
    mechanism with a sentinel to adaptively decide whether to attend to background
    knowledge and which information from KBs is useful. Experimental results show
    that our model achieves accuracies that surpass the previous state-of-the-art
    results for both entity extraction and event extraction on the widely used ACE2005
    dataset.
  address: Vancouver, Canada
  author:
  - first: Bishan
    full: Bishan Yang
    id: bishan-yang
    last: Yang
  - first: Tom
    full: Tom Mitchell
    id: tom-mitchell
    last: Mitchell
  author_string: Bishan Yang, Tom Mitchell
  bibkey: yang-mitchell-2017-leveraging
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1132
  month: July
  page_first: '1436'
  page_last: '1446'
  pages: "1436\u20131446"
  paper_id: '132'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1132.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1132.jpg
  title: Leveraging Knowledge Bases in LSTMs for Improving Machine Reading
  title_html: Leveraging Knowledge Bases in <span class="acl-fixed-case">LSTM</span>s
    for Improving Machine Reading
  url: https://www.aclweb.org/anthology/P17-1132
  year: '2017'
P17-1133:
  abstract: What prerequisite knowledge should students achieve a level of mastery
    before moving forward to learn subsequent coursewares? We study the extent to
    which the prerequisite relation between knowledge concepts in Massive Open Online
    Courses (MOOCs) can be inferred automatically. In particular, what kinds of information
    can be leverage to uncover the potential prerequisite relation between knowledge
    concepts. We first propose a representation learning-based method for learning
    latent representations of course concepts, and then investigate how different
    features capture the prerequisite relations between concepts. Our experiments
    on three datasets form Coursera show that the proposed method achieves significant
    improvements (+5.9-48.0% by F1-score) comparing with existing methods.
  address: Vancouver, Canada
  author:
  - first: Liangming
    full: Liangming Pan
    id: liangming-pan
    last: Pan
  - first: Chengjiang
    full: Chengjiang Li
    id: chengjiang-li
    last: Li
  - first: Juanzi
    full: Juanzi Li
    id: juanzi-li
    last: Li
  - first: Jie
    full: Jie Tang
    id: jie-tang
    last: Tang
  author_string: Liangming Pan, Chengjiang Li, Juanzi Li, Jie Tang
  bibkey: pan-etal-2017-prerequisite
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1133
  month: July
  page_first: '1447'
  page_last: '1456'
  pages: "1447\u20131456"
  paper_id: '133'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1133.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1133.jpg
  title: Prerequisite Relation Learning for Concepts in MOOCs
  title_html: Prerequisite Relation Learning for Concepts in <span class="acl-fixed-case">MOOC</span>s
  url: https://www.aclweb.org/anthology/P17-1133
  year: '2017'
P17-1134:
  abstract: Most work on segmenting text does so on the basis of topic changes, but
    it can be of interest to segment by other, stylistically expressed characteristics
    such as change of authorship or native language. We propose a Bayesian unsupervised
    text segmentation approach to the latter. While baseline models achieve essentially
    random segmentation on our task, indicating its difficulty, a Bayesian model that
    incorporates appropriately compact language models and alternating asymmetric
    priors can achieve scores on the standard metrics around halfway to perfect segmentation.
  address: Vancouver, Canada
  author:
  - first: Shervin
    full: Shervin Malmasi
    id: shervin-malmasi
    last: Malmasi
  - first: Mark
    full: Mark Dras
    id: mark-dras
    last: Dras
  - first: Mark
    full: Mark Johnson
    id: mark-johnson
    last: Johnson
  - first: Lan
    full: Lan Du
    id: lan-du
    last: Du
  - first: Magdalena
    full: Magdalena Wolska
    id: magdalena-wolska
    last: Wolska
  author_string: Shervin Malmasi, Mark Dras, Mark Johnson, Lan Du, Magdalena Wolska
  bibkey: malmasi-etal-2017-unsupervised
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1134
  month: July
  page_first: '1457'
  page_last: '1469'
  pages: "1457\u20131469"
  paper_id: '134'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1134.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1134.jpg
  title: Unsupervised Text Segmentation Based on Native Language Characteristics
  title_html: Unsupervised Text Segmentation Based on Native Language Characteristics
  url: https://www.aclweb.org/anthology/P17-1134
  year: '2017'
P17-1135:
  abstract: The state-of-the-art named entity recognition (NER) systems are supervised
    machine learning models that require large amounts of manually annotated data
    to achieve high accuracy. However, annotating NER data by human is expensive and
    time-consuming, and can be quite difficult for a new language. In this paper,
    we present two weakly supervised approaches for cross-lingual NER with no human
    annotation in a target language. The first approach is to create automatically
    labeled NER data for a target language via annotation projection on comparable
    corpora, where we develop a heuristic scheme that effectively selects good-quality
    projection-labeled data from noisy data. The second approach is to project distributed
    representations of words (word embeddings) from a target language to a source
    language, so that the source-language NER system can be applied to the target
    language without re-training. We also design two co-decoding schemes that effectively
    combine the outputs of the two projection-based approaches. We evaluate the performance
    of the proposed approaches on both in-house and open NER data for several target
    languages. The results show that the combined systems outperform three other weakly
    supervised approaches on the CoNLL data.
  address: Vancouver, Canada
  author:
  - first: Jian
    full: Jian Ni
    id: jian-ni
    last: Ni
  - first: Georgiana
    full: Georgiana Dinu
    id: georgiana-dinu
    last: Dinu
  - first: Radu
    full: Radu Florian
    id: radu-florian
    last: Florian
  author_string: Jian Ni, Georgiana Dinu, Radu Florian
  bibkey: ni-etal-2017-weakly
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1135
  month: July
  page_first: '1470'
  page_last: '1480'
  pages: "1470\u20131480"
  paper_id: '135'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1135.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1135.jpg
  title: Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation
    and Representation Projection
  title_html: Weakly Supervised Cross-Lingual Named Entity Recognition via Effective
    Annotation and Representation Projection
  url: https://www.aclweb.org/anthology/P17-1135
  year: '2017'
P17-1136:
  abstract: We introduce a composite deep neural network architecture for supervised
    and language independent context sensitive lemmatization. The proposed method
    considers the task as to identify the correct edit tree representing the transformation
    between a word-lemma pair. To find the lemma of a surface word, we exploit two
    successive bidirectional gated recurrent structures - the first one is used to
    extract the character level dependencies and the next one captures the contextual
    information of the given word. The key advantages of our model compared to the
    state-of-the-art lemmatizers such as Lemming and Morfette are - (i) it is independent
    of human decided features (ii) except the gold lemma, no other expensive morphological
    attribute is required for joint learning. We evaluate the lemmatizer on nine languages
    - Bengali, Catalan, Dutch, Hindi, Hungarian, Italian, Latin, Romanian and Spanish.
    It is found that except Bengali, the proposed method outperforms Lemming and Morfette
    on the other languages. To train the model on Bengali, we develop a gold lemma
    annotated dataset (having 1,702 sentences with a total of 20,257 word tokens),
    which is an additional contribution of this work.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1136.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1136.Software.zip
  - filename: P17-1136.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1136.Datasets.zip
  author:
  - first: Abhisek
    full: Abhisek Chakrabarty
    id: abhisek-chakrabarty
    last: Chakrabarty
  - first: Onkar Arun
    full: Onkar Arun Pandit
    id: onkar-arun-pandit
    last: Pandit
  - first: Utpal
    full: Utpal Garain
    id: utpal-garain
    last: Garain
  author_string: Abhisek Chakrabarty, Onkar Arun Pandit, Utpal Garain
  bibkey: chakrabarty-etal-2017-context
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1136
  month: July
  page_first: '1481'
  page_last: '1491'
  pages: "1481\u20131491"
  paper_id: '136'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1136.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1136.jpg
  title: Context Sensitive Lemmatization Using Two Successive Bidirectional Gated
    Recurrent Networks
  title_html: Context Sensitive Lemmatization Using Two Successive Bidirectional Gated
    Recurrent Networks
  url: https://www.aclweb.org/anthology/P17-1136
  year: '2017'
P17-1137:
  abstract: "Fixed-vocabulary language models fail to account for one of the most\
    \ characteristic statistical facts of natural language: the frequent creation\
    \ and reuse of new word types. Although character-level language models offer\
    \ a partial solution in that they can create word types not attested in the training\
    \ corpus, they do not capture the \u201Cbursty\u201D distribution of such words.\
    \ In this paper, we augment a hierarchical LSTM language model that generates\
    \ sequences of word tokens character by character with a caching mechanism that\
    \ learns to reuse previously generated words. To validate our model we construct\
    \ a new open-vocabulary language modeling corpus (the Multilingual Wikipedia Corpus;\
    \ MWC) from comparable Wikipedia articles in 7 typologically diverse languages\
    \ and demonstrate the effectiveness of our model across this range of languages."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1137.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1137.Datasets.zip
  author:
  - first: Kazuya
    full: Kazuya Kawakami
    id: kazuya-kawakami
    last: Kawakami
  - first: Chris
    full: Chris Dyer
    id: chris-dyer
    last: Dyer
  - first: Phil
    full: Phil Blunsom
    id: phil-blunsom
    last: Blunsom
  author_string: Kazuya Kawakami, Chris Dyer, Phil Blunsom
  bibkey: kawakami-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1137
  month: July
  page_first: '1492'
  page_last: '1502'
  pages: "1492\u20131502"
  paper_id: '137'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1137.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1137.jpg
  title: Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling
  title_html: Learning to Create and Reuse Words in Open-Vocabulary Neural Language
    Modeling
  url: https://www.aclweb.org/anthology/P17-1137
  year: '2017'
P17-1138:
  abstract: Bandit structured prediction describes a stochastic optimization framework
    where learning is performed from partial feedback. This feedback is received in
    the form of a task loss evaluation to a predicted output structure, without having
    access to gold standard structures. We advance this framework by lifting linear
    bandit learning to neural sequence-to-sequence learning problems using attention-based
    recurrent neural networks. Furthermore, we show how to incorporate control variates
    into our learning algorithms for variance reduction and improved generalization.
    We present an evaluation on a neural machine translation task that shows improvements
    of up to 5.89 BLEU points for domain adaptation from simulated bandit feedback.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1138.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1138.Poster.pdf
  author:
  - first: Julia
    full: Julia Kreutzer
    id: julia-kreutzer
    last: Kreutzer
  - first: Artem
    full: Artem Sokolov
    id: artem-sokolov
    last: Sokolov
  - first: Stefan
    full: Stefan Riezler
    id: stefan-riezler
    last: Riezler
  author_string: Julia Kreutzer, Artem Sokolov, Stefan Riezler
  bibkey: kreutzer-etal-2017-bandit
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1138
  month: July
  page_first: '1503'
  page_last: '1513'
  pages: "1503\u20131513"
  paper_id: '138'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1138.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1138.jpg
  title: Bandit Structured Prediction for Neural Sequence-to-Sequence Learning
  title_html: Bandit Structured Prediction for Neural Sequence-to-Sequence Learning
  url: https://www.aclweb.org/anthology/P17-1138
  year: '2017'
P17-1139:
  abstract: Although neural machine translation has made significant progress recently,
    how to integrate multiple overlapping, arbitrary prior knowledge sources remains
    a challenge. In this work, we propose to use posterior regularization to provide
    a general framework for integrating prior knowledge into neural machine translation.
    We represent prior knowledge sources as features in a log-linear model, which
    guides the learning processing of the neural translation model. Experiments on
    Chinese-English dataset show that our approach leads to significant improvements.
  address: Vancouver, Canada
  author:
  - first: Jiacheng
    full: Jiacheng Zhang
    id: jiacheng-zhang
    last: Zhang
  - first: Yang
    full: Yang Liu
    id: yang-liu-ict
    last: Liu
  - first: Huanbo
    full: Huanbo Luan
    id: huanbo-luan
    last: Luan
  - first: Jingfang
    full: Jingfang Xu
    id: jingfang-xu
    last: Xu
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Jiacheng Zhang, Yang Liu, Huanbo Luan, Jingfang Xu, Maosong Sun
  bibkey: zhang-etal-2017-prior
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1139
  month: July
  page_first: '1514'
  page_last: '1523'
  pages: "1514\u20131523"
  paper_id: '139'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1139.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1139.jpg
  title: Prior Knowledge Integration for Neural Machine Translation using Posterior
    Regularization
  title_html: Prior Knowledge Integration for Neural Machine Translation using Posterior
    Regularization
  url: https://www.aclweb.org/anthology/P17-1139
  year: '2017'
P17-1140:
  abstract: This paper proposes three distortion models to explicitly incorporate
    the word reordering knowledge into attention-based Neural Machine Translation
    (NMT) for further improving translation performance. Our proposed models enable
    attention mechanism to attend to source words regarding both the semantic requirement
    and the word reordering penalty. Experiments on Chinese-English translation show
    that the approaches can improve word alignment quality and achieve significant
    translation improvements over a basic attention-based NMT by large margins. Compared
    with previous works on identical corpora, our system achieves the state-of-the-art
    performance on translation quality.
  address: Vancouver, Canada
  author:
  - first: Jinchao
    full: Jinchao Zhang
    id: jinchao-zhang
    last: Zhang
  - first: Mingxuan
    full: Mingxuan Wang
    id: mingxuan-wang
    last: Wang
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  - first: Jie
    full: Jie Zhou
    id: jie-zhou
    last: Zhou
  author_string: Jinchao Zhang, Mingxuan Wang, Qun Liu, Jie Zhou
  bibkey: zhang-etal-2017-incorporating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1140
  month: July
  page_first: '1524'
  page_last: '1534'
  pages: "1524\u20131534"
  paper_id: '140'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1140.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1140.jpg
  title: Incorporating Word Reordering Knowledge into Attention-based Neural Machine
    Translation
  title_html: Incorporating Word Reordering Knowledge into Attention-based Neural
    Machine Translation
  url: https://www.aclweb.org/anthology/P17-1140
  year: '2017'
P17-1141:
  abstract: "We present Grid Beam Search (GBS), an algorithm which extends beam search\
    \ to allow the inclusion of pre-specified lexical constraints. The algorithm can\
    \ be used with any model which generates sequences token by token. Lexical constraints\
    \ take the form of phrases or words that must be present in the output sequence.\
    \ This is a very general way to incorporate auxillary knowledge into a model\u2019\
    s output without requiring any modification of the parameters or training data.\
    \ We demonstrate the feasibility and flexibility of Lexically Constrained Decoding\
    \ by conducting experiments on Neural Interactive-Predictive Translation, as well\
    \ as Domain Adaptation for Neural Machine Translation. Experiments show that GBS\
    \ can provide large improvements in translation quality in interactive scenarios,\
    \ and that, even without any user input, GBS can be used to achieve significant\
    \ gains in performance in domain adaptation scenarios."
  address: Vancouver, Canada
  author:
  - first: Chris
    full: Chris Hokamp
    id: chris-hokamp
    last: Hokamp
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  author_string: Chris Hokamp, Qun Liu
  bibkey: hokamp-liu-2017-lexically
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1141
  month: July
  page_first: '1535'
  page_last: '1546'
  pages: "1535\u20131546"
  paper_id: '141'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1141.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1141.jpg
  title: Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search
  title_html: Lexically Constrained Decoding for Sequence Generation Using Grid Beam
    Search
  url: https://www.aclweb.org/anthology/P17-1141
  year: '2017'
P17-1142:
  abstract: 'Human trafficking is a global epidemic affecting millions of people across
    the planet. Sex trafficking, the dominant form of human trafficking, has seen
    a significant rise mostly due to the abundance of escort websites, where human
    traffickers can openly advertise among at-will escort advertisements. In this
    paper, we take a major step in the automatic detection of advertisements suspected
    to pertain to human trafficking. We present a novel dataset called Trafficking-10k,
    with more than 10,000 advertisements annotated for this task. The dataset contains
    two sources of information per advertisement: text and images. For the accurate
    detection of trafficking advertisements, we designed and trained a deep multimodal
    model called the Human Trafficking Deep Network (HTDN).'
  address: Vancouver, Canada
  author:
  - first: Edmund
    full: Edmund Tong
    id: edmund-tong
    last: Tong
  - first: Amir
    full: Amir Zadeh
    id: amir-zadeh
    last: Zadeh
  - first: Cara
    full: Cara Jones
    id: cara-jones
    last: Jones
  - first: Louis-Philippe
    full: Louis-Philippe Morency
    id: louis-philippe-morency
    last: Morency
  author_string: Edmund Tong, Amir Zadeh, Cara Jones, Louis-Philippe Morency
  bibkey: tong-etal-2017-combating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1142
  month: July
  page_first: '1547'
  page_last: '1556'
  pages: "1547\u20131556"
  paper_id: '142'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1142.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1142.jpg
  title: Combating Human Trafficking with Multimodal Deep Models
  title_html: Combating Human Trafficking with Multimodal Deep Models
  url: https://www.aclweb.org/anthology/P17-1142
  year: '2017'
P17-1143:
  abstract: Cybersecurity risks and malware threats are becoming increasingly dangerous
    and common. Despite the severity of the problem, there has been few NLP efforts
    focused on tackling cybersecurity. In this paper, we discuss the construction
    of a new database for annotated malware texts. An annotation framework is introduced
    based on the MAEC vocabulary for defining malware characteristics, along with
    a database consisting of 39 annotated APT reports with a total of 6,819 sentences.
    We also use the database to construct models that can potentially help cybersecurity
    researchers in their data collection and analytics efforts.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1143.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1143.Notes.zip
  - filename: P17-1143.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1143.Datasets.zip
  author:
  - first: Swee Kiat
    full: Swee Kiat Lim
    id: swee-kiat-lim
    last: Lim
  - first: Aldrian Obaja
    full: Aldrian Obaja Muis
    id: aldrian-obaja-muis
    last: Muis
  - first: Wei
    full: Wei Lu
    id: wei-lu
    last: Lu
  - first: Chen Hui
    full: Chen Hui Ong
    id: chen-hui-ong
    last: Ong
  author_string: Swee Kiat Lim, Aldrian Obaja Muis, Wei Lu, Chen Hui Ong
  bibkey: lim-etal-2017-malwaretextdb
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1143
  month: July
  page_first: '1557'
  page_last: '1567'
  pages: "1557\u20131567"
  paper_id: '143'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1143.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1143.jpg
  title: 'MalwareTextDB: A Database for Annotated Malware Articles'
  title_html: '<span class="acl-fixed-case">M</span>alware<span class="acl-fixed-case">T</span>ext<span
    class="acl-fixed-case">DB</span>: A Database for Annotated Malware Articles'
  url: https://www.aclweb.org/anthology/P17-1143
  year: '2017'
P17-1144:
  abstract: "This paper presents ArgRewrite, a corpus of between-draft revisions of\
    \ argumentative essays. Drafts are manually aligned at the sentence level, and\
    \ the writer\u2019s purpose for each revision is annotated with categories analogous\
    \ to those used in argument mining and discourse analysis. The corpus should enable\
    \ advanced research in writing comparison and revision analysis, as demonstrated\
    \ via our own studies of student revision behavior and of automatic revision purpose\
    \ prediction."
  address: Vancouver, Canada
  author:
  - first: Fan
    full: Fan Zhang
    id: fan-zhang
    last: Zhang
  - first: Homa B.
    full: Homa B. Hashemi
    id: homa-b-hashemi
    last: Hashemi
  - first: Rebecca
    full: Rebecca Hwa
    id: rebecca-hwa
    last: Hwa
  - first: Diane
    full: Diane Litman
    id: diane-litman
    last: Litman
  author_string: Fan Zhang, Homa B. Hashemi, Rebecca Hwa, Diane Litman
  bibkey: zhang-etal-2017-corpus
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1144
  month: July
  page_first: '1568'
  page_last: '1578'
  pages: "1568\u20131578"
  paper_id: '144'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1144.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1144.jpg
  title: A Corpus of Annotated Revisions for Studying Argumentative Writing
  title_html: A Corpus of Annotated Revisions for Studying Argumentative Writing
  url: https://www.aclweb.org/anthology/P17-1144
  year: '2017'
P17-1145:
  abstract: This paper presents a new graph-based approach that induces synsets using
    synonymy dictionaries and word embeddings. First, we build a weighted graph of
    synonyms extracted from commonly available resources, such as Wiktionary. Second,
    we apply word sense induction to deal with ambiguous words. Finally, we cluster
    the disambiguated version of the ambiguous input graph into synsets. Our meta-clustering
    approach lets us use an efficient hard clustering algorithm to perform a fuzzy
    clustering of the graph. Despite its simplicity, our approach shows excellent
    results, outperforming five competitive state-of-the-art methods in terms of F-score
    on three gold standard datasets for English and Russian derived from large-scale
    manually constructed lexical resources.
  address: Vancouver, Canada
  author:
  - first: Dmitry
    full: Dmitry Ustalov
    id: dmitry-ustalov
    last: Ustalov
  - first: Alexander
    full: Alexander Panchenko
    id: alexander-panchenko
    last: Panchenko
  - first: Chris
    full: Chris Biemann
    id: chris-biemann
    last: Biemann
  author_string: Dmitry Ustalov, Alexander Panchenko, Chris Biemann
  bibkey: ustalov-etal-2017-watset
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1145
  month: July
  page_first: '1579'
  page_last: '1590'
  pages: "1579\u20131590"
  paper_id: '145'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1145.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1145.jpg
  title: 'Watset: Automatic Induction of Synsets from a Graph of Synonyms'
  title_html: '<span class="acl-fixed-case">W</span>atset: Automatic Induction of
    Synsets from a Graph of Synonyms'
  url: https://www.aclweb.org/anthology/P17-1145
  year: '2017'
P17-1146:
  abstract: The performance of Japanese predicate argument structure (PAS) analysis
    has improved in recent years thanks to the joint modeling of interactions between
    multiple predicates. However, this approach relies heavily on syntactic information
    predicted by parsers, and suffers from errorpropagation. To remedy this problem,
    we introduce a model that uses grid-type recurrent neural networks. The proposed
    model automatically induces features sensitive to multi-predicate interactions
    from the word sequence information of a sentence. Experiments on the NAIST Text
    Corpus demonstrate that without syntactic information, our model outperforms previous
    syntax-dependent models.
  address: Vancouver, Canada
  author:
  - first: Hiroki
    full: Hiroki Ouchi
    id: hiroki-ouchi
    last: Ouchi
  - first: Hiroyuki
    full: Hiroyuki Shindo
    id: hiroyuki-shindo
    last: Shindo
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Hiroki Ouchi, Hiroyuki Shindo, Yuji Matsumoto
  bibkey: ouchi-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1146
  month: July
  page_first: '1591'
  page_last: '1600'
  pages: "1591\u20131600"
  paper_id: '146'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1146.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1146.jpg
  title: Neural Modeling of Multi-Predicate Interactions for Japanese Predicate Argument
    Structure Analysis
  title_html: Neural Modeling of Multi-Predicate Interactions for <span class="acl-fixed-case">J</span>apanese
    Predicate Argument Structure Analysis
  url: https://www.aclweb.org/anthology/P17-1146
  year: '2017'
P17-1147:
  abstract: 'We present TriviaQA, a challenging reading comprehension dataset containing
    over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer
    pairs authored by trivia enthusiasts and independently gathered evidence documents,
    six per question on average, that provide high quality distant supervision for
    answering the questions. We show that, in comparison to other recently introduced
    large-scale datasets, TriviaQA (1) has relatively complex, compositional questions,
    (2) has considerable syntactic and lexical variability between questions and corresponding
    answer-evidence sentences, and (3) requires more cross sentence reasoning to find
    answers. We also present two baseline algorithms: a feature-based classifier and
    a state-of-the-art neural network, that performs well on SQuAD reading comprehension.
    Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting
    that TriviaQA is a challenging testbed that is worth significant future study.'
  address: Vancouver, Canada
  author:
  - first: Mandar
    full: Mandar Joshi
    id: mandar-joshi
    last: Joshi
  - first: Eunsol
    full: Eunsol Choi
    id: eunsol-choi
    last: Choi
  - first: Daniel
    full: Daniel Weld
    id: daniel-s-weld
    last: Weld
  - first: Luke
    full: Luke Zettlemoyer
    id: luke-zettlemoyer
    last: Zettlemoyer
  author_string: Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer
  bibkey: joshi-etal-2017-triviaqa
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1147
  month: July
  page_first: '1601'
  page_last: '1611'
  pages: "1601\u20131611"
  paper_id: '147'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1147.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1147.jpg
  title: 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading
    Comprehension'
  title_html: '<span class="acl-fixed-case">T</span>rivia<span class="acl-fixed-case">QA</span>:
    A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension'
  url: https://www.aclweb.org/anthology/P17-1147
  year: '2017'
P17-1148:
  abstract: We consider the problem of translating high-level textual descriptions
    to formal representations in technical documentation as part of an effort to model
    the meaning of such documentation. We focus specifically on the problem of learning
    translational correspondences between text descriptions and grounded representations
    in the target documentation, such as formal representation of functions or code
    templates. Our approach exploits the parallel nature of such documentation, or
    the tight coupling between high-level text and the low-level representations we
    aim to learn. Data is collected by mining technical documents for such parallel
    text-representation pairs, which we use to train a simple semantic parsing model.
    We report new baseline results on sixteen novel datasets, including the standard
    library documentation for nine popular programming languages across seven natural
    languages, and a small collection of Unix utility manuals.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1148.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1148.Notes.pdf
  author:
  - first: Kyle
    full: Kyle Richardson
    id: kyle-richardson
    last: Richardson
  - first: Jonas
    full: Jonas Kuhn
    id: jonas-kuhn
    last: Kuhn
  author_string: Kyle Richardson, Jonas Kuhn
  bibkey: richardson-kuhn-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1148
  month: July
  page_first: '1612'
  page_last: '1622'
  pages: "1612\u20131622"
  paper_id: '148'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1148.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1148.jpg
  title: Learning Semantic Correspondences in Technical Documentation
  title_html: Learning Semantic Correspondences in Technical Documentation
  url: https://www.aclweb.org/anthology/P17-1148
  year: '2017'
P17-1149:
  abstract: Integrating text and knowledge into a unified semantic space has attracted
    significant research interests recently. However, the ambiguity in the common
    space remains a challenge, namely that the same mention phrase usually refers
    to various entities. In this paper, to deal with the ambiguity of entity mentions,
    we propose a novel Multi-Prototype Mention Embedding model, which learns multiple
    sense embeddings for each mention by jointly modeling words from textual contexts
    and entities derived from a knowledge base. In addition, we further design an
    efficient language model based approach to disambiguate each mention to a specific
    sense. In experiments, both qualitative and quantitative analysis demonstrate
    the high quality of the word, entity and multi-prototype mention embeddings. Using
    entity linking as a study case, we apply our disambiguation method as well as
    the multi-prototype mention embeddings on the benchmark dataset, and achieve state-of-the-art
    performance.
  address: Vancouver, Canada
  author:
  - first: Yixin
    full: Yixin Cao
    id: yixin-cao
    last: Cao
  - first: Lifu
    full: Lifu Huang
    id: lifu-huang
    last: Huang
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  - first: Xu
    full: Xu Chen
    id: xu-chen
    last: Chen
  - first: Juanzi
    full: Juanzi Li
    id: juanzi-li
    last: Li
  author_string: Yixin Cao, Lifu Huang, Heng Ji, Xu Chen, Juanzi Li
  bibkey: cao-etal-2017-bridge
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1149
  month: July
  page_first: '1623'
  page_last: '1633'
  pages: "1623\u20131633"
  paper_id: '149'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1149.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1149.jpg
  title: Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding
  title_html: Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention
    Embedding
  url: https://www.aclweb.org/anthology/P17-1149
  year: '2017'
P17-1150:
  abstract: To enable human-robot communication and collaboration, previous works
    represent grounded verb semantics as the potential change of state to the physical
    world caused by these verbs. Grounded verb semantics are acquired mainly based
    on the parallel data of the use of a verb phrase and its corresponding sequences
    of primitive actions demonstrated by humans. The rich interaction between teachers
    and students that is considered important in learning new skills has not yet been
    explored. To address this limitation, this paper presents a new interactive learning
    approach that allows robots to proactively engage in interaction with human partners
    by asking good questions to learn models for grounded verb semantics. The proposed
    approach uses reinforcement learning to allow the robot to acquire an optimal
    policy for its question-asking behaviors by maximizing the long-term reward. Our
    empirical results have shown that the interactive learning approach leads to more
    reliable models for grounded verb semantics, especially in the noisy environment
    which is full of uncertainties. Compared to previous work, the models acquired
    from interactive learning result in a 48% to 145% performance gain when applied
    in new situations.
  address: Vancouver, Canada
  author:
  - first: Lanbo
    full: Lanbo She
    id: lanbo-she
    last: She
  - first: Joyce
    full: Joyce Chai
    id: joyce-chai
    last: Chai
  author_string: Lanbo She, Joyce Chai
  bibkey: she-chai-2017-interactive
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1150
  month: July
  page_first: '1634'
  page_last: '1644'
  pages: "1634\u20131644"
  paper_id: '150'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1150.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1150.jpg
  title: Interactive Learning of Grounded Verb Semantics towards Human-Robot Communication
  title_html: Interactive Learning of Grounded Verb Semantics towards Human-Robot
    Communication
  url: https://www.aclweb.org/anthology/P17-1150
  year: '2017'
P17-1151:
  abstract: Word embeddings provide point representations of words containing useful
    semantic information. We introduce multimodal word distributions formed from Gaussian
    mixtures, for multiple word meanings, entailment, and rich uncertainty information.
    To learn these distributions, we propose an energy-based max-margin objective.
    We show that the resulting approach captures uniquely expressive semantic information,
    and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings,
    on benchmark datasets such as word similarity and entailment.
  address: Vancouver, Canada
  author:
  - first: Ben
    full: Ben Athiwaratkun
    id: ben-athiwaratkun
    last: Athiwaratkun
  - first: Andrew
    full: Andrew Wilson
    id: andrew-wilson
    last: Wilson
  author_string: Ben Athiwaratkun, Andrew Wilson
  bibkey: athiwaratkun-wilson-2017-multimodal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1151
  month: July
  page_first: '1645'
  page_last: '1656'
  pages: "1645\u20131656"
  paper_id: '151'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1151.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1151.jpg
  title: Multimodal Word Distributions
  title_html: Multimodal Word Distributions
  url: https://www.aclweb.org/anthology/P17-1151
  year: '2017'
P17-1152:
  abstract: "Reasoning and inference are central to human and artificial intelligence.\
    \ Modeling inference in human language is very challenging. With the availability\
    \ of large annotated data (Bowman et al., 2015), it has recently become feasible\
    \ to train neural network based inference models, which have shown to be very\
    \ effective. In this paper, we present a new state-of-the-art result, achieving\
    \ the accuracy of 88.6% on the Stanford Natural Language Inference Dataset. Unlike\
    \ the previous top models that use very complicated network architectures, we\
    \ first demonstrate that carefully designing sequential inference models based\
    \ on chain LSTMs can outperform all previous models. Based on this, we further\
    \ show that by explicitly considering recursive architectures in both local inference\
    \ modeling and inference composition, we achieve additional improvement. Particularly,\
    \ incorporating syntactic parsing information contributes to our best result\u2014\
    it further improves the performance even when added to the already very strong\
    \ model."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1152.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1152.Poster.pdf
  author:
  - first: Qian
    full: Qian Chen
    id: qian-chen
    last: Chen
  - first: Xiaodan
    full: Xiaodan Zhu
    id: xiaodan-zhu
    last: Zhu
  - first: Zhen-Hua
    full: Zhen-Hua Ling
    id: zhen-hua-ling
    last: Ling
  - first: Si
    full: Si Wei
    id: si-wei
    last: Wei
  - first: Hui
    full: Hui Jiang
    id: hui-jiang
    last: Jiang
  - first: Diana
    full: Diana Inkpen
    id: diana-inkpen
    last: Inkpen
  author_string: Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, Diana Inkpen
  bibkey: chen-etal-2017-enhanced
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1152
  month: July
  page_first: '1657'
  page_last: '1668'
  pages: "1657\u20131668"
  paper_id: '152'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1152.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1152.jpg
  title: Enhanced LSTM for Natural Language Inference
  title_html: Enhanced <span class="acl-fixed-case">LSTM</span> for Natural Language
    Inference
  url: https://www.aclweb.org/anthology/P17-1152
  year: '2017'
P17-1153:
  abstract: "We examine differences in portrayal of characters in movies using psycholinguistic\
    \ and graph theoretic measures computed directly from screenplays. Differences\
    \ are examined with respect to characters\u2019 gender, race, age and other metadata.\
    \ Psycholinguistic metrics are extrapolated to dialogues in movies using a linear\
    \ regression model built on a set of manually annotated seed words. Interesting\
    \ patterns are revealed about relationships between genders of production team\
    \ and the gender ratio of characters. Several correlations are noted between gender,\
    \ race, age of characters and the linguistic metrics."
  address: Vancouver, Canada
  author:
  - first: Anil
    full: Anil Ramakrishna
    id: anil-ramakrishna
    last: Ramakrishna
  - first: Victor R.
    full: "Victor R. Mart\xEDnez"
    id: victor-r-martinez
    last: "Mart\xEDnez"
  - first: Nikolaos
    full: Nikolaos Malandrakis
    id: nikolaos-malandrakis
    last: Malandrakis
  - first: Karan
    full: Karan Singla
    id: karan-singla
    last: Singla
  - first: Shrikanth
    full: Shrikanth Narayanan
    id: shrikanth-narayanan
    last: Narayanan
  author_string: "Anil Ramakrishna, Victor R. Mart\xEDnez, Nikolaos Malandrakis, Karan\
    \ Singla, Shrikanth Narayanan"
  bibkey: ramakrishna-etal-2017-linguistic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1153
  month: July
  page_first: '1669'
  page_last: '1678'
  pages: "1669\u20131678"
  paper_id: '153'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1153.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1153.jpg
  title: Linguistic analysis of differences in portrayal of movie characters
  title_html: Linguistic analysis of differences in portrayal of movie characters
  url: https://www.aclweb.org/anthology/P17-1153
  year: '2017'
P17-1154:
  abstract: This paper deals with sentence-level sentiment classification. Though
    a variety of neural network models have been proposed recently, however, previous
    models either depend on expensive phrase-level annotation, most of which has remarkably
    degraded performance when trained with only sentence-level annotation; or do not
    fully employ linguistic resources (e.g., sentiment lexicons, negation words, intensity
    words). In this paper, we propose simple models trained with sentence-level annotation,
    but also attempt to model the linguistic role of sentiment lexicons, negation
    words, and intensity words. Results show that our models are able to capture the
    linguistic role of sentiment words, negation words, and intensity words in sentiment
    expression.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1154.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1154.Notes.pdf
  author:
  - first: Qiao
    full: Qiao Qian
    id: qiao-qian
    last: Qian
  - first: Minlie
    full: Minlie Huang
    id: minlie-huang
    last: Huang
  - first: Jinhao
    full: Jinhao Lei
    id: jinhao-lei
    last: Lei
  - first: Xiaoyan
    full: Xiaoyan Zhu
    id: xiaoyan-zhu
    last: Zhu
  author_string: Qiao Qian, Minlie Huang, Jinhao Lei, Xiaoyan Zhu
  bibkey: qian-etal-2017-linguistically
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1154
  month: July
  page_first: '1679'
  page_last: '1689'
  pages: "1679\u20131689"
  paper_id: '154'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1154.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1154.jpg
  title: Linguistically Regularized LSTM for Sentiment Classification
  title_html: Linguistically Regularized <span class="acl-fixed-case">LSTM</span>
    for Sentiment Classification
  url: https://www.aclweb.org/anthology/P17-1154
  year: '2017'
P17-1155:
  abstract: "Sarcasm is a form of speech in which speakers say the opposite of what\
    \ they truly mean in order to convey a strong sentiment. In other words, \u201C\
    Sarcasm is the giant chasm between what I say, and the person who doesn\u2019\
    t get it.\u201D. In this paper we present the novel task of sarcasm interpretation,\
    \ defined as the generation of a non-sarcastic utterance conveying the same message\
    \ as the original sarcastic one. We introduce a novel dataset of 3000 sarcastic\
    \ tweets, each interpreted by five human judges. Addressing the task as monolingual\
    \ machine translation (MT), we experiment with MT algorithms and evaluation measures.\
    \ We then present SIGN: an MT based sarcasm interpretation algorithm that targets\
    \ sentiment words, a defining element of textual sarcasm. We show that while the\
    \ scores of n-gram based automatic measures are similar for all interpretation\
    \ models, SIGN\u2019s interpretations are scored higher by humans for adequacy\
    \ and sentiment polarity. We conclude with a discussion on future research directions\
    \ for our new task."
  address: Vancouver, Canada
  author:
  - first: Lotem
    full: Lotem Peled
    id: lotem-peled
    last: Peled
  - first: Roi
    full: Roi Reichart
    id: roi-reichart
    last: Reichart
  author_string: Lotem Peled, Roi Reichart
  bibkey: peled-reichart-2017-sarcasm
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1155
  month: July
  page_first: '1690'
  page_last: '1700'
  pages: "1690\u20131700"
  paper_id: '155'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1155.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1155.jpg
  title: 'Sarcasm SIGN: Interpreting Sarcasm with Sentiment Based Monolingual Machine
    Translation'
  title_html: 'Sarcasm <span class="acl-fixed-case">SIGN</span>: Interpreting Sarcasm
    with Sentiment Based Monolingual Machine Translation'
  url: https://www.aclweb.org/anthology/P17-1155
  year: '2017'
P17-1156:
  abstract: Domain adaptation is an important technology to handle domain dependence
    problem in sentiment analysis field. Existing methods usually rely on sentiment
    classifiers trained in source domains. However, their performance may heavily
    decline if the distributions of sentiment features in source and target domains
    have significant difference. In this paper, we propose an active sentiment domain
    adaptation approach to handle this problem. Instead of the source domain sentiment
    classifiers, our approach adapts the general-purpose sentiment lexicons to target
    domain with the help of a small number of labeled samples which are selected and
    annotated in an active learning mode, as well as the domain-specific sentiment
    similarities among words mined from unlabeled samples of target domain. A unified
    model is proposed to fuse different types of sentiment information and train sentiment
    classifier for target domain. Extensive experiments on benchmark datasets show
    that our approach can train accurate sentiment classifier with less labeled samples.
  address: Vancouver, Canada
  author:
  - first: Fangzhao
    full: Fangzhao Wu
    id: fangzhao-wu
    last: Wu
  - first: Yongfeng
    full: Yongfeng Huang
    id: yongfeng-huang
    last: Huang
  - first: Jun
    full: Jun Yan
    id: jun-yan
    last: Yan
  author_string: Fangzhao Wu, Yongfeng Huang, Jun Yan
  bibkey: wu-etal-2017-active
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1156
  month: July
  page_first: '1701'
  page_last: '1711'
  pages: "1701\u20131711"
  paper_id: '156'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1156.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1156.jpg
  title: Active Sentiment Domain Adaptation
  title_html: Active Sentiment Domain Adaptation
  url: https://www.aclweb.org/anthology/P17-1156
  year: '2017'
P17-1157:
  abstract: "Volatility prediction\u2014an essential concept in financial markets\u2014\
    has recently been addressed using sentiment analysis methods. We investigate the\
    \ sentiment of annual disclosures of companies in stock markets to forecast volatility.\
    \ We specifically explore the use of recent Information Retrieval (IR) term weighting\
    \ models that are effectively extended by related terms using word embeddings.\
    \ In parallel to textual information, factual market data have been widely used\
    \ as the mainstream approach to forecast market risk. We therefore study different\
    \ fusion methods to combine text and market data resources. Our word embedding-based\
    \ approach significantly outperforms state-of-the-art methods. In addition, we\
    \ investigate the characteristics of the reports of the companies in different\
    \ financial sectors."
  address: Vancouver, Canada
  author:
  - first: Navid
    full: Navid Rekabsaz
    id: navid-rekabsaz
    last: Rekabsaz
  - first: Mihai
    full: Mihai Lupu
    id: mihai-lupu
    last: Lupu
  - first: Artem
    full: Artem Baklanov
    id: artem-baklanov
    last: Baklanov
  - first: Alexander
    full: "Alexander D\xFCr"
    id: alexander-dur
    last: "D\xFCr"
  - first: Linda
    full: Linda Andersson
    id: linda-andersson
    last: Andersson
  - first: Allan
    full: Allan Hanbury
    id: allan-hanbury
    last: Hanbury
  author_string: "Navid Rekabsaz, Mihai Lupu, Artem Baklanov, Alexander D\xFCr, Linda\
    \ Andersson, Allan Hanbury"
  bibkey: rekabsaz-etal-2017-volatility
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1157
  month: July
  page_first: '1712'
  page_last: '1721'
  pages: "1712\u20131721"
  paper_id: '157'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1157.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1157.jpg
  title: Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based
    IR Models
  title_html: Volatility Prediction using Financial Disclosures Sentiments with Word
    Embedding-based <span class="acl-fixed-case">IR</span> Models
  url: https://www.aclweb.org/anthology/P17-1157
  year: '2017'
P17-1158:
  abstract: Network embedding (NE) is playing a critical role in network analysis,
    due to its ability to represent vertices with efficient low-dimensional embedding
    vectors. However, existing NE models aim to learn a fixed context-free embedding
    for each vertex and neglect the diverse roles when interacting with other vertices.
    In this paper, we assume that one vertex usually shows different aspects when
    interacting with different neighbor vertices, and should own different embeddings
    respectively. Therefore, we present Context-Aware Network Embedding (CANE), a
    novel NE model to address this issue. CANE learns context-aware embeddings for
    vertices with mutual attention mechanism and is expected to model the semantic
    relationships between vertices more precisely. In experiments, we compare our
    model with existing NE models on three real-world datasets. Experimental results
    show that CANE achieves significant improvement than state-of-the-art methods
    on link prediction and comparable performance on vertex classification. The source
    code and datasets can be obtained from https://github.com/thunlp/CANE.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1158.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1158.Software.zip
  - filename: P17-1158.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1158.Datasets.zip
  author:
  - first: Cunchao
    full: Cunchao Tu
    id: cunchao-tu
    last: Tu
  - first: Han
    full: Han Liu
    id: han-liu
    last: Liu
  - first: Zhiyuan
    full: Zhiyuan Liu
    id: zhiyuan-liu
    last: Liu
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Cunchao Tu, Han Liu, Zhiyuan Liu, Maosong Sun
  bibkey: tu-etal-2017-cane
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1158
  month: July
  page_first: '1722'
  page_last: '1731'
  pages: "1722\u20131731"
  paper_id: '158'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1158.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1158.jpg
  title: 'CANE: Context-Aware Network Embedding for Relation Modeling'
  title_html: '<span class="acl-fixed-case">CANE</span>: Context-Aware Network Embedding
    for Relation Modeling'
  url: https://www.aclweb.org/anthology/P17-1158
  year: '2017'
P17-1159:
  abstract: Singlish can be interesting to the ACL community both linguistically as
    a major creole based on English, and computationally for information extraction
    and sentiment analysis of regional social media. We investigate dependency parsing
    of Singlish by constructing a dependency treebank under the Universal Dependencies
    scheme, and then training a neural network model by integrating English syntactic
    knowledge into a state-of-the-art parser trained on the Singlish treebank. Results
    show that English knowledge can lead to 25% relative error reduction, resulting
    in a parser of 84.47% accuracies. To the best of our knowledge, we are the first
    to use neural stacking to improve cross-lingual dependency parsing on low-resource
    languages. We make both our annotation and parser available for further research.
  address: Vancouver, Canada
  author:
  - first: Hongmin
    full: Hongmin Wang
    id: hongmin-wang
    last: Wang
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: GuangYong Leonard
    full: GuangYong Leonard Chan
    id: guangyong-leonard-chan
    last: Chan
  - first: Jie
    full: Jie Yang
    id: jie-yang
    last: Yang
  - first: Hai Leong
    full: Hai Leong Chieu
    id: hai-leong-chieu
    last: Chieu
  author_string: Hongmin Wang, Yue Zhang, GuangYong Leonard Chan, Jie Yang, Hai Leong
    Chieu
  bibkey: wang-etal-2017-universal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1159
  month: July
  page_first: '1732'
  page_last: '1744'
  pages: "1732\u20131744"
  paper_id: '159'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1159.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1159.jpg
  title: Universal Dependencies Parsing for Colloquial Singaporean English
  title_html: Universal Dependencies Parsing for Colloquial Singaporean <span class="acl-fixed-case">E</span>nglish
  url: https://www.aclweb.org/anthology/P17-1159
  year: '2017'
P17-1160:
  abstract: 'We present a simple encoding for unlabeled noncrossing graphs and show
    how its latent counterpart helps us to represent several families of directed
    and undirected graphs used in syntactic and semantic parsing of natural language
    as context-free languages. The families are separated purely on the basis of forbidden
    patterns in latent encoding, eliminating the need to differentiate the families
    of non-crossing graphs in inference algorithms: one algorithm works for all when
    the search space can be controlled in parser input.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1160.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1160.Poster.pdf
  - filename: P17-1160.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1160.Software.zip
  author:
  - first: Anssi
    full: "Anssi Yli-Jyr\xE4"
    id: anssi-yli-jyra
    last: "Yli-Jyr\xE4"
  - first: Carlos
    full: "Carlos G\xF3mez-Rodr\xEDguez"
    id: carlos-gomez-rodriguez
    last: "G\xF3mez-Rodr\xEDguez"
  author_string: "Anssi Yli-Jyr\xE4, Carlos G\xF3mez-Rodr\xEDguez"
  bibkey: yli-jyra-gomez-rodriguez-2017-generic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1160
  month: July
  page_first: '1745'
  page_last: '1755'
  pages: "1745\u20131755"
  paper_id: '160'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1160.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1160.jpg
  title: Generic Axiomatization of Families of Noncrossing Graphs in Dependency Parsing
  title_html: Generic Axiomatization of Families of Noncrossing Graphs in Dependency
    Parsing
  url: https://www.aclweb.org/anthology/P17-1160
  year: '2017'
P17-1161:
  abstract: Pre-trained word embeddings learned from unlabeled text have become a
    standard component of neural network architectures for NLP tasks. However, in
    most cases, the recurrent network that operates on word-level representations
    to produce context sensitive representations is trained on relatively little labeled
    data. In this paper, we demonstrate a general semi-supervised approach for adding
    pretrained context embeddings from bidirectional language models to NLP systems
    and apply it to sequence labeling tasks. We evaluate our model on two standard
    datasets for named entity recognition (NER) and chunking, and in both cases achieve
    state of the art results, surpassing previous systems that use other forms of
    transfer or joint learning with additional labeled data and task specific gazetteers.
  address: Vancouver, Canada
  author:
  - first: Matthew
    full: Matthew Peters
    id: matthew-peters
    last: Peters
  - first: Waleed
    full: Waleed Ammar
    id: waleed-ammar
    last: Ammar
  - first: Chandra
    full: Chandra Bhagavatula
    id: chandra-bhagavatula
    last: Bhagavatula
  - first: Russell
    full: Russell Power
    id: russell-power
    last: Power
  author_string: Matthew Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power
  bibkey: peters-etal-2017-semi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1161
  month: July
  page_first: '1756'
  page_last: '1765'
  pages: "1756\u20131765"
  paper_id: '161'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1161.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1161.jpg
  title: Semi-supervised sequence tagging with bidirectional language models
  title_html: Semi-supervised sequence tagging with bidirectional language models
  url: https://www.aclweb.org/anthology/P17-1161
  year: '2017'
P17-1162:
  abstract: We study a symmetric collaborative dialogue setting in which two agents,
    each with private knowledge, must strategically communicate to achieve a common
    goal. The open-ended dialogue state in this setting poses new challenges for existing
    dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits
    interesting lexical, semantic, and strategic elements. To model both structured
    knowledge and unstructured language, we propose a neural model with dynamic knowledge
    graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations
    show that our model is both more effective at achieving the goal and more human-like
    than baseline neural and rule-based models.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1162.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1162.Notes.pdf
  author:
  - first: He
    full: He He
    id: he-he
    last: He
  - first: Anusha
    full: Anusha Balakrishnan
    id: anusha-balakrishnan
    last: Balakrishnan
  - first: Mihail
    full: Mihail Eric
    id: mihail-eric
    last: Eric
  - first: Percy
    full: Percy Liang
    id: percy-liang
    last: Liang
  author_string: He He, Anusha Balakrishnan, Mihail Eric, Percy Liang
  bibkey: he-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1162
  month: July
  page_first: '1766'
  page_last: '1776'
  pages: "1766\u20131776"
  paper_id: '162'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1162.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1162.jpg
  title: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph
    Embeddings
  title_html: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge
    Graph Embeddings
  url: https://www.aclweb.org/anthology/P17-1162
  year: '2017'
P17-1163:
  abstract: "One of the core components of modern spoken dialogue systems is the belief\
    \ tracker, which estimates the user\u2019s goal at every step of the dialogue.\
    \ However, most current approaches have difficulty scaling to larger, more complex\
    \ dialogue domains. This is due to their dependency on either: a) Spoken Language\
    \ Understanding models that require large amounts of annotated training data;\
    \ or b) hand-crafted lexicons for capturing some of the linguistic variation in\
    \ users\u2019 language. We propose a novel Neural Belief Tracking (NBT) framework\
    \ which overcomes these problems by building on recent advances in representation\
    \ learning. NBT models reason over pre-trained word vectors, learning to compose\
    \ them into distributed representations of user utterances and dialogue context.\
    \ Our evaluation on two datasets shows that this approach surpasses past limitations,\
    \ matching the performance of state-of-the-art models which rely on hand-crafted\
    \ semantic lexicons and outperforming them when such lexicons are not provided."
  address: Vancouver, Canada
  author:
  - first: Nikola
    full: "Nikola Mrk\u0161i\u0107"
    id: nikola-mrksic
    last: "Mrk\u0161i\u0107"
  - first: Diarmuid
    full: "Diarmuid \xD3 S\xE9aghdha"
    id: diarmuid-o-seaghdha
    last: "\xD3 S\xE9aghdha"
  - first: Tsung-Hsien
    full: Tsung-Hsien Wen
    id: tsung-hsien-wen
    last: Wen
  - first: Blaise
    full: Blaise Thomson
    id: blaise-thomson
    last: Thomson
  - first: Steve
    full: Steve Young
    id: steve-young
    last: Young
  author_string: "Nikola Mrk\u0161i\u0107, Diarmuid \xD3 S\xE9aghdha, Tsung-Hsien\
    \ Wen, Blaise Thomson, Steve Young"
  bibkey: mrksic-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1163
  month: July
  page_first: '1777'
  page_last: '1788'
  pages: "1777\u20131788"
  paper_id: '163'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1163.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1163.jpg
  title: 'Neural Belief Tracker: Data-Driven Dialogue State Tracking'
  title_html: 'Neural Belief Tracker: Data-Driven Dialogue State Tracking'
  url: https://www.aclweb.org/anthology/P17-1163
  year: '2017'
P17-1164:
  abstract: This paper tackles the task of event detection (ED), which involves identifying
    and categorizing events. We argue that arguments provide significant clues to
    this task, but they are either completely ignored or exploited in an indirect
    manner in existing detection approaches. In this work, we propose to exploit argument
    information explicitly for ED via supervised attention mechanisms. In specific,
    we systematically investigate the proposed model under the supervision of different
    attention strategies. Experimental results show that our approach advances state-of-the-arts
    and achieves the best F1 score on ACE 2005 dataset.
  address: Vancouver, Canada
  author:
  - first: Shulin
    full: Shulin Liu
    id: shulin-liu
    last: Liu
  - first: Yubo
    full: Yubo Chen
    id: yubo-chen
    last: Chen
  - first: Kang
    full: Kang Liu
    id: kang-liu
    last: Liu
  - first: Jun
    full: Jun Zhao
    id: jun-zhao
    last: Zhao
  author_string: Shulin Liu, Yubo Chen, Kang Liu, Jun Zhao
  bibkey: liu-etal-2017-exploiting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1164
  month: July
  page_first: '1789'
  page_last: '1798'
  pages: "1789\u20131798"
  paper_id: '164'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1164.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1164.jpg
  title: Exploiting Argument Information to Improve Event Detection via Supervised
    Attention Mechanisms
  title_html: Exploiting Argument Information to Improve Event Detection via Supervised
    Attention Mechanisms
  url: https://www.aclweb.org/anthology/P17-1164
  year: '2017'
P17-1165:
  abstract: This paper presents an LDA-based model that generates topically coherent
    segments within documents by jointly segmenting documents and assigning topics
    to their words. The coherence between topics is ensured through a copula, binding
    the topics associated to the words of a segment. In addition, this model relies
    on both document and segment specific topic distributions so as to capture fine
    grained differences in topic assignments. We show that the proposed model naturally
    encompasses other state-of-the-art LDA-based models designed for similar tasks.
    Furthermore, our experiments, conducted on six different publicly available datasets,
    show the effectiveness of our model in terms of perplexity, Normalized Pointwise
    Mutual Information, which captures the coherence between the generated topics,
    and the Micro F1 measure for text classification.
  address: Vancouver, Canada
  author:
  - first: Hesam
    full: Hesam Amoualian
    id: hesam-amoualian
    last: Amoualian
  - first: Wei
    full: Wei Lu
    id: wei-lu
    last: Lu
  - first: Eric
    full: Eric Gaussier
    id: eric-gaussier
    last: Gaussier
  - first: Georgios
    full: Georgios Balikas
    id: georgios-balikas
    last: Balikas
  - first: Massih R.
    full: Massih R. Amini
    id: massih-r-amini
    last: Amini
  - first: Marianne
    full: Marianne Clausel
    id: marianne-clausel
    last: Clausel
  author_string: Hesam Amoualian, Wei Lu, Eric Gaussier, Georgios Balikas, Massih
    R. Amini, Marianne Clausel
  bibkey: amoualian-etal-2017-topical
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1165
  month: July
  page_first: '1799'
  page_last: '1809'
  pages: "1799\u20131809"
  paper_id: '165'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1165.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1165.jpg
  title: Topical Coherence in LDA-based Models through Induced Segmentation
  title_html: Topical Coherence in <span class="acl-fixed-case">LDA</span>-based Models
    through Induced Segmentation
  url: https://www.aclweb.org/anthology/P17-1165
  year: '2017'
P17-1166:
  abstract: Connections between relations in relation extraction, which we call class
    ties, are common. In distantly supervised scenario, one entity tuple may have
    multiple relation facts. Exploiting class ties between relations of one entity
    tuple will be promising for distantly supervised relation extraction. However,
    previous models are not effective or ignore to model this property. In this work,
    to effectively leverage class ties, we propose to make joint relation extraction
    with a unified model that integrates convolutional neural network (CNN) with a
    general pairwise ranking framework, in which three novel ranking loss functions
    are introduced. Additionally, an effective method is presented to relieve the
    severe class imbalance problem from NR (not relation) for model training. Experiments
    on a widely used dataset show that leveraging class ties will enhance extraction
    and demonstrate the effectiveness of our model to learn class ties. Our model
    outperforms the baselines significantly, achieving state-of-the-art performance.
  address: Vancouver, Canada
  author:
  - first: Hai
    full: Hai Ye
    id: hai-ye
    last: Ye
  - first: Wenhan
    full: Wenhan Chao
    id: wenhan-chao
    last: Chao
  - first: Zhunchen
    full: Zhunchen Luo
    id: zhunchen-luo
    last: Luo
  - first: Zhoujun
    full: Zhoujun Li
    id: zhoujun-li
    last: Li
  author_string: Hai Ye, Wenhan Chao, Zhunchen Luo, Zhoujun Li
  bibkey: ye-etal-2017-jointly
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1166
  month: July
  page_first: '1810'
  page_last: '1820'
  pages: "1810\u20131820"
  paper_id: '166'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1166.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1166.jpg
  title: Jointly Extracting Relations with Class Ties via Effective Deep Ranking
  title_html: Jointly Extracting Relations with Class Ties via Effective Deep Ranking
  url: https://www.aclweb.org/anthology/P17-1166
  year: '2017'
P17-1167:
  abstract: 'Recent work in semantic parsing for question answering has focused on
    long and complicated questions, many of which would seem unnatural if asked in
    a normal conversation between two humans. In an effort to explore a conversational
    QA setting, we present a more realistic task: answering sequences of simple but
    inter-related questions. We collect a dataset of 6,066 question sequences that
    inquire about semi-structured tables from Wikipedia, with 17,553 question-answer
    pairs in total. To solve this sequential question answering task, we propose a
    novel dynamic neural semantic parsing framework trained using a weakly supervised
    reward-guided search. Our model effectively leverages the sequential context to
    outperform state-of-the-art QA systems that are designed to answer highly complex
    questions.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1167.Presentation.pptx
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-1167.Presentation.pptx
  author:
  - first: Mohit
    full: Mohit Iyyer
    id: mohit-iyyer
    last: Iyyer
  - first: Wen-tau
    full: Wen-tau Yih
    id: wen-tau-yih
    last: Yih
  - first: Ming-Wei
    full: Ming-Wei Chang
    id: ming-wei-chang
    last: Chang
  author_string: Mohit Iyyer, Wen-tau Yih, Ming-Wei Chang
  bibkey: iyyer-etal-2017-search
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1167
  month: July
  page_first: '1821'
  page_last: '1831'
  pages: "1821\u20131831"
  paper_id: '167'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1167.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1167.jpg
  title: Search-based Neural Structured Learning for Sequential Question Answering
  title_html: Search-based Neural Structured Learning for Sequential Question Answering
  url: https://www.aclweb.org/anthology/P17-1167
  year: '2017'
P17-1168:
  abstract: "In this paper we study the problem of answering cloze-style questions\
    \ over documents. Our model, the Gated-Attention (GA) Reader, integrates a multi-hop\
    \ architecture with a novel attention mechanism, which is based on multiplicative\
    \ interactions between the query embedding and the intermediate states of a recurrent\
    \ neural network document reader. This enables the reader to build query-specific\
    \ representations of tokens in the document for accurate answer selection. The\
    \ GA Reader obtains state-of-the-art results on three benchmarks for this task\u2013\
    the CNN & Daily Mail news stories and the Who Did What dataset. The effectiveness\
    \ of multiplicative interaction is demonstrated by an ablation study, and by comparing\
    \ to alternative compositional operators for implementing the gated-attention."
  address: Vancouver, Canada
  author:
  - first: Bhuwan
    full: Bhuwan Dhingra
    id: bhuwan-dhingra
    last: Dhingra
  - first: Hanxiao
    full: Hanxiao Liu
    id: hanxiao-liu
    last: Liu
  - first: Zhilin
    full: Zhilin Yang
    id: zhilin-yang
    last: Yang
  - first: William
    full: William Cohen
    id: william-cohen
    last: Cohen
  - first: Ruslan
    full: Ruslan Salakhutdinov
    id: ruslan-salakhutdinov
    last: Salakhutdinov
  author_string: Bhuwan Dhingra, Hanxiao Liu, Zhilin Yang, William Cohen, Ruslan Salakhutdinov
  bibkey: dhingra-etal-2017-gated
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1168
  month: July
  page_first: '1832'
  page_last: '1846'
  pages: "1832\u20131846"
  paper_id: '168'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1168.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1168.jpg
  title: Gated-Attention Readers for Text Comprehension
  title_html: Gated-Attention Readers for Text Comprehension
  url: https://www.aclweb.org/anthology/P17-1168
  year: '2017'
P17-1169:
  abstract: Word embeddings have become widely-used in document analysis. While a
    large number of models for mapping words to vector spaces have been developed,
    it remains undetermined how much net gain can be achieved over traditional approaches
    based on bag-of-words. In this paper, we propose a new document clustering approach
    by combining any word embedding with a state-of-the-art algorithm for clustering
    empirical distributions. By using the Wasserstein distance between distributions,
    the word-to-word semantic relationship is taken into account in a principled way.
    The new clustering method is easy to use and consistently outperforms other methods
    on a variety of data sets. More importantly, the method provides an effective
    framework for determining when and how much word embeddings contribute to document
    analysis. Experimental results with multiple embedding models are reported.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1169.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1169.Notes.pdf
  author:
  - first: Jianbo
    full: Jianbo Ye
    id: jianbo-ye
    last: Ye
  - first: Yanran
    full: Yanran Li
    id: yanran-li
    last: Li
  - first: Zhaohui
    full: Zhaohui Wu
    id: zhaohui-wu
    last: Wu
  - first: James Z.
    full: James Z. Wang
    id: james-z-wang
    last: Wang
  - first: Wenjie
    full: Wenjie Li
    id: wenjie-li
    last: Li
  - first: Jia
    full: Jia Li
    id: jia-li
    last: Li
  author_string: Jianbo Ye, Yanran Li, Zhaohui Wu, James Z. Wang, Wenjie Li, Jia Li
  bibkey: ye-etal-2017-determining
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1169
  month: July
  page_first: '1847'
  page_last: '1856'
  pages: "1847\u20131856"
  paper_id: '169'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1169.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1169.jpg
  title: Determining Gains Acquired from Word Embedding Quantitatively Using Discrete
    Distribution Clustering
  title_html: Determining Gains Acquired from Word Embedding Quantitatively Using
    Discrete Distribution Clustering
  url: https://www.aclweb.org/anthology/P17-1169
  year: '2017'
P17-1170:
  abstract: Lexical ambiguity can impede NLP systems from accurate understanding of
    semantics. Despite its potential benefits, the integration of sense-level information
    into NLP systems has remained understudied. By incorporating a novel disambiguation
    algorithm into a state-of-the-art classification model, we create a pipeline to
    integrate sense-level information into downstream NLP applications. We show that
    a simple disambiguation of the input text can lead to consistent performance improvement
    on multiple topic categorization and polarity detection datasets, particularly
    when the fine granularity of the underlying sense inventory is reduced and the
    document is sufficiently large. Our results also point to the need for sense representation
    research to focus more on in vivo evaluations which target the performance in
    downstream NLP applications rather than artificial benchmarks.
  address: Vancouver, Canada
  author:
  - first: Mohammad Taher
    full: Mohammad Taher Pilehvar
    id: mohammad-taher-pilehvar
    last: Pilehvar
  - first: Jose
    full: Jose Camacho-Collados
    id: jose-camacho-collados
    last: Camacho-Collados
  - first: Roberto
    full: Roberto Navigli
    id: roberto-navigli
    last: Navigli
  - first: Nigel
    full: Nigel Collier
    id: nigel-collier
    last: Collier
  author_string: Mohammad Taher Pilehvar, Jose Camacho-Collados, Roberto Navigli,
    Nigel Collier
  bibkey: pilehvar-etal-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1170
  month: July
  page_first: '1857'
  page_last: '1869'
  pages: "1857\u20131869"
  paper_id: '170'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1170.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1170.jpg
  title: Towards a Seamless Integration of Word Senses into Downstream NLP Applications
  title_html: Towards a Seamless Integration of Word Senses into Downstream <span
    class="acl-fixed-case">NLP</span> Applications
  url: https://www.aclweb.org/anthology/P17-1170
  year: '2017'
P17-1171:
  abstract: 'This paper proposes to tackle open-domain question answering using Wikipedia
    as the unique knowledge source: the answer to any factoid question is a text span
    in a Wikipedia article. This task of machine reading at scale combines the challenges
    of document retrieval (finding the relevant articles) with that of machine comprehension
    of text (identifying the answer spans from those articles). Our approach combines
    a search component based on bigram hashing and TF-IDF matching with a multi-layer
    recurrent neural network model trained to detect answers in Wikipedia paragraphs.
    Our experiments on multiple existing QA datasets indicate that (1) both modules
    are highly competitive with respect to existing counterparts and (2) multitask
    learning using distant supervision on their combination is an effective complete
    system on this challenging task.'
  address: Vancouver, Canada
  author:
  - first: Danqi
    full: Danqi Chen
    id: danqi-chen
    last: Chen
  - first: Adam
    full: Adam Fisch
    id: adam-fisch
    last: Fisch
  - first: Jason
    full: Jason Weston
    id: jason-weston
    last: Weston
  - first: Antoine
    full: Antoine Bordes
    id: antoine-bordes
    last: Bordes
  author_string: Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes
  bibkey: chen-etal-2017-reading
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1171
  month: July
  page_first: '1870'
  page_last: '1879'
  pages: "1870\u20131879"
  paper_id: '171'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1171.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1171.jpg
  title: Reading Wikipedia to Answer Open-Domain Questions
  title_html: Reading <span class="acl-fixed-case">W</span>ikipedia to Answer Open-Domain
    Questions
  url: https://www.aclweb.org/anthology/P17-1171
  year: '2017'
P17-1172:
  abstract: Recurrent Neural Networks are showing much promise in many sub-areas of
    natural language processing, ranging from document classification to machine translation
    to automatic question answering. Despite their promise, many recurrent models
    have to read the whole text word by word, making it slow to handle long documents.
    For example, it is difficult to use a recurrent network to read a book and answer
    questions about it. In this paper, we present an approach of reading text while
    skipping irrelevant information if needed. The underlying model is a recurrent
    network that learns how far to jump after reading a few words of the input text.
    We employ a standard policy gradient method to train the model to make discrete
    jumping decisions. In our benchmarks on four different tasks, including number
    prediction, sentiment analysis, news article classification and automatic Q&A,
    our proposed model, a modified LSTM with jumping, is up to 6 times faster than
    the standard sequential LSTM, while maintaining the same or even better accuracy.
  address: Vancouver, Canada
  author:
  - first: Adams Wei
    full: Adams Wei Yu
    id: adams-wei-yu
    last: Yu
  - first: Hongrae
    full: Hongrae Lee
    id: hongrae-lee
    last: Lee
  - first: Quoc
    full: Quoc Le
    id: quoc-le
    last: Le
  author_string: Adams Wei Yu, Hongrae Lee, Quoc Le
  bibkey: yu-etal-2017-learning-skim
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1172
  month: July
  page_first: '1880'
  page_last: '1890'
  pages: "1880\u20131890"
  paper_id: '172'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1172.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1172.jpg
  title: Learning to Skim Text
  title_html: Learning to Skim Text
  url: https://www.aclweb.org/anthology/P17-1172
  year: '2017'
P17-1173:
  abstract: Though feature extraction is a necessary first step in statistical NLP,
    it is often seen as a mere preprocessing step. Yet, it can dominate computation
    time, both during training, and especially at deployment. In this paper, we formalize
    feature extraction from an algebraic perspective. Our formalization allows us
    to define a message passing algorithm that can restructure feature templates to
    be more computationally efficient. We show via experiments on text chunking and
    relation extraction that this restructuring does indeed speed up feature extraction
    in practice by reducing redundant computation.
  address: Vancouver, Canada
  author:
  - first: Vivek
    full: Vivek Srikumar
    id: vivek-srikumar
    last: Srikumar
  author_string: Vivek Srikumar
  bibkey: srikumar-2017-algebra
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1173
  month: July
  page_first: '1891'
  page_last: '1900'
  pages: "1891\u20131900"
  paper_id: '173'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1173.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1173.jpg
  title: An Algebra for Feature Extraction
  title_html: An Algebra for Feature Extraction
  url: https://www.aclweb.org/anthology/P17-1173
  year: '2017'
P17-1174:
  abstract: "Chunks (or phrases) once played a pivotal role in machine translation.\
    \ By using a chunk rather than a word as the basic translation unit, local (intra-chunk)\
    \ and global (inter-chunk) word orders and dependencies can be easily modeled.\
    \ The chunk structure, despite its importance, has not been considered in the\
    \ decoders used for neural machine translation (NMT). In this paper, we propose\
    \ chunk-based decoders for (NMT), each of which consists of a chunk-level decoder\
    \ and a word-level decoder. The chunk-level decoder models global dependencies\
    \ while the word-level decoder decides the local word order in a chunk. To output\
    \ a target sentence, the chunk-level decoder generates a chunk representation\
    \ containing global information, which the word-level decoder then uses as a basis\
    \ to predict the words inside the chunk. Experimental results show that our proposed\
    \ decoders can significantly improve translation performance in a WAT \u201816\
    \ English-to-Japanese translation task."
  address: Vancouver, Canada
  author:
  - first: Shonosuke
    full: Shonosuke Ishiwatari
    id: shonosuke-ishiwatari
    last: Ishiwatari
  - first: Jingtao
    full: Jingtao Yao
    id: jingtao-yao
    last: Yao
  - first: Shujie
    full: Shujie Liu
    id: shujie-liu
    last: Liu
  - first: Mu
    full: Mu Li
    id: mu-li
    last: Li
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  - first: Naoki
    full: Naoki Yoshinaga
    id: naoki-yoshinaga
    last: Yoshinaga
  - first: Masaru
    full: Masaru Kitsuregawa
    id: masaru-kitsuregawa
    last: Kitsuregawa
  - first: Weijia
    full: Weijia Jia
    id: weijia-jia
    last: Jia
  author_string: Shonosuke Ishiwatari, Jingtao Yao, Shujie Liu, Mu Li, Ming Zhou,
    Naoki Yoshinaga, Masaru Kitsuregawa, Weijia Jia
  bibkey: ishiwatari-etal-2017-chunk
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1174
  month: July
  page_first: '1901'
  page_last: '1912'
  pages: "1901\u20131912"
  paper_id: '174'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1174.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1174.jpg
  title: Chunk-based Decoder for Neural Machine Translation
  title_html: Chunk-based Decoder for Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1174
  year: '2017'
P17-1175:
  abstract: We introduce a Multi-modal Neural Machine Translation model in which a
    doubly-attentive decoder naturally incorporates spatial visual features obtained
    using pre-trained convolutional neural networks, bridging the gap between image
    description and translation. Our decoder learns to attend to source-language words
    and parts of an image independently by means of two separate attention mechanisms
    as it generates words in the target language. We find that our model can efficiently
    exploit not just back-translated in-domain multi-modal data but also large general-domain
    text-only MT corpora. We also report state-of-the-art results on the Multi30k
    data set.
  address: Vancouver, Canada
  author:
  - first: Iacer
    full: Iacer Calixto
    id: iacer-calixto
    last: Calixto
  - first: Qun
    full: Qun Liu
    id: qun-liu
    last: Liu
  - first: Nick
    full: Nick Campbell
    id: nick-campbell
    last: Campbell
  author_string: Iacer Calixto, Qun Liu, Nick Campbell
  bibkey: calixto-etal-2017-doubly
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1175
  month: July
  page_first: '1913'
  page_last: '1924'
  pages: "1913\u20131924"
  paper_id: '175'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1175.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1175.jpg
  title: Doubly-Attentive Decoder for Multi-modal Neural Machine Translation
  title_html: Doubly-Attentive Decoder for Multi-modal Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1175
  year: '2017'
P17-1176:
  abstract: "While end-to-end neural machine translation (NMT) has made remarkable\
    \ progress recently, it still suffers from the data scarcity problem for low-resource\
    \ language pairs and domains. In this paper, we propose a method for zero-resource\
    \ NMT by assuming that parallel sentences have close probabilities of generating\
    \ a sentence in a third language. Based on the assumption, our method is able\
    \ to train a source-to-target NMT model (\u201Cstudent\u201D) without parallel\
    \ corpora available guided by an existing pivot-to-target NMT model (\u201Cteacher\u201D\
    ) on a source-pivot parallel corpus. Experimental results show that the proposed\
    \ method significantly improves over a baseline pivot-based model by +3.0 BLEU\
    \ points across various language pairs."
  address: Vancouver, Canada
  author:
  - first: Yun
    full: Yun Chen
    id: yun-chen
    last: Chen
  - first: Yang
    full: Yang Liu
    id: yang-liu-ict
    last: Liu
  - first: Yong
    full: Yong Cheng
    id: yong-cheng
    last: Cheng
  - first: Victor O.K.
    full: Victor O.K. Li
    id: victor-o-k-li
    last: Li
  author_string: Yun Chen, Yang Liu, Yong Cheng, Victor O.K. Li
  bibkey: chen-etal-2017-teacher
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1176
  month: July
  page_first: '1925'
  page_last: '1935'
  pages: "1925\u20131935"
  paper_id: '176'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1176.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1176.jpg
  title: A Teacher-Student Framework for Zero-Resource Neural Machine Translation
  title_html: A Teacher-Student Framework for Zero-Resource Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-1176
  year: '2017'
P17-1177:
  abstract: Most neural machine translation (NMT) models are based on the sequential
    encoder-decoder framework, which makes no use of syntactic information. In this
    paper, we improve this model by explicitly incorporating source-side syntactic
    trees. More specifically, we propose (1) a bidirectional tree encoder which learns
    both sequential and tree structured representations; (2) a tree-coverage model
    that lets the attention depend on the source-side syntax. Experiments on Chinese-English
    translation demonstrate that our proposed models outperform the sequential attentional
    model as well as a stronger baseline with a bottom-up tree encoder and word coverage.
  address: Vancouver, Canada
  author:
  - first: Huadong
    full: Huadong Chen
    id: huadong-chen
    last: Chen
  - first: Shujian
    full: Shujian Huang
    id: shujian-huang
    last: Huang
  - first: David
    full: David Chiang
    id: david-chiang
    last: Chiang
  - first: Jiajun
    full: Jiajun Chen
    id: jiajun-chen
    last: Chen
  author_string: Huadong Chen, Shujian Huang, David Chiang, Jiajun Chen
  bibkey: chen-etal-2017-improved
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1177
  month: July
  page_first: '1936'
  page_last: '1945'
  pages: "1936\u20131945"
  paper_id: '177'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1177.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1177.jpg
  title: Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder
  title_html: Improved Neural Machine Translation with a Syntax-Aware Encoder and
    Decoder
  url: https://www.aclweb.org/anthology/P17-1177
  year: '2017'
P17-1178:
  abstract: "The ambitious goal of this work is to develop a cross-lingual name tagging\
    \ and linking framework for 282 languages that exist in Wikipedia. Given a document\
    \ in any of these languages, our framework is able to identify name mentions,\
    \ assign a coarse-grained or fine-grained type to each mention, and link it to\
    \ an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing\
    \ a series of new KB mining methods: generating \u201Csilver-standard\u201D annotations\
    \ by transferring annotations from English to other languages through cross-lingual\
    \ links and KB properties, refining annotations through self-training and topic\
    \ selection, deriving language-specific morphology features from anchor links,\
    \ and mining word translation pairs from cross-lingual links. Both name tagging\
    \ and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia\
    \ data."
  address: Vancouver, Canada
  author:
  - first: Xiaoman
    full: Xiaoman Pan
    id: xiaoman-pan
    last: Pan
  - first: Boliang
    full: Boliang Zhang
    id: boliang-zhang
    last: Zhang
  - first: Jonathan
    full: Jonathan May
    id: jonathan-may
    last: May
  - first: Joel
    full: Joel Nothman
    id: joel-nothman
    last: Nothman
  - first: Kevin
    full: Kevin Knight
    id: kevin-knight
    last: Knight
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  author_string: Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight,
    Heng Ji
  bibkey: pan-etal-2017-cross
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1178
  month: July
  page_first: '1946'
  page_last: '1958'
  pages: "1946\u20131958"
  paper_id: '178'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1178.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1178.jpg
  title: Cross-lingual Name Tagging and Linking for 282 Languages
  title_html: Cross-lingual Name Tagging and Linking for 282 Languages
  url: https://www.aclweb.org/anthology/P17-1178
  year: '2017'
P17-1179:
  abstract: Word embeddings are well known to capture linguistic regularities of the
    language on which they are trained. Researchers also observe that these regularities
    can transfer across languages. However, previous endeavors to connect separate
    monolingual word embeddings typically require cross-lingual signals as supervision,
    either in the form of parallel corpus or seed lexicon. In this work, we show that
    such cross-lingual connection can actually be established without any form of
    supervision. We achieve this end by formulating the problem as a natural adversarial
    game, and investigating techniques that are crucial to successful training. We
    carry out evaluation on the unsupervised bilingual lexicon induction task. Even
    though this task appears intrinsically cross-lingual, we are able to demonstrate
    encouraging performance without any cross-lingual clues.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1179.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1179.Software.zip
  - filename: P17-1179.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1179.Poster.pdf
  author:
  - first: Meng
    full: Meng Zhang
    id: meng-zhang
    last: Zhang
  - first: Yang
    full: Yang Liu
    id: yang-liu-ict
    last: Liu
  - first: Huanbo
    full: Huanbo Luan
    id: huanbo-luan
    last: Luan
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Meng Zhang, Yang Liu, Huanbo Luan, Maosong Sun
  bibkey: zhang-etal-2017-adversarial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1179
  month: July
  page_first: '1959'
  page_last: '1970'
  pages: "1959\u20131970"
  paper_id: '179'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1179.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1179.jpg
  title: Adversarial Training for Unsupervised Bilingual Lexicon Induction
  title_html: Adversarial Training for Unsupervised Bilingual Lexicon Induction
  url: https://www.aclweb.org/anthology/P17-1179
  year: '2017'
P17-1180:
  abstract: Word-level language detection is necessary for analyzing code-switched
    text, where multiple languages could be mixed within a sentence. Existing models
    are restricted to code-switching between two specific languages and fail in real-world
    scenarios as text input rarely has a priori information on the languages used.
    We present a novel unsupervised word-level language detection technique for code-switched
    text for an arbitrarily large number of languages, which does not require any
    manually annotated training data. Our experiments with tweets in seven languages
    show a 74% relative error reduction in word-level labeling with respect to competitive
    baselines. We then use this system to conduct a large-scale quantitative analysis
    of code-switching patterns on Twitter, both global as well as region-specific,
    with 58M tweets.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1180.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1180.Notes.pdf
  author:
  - first: Shruti
    full: Shruti Rijhwani
    id: shruti-rijhwani
    last: Rijhwani
  - first: Royal
    full: Royal Sequiera
    id: royal-sequiera
    last: Sequiera
  - first: Monojit
    full: Monojit Choudhury
    id: monojit-choudhury
    last: Choudhury
  - first: Kalika
    full: Kalika Bali
    id: kalika-bali
    last: Bali
  - first: Chandra Shekhar
    full: Chandra Shekhar Maddila
    id: chandra-shekhar-maddila
    last: Maddila
  author_string: Shruti Rijhwani, Royal Sequiera, Monojit Choudhury, Kalika Bali,
    Chandra Shekhar Maddila
  bibkey: rijhwani-etal-2017-estimating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1180
  month: July
  page_first: '1971'
  page_last: '1982'
  pages: "1971\u20131982"
  paper_id: '180'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1180.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1180.jpg
  title: Estimating Code-Switching on Twitter with a Novel Generalized Word-Level
    Language Detection Technique
  title_html: Estimating Code-Switching on Twitter with a Novel Generalized Word-Level
    Language Detection Technique
  url: https://www.aclweb.org/anthology/P17-1180
  year: '2017'
P17-1181:
  abstract: Global constraints and reranking have not been used in cognates detection
    research to date. We propose methods for using global constraints by performing
    rescoring of the score matrices produced by state of the art cognates detection
    systems. Using global constraints to perform rescoring is complementary to state
    of the art methods for performing cognates detection and results in significant
    performance improvements beyond current state of the art performance on publicly
    available datasets with different language pairs and various conditions such as
    different levels of baseline state of the art performance and different data size
    conditions, including with more realistic large data size conditions than have
    been evaluated with in the past.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1181.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1181.Poster.pdf
  author:
  - first: Michael
    full: Michael Bloodgood
    id: michael-bloodgood
    last: Bloodgood
  - first: Benjamin
    full: Benjamin Strauss
    id: benjamin-strauss
    last: Strauss
  author_string: Michael Bloodgood, Benjamin Strauss
  bibkey: bloodgood-strauss-2017-using
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1181
  month: July
  page_first: '1983'
  page_last: '1992'
  pages: "1983\u20131992"
  paper_id: '181'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1181.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1181.jpg
  title: Using Global Constraints and Reranking to Improve Cognates Detection
  title_html: Using Global Constraints and Reranking to Improve Cognates Detection
  url: https://www.aclweb.org/anthology/P17-1181
  year: '2017'
P17-1182:
  abstract: We present a novel cross-lingual transfer method for paradigm completion,
    the task of mapping a lemma to its inflected forms, using a neural encoder-decoder
    model, the state of the art for the monolingual task. We use labeled data from
    a high-resource language to increase performance on a low-resource language. In
    experiments on 21 language pairs from four different language families, we obtain
    up to 58% higher accuracy than without transfer and show that even zero-shot and
    one-shot learning are possible. We further find that the degree of language relatedness
    strongly influences the ability to transfer morphological knowledge.
  address: Vancouver, Canada
  author:
  - first: Katharina
    full: Katharina Kann
    id: katharina-kann
    last: Kann
  - first: Ryan
    full: Ryan Cotterell
    id: ryan-cotterell
    last: Cotterell
  - first: Hinrich
    full: "Hinrich Sch\xFCtze"
    id: hinrich-schutze
    last: "Sch\xFCtze"
  author_string: "Katharina Kann, Ryan Cotterell, Hinrich Sch\xFCtze"
  bibkey: kann-etal-2017-one
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1182
  month: July
  page_first: '1993'
  page_last: '2003'
  pages: "1993\u20132003"
  paper_id: '182'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1182.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1182.jpg
  title: One-Shot Neural Cross-Lingual Transfer for Paradigm Completion
  title_html: One-Shot Neural Cross-Lingual Transfer for Paradigm Completion
  url: https://www.aclweb.org/anthology/P17-1182
  year: '2017'
P17-1183:
  abstract: We present a neural model for morphological inflection generation which
    employs a hard attention mechanism, inspired by the nearly-monotonic alignment
    commonly found between the characters in a word and the characters in its inflection.
    We evaluate the model on three previously studied morphological inflection generation
    datasets and show that it provides state of the art results in various setups
    compared to previous neural and non-neural approaches. Finally we present an analysis
    of the continuous representations learned by both the hard and soft (Bahdanau,
    2014) attention models for the task, shedding some light on the features such
    models extract.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1183.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1183.Poster.pdf
  author:
  - first: Roee
    full: Roee Aharoni
    id: roee-aharoni
    last: Aharoni
  - first: Yoav
    full: Yoav Goldberg
    id: yoav-goldberg
    last: Goldberg
  author_string: Roee Aharoni, Yoav Goldberg
  bibkey: aharoni-goldberg-2017-morphological
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1183
  month: July
  page_first: '2004'
  page_last: '2015'
  pages: "2004\u20132015"
  paper_id: '183'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1183.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1183.jpg
  title: Morphological Inflection Generation with Hard Monotonic Attention
  title_html: Morphological Inflection Generation with Hard Monotonic Attention
  url: https://www.aclweb.org/anthology/P17-1183
  year: '2017'
P17-1184:
  abstract: 'Words can be represented by composing the representations of subword
    units such as word segments, characters, and/or character n-grams. While such
    representations are effective and may capture the morphological regularities of
    words, they have not been systematically compared, and it is not understood how
    they interact with different morphological typologies. On a language modeling
    task, we present experiments that systematically vary (1) the basic unit of representation,
    (2) the composition of these representations, and (3) the morphological typology
    of the language modeled. Our results extend previous findings that character representations
    are effective across typologies, and we find that a previously unstudied combination
    of character trigram representations composed with bi-LSTMs outperforms most others.
    But we also find room for improvement: none of the character-level models match
    the predictive accuracy of a model with access to true morphological analyses,
    even when learned from an order of magnitude more data.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1184.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1184.Poster.pdf
  author:
  - first: Clara
    full: Clara Vania
    id: clara-vania
    last: Vania
  - first: Adam
    full: Adam Lopez
    id: adam-lopez
    last: Lopez
  author_string: Clara Vania, Adam Lopez
  bibkey: vania-lopez-2017-characters
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1184
  month: July
  page_first: '2016'
  page_last: '2027'
  pages: "2016\u20132027"
  paper_id: '184'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1184.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1184.jpg
  title: 'From Characters to Words to in Between: Do We Capture Morphology?'
  title_html: 'From Characters to Words to in Between: Do We Capture Morphology?'
  url: https://www.aclweb.org/anthology/P17-1184
  year: '2017'
P17-1185:
  abstract: "Skip-Gram Negative Sampling (SGNS) word embedding model, well known by\
    \ its implementation in \u201Cword2vec\u201D software, is usually optimized by\
    \ stochastic gradient descent. However, the optimization of SGNS objective can\
    \ be viewed as a problem of searching for a good matrix with the low-rank constraint.\
    \ The most standard way to solve this type of problems is to apply Riemannian\
    \ optimization framework to optimize the SGNS objective over the manifold of required\
    \ low-rank matrices. In this paper, we propose an algorithm that optimizes SGNS\
    \ objective using Riemannian optimization and demonstrates its superiority over\
    \ popular competitors, such as the original method to train SGNS and SVD over\
    \ SPPMI matrix."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1185.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1185.Poster.pdf
  author:
  - first: Alexander
    full: Alexander Fonarev
    id: alexander-fonarev
    last: Fonarev
  - first: Oleksii
    full: Oleksii Grinchuk
    id: oleksii-grinchuk
    last: Grinchuk
  - first: Gleb
    full: Gleb Gusev
    id: gleb-gusev
    last: Gusev
  - first: Pavel
    full: Pavel Serdyukov
    id: pavel-serdyukov
    last: Serdyukov
  - first: Ivan
    full: Ivan Oseledets
    id: ivan-oseledets
    last: Oseledets
  author_string: Alexander Fonarev, Oleksii Grinchuk, Gleb Gusev, Pavel Serdyukov,
    Ivan Oseledets
  bibkey: fonarev-etal-2017-riemannian
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1185
  month: July
  page_first: '2028'
  page_last: '2036'
  pages: "2028\u20132036"
  paper_id: '185'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1185.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1185.jpg
  title: Riemannian Optimization for Skip-Gram Negative Sampling
  title_html: <span class="acl-fixed-case">R</span>iemannian Optimization for Skip-Gram
    Negative Sampling
  url: https://www.aclweb.org/anthology/P17-1185
  year: '2017'
P17-1186:
  abstract: "We present a deep neural architecture that parses sentences into three\
    \ semantic dependency graph formalisms. By using efficient, nearly arc-factored\
    \ inference and a bidirectional-LSTM composed with a multi-layer perceptron, our\
    \ base system is able to significantly improve the state of the art for semantic\
    \ dependency parsing, without using hand-engineered features or syntax. We then\
    \ explore two multitask learning approaches\u2014one that shares parameters across\
    \ formalisms, and one that uses higher-order structures to predict the graphs\
    \ jointly. We find that both approaches improve performance across formalisms\
    \ on average, achieving a new state of the art. Our code is open-source and available\
    \ at https://github.com/Noahs-ARK/NeurboParser."
  address: Vancouver, Canada
  author:
  - first: Hao
    full: Hao Peng
    id: hao-peng
    last: Peng
  - first: Sam
    full: Sam Thomson
    id: sam-thomson
    last: Thomson
  - first: Noah A.
    full: Noah A. Smith
    id: noah-a-smith
    last: Smith
  author_string: Hao Peng, Sam Thomson, Noah A. Smith
  bibkey: peng-etal-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1186
  month: July
  page_first: '2037'
  page_last: '2048'
  pages: "2037\u20132048"
  paper_id: '186'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1186.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1186.jpg
  title: Deep Multitask Learning for Semantic Dependency Parsing
  title_html: Deep Multitask Learning for Semantic Dependency Parsing
  url: https://www.aclweb.org/anthology/P17-1186
  year: '2017'
P17-1187:
  abstract: Sememes are minimum semantic units of word meanings, and the meaning of
    each word sense is typically composed by several sememes. Since sememes are not
    explicit for each word, people manually annotate word sememes and form linguistic
    common-sense knowledge bases. In this paper, we present that, word sememe information
    can improve word representation learning (WRL), which maps words into a low-dimensional
    semantic space and serves as a fundamental step for many NLP tasks. The key idea
    is to utilize word sememes to capture exact meanings of a word within specific
    contexts accurately. More specifically, we follow the framework of Skip-gram and
    present three sememe-encoded models to learn representations of sememes, senses
    and words, where we apply the attention scheme to detect word senses in various
    contexts. We conduct experiments on two tasks including word similarity and word
    analogy, and our models significantly outperform baselines. The results indicate
    that WRL can benefit from sememes via the attention scheme, and also confirm our
    models being capable of correctly modeling sememe information.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1187.Software.zip
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1187.Software.zip
  - filename: P17-1187.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1187.Datasets.zip
  author:
  - first: Yilin
    full: Yilin Niu
    id: yilin-niu
    last: Niu
  - first: Ruobing
    full: Ruobing Xie
    id: ruobing-xie
    last: Xie
  - first: Zhiyuan
    full: Zhiyuan Liu
    id: zhiyuan-liu
    last: Liu
  - first: Maosong
    full: Maosong Sun
    id: maosong-sun
    last: Sun
  author_string: Yilin Niu, Ruobing Xie, Zhiyuan Liu, Maosong Sun
  bibkey: niu-etal-2017-improved
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1187
  month: July
  page_first: '2049'
  page_last: '2058'
  pages: "2049\u20132058"
  paper_id: '187'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1187.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1187.jpg
  title: Improved Word Representation Learning with Sememes
  title_html: Improved Word Representation Learning with Sememes
  url: https://www.aclweb.org/anthology/P17-1187
  year: '2017'
P17-1188:
  abstract: 'Previous work has modeled the compositionality of words by creating character-level
    models of meaning, reducing problems of sparsity for rare words. However, in many
    writing systems compositionality has an effect even on the character-level: the
    meaning of a character is derived by the sum of its parts. In this paper, we model
    this effect by creating embeddings for characters based on their visual characteristics,
    creating an image for the character and running it through a convolutional neural
    network to produce a visual character embedding. Experiments on a text classification
    task demonstrate that such model allows for better processing of instances with
    rare characters in languages such as Chinese, Japanese, and Korean. Additionally,
    qualitative analyses demonstrate that our proposed model learns to focus on the
    parts of characters that carry topical content which resulting in embeddings that
    are coherent in visual space.'
  address: Vancouver, Canada
  author:
  - first: Frederick
    full: Frederick Liu
    id: frederick-liu
    last: Liu
  - first: Han
    full: Han Lu
    id: han-lu
    last: Lu
  - first: Chieh
    full: Chieh Lo
    id: chieh-lo
    last: Lo
  - first: Graham
    full: Graham Neubig
    id: graham-neubig
    last: Neubig
  author_string: Frederick Liu, Han Lu, Chieh Lo, Graham Neubig
  bibkey: liu-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1188
  month: July
  page_first: '2059'
  page_last: '2068'
  pages: "2059\u20132068"
  paper_id: '188'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1188.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1188.jpg
  title: Learning Character-level Compositionality with Visual Features
  title_html: Learning Character-level Compositionality with Visual Features
  url: https://www.aclweb.org/anthology/P17-1188
  year: '2017'
P17-1189:
  abstract: Previous studies on Chinese semantic role labeling (SRL) have concentrated
    on a single semantically annotated corpus. But the training data of single corpus
    is often limited. Whereas the other existing semantically annotated corpora for
    Chinese SRL are scattered across different annotation frameworks. But still, Data
    sparsity remains a bottleneck. This situation calls for larger training datasets,
    or effective approaches which can take advantage of highly heterogeneous data.
    In this paper, we focus mainly on the latter, that is, to improve Chinese SRL
    by using heterogeneous corpora together. We propose a novel progressive learning
    model which augments the Progressive Neural Network with Gated Recurrent Adapters.
    The model can accommodate heterogeneous inputs and effectively transfer knowledge
    between them. We also release a new corpus, Chinese SemBank, for Chinese SRL.
    Experiments on CPB 1.0 show that our model outperforms state-of-the-art methods.
  address: Vancouver, Canada
  author:
  - first: Qiaolin
    full: Qiaolin Xia
    id: qiaolin-xia
    last: Xia
  - first: Lei
    full: Lei Sha
    id: lei-sha
    last: Sha
  - first: Baobao
    full: Baobao Chang
    id: baobao-chang
    last: Chang
  - first: Zhifang
    full: Zhifang Sui
    id: zhifang-sui
    last: Sui
  author_string: Qiaolin Xia, Lei Sha, Baobao Chang, Zhifang Sui
  bibkey: xia-etal-2017-progressive
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1189
  month: July
  page_first: '2069'
  page_last: '2077'
  pages: "2069\u20132077"
  paper_id: '189'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1189.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1189.jpg
  title: A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data
  title_html: A Progressive Learning Approach to <span class="acl-fixed-case">C</span>hinese
    <span class="acl-fixed-case">SRL</span> Using Heterogeneous Data
  url: https://www.aclweb.org/anthology/P17-1189
  year: '2017'
P17-1190:
  abstract: We consider the problem of learning general-purpose, paraphrastic sentence
    embeddings, revisiting the setting of Wieting et al. (2016b). While they found
    LSTM recurrent networks to underperform word averaging, we present several developments
    that together produce the opposite conclusion. These include training on sentence
    pairs rather than phrase pairs, averaging states to represent sequences, and regularizing
    aggressively. These improve LSTMs in both transfer learning and supervised settings.
    We also introduce a new recurrent architecture, the Gated Recurrent Averaging
    Network, that is inspired by averaging and LSTMs while outperforming them both.
    We analyze our learned models, finding evidence of preferences for particular
    parts of speech and dependency relations.
  address: Vancouver, Canada
  author:
  - first: John
    full: John Wieting
    id: john-wieting
    last: Wieting
  - first: Kevin
    full: Kevin Gimpel
    id: kevin-gimpel
    last: Gimpel
  author_string: John Wieting, Kevin Gimpel
  bibkey: wieting-gimpel-2017-revisiting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1190
  month: July
  page_first: '2078'
  page_last: '2088'
  pages: "2078\u20132088"
  paper_id: '190'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1190.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1190.jpg
  title: Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings
  title_html: Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings
  url: https://www.aclweb.org/anthology/P17-1190
  year: '2017'
P17-1191:
  abstract: Type-level word embeddings use the same set of parameters to represent
    all instances of a word regardless of its context, ignoring the inherent lexical
    ambiguity in language. Instead, we embed semantic concepts (or synsets) as defined
    in WordNet and represent a word token in a particular context by estimating a
    distribution over relevant semantic concepts. We use the new, context-sensitive
    embeddings in a model for predicting prepositional phrase (PP) attachments and
    jointly learn the concept embeddings and model parameters. We show that using
    context-sensitive embeddings improves the accuracy of the PP attachment model
    by 5.4% absolute points, which amounts to a 34.4% relative reduction in errors.
  address: Vancouver, Canada
  author:
  - first: Pradeep
    full: Pradeep Dasigi
    id: pradeep-dasigi
    last: Dasigi
  - first: Waleed
    full: Waleed Ammar
    id: waleed-ammar
    last: Ammar
  - first: Chris
    full: Chris Dyer
    id: chris-dyer
    last: Dyer
  - first: Eduard
    full: Eduard Hovy
    id: eduard-hovy
    last: Hovy
  author_string: Pradeep Dasigi, Waleed Ammar, Chris Dyer, Eduard Hovy
  bibkey: dasigi-etal-2017-ontology
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1191
  month: July
  page_first: '2089'
  page_last: '2098'
  pages: "2089\u20132098"
  paper_id: '191'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1191.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1191.jpg
  title: Ontology-Aware Token Embeddings for Prepositional Phrase Attachment
  title_html: Ontology-Aware Token Embeddings for Prepositional Phrase Attachment
  url: https://www.aclweb.org/anthology/P17-1191
  year: '2017'
P17-1192:
  abstract: "We present a method for populating fine-grained classes (e.g., \u201C\
    1950s American jazz musicians\u201D) with instances (e.g., Charles Mingus ). While\
    \ state-of-the-art methods tend to treat class labels as single lexical units,\
    \ the proposed method considers each of the individual modifiers in the class\
    \ label relative to the head. An evaluation on the task of reconstructing Wikipedia\
    \ category pages demonstrates a >10 point increase in AUC, over a strong baseline\
    \ relying on widely-used Hearst patterns."
  address: Vancouver, Canada
  attachment:
  - filename: P17-1192.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1192.Notes.pdf
  - filename: P17-1192.Datasets.tgz
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-1192.Datasets.tgz
  author:
  - first: Ellie
    full: Ellie Pavlick
    id: ellie-pavlick
    last: Pavlick
  - first: Marius
    full: "Marius Pa\u015Fca"
    id: marius-pasca
    last: "Pa\u015Fca"
  author_string: "Ellie Pavlick, Marius Pa\u015Fca"
  bibkey: pavlick-pasca-2017-identifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1192
  month: July
  page_first: '2099'
  page_last: '2109'
  pages: "2099\u20132109"
  paper_id: '192'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1192.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1192.jpg
  title: 'Identifying 1950s American Jazz Musicians: Fine-Grained IsA Extraction via
    Modifier Composition'
  title_html: 'Identifying 1950s <span class="acl-fixed-case">A</span>merican Jazz
    Musicians: Fine-Grained <span class="acl-fixed-case">I</span>s<span class="acl-fixed-case">A</span>
    Extraction via Modifier Composition'
  url: https://www.aclweb.org/anthology/P17-1192
  year: '2017'
P17-1193:
  abstract: 'We study the Maximum Subgraph problem in deep dependency parsing. We
    consider two restrictions to deep dependency graphs: (a) 1-endpoint-crossing and
    (b) pagenumber-2. Our main contribution is an exact algorithm that obtains maximum
    subgraphs satisfying both restrictions simultaneously in time O(n5). Moreover,
    ignoring one linguistically-rare structure descreases the complexity to O(n4).
    We also extend our quartic-time algorithm into a practical parser with a discriminative
    disambiguation model and evaluate its performance on four linguistic data sets
    used in semantic dependency parsing.'
  address: Vancouver, Canada
  attachment:
  - filename: P17-1193.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-1193.Notes.pdf
  - filename: P17-1193.Software.tgz
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-1193.Software.tgz
  author:
  - first: Junjie
    full: Junjie Cao
    id: junjie-cao
    last: Cao
  - first: Sheng
    full: Sheng Huang
    id: sheng-huang
    last: Huang
  - first: Weiwei
    full: Weiwei Sun
    id: weiwei-sun
    last: Sun
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  author_string: Junjie Cao, Sheng Huang, Weiwei Sun, Xiaojun Wan
  bibkey: cao-etal-2017-parsing
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1193
  month: July
  page_first: '2110'
  page_last: '2120'
  pages: "2110\u20132120"
  paper_id: '193'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1193.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1193.jpg
  title: Parsing to 1-Endpoint-Crossing, Pagenumber-2 Graphs
  title_html: Parsing to 1-Endpoint-Crossing, Pagenumber-2 Graphs
  url: https://www.aclweb.org/anthology/P17-1193
  year: '2017'
P17-1194:
  abstract: We propose a sequence labeling framework with a secondary training objective,
    learning to predict surrounding words for every word in the dataset. This language
    modeling objective incentivises the system to learn general-purpose patterns of
    semantic and syntactic composition, which are also useful for improving accuracy
    on different sequence labeling tasks. The architecture was evaluated on a range
    of datasets, covering the tasks of error detection in learner texts, named entity
    recognition, chunking and POS-tagging. The novel language modeling objective provided
    consistent performance improvements on every benchmark, without requiring any
    additional annotated or unannotated data.
  address: Vancouver, Canada
  attachment:
  - filename: P17-1194.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-1194.Poster.pdf
  author:
  - first: Marek
    full: Marek Rei
    id: marek-rei
    last: Rei
  author_string: Marek Rei
  bibkey: rei-2017-semi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1194
  month: July
  page_first: '2121'
  page_last: '2130'
  pages: "2121\u20132130"
  paper_id: '194'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1194.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1194.jpg
  title: Semi-supervised Multitask Learning for Sequence Labeling
  title_html: Semi-supervised Multitask Learning for Sequence Labeling
  url: https://www.aclweb.org/anthology/P17-1194
  year: '2017'
P17-1195:
  abstract: We have been developing an end-to-end math problem solving system that
    accepts natural language input. The current paper focuses on how we analyze the
    problem sentences to produce logical forms. We chose a hybrid approach combining
    a shallow syntactic analyzer and a manually-developed lexicalized grammar. A feature
    of the grammar is that it is extensively typed on the basis of a formal ontology
    for pre-university math. These types are helpful in semantic disambiguation inside
    and across sentences. Experimental results show that the hybrid system produces
    a well-formed logical form with 88% precision and 56% recall.
  address: Vancouver, Canada
  author:
  - first: Takuya
    full: Takuya Matsuzaki
    id: takuya-matsuzaki
    last: Matsuzaki
  - first: Takumi
    full: Takumi Ito
    id: takumi-ito
    last: Ito
  - first: Hidenao
    full: Hidenao Iwane
    id: hidenao-iwane
    last: Iwane
  - first: Hirokazu
    full: Hirokazu Anai
    id: hirokazu-anai
    last: Anai
  - first: Noriko
    full: Noriko H. Arai
    id: noriko-h-arai
    last: H. Arai
  author_string: Takuya Matsuzaki, Takumi Ito, Hidenao Iwane, Hirokazu Anai, Noriko
    H. Arai
  bibkey: matsuzaki-etal-2017-semantic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)'
  doi: 10.18653/v1/P17-1195
  month: July
  page_first: '2131'
  page_last: '2141'
  pages: "2131\u20132141"
  paper_id: '195'
  parent_volume_id: P17-1
  pdf: https://www.aclweb.org/anthology/P17-1195.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-1195.jpg
  title: Semantic Parsing of Pre-university Math Problems
  title_html: Semantic Parsing of Pre-university Math Problems
  url: https://www.aclweb.org/anthology/P17-1195
  year: '2017'
P17-2000:
  address: Vancouver, Canada
  author:
  - first: Regina
    full: Regina Barzilay
    id: regina-barzilay
    last: Barzilay
  - first: Min-Yen
    full: Min-Yen Kan
    id: min-yen-kan
    last: Kan
  author_string: Regina Barzilay, Min-Yen Kan
  bibkey: acl-2017-association-linguistics
  bibtype: proceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2
  month: July
  paper_id: '0'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2000.jpg
  title: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  title_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  url: https://www.aclweb.org/anthology/P17-2000
  year: '2017'
P17-2001:
  abstract: "Temporal relation classification is becoming an active research field.\
    \ Lots of methods have been proposed, while most of them focus on extracting features\
    \ from external resources. Less attention has been paid to a significant advance\
    \ in a closely related task: relation extraction. In this work, we borrow a state-of-the-art\
    \ method in relation extraction by adopting bidirectional long short-term memory\
    \ (Bi-LSTM) along dependency paths (DP). We make a \u201Ccommon root\u201D assumption\
    \ to extend DP representations of cross-sentence links. In the final comparison\
    \ to two state-of-the-art systems on TimeBank-Dense, our model achieves comparable\
    \ performance, without using external knowledge, as well as manually annotated\
    \ attributes of entities (class, tense, polarity, etc.)."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953227
    type: video
    url: https://vimeo.com/234953227
  author:
  - first: Fei
    full: Fei Cheng
    id: fei-cheng
    last: Cheng
  - first: Yusuke
    full: Yusuke Miyao
    id: yusuke-miyao
    last: Miyao
  author_string: Fei Cheng, Yusuke Miyao
  bibkey: cheng-miyao-2017-classifying
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2001
  month: July
  page_first: '1'
  page_last: '6'
  pages: "1\u20136"
  paper_id: '1'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2001.jpg
  title: Classifying Temporal Relations by Bidirectional LSTM over Dependency Paths
  title_html: Classifying Temporal Relations by Bidirectional <span class="acl-fixed-case">LSTM</span>
    over Dependency Paths
  url: https://www.aclweb.org/anthology/P17-2001
  year: '2017'
P17-2002:
  abstract: This paper addresses the task of AMR-to-text generation by leveraging
    synchronous node replacement grammar. During training, graph-to-string rules are
    learned using a heuristic extraction algorithm. At test time, a graph transducer
    is applied to collapse input AMRs and generate output sentences. Evaluated on
    a standard benchmark, our method gives the state-of-the-art result.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954327
    type: video
    url: https://vimeo.com/234954327
  author:
  - first: Linfeng
    full: Linfeng Song
    id: linfeng-song
    last: Song
  - first: Xiaochang
    full: Xiaochang Peng
    id: xiaochang-peng
    last: Peng
  - first: Yue
    full: Yue Zhang
    id: yue-zhang
    last: Zhang
  - first: Zhiguo
    full: Zhiguo Wang
    id: zhiguo-wang
    last: Wang
  - first: Daniel
    full: Daniel Gildea
    id: daniel-gildea
    last: Gildea
  author_string: Linfeng Song, Xiaochang Peng, Yue Zhang, Zhiguo Wang, Daniel Gildea
  bibkey: song-etal-2017-amr
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2002
  month: July
  page_first: '7'
  page_last: '13'
  pages: "7\u201313"
  paper_id: '2'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2002.jpg
  title: AMR-to-text Generation with Synchronous Node Replacement Grammar
  title_html: <span class="acl-fixed-case">AMR</span>-to-text Generation with Synchronous
    Node Replacement Grammar
  url: https://www.aclweb.org/anthology/P17-2002
  year: '2017'
P17-2003:
  abstract: Lexical features are a major source of information in state-of-the-art
    coreference resolvers. Lexical features implicitly model some of the linguistic
    phenomena at a fine granularity level. They are especially useful for representing
    the context of mentions. In this paper we investigate a drawback of using many
    lexical features in state-of-the-art coreference resolvers. We show that if coreference
    resolvers mainly rely on lexical features, they can hardly generalize to unseen
    domains. Furthermore, we show that the current coreference resolution evaluation
    is clearly flawed by only evaluating on a specific split of a specific dataset
    in which there is a notable overlap between the training, development and test
    sets.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234953454
    type: video
    url: https://vimeo.com/234953454
  author:
  - first: Nafise Sadat
    full: Nafise Sadat Moosavi
    id: nafise-sadat-moosavi
    last: Moosavi
  - first: Michael
    full: Michael Strube
    id: michael-strube
    last: Strube
  author_string: Nafise Sadat Moosavi, Michael Strube
  bibkey: moosavi-strube-2017-lexical
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2003
  month: July
  page_first: '14'
  page_last: '19'
  pages: "14\u201319"
  paper_id: '3'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2003.jpg
  title: 'Lexical Features in Coreference Resolution: To be Used With Caution'
  title_html: 'Lexical Features in Coreference Resolution: To be Used With Caution'
  url: https://www.aclweb.org/anthology/P17-2003
  year: '2017'
P17-2004:
  abstract: "MT evaluation metrics are tested for correlation with human judgments\
    \ either at the sentence- or the corpus-level. Trained metrics ignore corpus-level\
    \ judgments and are trained for high sentence-level correlation only. We show\
    \ that training only for one objective (sentence or corpus level), can not only\
    \ harm the performance on the other objective, but it can also be suboptimal for\
    \ the objective being optimized. To this end we present a metric trained for corpus-level\
    \ and show empirical comparison against a metric trained for sentence-level exemplifying\
    \ how their performance may vary per language pair, type and level of judgment.\
    \ Subsequently we propose a model trained to optimize both objectives simultaneously\
    \ and show that it is far more stable than\u2013and on average outperforms\u2013\
    both models on both objectives."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234951559
    type: video
    url: https://vimeo.com/234951559
  author:
  - first: "Milo\u0161"
    full: "Milo\u0161 Stanojevi\u0107"
    id: milos-stanojevic
    last: "Stanojevi\u0107"
  - first: Khalil
    full: "Khalil Sima\u2019an"
    id: khalil-simaan
    last: "Sima\u2019an"
  author_string: "Milo\u0161 Stanojevi\u0107, Khalil Sima\u2019an"
  bibkey: stanojevic-simaan-2017-alternative
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2004
  month: July
  page_first: '20'
  page_last: '25'
  pages: "20\u201325"
  paper_id: '4'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2004.jpg
  title: Alternative Objective Functions for Training MT Evaluation Metrics
  title_html: Alternative Objective Functions for Training <span class="acl-fixed-case">MT</span>
    Evaluation Metrics
  url: https://www.aclweb.org/anthology/P17-2004
  year: '2017'
P17-2005:
  abstract: We present a new framework for evaluating extractive summarizers, which
    is based on a principled representation as optimization problem. We prove that
    every extractive summarizer can be decomposed into an objective function and an
    optimization technique. We perform a comparative analysis and evaluation of several
    objective functions embedded in well-known summarizers regarding their correlation
    with human judgments. Our comparison of these correlations across two datasets
    yields surprising insights into the role and performance of objective functions
    in the different summarizers.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2005.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2005.Notes.pdf
  - filename: https://vimeo.com/234952413
    type: video
    url: https://vimeo.com/234952413
  author:
  - first: Maxime
    full: Maxime Peyrard
    id: maxime-peyrard
    last: Peyrard
  - first: Judith
    full: Judith Eckle-Kohler
    id: judith-eckle-kohler
    last: Eckle-Kohler
  author_string: Maxime Peyrard, Judith Eckle-Kohler
  bibkey: peyrard-eckle-kohler-2017-principled
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2005
  month: July
  page_first: '26'
  page_last: '31'
  pages: "26\u201331"
  paper_id: '5'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2005.jpg
  title: 'A Principled Framework for Evaluating Summarizers: Comparing Models of Summary
    Quality against Human Judgments'
  title_html: 'A Principled Framework for Evaluating Summarizers: Comparing Models
    of Summary Quality against Human Judgments'
  url: https://www.aclweb.org/anthology/P17-2005
  year: '2017'
P17-2006:
  abstract: A common test administered during neurological examination is the semantic
    fluency test, in which the patient must list as many examples of a given semantic
    category as possible under timed conditions. Poor performance is associated with
    neurological conditions characterized by impairments in executive function, such
    as dementia, schizophrenia, and autism spectrum disorder (ASD). Methods for analyzing
    semantic fluency responses at the level of detail necessary to uncover these differences
    have typically relied on subjective manual annotation. In this paper, we explore
    automated approaches for scoring semantic fluency responses that leverage ontological
    resources and distributional semantic models to characterize the semantic fluency
    responses produced by young children with and without ASD. Using these methods,
    we find significant differences in the semantic fluency responses of children
    with ASD, demonstrating the utility of using objective methods for clinical language
    analysis.
  address: Vancouver, Canada
  author:
  - first: Emily
    full: "Emily Prud\u2019hommeaux"
    id: emily-prudhommeaux
    last: "Prud\u2019hommeaux"
  - first: Jan
    full: Jan van Santen
    id: jan-van-santen
    last: van Santen
  - first: Douglas
    full: Douglas Gliner
    id: douglas-gliner
    last: Gliner
  author_string: "Emily Prud\u2019hommeaux, Jan van Santen, Douglas Gliner"
  bibkey: prudhommeaux-etal-2017-vector
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2006
  month: July
  page_first: '32'
  page_last: '37'
  pages: "32\u201337"
  paper_id: '6'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2006.jpg
  title: Vector space models for evaluating semantic fluency in autism
  title_html: Vector space models for evaluating semantic fluency in autism
  url: https://www.aclweb.org/anthology/P17-2006
  year: '2017'
P17-2007:
  abstract: In this paper, we address semantic parsing in a multilingual context.
    We train one multilingual model that is capable of parsing natural language sentences
    from multiple different languages into their corresponding formal semantic representations.
    We extend an existing sequence-to-tree model to a multi-task learning framework
    which shares the decoder for generating semantic representations. We report evaluation
    results on the multilingual GeoQuery corpus and introduce a new multilingual version
    of the ATIS corpus.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954840
    type: video
    url: https://vimeo.com/234954840
  author:
  - first: Raymond Hendy
    full: Raymond Hendy Susanto
    id: raymond-hendy-susanto
    last: Susanto
  - first: Wei
    full: Wei Lu
    id: wei-lu
    last: Lu
  author_string: Raymond Hendy Susanto, Wei Lu
  bibkey: susanto-lu-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2007
  month: July
  page_first: '38'
  page_last: '44'
  pages: "38\u201344"
  paper_id: '7'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2007.jpg
  title: Neural Architectures for Multilingual Semantic Parsing
  title_html: Neural Architectures for Multilingual Semantic Parsing
  url: https://www.aclweb.org/anthology/P17-2007
  year: '2017'
P17-2008:
  abstract: There is a growing demand for automatic assessment of spoken English proficiency.
    These systems need to handle large variations in input data owing to the wide
    range of candidate skill levels and L1s, and errors from ASR. Some candidates
    will be a poor match to the training data set, undermining the validity of the
    predicted grade. For high stakes tests it is essential for such systems not only
    to grade well, but also to provide a measure of their uncertainty in their predictions,
    enabling rejection to human graders. Previous work examined Gaussian Process (GP)
    graders which, though successful, do not scale well with large data sets. Deep
    Neural Network (DNN) may also be used to provide uncertainty using Monte-Carlo
    Dropout (MCD). This paper proposes a novel method to yield uncertainty and compares
    it to GPs and DNNs with MCD. The proposed approach explicitly teaches a DNN to
    have low uncertainty on training data and high uncertainty on generated artificial
    data. On experiments conducted on data from the Business Language Testing Service
    (BULATS), the proposed approach is found to outperform GPs and DNNs with MCD in
    uncertainty-based rejection whilst achieving comparable grading performance.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234954045
    type: video
    url: https://vimeo.com/234954045
  author:
  - first: Andrey
    full: Andrey Malinin
    id: andrey-malinin
    last: Malinin
  - first: Anton
    full: Anton Ragni
    id: anton-ragni
    last: Ragni
  - first: Kate
    full: Kate Knill
    id: kate-knill
    last: Knill
  - first: Mark
    full: Mark Gales
    id: mark-gales
    last: Gales
  author_string: Andrey Malinin, Anton Ragni, Kate Knill, Mark Gales
  bibkey: malinin-etal-2017-incorporating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2008
  month: July
  page_first: '45'
  page_last: '50'
  pages: "45\u201350"
  paper_id: '8'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2008.jpg
  title: Incorporating Uncertainty into Deep Learning for Spoken Language Assessment
  title_html: Incorporating Uncertainty into Deep Learning for Spoken Language Assessment
  url: https://www.aclweb.org/anthology/P17-2008
  year: '2017'
P17-2009:
  abstract: "Language identification (LID) is a critical first step for processing\
    \ multilingual text. Yet most LID systems are not designed to handle the linguistic\
    \ diversity of global platforms like Twitter, where local dialects and rampant\
    \ code-switching lead language classifiers to systematically miss minority dialect\
    \ speakers and multilingual speakers. We propose a new dataset and a character-based\
    \ sequence-to-sequence model for LID designed to support dialectal and multilingual\
    \ language varieties. Our model achieves state-of-the-art performance on multiple\
    \ LID benchmarks. Furthermore, in a case study using Twitter for health tracking,\
    \ our method substantially increases the availability of texts written by underrepresented\
    \ populations, enabling the development of \u201Csocially inclusive\u201D NLP\
    \ tools."
  address: Vancouver, Canada
  attachment:
  - filename: P17-2009.Notes.zip
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2009.Notes.zip
  - filename: https://vimeo.com/234952193
    type: video
    url: https://vimeo.com/234952193
  author:
  - first: David
    full: David Jurgens
    id: david-jurgens
    last: Jurgens
  - first: Yulia
    full: Yulia Tsvetkov
    id: yulia-tsvetkov
    last: Tsvetkov
  - first: Dan
    full: Dan Jurafsky
    id: dan-jurafsky
    last: Jurafsky
  author_string: David Jurgens, Yulia Tsvetkov, Dan Jurafsky
  bibkey: jurgens-etal-2017-incorporating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2009
  month: July
  page_first: '51'
  page_last: '57'
  pages: "51\u201357"
  paper_id: '9'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2009.jpg
  title: Incorporating Dialectal Variability for Socially Equitable Language Identification
  title_html: Incorporating Dialectal Variability for Socially Equitable Language
    Identification
  url: https://www.aclweb.org/anthology/P17-2009
  year: '2017'
P17-2010:
  abstract: Traditionally, compound splitters are evaluated intrinsically on gold-standard
    data or extrinsically on the task of statistical machine translation. We explore
    a novel way for the extrinsic evaluation of compound splitters, namely recognizing
    textual entailment. Compound splitting has great potential for this novel task
    that is both transparent and well-defined. Moreover, we show that it addresses
    certain aspects that are either ignored in intrinsic evaluations or compensated
    for by taskinternal mechanisms in statistical machine translation. We show significant
    improvements using different compound splitting methods on a German textual entailment
    dataset.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234952906
    type: video
    url: https://vimeo.com/234952906
  author:
  - first: Glorianna
    full: Glorianna Jagfeld
    id: glorianna-jagfeld
    last: Jagfeld
  - first: Patrick
    full: Patrick Ziering
    id: patrick-ziering
    last: Ziering
  - first: Lonneke
    full: Lonneke van der Plas
    id: lonneke-van-der-plas
    last: van der Plas
  author_string: Glorianna Jagfeld, Patrick Ziering, Lonneke van der Plas
  bibkey: jagfeld-etal-2017-evaluating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2010
  month: July
  page_first: '58'
  page_last: '63'
  pages: "58\u201363"
  paper_id: '10'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2010.jpg
  title: Evaluating Compound Splitters Extrinsically with Textual Entailment
  title_html: Evaluating Compound Splitters Extrinsically with Textual Entailment
  url: https://www.aclweb.org/anthology/P17-2010
  year: '2017'
P17-2011:
  abstract: A large amount of recent research has focused on tasks that combine language
    and vision, resulting in a proliferation of datasets and methods. One such task
    is action recognition, whose applications include image annotation, scene understanding
    and image retrieval. In this survey, we categorize the existing approaches based
    on how they conceptualize this problem and provide a detailed review of existing
    datasets, highlighting their diversity as well as advantages and disadvantages.
    We focus on recently developed datasets which link visual information with linguistic
    resources and provide a fine-grained syntactic and semantic analysis of actions
    in images.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958170
    type: video
    url: https://vimeo.com/234958170
  author:
  - first: Spandana
    full: Spandana Gella
    id: spandana-gella
    last: Gella
  - first: Frank
    full: Frank Keller
    id: frank-keller
    last: Keller
  author_string: Spandana Gella, Frank Keller
  bibkey: gella-keller-2017-analysis
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2011
  month: July
  page_first: '64'
  page_last: '71'
  pages: "64\u201371"
  paper_id: '11'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2011.jpg
  title: An Analysis of Action Recognition Datasets for Language and Vision Tasks
  title_html: An Analysis of Action Recognition Datasets for Language and Vision Tasks
  url: https://www.aclweb.org/anthology/P17-2011
  year: '2017'
P17-2012:
  abstract: There has been relatively little attention to incorporating linguistic
    prior to neural machine translation. Much of the previous work was further constrained
    to considering linguistic prior on the source side. In this paper, we propose
    a hybrid model, called NMT+RNNG, that learns to parse and translate by combining
    the recurrent neural network grammar into the attention-based neural machine translation.
    Our approach encourages the neural machine translation model to incorporate linguistic
    prior during training, and lets it translate on its own afterward. Extensive experiments
    with four language pairs show the effectiveness of the proposed NMT+RNNG.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955092
    type: video
    url: https://vimeo.com/234955092
  author:
  - first: Akiko
    full: Akiko Eriguchi
    id: akiko-eriguchi
    last: Eriguchi
  - first: Yoshimasa
    full: Yoshimasa Tsuruoka
    id: yoshimasa-tsuruoka
    last: Tsuruoka
  - first: Kyunghyun
    full: Kyunghyun Cho
    id: kyunghyun-cho
    last: Cho
  author_string: Akiko Eriguchi, Yoshimasa Tsuruoka, Kyunghyun Cho
  bibkey: eriguchi-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2012
  month: July
  page_first: '72'
  page_last: '78'
  pages: "72\u201378"
  paper_id: '12'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2012.jpg
  title: Learning to Parse and Translate Improves Neural Machine Translation
  title_html: Learning to Parse and Translate Improves Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-2012
  year: '2017'
P17-2013:
  abstract: Natural language processing has increasingly moved from modeling documents
    and words toward studying the people behind the language. This move to working
    with data at the user or community level has presented the field with different
    characteristics of linguistic data. In this paper, we empirically characterize
    various lexical distributions at different levels of analysis, showing that, while
    most features are decidedly sparse and non-normal at the message-level (as with
    traditional NLP), they follow the central limit theorem to become much more Log-normal
    or even Normal at the user- and county-levels. Finally, we demonstrate that modeling
    lexical features for the correct level of analysis leads to marked improvements
    in common social scientific prediction tasks.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955925
    type: video
    url: https://vimeo.com/234955925
  author:
  - first: Fatemeh
    full: Fatemeh Almodaresi
    id: fatemeh-almodaresi
    last: Almodaresi
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  - first: Vivek
    full: Vivek Kulkarni
    id: vivek-kulkarni
    last: Kulkarni
  - first: Mohsen
    full: Mohsen Zakeri
    id: mohsen-zakeri
    last: Zakeri
  - first: Salvatore
    full: Salvatore Giorgi
    id: salvatore-giorgi
    last: Giorgi
  - first: H. Andrew
    full: H. Andrew Schwartz
    id: h-andrew-schwartz
    last: Schwartz
  author_string: Fatemeh Almodaresi, Lyle Ungar, Vivek Kulkarni, Mohsen Zakeri, Salvatore
    Giorgi, H. Andrew Schwartz
  bibkey: almodaresi-etal-2017-distribution
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2013
  month: July
  page_first: '79'
  page_last: '84'
  pages: "79\u201384"
  paper_id: '13'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2013.jpg
  title: On the Distribution of Lexical Features at Multiple Levels of Analysis
  title_html: On the Distribution of Lexical Features at Multiple Levels of Analysis
  url: https://www.aclweb.org/anthology/P17-2013
  year: '2017'
P17-2014:
  abstract: We present the first attempt at using sequence to sequence neural networks
    to model text simplification (TS). Unlike the previously proposed automated TS
    systems, our neural text simplification (NTS) systems are able to simultaneously
    perform lexical simplification and content reduction. An extensive human evaluation
    of the output has shown that NTS systems achieve almost perfect grammaticality
    and meaning preservation of output sentences and higher level of simplification
    than the state-of-the-art automated TS systems
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956698
    type: video
    url: https://vimeo.com/234956698
  author:
  - first: Sergiu
    full: Sergiu Nisioi
    id: sergiu-nisioi
    last: Nisioi
  - first: Sanja
    full: "Sanja \u0160tajner"
    id: sanja-stajner
    last: "\u0160tajner"
  - first: Simone Paolo
    full: Simone Paolo Ponzetto
    id: simone-paolo-ponzetto
    last: Ponzetto
  - first: Liviu P.
    full: Liviu P. Dinu
    id: liviu-p-dinu
    last: Dinu
  author_string: "Sergiu Nisioi, Sanja \u0160tajner, Simone Paolo Ponzetto, Liviu\
    \ P. Dinu"
  bibkey: nisioi-etal-2017-exploring
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2014
  month: July
  page_first: '85'
  page_last: '91'
  pages: "85\u201391"
  paper_id: '14'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2014.jpg
  title: Exploring Neural Text Simplification Models
  title_html: Exploring Neural Text Simplification Models
  url: https://www.aclweb.org/anthology/P17-2014
  year: '2017'
P17-2015:
  abstract: This paper highlights challenges in industrial research related to translating
    research in natural language processing into commercial products. While the interest
    in natural language processing from industry is significant, the transfer of research
    to commercial products is non-trivial and its challenges are often unknown to
    or underestimated by many researchers. I discuss current obstacles and provide
    suggestions for increasing the chances for translating research to commercial
    success based on my experience in industrial research.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2015.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2015.Presentation.pdf
  - filename: https://vimeo.com/234956890
    type: video
    url: https://vimeo.com/234956890
  author:
  - first: Daniel
    full: Daniel Dahlmeier
    id: daniel-dahlmeier
    last: Dahlmeier
  author_string: Daniel Dahlmeier
  bibkey: dahlmeier-2017-challenges
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2015
  month: July
  page_first: '92'
  page_last: '96'
  pages: "92\u201396"
  paper_id: '15'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2015.jpg
  title: On the Challenges of Translating NLP Research into Commercial Products
  title_html: On the Challenges of Translating <span class="acl-fixed-case">NLP</span>
    Research into Commercial Products
  url: https://www.aclweb.org/anthology/P17-2015
  year: '2017'
P17-2016:
  abstract: We provide several methods for sentence-alignment of texts with different
    complexity levels. Using the best of them, we sentence-align the Newsela corpora,
    thus providing large training materials for automatic text simplification (ATS)
    systems. We show that using this dataset, even the standard phrase-based statistical
    machine translation models for ATS can outperform the state-of-the-art ATS systems.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234958364
    type: video
    url: https://vimeo.com/234958364
  author:
  - first: Sanja
    full: "Sanja \u0160tajner"
    id: sanja-stajner
    last: "\u0160tajner"
  - first: Marc
    full: Marc Franco-Salvador
    id: marc-franco-salvador
    last: Franco-Salvador
  - first: Simone Paolo
    full: Simone Paolo Ponzetto
    id: simone-paolo-ponzetto
    last: Ponzetto
  - first: Paolo
    full: Paolo Rosso
    id: paolo-rosso
    last: Rosso
  - first: Heiner
    full: Heiner Stuckenschmidt
    id: heiner-stuckenschmidt
    last: Stuckenschmidt
  author_string: "Sanja \u0160tajner, Marc Franco-Salvador, Simone Paolo Ponzetto,\
    \ Paolo Rosso, Heiner Stuckenschmidt"
  bibkey: stajner-etal-2017-sentence
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2016
  month: July
  page_first: '97'
  page_last: '102'
  pages: "97\u2013102"
  paper_id: '16'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2016.jpg
  title: Sentence Alignment Methods for Improving Text Simplification Systems
  title_html: Sentence Alignment Methods for Improving Text Simplification Systems
  url: https://www.aclweb.org/anthology/P17-2016
  year: '2017'
P17-2017:
  abstract: Linguistically diverse datasets are critical for training and evaluating
    robust machine learning systems, but data collection is a costly process that
    often requires experts. Crowdsourcing the process of paraphrase generation is
    an effective means of expanding natural language datasets, but there has been
    limited analysis of the trade-offs that arise when designing tasks. In this paper,
    we present the first systematic study of the key factors in crowdsourcing paraphrase
    collection. We consider variations in instructions, incentives, data domains,
    and workflows. We manually analyzed paraphrases for correctness, grammaticality,
    and linguistic diversity. Our observations provide new insight into the trade-offs
    between accuracy and diversity in crowd responses that arise as a result of task
    design, providing guidance for future paraphrase generation procedures.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2017.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2017.Presentation.pdf
  - filename: P17-2017.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-2017.Datasets.zip
  - filename: https://vimeo.com/234958413
    type: video
    url: https://vimeo.com/234958413
  author:
  - first: Youxuan
    full: Youxuan Jiang
    id: youxuan-jiang
    last: Jiang
  - first: Jonathan K.
    full: Jonathan K. Kummerfeld
    id: jonathan-k-kummerfeld
    last: Kummerfeld
  - first: Walter S.
    full: Walter S. Lasecki
    id: walter-lasecki
    last: Lasecki
  author_string: Youxuan Jiang, Jonathan K. Kummerfeld, Walter S. Lasecki
  bibkey: jiang-etal-2017-understanding
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2017
  month: July
  page_first: '103'
  page_last: '109'
  pages: "103\u2013109"
  paper_id: '17'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2017.jpg
  title: Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection
  title_html: Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection
  url: https://www.aclweb.org/anthology/P17-2017
  year: '2017'
P17-2018:
  abstract: "Transition-based dependency parsers often need sequences of local shift\
    \ and reduce operations to produce certain attachments. Correct individual decisions\
    \ hence require global information about the sentence context and mistakes cause\
    \ error propagation. This paper proposes a novel transition system, arc-swift,\
    \ that enables direct attachments between tokens farther apart with a single transition.\
    \ This allows the parser to leverage lexical information more directly in transition\
    \ decisions. Hence, arc-swift can achieve significantly better performance with\
    \ a very small beam size. Our parsers reduce error by 3.7\u20137.6% relative to\
    \ those using existing transition systems on the Penn Treebank dependency parsing\
    \ task and English Universal Dependencies."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957642
    type: video
    url: https://vimeo.com/234957642
  author:
  - first: Peng
    full: Peng Qi
    id: peng-qi
    last: Qi
  - first: Christopher D.
    full: Christopher D. Manning
    id: christopher-d-manning
    last: Manning
  author_string: Peng Qi, Christopher D. Manning
  bibkey: qi-manning-2017-arc
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2018
  month: July
  page_first: '110'
  page_last: '117'
  pages: "110\u2013117"
  paper_id: '18'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2018.jpg
  title: 'Arc-swift: A Novel Transition System for Dependency Parsing'
  title_html: 'Arc-swift: A Novel Transition System for Dependency Parsing'
  url: https://www.aclweb.org/anthology/P17-2018
  year: '2017'
P17-2019:
  abstract: Generative models defining joint distributions over parse trees and sentences
    are useful for parsing and language modeling, but impose restrictions on the scope
    of features and are often outperformed by discriminative models. We propose a
    framework for parsing and language modeling which marries a generative model with
    a discriminative recognition model in an encoder-decoder setting. We provide interpretations
    of the framework based on expectation maximization and variational inference,
    and show that it enables parsing and language modeling within a single implementation.
    On the English Penn Treen-bank, our framework obtains competitive performance
    on constituency parsing while matching the state-of-the-art single-model language
    modeling score.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957682
    type: video
    url: https://vimeo.com/234957682
  author:
  - first: Jianpeng
    full: Jianpeng Cheng
    id: jianpeng-cheng
    last: Cheng
  - first: Adam
    full: Adam Lopez
    id: adam-lopez
    last: Lopez
  - first: Mirella
    full: Mirella Lapata
    id: mirella-lapata
    last: Lapata
  author_string: Jianpeng Cheng, Adam Lopez, Mirella Lapata
  bibkey: cheng-etal-2017-generative
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2019
  month: July
  page_first: '118'
  page_last: '124'
  pages: "118\u2013124"
  paper_id: '19'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2019.jpg
  title: A Generative Parser with a Discriminative Recognition Algorithm
  title_html: A Generative Parser with a Discriminative Recognition Algorithm
  url: https://www.aclweb.org/anthology/P17-2019
  year: '2017'
P17-2020:
  abstract: Recently, the neural machine translation systems showed their promising
    performance and surpassed the phrase-based systems for most translation tasks.
    Retreating into conventional concepts machine translation while utilizing effective
    neural models is vital for comprehending the leap accomplished by neural machine
    translation over phrase-based methods. This work proposes a direct HMM with neural
    network-based lexicon and alignment models, which are trained jointly using the
    Baum-Welch algorithm. The direct HMM is applied to rerank the n-best list created
    by a state-of-the-art phrase-based translation system and it provides improvements
    by up to 1.0% Bleu scores on two different translation tasks.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955312
    type: video
    url: https://vimeo.com/234955312
  author:
  - first: Weiyue
    full: Weiyue Wang
    id: weiyue-wang
    last: Wang
  - first: Tamer
    full: Tamer Alkhouli
    id: tamer-alkhouli
    last: Alkhouli
  - first: Derui
    full: Derui Zhu
    id: derui-zhu
    last: Zhu
  - first: Hermann
    full: Hermann Ney
    id: hermann-ney
    last: Ney
  author_string: Weiyue Wang, Tamer Alkhouli, Derui Zhu, Hermann Ney
  bibkey: wang-etal-2017-hybrid
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2020
  month: July
  page_first: '125'
  page_last: '131'
  pages: "125\u2013131"
  paper_id: '20'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2020.jpg
  title: Hybrid Neural Network Alignment and Lexicon Model in Direct HMM for Statistical
    Machine Translation
  title_html: Hybrid Neural Network Alignment and Lexicon Model in Direct <span class="acl-fixed-case">HMM</span>
    for Statistical Machine Translation
  url: https://www.aclweb.org/anthology/P17-2020
  year: '2017'
P17-2021:
  abstract: We present a simple method to incorporate syntactic information about
    the target language in a neural machine translation system by translating into
    linearized, lexicalized constituency trees. An experiment on the WMT16 German-English
    news translation task resulted in an improved BLEU score when compared to a syntax-agnostic
    NMT baseline trained on the same dataset. An analysis of the translations from
    the syntax-aware system shows that it performs more reordering during translation
    in comparison to the baseline. A small-scale human evaluation also showed an advantage
    to the syntax-aware system.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2021.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2021.Presentation.pdf
  - filename: https://vimeo.com/234955359
    type: video
    url: https://vimeo.com/234955359
  author:
  - first: Roee
    full: Roee Aharoni
    id: roee-aharoni
    last: Aharoni
  - first: Yoav
    full: Yoav Goldberg
    id: yoav-goldberg
    last: Goldberg
  author_string: Roee Aharoni, Yoav Goldberg
  bibkey: aharoni-goldberg-2017-towards
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2021
  month: July
  page_first: '132'
  page_last: '140'
  pages: "132\u2013140"
  paper_id: '21'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2021.jpg
  title: Towards String-To-Tree Neural Machine Translation
  title_html: Towards String-To-Tree Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-2021
  year: '2017'
P17-2022:
  abstract: "Informal first-person narratives are a unique resource for computational\
    \ models of everyday events and people\u2019s affective reactions to them. People\
    \ blogging about their day tend not to explicitly say I am happy. Instead they\
    \ describe situations from which other humans can readily infer their affective\
    \ reactions. However current sentiment dictionaries are missing much of the information\
    \ needed to make similar inferences. We build on recent work that models affect\
    \ in terms of lexical predicate functions and affect on the predicate\u2019s arguments.\
    \ We present a method to learn proxies for these functions from first-person narratives.\
    \ We construct a novel fine-grained test set, and show that the patterns we learn\
    \ improve our ability to predict first-person affective reactions to everyday\
    \ events, from a Stanford sentiment baseline of .67F to .75F."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956090
    type: video
    url: https://vimeo.com/234956090
  author:
  - first: Lena
    full: Lena Reed
    id: lena-reed
    last: Reed
  - first: Jiaqi
    full: Jiaqi Wu
    id: jiaqi-wu
    last: Wu
  - first: Shereen
    full: Shereen Oraby
    id: shereen-oraby
    last: Oraby
  - first: Pranav
    full: Pranav Anand
    id: pranav-anand
    last: Anand
  - first: Marilyn
    full: Marilyn Walker
    id: marilyn-walker
    last: Walker
  author_string: Lena Reed, Jiaqi Wu, Shereen Oraby, Pranav Anand, Marilyn Walker
  bibkey: reed-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2022
  month: July
  page_first: '141'
  page_last: '147'
  pages: "141\u2013147"
  paper_id: '22'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2022.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2022.jpg
  title: Learning Lexico-Functional Patterns for First-Person Affect
  title_html: Learning Lexico-Functional Patterns for First-Person Affect
  url: https://www.aclweb.org/anthology/P17-2022
  year: '2017'
P17-2023:
  abstract: This paper makes a focused contribution to supervised aspect extraction.
    It shows that if the system has performed aspect extraction from many past domains
    and retained their results as knowledge, Conditional Random Fields (CRF) can leverage
    this knowledge in a lifelong learning manner to extract in a new domain markedly
    better than the traditional CRF without using this prior knowledge. The key innovation
    is that even after CRF training, the model can still improve its extraction with
    experiences in its applications.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956125
    type: video
    url: https://vimeo.com/234956125
  author:
  - first: Lei
    full: Lei Shu
    id: lei-shu
    last: Shu
  - first: Hu
    full: Hu Xu
    id: hu-xu
    last: Xu
  - first: Bing
    full: Bing Liu
    id: bing-liu
    last: Liu
  author_string: Lei Shu, Hu Xu, Bing Liu
  bibkey: shu-etal-2017-lifelong
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2023
  month: July
  page_first: '148'
  page_last: '154'
  pages: "148\u2013154"
  paper_id: '23'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2023.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2023.jpg
  title: Lifelong Learning CRF for Supervised Aspect Extraction
  title_html: Lifelong Learning <span class="acl-fixed-case">CRF</span> for Supervised
    Aspect Extraction
  url: https://www.aclweb.org/anthology/P17-2023
  year: '2017'
P17-2024:
  abstract: A fundamental advantage of neural models for NLP is their ability to learn
    representations from scratch. However, in practice this often means ignoring existing
    external linguistic resources, e.g., WordNet or domain specific ontologies such
    as the Unified Medical Language System (UMLS). We propose a general, novel method
    for exploiting such resources via weight sharing. Prior work on weight sharing
    in neural networks has considered it largely as a means of model compression.
    In contrast, we treat weight sharing as a flexible mechanism for incorporating
    prior knowledge into neural models. We show that this approach consistently yields
    improved performance on classification tasks compared to baseline strategies that
    do not exploit weight sharing.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234956168
    type: video
    url: https://vimeo.com/234956168
  author:
  - first: Ye
    full: Ye Zhang
    id: ye-zhang
    last: Zhang
  - first: Matthew
    full: Matthew Lease
    id: matthew-lease
    last: Lease
  - first: Byron C.
    full: Byron C. Wallace
    id: byron-c-wallace
    last: Wallace
  author_string: Ye Zhang, Matthew Lease, Byron C. Wallace
  bibkey: zhang-etal-2017-exploiting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2024
  month: July
  page_first: '155'
  page_last: '160'
  pages: "155\u2013160"
  paper_id: '24'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2024.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2024.jpg
  title: Exploiting Domain Knowledge via Grouped Weight Sharing with Application to
    Text Categorization
  title_html: Exploiting Domain Knowledge via Grouped Weight Sharing with Application
    to Text Categorization
  url: https://www.aclweb.org/anthology/P17-2024
  year: '2017'
P17-2025:
  abstract: Recent work has proposed several generative neural models for constituency
    parsing that achieve state-of-the-art results. Since direct search in these generative
    models is difficult, they have primarily been used to rescore candidate outputs
    from base parsers in which decoding is more straightforward. We first present
    an algorithm for direct search in these generative models. We then demonstrate
    that the rescoring results are at least partly due to implicit model combination
    rather than reranking effects. Finally, we show that explicit model combination
    can improve performance even further, resulting in new state-of-the-art numbers
    on the PTB of 94.25 F1 when training only on gold data and 94.66 F1 when using
    external data.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234957130
    type: video
    url: https://vimeo.com/234957130
  author:
  - first: Daniel
    full: Daniel Fried
    id: daniel-fried
    last: Fried
  - first: Mitchell
    full: Mitchell Stern
    id: mitchell-stern
    last: Stern
  - first: Dan
    full: Dan Klein
    id: dan-klein
    last: Klein
  author_string: Daniel Fried, Mitchell Stern, Dan Klein
  bibkey: fried-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2025
  month: July
  page_first: '161'
  page_last: '166'
  pages: "161\u2013166"
  paper_id: '25'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2025.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2025.jpg
  title: Improving Neural Parsing by Disentangling Model Combination and Reranking
    Effects
  title_html: Improving Neural Parsing by Disentangling Model Combination and Reranking
    Effects
  url: https://www.aclweb.org/anthology/P17-2025
  year: '2017'
P17-2026:
  abstract: "In this paper we define a measure of dependency between two random variables,\
    \ based on the Jensen-Shannon (JS) divergence between their joint distribution\
    \ and the product of their marginal distributions. Then, we show that word2vec\u2019\
    s skip-gram with negative sampling embedding algorithm finds the optimal low-dimensional\
    \ approximation of this JS dependency measure between the words and their contexts.\
    \ The gap between the optimal score and the low-dimensional approximation is demonstrated\
    \ on a standard text corpus."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955606
    type: video
    url: https://vimeo.com/234955606
  author:
  - first: Oren
    full: Oren Melamud
    id: oren-melamud
    last: Melamud
  - first: Jacob
    full: Jacob Goldberger
    id: jacob-goldberger
    last: Goldberger
  author_string: Oren Melamud, Jacob Goldberger
  bibkey: melamud-goldberger-2017-information
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2026
  month: July
  page_first: '167'
  page_last: '171'
  pages: "167\u2013171"
  paper_id: '26'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2026.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2026.jpg
  title: Information-Theory Interpretation of the Skip-Gram Negative-Sampling Objective
    Function
  title_html: Information-Theory Interpretation of the Skip-Gram Negative-Sampling
    Objective Function
  url: https://www.aclweb.org/anthology/P17-2026
  year: '2017'
P17-2027:
  abstract: In this work, we propose a novel, implicitly-defined neural network architecture
    and describe a method to compute its components. The proposed architecture forgoes
    the causality assumption used to formulate recurrent neural networks and instead
    couples the hidden states of the network, allowing improvement on problems with
    complex, long-distance dependencies. Initial experiments demonstrate the new architecture
    outperforms both the Stanford Parser and baseline bidirectional networks on the
    Penn Treebank Part-of-Speech tagging task and a baseline bidirectional network
    on an additional artificial random biased walk task.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234955651
    type: video
    url: https://vimeo.com/234955651
  author:
  - first: Michaeel
    full: Michaeel Kazi
    id: michaeel-kazi
    last: Kazi
  - first: Brian
    full: Brian Thompson
    id: brian-thompson
    last: Thompson
  author_string: Michaeel Kazi, Brian Thompson
  bibkey: kazi-thompson-2017-implicitly
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2027
  month: July
  page_first: '172'
  page_last: '177'
  pages: "172\u2013177"
  paper_id: '27'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2027.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2027.jpg
  title: Implicitly-Defined Neural Networks for Sequence Labeling
  title_html: Implicitly-Defined Neural Networks for Sequence Labeling
  url: https://www.aclweb.org/anthology/P17-2027
  year: '2017'
P17-2028:
  abstract: This study explores the role of speech register and prosody for the task
    of word segmentation. Since these two factors are thought to play an important
    role in early language acquisition, we aim to quantify their contribution for
    this task. We study a Japanese corpus containing both infant- and adult-directed
    speech and we apply four different word segmentation models, with and without
    knowledge of prosodic boundaries. The results showed that the difference between
    registers is smaller than previously reported and that prosodic boundary information
    helps more adult- than infant-directed speech.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234959028
    type: video
    url: https://vimeo.com/234959028
  author:
  - first: Bogdan
    full: Bogdan Ludusan
    id: bogdan-ludusan
    last: Ludusan
  - first: Reiko
    full: Reiko Mazuka
    id: reiko-mazuka
    last: Mazuka
  - first: Mathieu
    full: Mathieu Bernard
    id: mathieu-bernard
    last: Bernard
  - first: Alejandrina
    full: Alejandrina Cristia
    id: alejandrina-cristia
    last: Cristia
  - first: Emmanuel
    full: Emmanuel Dupoux
    id: emmanuel-dupoux
    last: Dupoux
  author_string: Bogdan Ludusan, Reiko Mazuka, Mathieu Bernard, Alejandrina Cristia,
    Emmanuel Dupoux
  bibkey: ludusan-etal-2017-role
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2028
  month: July
  page_first: '178'
  page_last: '183'
  pages: "178\u2013183"
  paper_id: '28'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2028.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2028.jpg
  title: 'The Role of Prosody and Speech Register in Word Segmentation: A Computational
    Modelling Perspective'
  title_html: 'The Role of Prosody and Speech Register in Word Segmentation: A Computational
    Modelling Perspective'
  url: https://www.aclweb.org/anthology/P17-2028
  year: '2017'
P17-2029:
  abstract: Previous work introduced transition-based algorithms to form a unified
    architecture of parsing rhetorical structures (including span, nuclearity and
    relation), but did not achieve satisfactory performance. In this paper, we propose
    that transition-based model is more appropriate for parsing the naked discourse
    tree (i.e., identifying span and nuclearity) due to data sparsity. At the same
    time, we argue that relation labeling can benefit from naked tree structure and
    should be treated elaborately with consideration of three kinds of relations including
    within-sentence, across-sentence and across-paragraph relations. Thus, we design
    a pipelined two-stage parsing method for generating an RST tree from text. Experimental
    results show that our method achieves state-of-the-art performance, especially
    on span and nuclearity identification.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234959057
    type: video
    url: https://vimeo.com/234959057
  author:
  - first: Yizhong
    full: Yizhong Wang
    id: yizhong-wang
    last: Wang
  - first: Sujian
    full: Sujian Li
    id: sujian-li
    last: Li
  - first: Houfeng
    full: Houfeng Wang
    id: houfeng-wang
    last: Wang
  author_string: Yizhong Wang, Sujian Li, Houfeng Wang
  bibkey: wang-etal-2017-two
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2029
  month: July
  page_first: '184'
  page_last: '188'
  pages: "184\u2013188"
  paper_id: '29'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2029.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2029.jpg
  title: A Two-Stage Parsing Method for Text-Level Discourse Analysis
  title_html: A Two-Stage Parsing Method for Text-Level Discourse Analysis
  url: https://www.aclweb.org/anthology/P17-2029
  year: '2017'
P17-2030:
  abstract: 'We propose a new dependency parsing scheme which jointly parses a sentence
    and repairs grammatical errors by extending the non-directional transition-based
    formalism of Goldberg and Elhadad (2010) with three additional actions: SUBSTITUTE,
    DELETE, INSERT. Because these actions may cause an infinite loop in derivation,
    we also introduce simple constraints that ensure the parser termination. We evaluate
    our model with respect to dependency accuracy and grammaticality improvements
    for ungrammatical sentences, demonstrating the robustness and applicability of
    our scheme.'
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234959088
    type: video
    url: https://vimeo.com/234959088
  author:
  - first: Keisuke
    full: Keisuke Sakaguchi
    id: keisuke-sakaguchi
    last: Sakaguchi
  - first: Matt
    full: Matt Post
    id: matt-post
    last: Post
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  author_string: Keisuke Sakaguchi, Matt Post, Benjamin Van Durme
  bibkey: sakaguchi-etal-2017-error
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2030
  month: July
  page_first: '189'
  page_last: '195'
  pages: "189\u2013195"
  paper_id: '30'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2030.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2030.jpg
  title: Error-repair Dependency Parsing for Ungrammatical Texts
  title_html: Error-repair Dependency Parsing for Ungrammatical Texts
  url: https://www.aclweb.org/anthology/P17-2030
  year: '2017'
P17-2031:
  abstract: Modeling attention in neural multi-source sequence-to-sequence learning
    remains a relatively unexplored area, despite its usefulness in tasks that incorporate
    multiple source languages or modalities. We propose two novel approaches to combine
    the outputs of attention mechanisms over each source sequence, flat and hierarchical.
    We compare the proposed methods with existing techniques and present results of
    systematic evaluation of those methods on the WMT16 Multimodal Translation and
    Automatic Post-editing tasks. We show that the proposed methods achieve competitive
    results on both tasks.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2031.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2031.Presentation.pdf
  - filename: https://vimeo.com/234946385
    type: video
    url: https://vimeo.com/234946385
  author:
  - first: "Jind\u0159ich"
    full: "Jind\u0159ich Libovick\xFD"
    id: jindrich-libovicky
    last: "Libovick\xFD"
  - first: "Jind\u0159ich"
    full: "Jind\u0159ich Helcl"
    id: jindrich-helcl
    last: Helcl
  author_string: "Jind\u0159ich Libovick\xFD, Jind\u0159ich Helcl"
  bibkey: libovicky-helcl-2017-attention
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2031
  month: July
  page_first: '196'
  page_last: '202'
  pages: "196\u2013202"
  paper_id: '31'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2031.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2031.jpg
  title: Attention Strategies for Multi-Source Sequence-to-Sequence Learning
  title_html: Attention Strategies for Multi-Source Sequence-to-Sequence Learning
  url: https://www.aclweb.org/anthology/P17-2031
  year: '2017'
P17-2032:
  abstract: We investigate the problem of sentence-level supporting argument detection
    from relevant documents for user-specified claims. A dataset containing claims
    and associated citation articles is collected from online debate website idebate.org.
    We then manually label sentence-level supporting arguments from the documents
    along with their types as study, factual, opinion, or reasoning. We further characterize
    arguments of different types, and explore whether leveraging type information
    can facilitate the supporting arguments detection task. Experimental results show
    that LambdaMART (Burges, 2010) ranker that uses features informed by argument
    types yields better performance than the same ranker trained without type information.
  address: Vancouver, Canada
  author:
  - first: Xinyu
    full: Xinyu Hua
    id: xinyu-hua
    last: Hua
  - first: Lu
    full: Lu Wang
    id: lu-wang
    last: Wang
  author_string: Xinyu Hua, Lu Wang
  bibkey: hua-wang-2017-understanding
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2032
  month: July
  page_first: '203'
  page_last: '208'
  pages: "203\u2013208"
  paper_id: '32'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2032.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2032.jpg
  title: Understanding and Detecting Supporting Arguments of Diverse Types
  title_html: Understanding and Detecting Supporting Arguments of Diverse Types
  url: https://www.aclweb.org/anthology/P17-2032
  year: '2017'
P17-2033:
  abstract: We propose a simple yet effective text-based user geolocation model based
    on a neural network with one hidden layer, which achieves state of the art performance
    over three Twitter benchmark geolocation datasets, in addition to producing word
    and phrase embeddings in the hidden layer that we show to be useful for detecting
    dialectal terms. As part of our analysis of dialectal terms, we release DAREDS,
    a dataset for evaluating dialect term detection methods.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234946757
    type: video
    url: https://vimeo.com/234946757
  author:
  - first: Afshin
    full: Afshin Rahimi
    id: afshin-rahimi
    last: Rahimi
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  - first: Timothy
    full: Timothy Baldwin
    id: timothy-baldwin
    last: Baldwin
  author_string: Afshin Rahimi, Trevor Cohn, Timothy Baldwin
  bibkey: rahimi-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2033
  month: July
  page_first: '209'
  page_last: '216'
  pages: "209\u2013216"
  paper_id: '33'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2033.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2033.jpg
  title: A Neural Model for User Geolocation and Lexical Dialectology
  title_html: A Neural Model for User Geolocation and Lexical Dialectology
  url: https://www.aclweb.org/anthology/P17-2033
  year: '2017'
P17-2034:
  abstract: We present a new visual reasoning language dataset, containing 92,244
    pairs of examples of natural statements grounded in synthetic images with 3,962
    unique sentences. We describe a method of crowdsourcing linguistically-diverse
    data, and present an analysis of our data. The data demonstrates a broad set of
    linguistic phenomena, requiring visual and set-theoretic reasoning. We experiment
    with various models, and show the data presents a strong challenge for future
    research.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2034.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2034.Notes.pdf
  - filename: https://vimeo.com/234946948
    type: video
    url: https://vimeo.com/234946948
  author:
  - first: Alane
    full: Alane Suhr
    id: alane-suhr
    last: Suhr
  - first: Mike
    full: Mike Lewis
    id: mike-lewis
    last: Lewis
  - first: James
    full: James Yeh
    id: james-yeh
    last: Yeh
  - first: Yoav
    full: Yoav Artzi
    id: yoav-artzi
    last: Artzi
  author_string: Alane Suhr, Mike Lewis, James Yeh, Yoav Artzi
  bibkey: suhr-etal-2017-corpus
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2034
  month: July
  page_first: '217'
  page_last: '223'
  pages: "217\u2013223"
  paper_id: '34'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2034.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2034.jpg
  title: A Corpus of Natural Language for Visual Reasoning
  title_html: A Corpus of Natural Language for Visual Reasoning
  url: https://www.aclweb.org/anthology/P17-2034
  year: '2017'
P17-2035:
  abstract: We present a neural architecture for containment relation identification
    between medical events and/or temporal expressions. We experiment on a corpus
    of de-identified clinical notes in English from the Mayo Clinic, namely the THYME
    corpus. Our model achieves an F-measure of 0.613 and outperforms the best result
    reported on this corpus to date.
  address: Vancouver, Canada
  author:
  - first: Julien
    full: Julien Tourille
    id: julien-tourille
    last: Tourille
  - first: Olivier
    full: Olivier Ferret
    id: olivier-ferret
    last: Ferret
  - first: "Aur\xE9lie"
    full: "Aur\xE9lie N\xE9v\xE9ol"
    id: aurelie-neveol
    last: "N\xE9v\xE9ol"
  - first: Xavier
    full: Xavier Tannier
    id: xavier-tannier
    last: Tannier
  author_string: "Julien Tourille, Olivier Ferret, Aur\xE9lie N\xE9v\xE9ol, Xavier\
    \ Tannier"
  bibkey: tourille-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2035
  month: July
  page_first: '224'
  page_last: '230'
  pages: "224\u2013230"
  paper_id: '35'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2035.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2035.jpg
  title: 'Neural Architecture for Temporal Relation Extraction: A Bi-LSTM Approach
    for Detecting Narrative Containers'
  title_html: 'Neural Architecture for Temporal Relation Extraction: A Bi-<span class="acl-fixed-case">LSTM</span>
    Approach for Detecting Narrative Containers'
  url: https://www.aclweb.org/anthology/P17-2035
  year: '2017'
P17-2036:
  abstract: Generative conversational systems are attracting increasing attention
    in natural language processing (NLP). Recently, researchers have noticed the importance
    of context information in dialog processing, and built various models to utilize
    context. However, there is no systematic comparison to analyze how to use context
    effectively. In this paper, we conduct an empirical study to compare various models
    and investigate the effect of context information in dialog systems. We also propose
    a variant that explicitly weights context vectors by context-query relevance,
    outperforming the other baselines.
  address: Vancouver, Canada
  author:
  - first: Zhiliang
    full: Zhiliang Tian
    id: zhiliang-tian
    last: Tian
  - first: Rui
    full: Rui Yan
    id: rui-yan
    last: Yan
  - first: Lili
    full: Lili Mou
    id: lili-mou
    last: Mou
  - first: Yiping
    full: Yiping Song
    id: yiping-song
    last: Song
  - first: Yansong
    full: Yansong Feng
    id: yansong-feng
    last: Feng
  - first: Dongyan
    full: Dongyan Zhao
    id: dongyan-zhao
    last: Zhao
  author_string: Zhiliang Tian, Rui Yan, Lili Mou, Yiping Song, Yansong Feng, Dongyan
    Zhao
  bibkey: tian-etal-2017-make
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2036
  month: July
  page_first: '231'
  page_last: '236'
  pages: "231\u2013236"
  paper_id: '36'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2036.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2036.jpg
  title: How to Make Context More Useful? An Empirical Study on Context-Aware Neural
    Conversational Models
  title_html: How to Make Context More Useful? An Empirical Study on Context-Aware
    Neural Conversational Models
  url: https://www.aclweb.org/anthology/P17-2036
  year: '2017'
P17-2037:
  abstract: Discourse segmentation is a crucial step in building end-to-end discourse
    parsers. However, discourse segmenters only exist for a few languages and domains.
    Typically they only detect intra-sentential segment boundaries, assuming gold
    standard sentence and token segmentation, and relying on high-quality syntactic
    parses and rich heuristics that are not generally available across languages and
    domains. In this paper, we propose statistical discourse segmenters for five languages
    and three domains that do not rely on gold pre-annotations. We also consider the
    problem of learning discourse segmenters when no labeled data is available for
    a language. Our fully supervised system obtains 89.5% F1 for English newswire,
    with slight drops in performance on other domains, and we report supervised and
    unsupervised (cross-lingual) results for five languages in total.
  address: Vancouver, Canada
  author:
  - first: "Chlo\xE9"
    full: "Chlo\xE9 Braud"
    id: chloe-braud
    last: Braud
  - first: "Oph\xE9lie"
    full: "Oph\xE9lie Lacroix"
    id: ophelie-lacroix
    last: Lacroix
  - first: Anders
    full: "Anders S\xF8gaard"
    id: anders-sogaard
    last: "S\xF8gaard"
  author_string: "Chlo\xE9 Braud, Oph\xE9lie Lacroix, Anders S\xF8gaard"
  bibkey: braud-etal-2017-cross-lingual
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2037
  month: July
  page_first: '237'
  page_last: '243'
  pages: "237\u2013243"
  paper_id: '37'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2037.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2037.jpg
  title: Cross-lingual and cross-domain discourse segmentation of entire documents
  title_html: Cross-lingual and cross-domain discourse segmentation of entire documents
  url: https://www.aclweb.org/anthology/P17-2037
  year: '2017'
P17-2038:
  abstract: "Automatic identification of good arguments on a controversial topic has\
    \ applications in civics and education, to name a few. While in the civics context\
    \ it might be acceptable to create separate models for each topic, in the context\
    \ of scoring of students\u2019 writing there is a preference for a single model\
    \ that applies to all responses. Given that good arguments for one topic are likely\
    \ to be irrelevant for another, is a single model for detecting good arguments\
    \ a contradiction in terms? We investigate the extent to which it is possible\
    \ to close the performance gap between topic-specific and across-topics models\
    \ for identification of good arguments."
  address: Vancouver, Canada
  author:
  - first: Beata
    full: Beata Beigman Klebanov
    id: beata-beigman-klebanov
    last: Beigman Klebanov
  - first: Binod
    full: Binod Gyawali
    id: binod-gyawali
    last: Gyawali
  - first: Yi
    full: Yi Song
    id: yi-song
    last: Song
  author_string: Beata Beigman Klebanov, Binod Gyawali, Yi Song
  bibkey: beigman-klebanov-etal-2017-detecting
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2038
  month: July
  page_first: '244'
  page_last: '249'
  pages: "244\u2013249"
  paper_id: '38'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2038.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2038.jpg
  title: 'Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?'
  title_html: 'Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?'
  url: https://www.aclweb.org/anthology/P17-2038
  year: '2017'
P17-2039:
  abstract: Argumentation quality is viewed differently in argumentation theory and
    in practical assessment approaches. This paper studies to what extent the views
    match empirically. We find that most observations on quality phrased spontaneously
    are in fact adequately represented by theory. Even more, relative comparisons
    of arguments in practice correlate with absolute quality ratings based on theory.
    Our results clarify how the two views can learn from each other.
  address: Vancouver, Canada
  author:
  - first: Henning
    full: Henning Wachsmuth
    id: henning-wachsmuth
    last: Wachsmuth
  - first: Nona
    full: Nona Naderi
    id: nona-naderi
    last: Naderi
  - first: Ivan
    full: Ivan Habernal
    id: ivan-habernal
    last: Habernal
  - first: Yufang
    full: Yufang Hou
    id: yufang-hou
    last: Hou
  - first: Graeme
    full: Graeme Hirst
    id: graeme-hirst
    last: Hirst
  - first: Iryna
    full: Iryna Gurevych
    id: iryna-gurevych
    last: Gurevych
  - first: Benno
    full: Benno Stein
    id: benno-stein
    last: Stein
  author_string: Henning Wachsmuth, Nona Naderi, Ivan Habernal, Yufang Hou, Graeme
    Hirst, Iryna Gurevych, Benno Stein
  bibkey: wachsmuth-etal-2017-argumentation
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2039
  month: July
  page_first: '250'
  page_last: '255'
  pages: "250\u2013255"
  paper_id: '39'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2039.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2039.jpg
  title: 'Argumentation Quality Assessment: Theory vs. Practice'
  title_html: 'Argumentation Quality Assessment: Theory vs. Practice'
  url: https://www.aclweb.org/anthology/P17-2039
  year: '2017'
P17-2040:
  abstract: "We introduce an attention-based Bi-LSTM for Chinese implicit discourse\
    \ relations and demonstrate that modeling argument pairs as a joint sequence can\
    \ outperform word order-agnostic approaches. Our model benefits from a partial\
    \ sampling scheme and is conceptually simple, yet achieves state-of-the-art performance\
    \ on the Chinese Discourse Treebank. We also visualize its attention activity\
    \ to illustrate the model\u2019s ability to selectively focus on the relevant\
    \ parts of an input sequence."
  address: Vancouver, Canada
  author:
  - first: Samuel
    full: "Samuel R\xF6nnqvist"
    id: samuel-ronnqvist
    last: "R\xF6nnqvist"
  - first: Niko
    full: Niko Schenk
    id: niko-schenk
    last: Schenk
  - first: Christian
    full: Christian Chiarcos
    id: christian-chiarcos
    last: Chiarcos
  author_string: "Samuel R\xF6nnqvist, Niko Schenk, Christian Chiarcos"
  bibkey: ronnqvist-etal-2017-recurrent
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2040
  month: July
  page_first: '256'
  page_last: '262'
  pages: "256\u2013262"
  paper_id: '40'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2040.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2040.jpg
  title: A Recurrent Neural Model with Attention for the Recognition of Chinese Implicit
    Discourse Relations
  title_html: A Recurrent Neural Model with Attention for the Recognition of <span
    class="acl-fixed-case">C</span>hinese Implicit Discourse Relations
  url: https://www.aclweb.org/anthology/P17-2040
  year: '2017'
P17-2041:
  abstract: The availability of the Rhetorical Structure Theory (RST) Discourse Treebank
    has spurred substantial research into discourse analysis of written texts; however,
    limited research has been conducted to date on RST annotation and parsing of spoken
    language, in particular, non-native spontaneous speech. Considering that the measurement
    of discourse coherence is typically a key metric in human scoring rubrics for
    assessments of spoken language, we initiated a research effort to obtain RST annotations
    of a large number of non-native spoken responses from a standardized assessment
    of academic English proficiency. The resulting inter-annotator kappa agreements
    on the three different levels of Span, Nuclearity, and Relation are 0.848, 0.766,
    and 0.653, respectively. Furthermore, a set of features was explored to evaluate
    the discourse structure of non-native spontaneous speech based on these annotations;
    the highest performing feature resulted in a correlation of 0.612 with scores
    of discourse coherence provided by expert human raters.
  address: Vancouver, Canada
  author:
  - first: Xinhao
    full: Xinhao Wang
    id: xinhao-wang
    last: Wang
  - first: James
    full: James Bruno
    id: james-bruno
    last: Bruno
  - first: Hillary
    full: Hillary Molloy
    id: hillary-molloy
    last: Molloy
  - first: Keelan
    full: Keelan Evanini
    id: keelan-evanini
    last: Evanini
  - first: Klaus
    full: Klaus Zechner
    id: klaus-zechner
    last: Zechner
  author_string: Xinhao Wang, James Bruno, Hillary Molloy, Keelan Evanini, Klaus Zechner
  bibkey: wang-etal-2017-discourse
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2041
  month: July
  page_first: '263'
  page_last: '268'
  pages: "263\u2013268"
  paper_id: '41'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2041.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2041.jpg
  title: Discourse Annotation of Non-native Spontaneous Spoken Responses Using the
    Rhetorical Structure Theory Framework
  title_html: Discourse Annotation of Non-native Spontaneous Spoken Responses Using
    the Rhetorical Structure Theory Framework
  url: https://www.aclweb.org/anthology/P17-2041
  year: '2017'
P17-2042:
  abstract: We introduce a simple and effective method to learn discourse-specific
    word embeddings (DSWE) for implicit discourse relation recognition. Specifically,
    DSWE is learned by performing connective classification on massive explicit discourse
    data, and capable of capturing discourse relationships between words. On the PDTB
    data set, using DSWE as features achieves significant improvements over baselines.
  address: Vancouver, Canada
  author:
  - first: Changxing
    full: Changxing Wu
    id: changxing-wu
    last: Wu
  - first: Xiaodong
    full: Xiaodong Shi
    id: xiaodong-shi
    last: Shi
  - first: Yidong
    full: Yidong Chen
    id: yidong-chen
    last: Chen
  - first: Jinsong
    full: Jinsong Su
    id: jinsong-su
    last: Su
  - first: Boli
    full: Boli Wang
    id: boli-wang
    last: Wang
  author_string: Changxing Wu, Xiaodong Shi, Yidong Chen, Jinsong Su, Boli Wang
  bibkey: wu-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2042
  month: July
  page_first: '269'
  page_last: '274'
  pages: "269\u2013274"
  paper_id: '42'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2042.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2042.jpg
  title: Improving Implicit Discourse Relation Recognition with Discourse-specific
    Word Embeddings
  title_html: Improving Implicit Discourse Relation Recognition with Discourse-specific
    Word Embeddings
  url: https://www.aclweb.org/anthology/P17-2042
  year: '2017'
P17-2043:
  abstract: This paper derives an Integer Linear Programming (ILP) formulation to
    obtain an oracle summary of the compressive summarization paradigm in terms of
    ROUGE. The oracle summary is essential to reveal the upper bound performance of
    the paradigm. Experimental results on the DUC dataset showed that ROUGE scores
    of compressive oracles are significantly higher than those of extractive oracles
    and state-of-the-art summarization systems. These results reveal that compressive
    summarization is a promising paradigm and encourage us to continue with the research
    to produce informative summaries.
  address: Vancouver, Canada
  author:
  - first: Tsutomu
    full: Tsutomu Hirao
    id: tsutomu-hirao
    last: Hirao
  - first: Masaaki
    full: Masaaki Nishino
    id: masaaki-nishino
    last: Nishino
  - first: Masaaki
    full: Masaaki Nagata
    id: masaaki-nagata
    last: Nagata
  author_string: Tsutomu Hirao, Masaaki Nishino, Masaaki Nagata
  bibkey: hirao-etal-2017-oracle
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2043
  month: July
  page_first: '275'
  page_last: '280'
  pages: "275\u2013280"
  paper_id: '43'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2043.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2043.jpg
  title: Oracle Summaries of Compressive Summarization
  title_html: Oracle Summaries of Compressive Summarization
  url: https://www.aclweb.org/anthology/P17-2043
  year: '2017'
P17-2044:
  abstract: In English, high-quality sentence compression models by deleting words
    have been trained on automatically created large training datasets. We work on
    Japanese sentence compression by a similar approach. To create a large Japanese
    training dataset, a method of creating English training dataset is modified based
    on the characteristics of the Japanese language. The created dataset is used to
    train Japanese sentence compression models based on the recurrent neural network.
  address: Vancouver, Canada
  author:
  - first: Shun
    full: Shun Hasegawa
    id: shun-hasegawa
    last: Hasegawa
  - first: Yuta
    full: Yuta Kikuchi
    id: yuta-kikuchi
    last: Kikuchi
  - first: Hiroya
    full: Hiroya Takamura
    id: hiroya-takamura
    last: Takamura
  - first: Manabu
    full: Manabu Okumura
    id: manabu-okumura
    last: Okumura
  author_string: Shun Hasegawa, Yuta Kikuchi, Hiroya Takamura, Manabu Okumura
  bibkey: hasegawa-etal-2017-japanese
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2044
  month: July
  page_first: '281'
  page_last: '286'
  pages: "281\u2013286"
  paper_id: '44'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2044.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2044.jpg
  title: Japanese Sentence Compression with a Large Training Dataset
  title_html: <span class="acl-fixed-case">J</span>apanese Sentence Compression with
    a Large Training Dataset
  url: https://www.aclweb.org/anthology/P17-2044
  year: '2017'
P17-2045:
  abstract: We propose a model to automatically describe changes introduced in the
    source code of a program using natural language. Our method receives as input
    a set of code commits, which contains both the modifications and message introduced
    by an user. These two modalities are used to train an encoder-decoder architecture.
    We evaluated our approach on twelve real world open source projects from four
    different programming languages. Quantitative and qualitative results showed that
    the proposed approach can generate feasible and semantically sound descriptions
    not only in standard in-project settings, but also in a cross-project setting.
  address: Vancouver, Canada
  author:
  - first: Pablo
    full: Pablo Loyola
    id: pablo-loyola
    last: Loyola
  - first: Edison
    full: Edison Marrese-Taylor
    id: edison-marrese-taylor
    last: Marrese-Taylor
  - first: Yutaka
    full: Yutaka Matsuo
    id: yutaka-matsuo
    last: Matsuo
  author_string: Pablo Loyola, Edison Marrese-Taylor, Yutaka Matsuo
  bibkey: loyola-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2045
  month: July
  page_first: '287'
  page_last: '292'
  pages: "287\u2013292"
  paper_id: '45'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2045.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2045.jpg
  title: A Neural Architecture for Generating Natural Language Descriptions from Source
    Code Changes
  title_html: A Neural Architecture for Generating Natural Language Descriptions from
    Source Code Changes
  url: https://www.aclweb.org/anthology/P17-2045
  year: '2017'
P17-2046:
  abstract: We propose novel radical features from automatic translation for event
    extraction. Event detection is a complex language processing task for which it
    is expensive to collect training data, making generalisation challenging. We derive
    meaningful subword features from automatic translations into target language.
    Results suggest this method is particularly useful when using languages with writing
    systems that facilitate easy decomposition into subword features, e.g., logograms
    and Cangjie. The best result combines logogram features from Chinese and Japanese
    with syllable features from Korean, providing an additional 3.0 points f-score
    when added to state-of-the-art generalisation features on the TAC KBP 2015 Event
    Nugget task.
  address: Vancouver, Canada
  author:
  - first: Sam
    full: Sam Wei
    id: sam-wei
    last: Wei
  - first: Igor
    full: Igor Korostil
    id: igor-korostil
    last: Korostil
  - first: Joel
    full: Joel Nothman
    id: joel-nothman
    last: Nothman
  - first: Ben
    full: Ben Hachey
    id: ben-hachey
    last: Hachey
  author_string: Sam Wei, Igor Korostil, Joel Nothman, Ben Hachey
  bibkey: wei-etal-2017-english
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2046
  month: July
  page_first: '293'
  page_last: '298'
  pages: "293\u2013298"
  paper_id: '46'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2046.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2046.jpg
  title: English Event Detection With Translated Language Features
  title_html: <span class="acl-fixed-case">E</span>nglish Event Detection With Translated
    Language Features
  url: https://www.aclweb.org/anthology/P17-2046
  year: '2017'
P17-2047:
  abstract: 'A critical task for question answering is the final answer selection
    stage, which has to combine multiple signals available about each answer candidate.
    This paper proposes EviNets: a novel neural network architecture for factoid question
    answering. EviNets scores candidate answer entities by combining the available
    supporting evidence, e.g., structured knowledge bases and unstructured text documents.
    EviNets represents each piece of evidence with a dense embeddings vector, scores
    their relevance to the question, and aggregates the support for each candidate
    to predict their final scores. Each of the components is generic and allows plugging
    in a variety of models for semantic similarity scoring and information aggregation.
    We demonstrate the effectiveness of EviNets in experiments on the existing TREC
    QA and WikiMovies benchmarks, and on the new Yahoo! Answers dataset introduced
    in this paper. EviNets can be extended to other information types and could facilitate
    future work on combining evidence signals for joint reasoning in question answering.'
  address: Vancouver, Canada
  author:
  - first: Denis
    full: Denis Savenkov
    id: denis-savenkov
    last: Savenkov
  - first: Eugene
    full: Eugene Agichtein
    id: eugene-agichtein
    last: Agichtein
  author_string: Denis Savenkov, Eugene Agichtein
  bibkey: savenkov-agichtein-2017-evinets
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2047
  month: July
  page_first: '299'
  page_last: '304'
  pages: "299\u2013304"
  paper_id: '47'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2047.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2047.jpg
  title: 'EviNets: Neural Networks for Combining Evidence Signals for Factoid Question
    Answering'
  title_html: '<span class="acl-fixed-case">E</span>vi<span class="acl-fixed-case">N</span>ets:
    Neural Networks for Combining Evidence Signals for Factoid Question Answering'
  url: https://www.aclweb.org/anthology/P17-2047
  year: '2017'
P17-2048:
  abstract: Existing Knowledge Base Population methods extract relations from a closed
    relational schema with limited coverage leading to sparse KBs. We propose Pocket
    Knowledge Base Population (PKBP), the task of dynamically constructing a KB of
    entities related to a query and finding the best characterization of relationships
    between entities. We describe novel Open Information Extraction methods which
    leverage the PKB to find informative trigger words. We evaluate using existing
    KBP shared-task data as well anew annotations collected for this work. Our methods
    produce high quality KB from just text with many more entities and relationships
    than existing KBP systems.
  address: Vancouver, Canada
  author:
  - first: Travis
    full: Travis Wolfe
    id: travis-wolfe
    last: Wolfe
  - first: Mark
    full: Mark Dredze
    id: mark-dredze
    last: Dredze
  - first: Benjamin
    full: Benjamin Van Durme
    id: benjamin-van-durme
    last: Van Durme
  author_string: Travis Wolfe, Mark Dredze, Benjamin Van Durme
  bibkey: wolfe-etal-2017-pocket
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2048
  month: July
  page_first: '305'
  page_last: '310'
  pages: "305\u2013310"
  paper_id: '48'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2048.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2048.jpg
  title: Pocket Knowledge Base Population
  title_html: Pocket Knowledge Base Population
  url: https://www.aclweb.org/anthology/P17-2048
  year: '2017'
P17-2049:
  abstract: While there has been substantial progress in factoid question-answering
    (QA), answering complex questions remains challenging, typically requiring both
    a large body of knowledge and inference techniques. Open Information Extraction
    (Open IE) provides a way to generate semi-structured knowledge for QA, but to
    date such knowledge has only been used to answer simple questions with retrieval-based
    methods. We overcome this limitation by presenting a method for reasoning with
    Open IE knowledge, allowing more complex questions to be handled. Using a recently
    proposed support graph optimization framework for QA, we develop a new inference
    model for Open IE, in particular one that can work effectively with multiple short
    facts, noise, and the relational structure of tuples. Our model significantly
    outperforms a state-of-the-art structured solver on complex questions of varying
    difficulty, while also removing the reliance on manually curated knowledge.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2049.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2049.Notes.pdf
  author:
  - first: Tushar
    full: Tushar Khot
    id: tushar-khot
    last: Khot
  - first: Ashish
    full: Ashish Sabharwal
    id: ashish-sabharwal
    last: Sabharwal
  - first: Peter
    full: Peter Clark
    id: peter-clark
    last: Clark
  author_string: Tushar Khot, Ashish Sabharwal, Peter Clark
  bibkey: khot-etal-2017-answering
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2049
  month: July
  page_first: '311'
  page_last: '316'
  pages: "311\u2013316"
  paper_id: '49'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2049.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2049.jpg
  title: Answering Complex Questions Using Open Information Extraction
  title_html: Answering Complex Questions Using Open Information Extraction
  url: https://www.aclweb.org/anthology/P17-2049
  year: '2017'
P17-2050:
  abstract: "We design and release BONIE, the first open numerical relation extractor,\
    \ for extracting Open IE tuples where one of the arguments is a number or a quantity-unit\
    \ phrase. BONIE uses bootstrapping to learn the specific dependency patterns that\
    \ express numerical relations in a sentence. BONIE\u2019s novelty lies in task-specific\
    \ customizations, such as inferring implicit relations, which are clear due to\
    \ context such as units (for e.g., \u2018square kilometers\u2019 suggests area,\
    \ even if the word \u2018area\u2019 is missing in the sentence). BONIE obtains\
    \ 1.5x yield and 15 point precision gain on numerical facts over a state-of-the-art\
    \ Open IE system."
  address: Vancouver, Canada
  author:
  - first: Swarnadeep
    full: Swarnadeep Saha
    id: swarnadeep-saha
    last: Saha
  - first: Harinder
    full: Harinder Pal
    id: harinder-pal
    last: Pal
  - first: ''
    full: Mausam
    id: mausam
    last: Mausam
  author_string: Swarnadeep Saha, Harinder Pal, Mausam
  bibkey: saha-etal-2017-bootstrapping
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2050
  month: July
  page_first: '317'
  page_last: '323'
  pages: "317\u2013323"
  paper_id: '50'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2050.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2050.jpg
  title: Bootstrapping for Numerical Open IE
  title_html: Bootstrapping for Numerical Open <span class="acl-fixed-case">IE</span>
  url: https://www.aclweb.org/anthology/P17-2050
  year: '2017'
P17-2051:
  abstract: We propose jointly modelling Knowledge Bases and aligned text with Feature-Rich
    Networks. Our models perform Knowledge Base Completion by learning to represent
    and compose diverse feature types from partially aligned and noisy resources.
    We perform experiments on Freebase utilizing additional entity type information
    and syntactic textual relations. Our evaluation suggests that the proposed models
    can better incorporate side information than previously proposed combinations
    of bilinear models with convolutional neural networks, showing large improvements
    when scoring the plausibility of unobserved facts with associated textual mentions.
  address: Vancouver, Canada
  author:
  - first: Alexandros
    full: Alexandros Komninos
    id: alexandros-komninos
    last: Komninos
  - first: Suresh
    full: Suresh Manandhar
    id: suresh-manandhar
    last: Manandhar
  author_string: Alexandros Komninos, Suresh Manandhar
  bibkey: komninos-manandhar-2017-feature
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2051
  month: July
  page_first: '324'
  page_last: '329'
  pages: "324\u2013329"
  paper_id: '51'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2051.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2051.jpg
  title: Feature-Rich Networks for Knowledge Base Completion
  title_html: Feature-Rich Networks for Knowledge Base Completion
  url: https://www.aclweb.org/anthology/P17-2051
  year: '2017'
P17-2052:
  abstract: As entity type systems become richer and more fine-grained, we expect
    the number of types assigned to a given entity to increase. However, most fine-grained
    typing work has focused on datasets that exhibit a low degree of type multiplicity.
    In this paper, we consider the high-multiplicity regime inherent in data sources
    such as Wikipedia that have semi-open type systems. We introduce a set-prediction
    approach to this problem and show that our model outperforms unstructured baselines
    on a new Wikipedia-based fine-grained typing corpus.
  address: Vancouver, Canada
  author:
  - first: Maxim
    full: Maxim Rabinovich
    id: maxim-rabinovich
    last: Rabinovich
  - first: Dan
    full: Dan Klein
    id: dan-klein
    last: Klein
  author_string: Maxim Rabinovich, Dan Klein
  bibkey: rabinovich-klein-2017-fine
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2052
  month: July
  page_first: '330'
  page_last: '334'
  pages: "330\u2013334"
  paper_id: '52'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2052.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2052.jpg
  title: Fine-Grained Entity Typing with High-Multiplicity Assignments
  title_html: Fine-Grained Entity Typing with High-Multiplicity Assignments
  url: https://www.aclweb.org/anthology/P17-2052
  year: '2017'
P17-2053:
  abstract: Question classification is an important task with wide applications. However,
    traditional techniques treat questions as general sentences, ignoring the corresponding
    answer data. In order to consider answer information into question modeling, we
    first introduce novel group sparse autoencoders which refine question representation
    by utilizing group information in the answer set. We then propose novel group
    sparse CNNs which naturally learn question representation with respect to their
    answers by implanting group sparse autoencoders into traditional CNNs. The proposed
    model significantly outperform strong baselines on four datasets.
  address: Vancouver, Canada
  author:
  - first: Mingbo
    full: Mingbo Ma
    id: mingbo-ma
    last: Ma
  - first: Liang
    full: Liang Huang
    id: liang-huang
    last: Huang
  - first: Bing
    full: Bing Xiang
    id: bing-xiang
    last: Xiang
  - first: Bowen
    full: Bowen Zhou
    id: bowen-zhou
    last: Zhou
  author_string: Mingbo Ma, Liang Huang, Bing Xiang, Bowen Zhou
  bibkey: ma-etal-2017-group
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2053
  month: July
  page_first: '335'
  page_last: '340'
  pages: "335\u2013340"
  paper_id: '53'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2053.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2053.jpg
  title: Group Sparse CNNs for Question Classification with Answer Sets
  title_html: Group Sparse <span class="acl-fixed-case">CNN</span>s for Question Classification
    with Answer Sets
  url: https://www.aclweb.org/anthology/P17-2053
  year: '2017'
P17-2054:
  abstract: Keyphrase boundary classification (KBC) is the task of detecting keyphrases
    in scientific articles and labelling them with respect to predefined types. Although
    important in practice, this task is so far underexplored, partly due to the lack
    of labelled data. To overcome this, we explore several auxiliary tasks, including
    semantic super-sense tagging and identification of multi-word expressions, and
    cast the task as a multi-task learning problem with deep recurrent neural networks.
    Our multi-task models perform significantly better than previous state of the
    art approaches on two scientific KBC datasets, particularly for long keyphrases.
  address: Vancouver, Canada
  author:
  - first: Isabelle
    full: Isabelle Augenstein
    id: isabelle-augenstein
    last: Augenstein
  - first: Anders
    full: "Anders S\xF8gaard"
    id: anders-sogaard
    last: "S\xF8gaard"
  author_string: "Isabelle Augenstein, Anders S\xF8gaard"
  bibkey: augenstein-sogaard-2017-multi
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2054
  month: July
  page_first: '341'
  page_last: '346'
  pages: "341\u2013346"
  paper_id: '54'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2054.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2054.jpg
  title: Multi-Task Learning of Keyphrase Boundary Classification
  title_html: Multi-Task Learning of Keyphrase Boundary Classification
  url: https://www.aclweb.org/anthology/P17-2054
  year: '2017'
P17-2055:
  abstract: Information extraction (IE) from text has largely focused on relations
    between individual entities, such as who has won which award. However, some facts
    are never fully mentioned, and no IE method has perfect recall. Thus, it is beneficial
    to also tap contents about the cardinalities of these relations, for example,
    how many awards someone has won. We introduce this novel problem of extracting
    cardinalities and discusses the specific challenges that set it apart from standard
    IE. We present a distant supervision method using conditional random fields. A
    preliminary evaluation results in precision between 3% and 55%, depending on the
    difficulty of relations.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2055.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2055.Presentation.pdf
  - filename: P17-2055.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-2055.Datasets.zip
  author:
  - first: Paramita
    full: Paramita Mirza
    id: paramita-mirza
    last: Mirza
  - first: Simon
    full: Simon Razniewski
    id: simon-razniewski
    last: Razniewski
  - first: Fariz
    full: Fariz Darari
    id: fariz-darari
    last: Darari
  - first: Gerhard
    full: Gerhard Weikum
    id: gerhard-weikum
    last: Weikum
  author_string: Paramita Mirza, Simon Razniewski, Fariz Darari, Gerhard Weikum
  bibkey: mirza-etal-2017-cardinal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2055
  month: July
  page_first: '347'
  page_last: '351'
  pages: "347\u2013351"
  paper_id: '55'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2055.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2055.jpg
  title: 'Cardinal Virtues: Extracting Relation Cardinalities from Text'
  title_html: 'Cardinal Virtues: Extracting Relation Cardinalities from Text'
  url: https://www.aclweb.org/anthology/P17-2055
  year: '2017'
P17-2056:
  abstract: Previous models for the assessment of commitment towards a predicate in
    a sentence (also known as factuality prediction) were trained and tested against
    a specific annotated dataset, subsequently limiting the generality of their results.
    In this work we propose an intuitive method for mapping three previously annotated
    corpora onto a single factuality scale, thereby enabling models to be tested across
    these corpora. In addition, we design a novel model for factuality prediction
    by first extending a previous rule-based factuality prediction system and applying
    it over an abstraction of dependency trees, and then using the output of this
    system in a supervised classifier. We show that this model outperforms previous
    methods on all three datasets. We make both the unified factuality corpus and
    our new model publicly available.
  address: Vancouver, Canada
  author:
  - first: Gabriel
    full: Gabriel Stanovsky
    id: gabriel-stanovsky
    last: Stanovsky
  - first: Judith
    full: Judith Eckle-Kohler
    id: judith-eckle-kohler
    last: Eckle-Kohler
  - first: Yevgeniy
    full: Yevgeniy Puzikov
    id: yevgeniy-puzikov
    last: Puzikov
  - first: Ido
    full: Ido Dagan
    id: ido-dagan
    last: Dagan
  - first: Iryna
    full: Iryna Gurevych
    id: iryna-gurevych
    last: Gurevych
  author_string: Gabriel Stanovsky, Judith Eckle-Kohler, Yevgeniy Puzikov, Ido Dagan,
    Iryna Gurevych
  bibkey: stanovsky-etal-2017-integrating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2056
  month: July
  page_first: '352'
  page_last: '357'
  pages: "352\u2013357"
  paper_id: '56'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2056.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2056.jpg
  title: Integrating Deep Linguistic Features in Factuality Prediction over Unified
    Datasets
  title_html: Integrating Deep Linguistic Features in Factuality Prediction over Unified
    Datasets
  url: https://www.aclweb.org/anthology/P17-2056
  year: '2017'
P17-2057:
  abstract: Existing question answering methods infer answers either from a knowledge
    base or from raw text. While knowledge base (KB) methods are good at answering
    compositional questions, their performance is often affected by the incompleteness
    of the KB. Au contraire, web text contains millions of facts that are absent in
    the KB, however in an unstructured form. Universal schema can support reasoning
    on the union of both structured KBs and unstructured text by aligning them in
    a common embedded space. In this paper we extend universal schema to natural language
    question answering, employing Memory networks to attend to the large body of facts
    in the combination of text and KB. Our models can be trained in an end-to-end
    fashion on question-answer pairs. Evaluation results on Spades fill-in-the-blank
    question answering dataset show that exploiting universal schema for question
    answering is better than using either a KB or text alone. This model also outperforms
    the current state-of-the-art by 8.5 F1 points.
  address: Vancouver, Canada
  author:
  - first: Rajarshi
    full: Rajarshi Das
    id: rajarshi-das
    last: Das
  - first: Manzil
    full: Manzil Zaheer
    id: manzil-zaheer
    last: Zaheer
  - first: Siva
    full: Siva Reddy
    id: siva-reddy
    last: Reddy
  - first: Andrew
    full: Andrew McCallum
    id: andrew-mccallum
    last: McCallum
  author_string: Rajarshi Das, Manzil Zaheer, Siva Reddy, Andrew McCallum
  bibkey: das-etal-2017-question
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2057
  month: July
  page_first: '358'
  page_last: '365'
  pages: "358\u2013365"
  paper_id: '57'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2057.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2057.jpg
  title: Question Answering on Knowledge Bases and Text using Universal Schema and
    Memory Networks
  title_html: Question Answering on Knowledge Bases and Text using Universal Schema
    and Memory Networks
  url: https://www.aclweb.org/anthology/P17-2057
  year: '2017'
P17-2058:
  abstract: "We demonstrate that a continuous relaxation of the argmax operation can\
    \ be used to create a differentiable approximation to greedy decoding in sequence-to-sequence\
    \ (seq2seq) models. By incorporating this approximation into the scheduled sampling\
    \ training procedure\u2013a well-known technique for correcting exposure bias\u2013\
    we introduce a new training objective that is continuous and differentiable everywhere\
    \ and can provide informative gradients near points where previous decoding decisions\
    \ change their value. By using a related approximation, we also demonstrate a\
    \ similar approach to sampled-based training. We show that our approach outperforms\
    \ both standard cross-entropy training and scheduled sampling procedures in two\
    \ sequence prediction tasks: named entity recognition and machine translation."
  address: Vancouver, Canada
  author:
  - first: Kartik
    full: Kartik Goyal
    id: kartik-goyal
    last: Goyal
  - first: Chris
    full: Chris Dyer
    id: chris-dyer
    last: Dyer
  - first: Taylor
    full: Taylor Berg-Kirkpatrick
    id: taylor-berg-kirkpatrick
    last: Berg-Kirkpatrick
  author_string: Kartik Goyal, Chris Dyer, Taylor Berg-Kirkpatrick
  bibkey: goyal-etal-2017-differentiable
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2058
  month: July
  page_first: '366'
  page_last: '371'
  pages: "366\u2013371"
  paper_id: '58'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2058.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2058.jpg
  title: Differentiable Scheduled Sampling for Credit Assignment
  title_html: Differentiable Scheduled Sampling for Credit Assignment
  url: https://www.aclweb.org/anthology/P17-2058
  year: '2017'
P17-2059:
  abstract: While natural languages are compositional, how state-of-the-art neural
    models achieve compositionality is still unclear. We propose a deep network, which
    not only achieves competitive accuracy for text classification, but also exhibits
    compositional behavior. That is, while creating hierarchical representations of
    a piece of text, such as a sentence, the lower layers of the network distribute
    their layer-specific attention weights to individual words. In contrast, the higher
    layers compose meaningful phrases and clauses, whose lengths increase as the networks
    get deeper until fully composing the sentence.
  address: Vancouver, Canada
  author:
  - first: Hongyu
    full: Hongyu Guo
    id: hongyu-guo
    last: Guo
  author_string: Hongyu Guo
  bibkey: guo-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2059
  month: July
  page_first: '372'
  page_last: '377'
  pages: "372\u2013377"
  paper_id: '59'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2059.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2059.jpg
  title: A Deep Network with Visual Text Composition Behavior
  title_html: A Deep Network with Visual Text Composition Behavior
  url: https://www.aclweb.org/anthology/P17-2059
  year: '2017'
P17-2060:
  abstract: Neural machine translation (NMT) becomes a new approach to machine translation
    and generates much more fluent results compared to statistical machine translation
    (SMT). However, SMT is usually better than NMT in translation adequacy. It is
    therefore a promising direction to combine the advantages of both NMT and SMT.
    In this paper, we propose a neural system combination framework leveraging multi-source
    NMT, which takes as input the outputs of NMT and SMT systems and produces the
    final translation. Extensive experiments on the Chinese-to-English translation
    task show that our model archives significant improvement by 5.3 BLEU points over
    the best single system output and 3.4 BLEU points over the state-of-the-art traditional
    system combination methods.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2060.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-2060.Poster.pdf
  author:
  - first: Long
    full: Long Zhou
    id: long-zhou
    last: Zhou
  - first: Wenpeng
    full: Wenpeng Hu
    id: wenpeng-hu
    last: Hu
  - first: Jiajun
    full: Jiajun Zhang
    id: jiajun-zhang
    last: Zhang
  - first: Chengqing
    full: Chengqing Zong
    id: chengqing-zong
    last: Zong
  author_string: Long Zhou, Wenpeng Hu, Jiajun Zhang, Chengqing Zong
  bibkey: zhou-etal-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2060
  month: July
  page_first: '378'
  page_last: '384'
  pages: "378\u2013384"
  paper_id: '60'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2060.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2060.jpg
  title: Neural System Combination for Machine Translation
  title_html: Neural System Combination for Machine Translation
  url: https://www.aclweb.org/anthology/P17-2060
  year: '2017'
P17-2061:
  abstract: "In this paper, we propose a novel domain adaptation method named \u201C\
    mixed fine tuning\u201D for neural machine translation (NMT). We combine two existing\
    \ approaches namely fine tuning and multi domain NMT. We first train an NMT model\
    \ on an out-of-domain parallel corpus, and then fine tune it on a parallel corpus\
    \ which is a mix of the in-domain and out-of-domain corpora. All corpora are augmented\
    \ with artificial tags to indicate specific domains. We empirically compare our\
    \ proposed method against fine tuning and multi domain methods and discuss its\
    \ benefits and shortcomings."
  address: Vancouver, Canada
  attachment:
  - filename: P17-2061.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-2061.Poster.pdf
  author:
  - first: Chenhui
    full: Chenhui Chu
    id: chenhui-chu
    last: Chu
  - first: Raj
    full: Raj Dabre
    id: raj-dabre
    last: Dabre
  - first: Sadao
    full: Sadao Kurohashi
    id: sadao-kurohashi
    last: Kurohashi
  author_string: Chenhui Chu, Raj Dabre, Sadao Kurohashi
  bibkey: chu-etal-2017-empirical
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2061
  month: July
  page_first: '385'
  page_last: '391'
  pages: "385\u2013391"
  paper_id: '61'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2061.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2061.jpg
  title: An Empirical Comparison of Domain Adaptation Methods for Neural Machine Translation
  title_html: An Empirical Comparison of Domain Adaptation Methods for Neural Machine
    Translation
  url: https://www.aclweb.org/anthology/P17-2061
  year: '2017'
P17-2062:
  abstract: We propose a new method for extracting pseudo-parallel sentences from
    a pair of large monolingual corpora, without relying on any document-level information.
    Our method first exploits word embeddings in order to efficiently evaluate trillions
    of candidate sentence pairs and then a classifier to find the most reliable ones.
    We report significant improvements in domain adaptation for statistical machine
    translation when using a translation model trained on the sentence pairs extracted
    from in-domain monolingual corpora.
  address: Vancouver, Canada
  author:
  - first: Benjamin
    full: Benjamin Marie
    id: benjamin-marie
    last: Marie
  - first: Atsushi
    full: Atsushi Fujita
    id: atsushi-fujita
    last: Fujita
  author_string: Benjamin Marie, Atsushi Fujita
  bibkey: marie-fujita-2017-efficient
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2062
  month: July
  page_first: '392'
  page_last: '398'
  pages: "392\u2013398"
  paper_id: '62'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2062.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2062.jpg
  title: Efficient Extraction of Pseudo-Parallel Sentences from Raw Monolingual Data
    Using Word Embeddings
  title_html: Efficient Extraction of Pseudo-Parallel Sentences from Raw Monolingual
    Data Using Word Embeddings
  url: https://www.aclweb.org/anthology/P17-2062
  year: '2017'
P17-2063:
  abstract: We evaluate feature hashing for language identification (LID), a method
    not previously used for this task. Using a standard dataset, we first show that
    while feature performance is high, LID data is highly dimensional and mostly sparse
    (>99.5%) as it includes large vocabularies for many languages; memory requirements
    grow as languages are added. Next we apply hashing using various hash sizes, demonstrating
    that there is no performance loss with dimensionality reductions of up to 86%.
    We also show that using an ensemble of low-dimension hash-based classifiers further
    boosts performance. Feature hashing is highly useful for LID and holds great promise
    for future work in this area.
  address: Vancouver, Canada
  author:
  - first: Shervin
    full: Shervin Malmasi
    id: shervin-malmasi
    last: Malmasi
  - first: Mark
    full: Mark Dras
    id: mark-dras
    last: Dras
  author_string: Shervin Malmasi, Mark Dras
  bibkey: malmasi-dras-2017-feature
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2063
  month: July
  page_first: '399'
  page_last: '403'
  pages: "399\u2013403"
  paper_id: '63'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2063.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2063.jpg
  title: Feature Hashing for Language and Dialect Identification
  title_html: Feature Hashing for Language and Dialect Identification
  url: https://www.aclweb.org/anthology/P17-2063
  year: '2017'
P17-2064:
  abstract: Selecting appropriate words to compose a sentence is one common problem
    faced by non-native Chinese learners. In this paper, we propose (bidirectional)
    LSTM sequence labeling models and explore various features to detect word usage
    errors in Chinese sentences. By combining CWINDOW word embedding features and
    POS information, the best bidirectional LSTM model achieves accuracy 0.5138 and
    MRR 0.6789 on the HSK dataset. For 80.79% of the test data, the model ranks the
    ground-truth within the top two at position level.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2064.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-2064.Datasets.zip
  author:
  - first: Yow-Ting
    full: Yow-Ting Shiue
    id: yow-ting-shiue
    last: Shiue
  - first: Hen-Hsen
    full: Hen-Hsen Huang
    id: hen-hsen-huang
    last: Huang
  - first: Hsin-Hsi
    full: Hsin-Hsi Chen
    id: hsin-hsi-chen
    last: Chen
  author_string: Yow-Ting Shiue, Hen-Hsen Huang, Hsin-Hsi Chen
  bibkey: shiue-etal-2017-detection
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2064
  month: July
  page_first: '404'
  page_last: '410'
  pages: "404\u2013410"
  paper_id: '64'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2064.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2064.jpg
  title: Detection of Chinese Word Usage Errors for Non-Native Chinese Learners with
    Bidirectional LSTM
  title_html: Detection of <span class="acl-fixed-case">C</span>hinese Word Usage
    Errors for Non-Native <span class="acl-fixed-case">C</span>hinese Learners with
    Bidirectional <span class="acl-fixed-case">LSTM</span>
  url: https://www.aclweb.org/anthology/P17-2064
  year: '2017'
P17-2065:
  abstract: "Compositor attribution, the clustering of pages in a historical printed\
    \ document by the individual who set the type, is a bibliographic task that relies\
    \ on analysis of orthographic variation and inspection of visual details of the\
    \ printed page. In this paper, we introduce a novel unsupervised model that jointly\
    \ describes the textual and visual features needed to distinguish compositors.\
    \ Applied to images of Shakespeare\u2019s First Folio, our model predicts attributions\
    \ that agree with the manual judgements of bibliographers with an accuracy of\
    \ 87%, even on text that is the output of OCR."
  address: Vancouver, Canada
  attachment:
  - filename: P17-2065.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-2065.Poster.pdf
  author:
  - first: Maria
    full: Maria Ryskina
    id: maria-ryskina
    last: Ryskina
  - first: Hannah
    full: Hannah Alpert-Abrams
    id: hannah-alpert-abrams
    last: Alpert-Abrams
  - first: Dan
    full: Dan Garrette
    id: dan-garrette
    last: Garrette
  - first: Taylor
    full: Taylor Berg-Kirkpatrick
    id: taylor-berg-kirkpatrick
    last: Berg-Kirkpatrick
  author_string: Maria Ryskina, Hannah Alpert-Abrams, Dan Garrette, Taylor Berg-Kirkpatrick
  bibkey: ryskina-etal-2017-automatic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2065
  month: July
  page_first: '411'
  page_last: '416'
  pages: "411\u2013416"
  paper_id: '65'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2065.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2065.jpg
  title: Automatic Compositor Attribution in the First Folio of Shakespeare
  title_html: Automatic Compositor Attribution in the First Folio of Shakespeare
  url: https://www.aclweb.org/anthology/P17-2065
  year: '2017'
P17-2066:
  abstract: In recent years, automatic generation of image descriptions (captions),
    that is, image captioning, has attracted a great deal of attention. In this paper,
    we particularly consider generating Japanese captions for images. Since most available
    caption datasets have been constructed for English language, there are few datasets
    for Japanese. To tackle this problem, we construct a large-scale Japanese image
    caption dataset based on images from MS-COCO, which is called STAIR Captions.
    STAIR Captions consists of 820,310 Japanese captions for 164,062 images. In the
    experiment, we show that a neural network trained using STAIR Captions can generate
    more natural and better Japanese captions, compared to those generated using English-Japanese
    machine translation after generating English captions.
  address: Vancouver, Canada
  author:
  - first: Yuya
    full: Yuya Yoshikawa
    id: yuya-yoshikawa
    last: Yoshikawa
  - first: Yutaro
    full: Yutaro Shigeto
    id: yutaro-shigeto
    last: Shigeto
  - first: Akikazu
    full: Akikazu Takeuchi
    id: akikazu-takeuchi
    last: Takeuchi
  author_string: Yuya Yoshikawa, Yutaro Shigeto, Akikazu Takeuchi
  bibkey: yoshikawa-etal-2017-stair
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2066
  month: July
  page_first: '417'
  page_last: '421'
  pages: "417\u2013421"
  paper_id: '66'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2066.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2066.jpg
  title: 'STAIR Captions: Constructing a Large-Scale Japanese Image Caption Dataset'
  title_html: '<span class="acl-fixed-case">STAIR</span> Captions: Constructing a
    Large-Scale <span class="acl-fixed-case">J</span>apanese Image Caption Dataset'
  url: https://www.aclweb.org/anthology/P17-2066
  year: '2017'
P17-2067:
  abstract: 'Automatic fake news detection is a challenging problem in deception detection,
    and it has tremendous real-world political and social impacts. However, statistical
    approaches to combating fake news has been dramatically limited by the lack of
    labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available
    dataset for fake news detection. We collected a decade-long, 12.8K manually labeled
    short statements in various contexts from PolitiFact.com, which provides detailed
    analysis report and links to source documents for each case. This dataset can
    be used for fact-checking research as well. Notably, this new dataset is an order
    of magnitude larger than previously largest public fake news datasets of similar
    type. Empirically, we investigate automatic fake news detection based on surface-level
    linguistic patterns. We have designed a novel, hybrid convolutional neural network
    to integrate meta-data with text. We show that this hybrid approach can improve
    a text-only deep learning model.'
  address: Vancouver, Canada
  author:
  - first: William Yang
    full: William Yang Wang
    id: william-yang-wang
    last: Wang
  author_string: William Yang Wang
  bibkey: wang-2017-liar
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2067
  month: July
  page_first: '422'
  page_last: '426'
  pages: "422\u2013426"
  paper_id: '67'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2067.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2067.jpg
  title: "\u201CLiar, Liar Pants on Fire\u201D: A New Benchmark Dataset for Fake News\
    \ Detection"
  title_html: "\u201CLiar, Liar Pants on Fire\u201D: A New Benchmark Dataset for Fake\
    \ News Detection"
  url: https://www.aclweb.org/anthology/P17-2067
  year: '2017'
P17-2068:
  abstract: Because syntactic structures and spans of multiword expressions (MWEs)
    are independently annotated in many English syntactic corpora, they are generally
    inconsistent with respect to one another, which is harmful to the implementation
    of an aggregate system. In this work, we construct a corpus that ensures consistency
    between dependency structures and MWEs, including named entities. Further, we
    explore models that predict both MWE-spans and an MWE-aware dependency structure.
    Experimental results show that our joint model using additional MWE-span features
    achieves an MWE recognition improvement of 1.35 points over a pipeline model.
  address: Vancouver, Canada
  author:
  - first: Akihiko
    full: Akihiko Kato
    id: akihiko-kato
    last: Kato
  - first: Hiroyuki
    full: Hiroyuki Shindo
    id: hiroyuki-shindo
    last: Shindo
  - first: Yuji
    full: Yuji Matsumoto
    id: yuji-matsumoto
    last: Matsumoto
  author_string: Akihiko Kato, Hiroyuki Shindo, Yuji Matsumoto
  bibkey: kato-etal-2017-english
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2068
  month: July
  page_first: '427'
  page_last: '432'
  pages: "427\u2013432"
  paper_id: '68'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2068.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2068.jpg
  title: English Multiword Expression-aware Dependency Parsing Including Named Entities
  title_html: <span class="acl-fixed-case">E</span>nglish Multiword Expression-aware
    Dependency Parsing Including Named Entities
  url: https://www.aclweb.org/anthology/P17-2068
  year: '2017'
P17-2069:
  abstract: Count-based distributional semantic models suffer from sparsity due to
    unobserved but plausible co-occurrences in any text collection. This problem is
    amplified for models like Anchored Packed Trees (APTs), that take the grammatical
    type of a co-occurrence into account. We therefore introduce a novel form of distributional
    inference that exploits the rich type structure in APTs and infers missing data
    by the same mechanism that is used for semantic composition.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2069.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-2069.Poster.pdf
  - filename: P17-2069.Software.tgz
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-2069.Software.tgz
  author:
  - first: Thomas
    full: Thomas Kober
    id: thomas-kober
    last: Kober
  - first: Julie
    full: Julie Weeds
    id: julie-weeds
    last: Weeds
  - first: Jeremy
    full: Jeremy Reffin
    id: jeremy-reffin
    last: Reffin
  - first: David
    full: David Weir
    id: david-weir
    last: Weir
  author_string: Thomas Kober, Julie Weeds, Jeremy Reffin, David Weir
  bibkey: kober-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2069
  month: July
  page_first: '433'
  page_last: '440'
  pages: "433\u2013440"
  paper_id: '69'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2069.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2069.jpg
  title: Improving Semantic Composition with Offset Inference
  title_html: Improving Semantic Composition with Offset Inference
  url: https://www.aclweb.org/anthology/P17-2069
  year: '2017'
P17-2070:
  abstract: Distributed word representations are widely used for modeling words in
    NLP tasks. Most of the existing models generate one representation per word and
    do not consider different meanings of a word. We present two approaches to learn
    multiple topic-sensitive representations per word by using Hierarchical Dirichlet
    Process. We observe that by modeling topics and integrating topic distributions
    for each document we obtain representations that are able to distinguish between
    different meanings of a given word. Our models yield statistically significant
    improvements for the lexical substitution task indicating that commonly used single
    word representations, even when combined with contextual information, are insufficient
    for this task.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2070.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2070.Presentation.pdf
  author:
  - first: Marzieh
    full: Marzieh Fadaee
    id: marzieh-fadaee
    last: Fadaee
  - first: Arianna
    full: Arianna Bisazza
    id: arianna-bisazza
    last: Bisazza
  - first: Christof
    full: Christof Monz
    id: christof-monz
    last: Monz
  author_string: Marzieh Fadaee, Arianna Bisazza, Christof Monz
  bibkey: fadaee-etal-2017-learning
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2070
  month: July
  page_first: '441'
  page_last: '447'
  pages: "441\u2013447"
  paper_id: '70'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2070.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2070.jpg
  title: Learning Topic-Sensitive Word Representations
  title_html: Learning Topic-Sensitive Word Representations
  url: https://www.aclweb.org/anthology/P17-2070
  year: '2017'
P17-2071:
  abstract: "This paper introduces the concept of temporal word analogies: pairs of\
    \ words which occupy the same semantic space at different points in time. One\
    \ well-known property of word embeddings is that they are able to effectively\
    \ model traditional word analogies (\u201Cword w1 is to word is to word w2 as\
    \ word as word w3 is to word is to word w4\u201D) through vector addition. Here,\
    \ I show that temporal word analogies (\u201Cword \u201D) through vector addition.\
    \ Here, I show that temporal word analogies (\u201Cword w1 at time at time t\U0001D6FC\
    \ is like word is like word w2 at time at time t\U0001D6FD\u201D) can effectively\
    \ be modeled with diachronic word embeddings, provided that the independent embedding\
    \ spaces from each time period are appropriately transformed into a common vector\
    \ space. When applied to a diachronic corpus of news articles, this method is\
    \ able to identify temporal word analogies such as \u201CRonald Reagan in 1987\
    \ is like Bill Clinton in 1997\u201D, or \u201CWalkman in 1987 is like iPod in\
    \ 2007\u201D. \u201D) can effectively be modeled with diachronic word embeddings,\
    \ provided that the independent embedding spaces from each time period are appropriately\
    \ transformed into a common vector space. When applied to a diachronic corpus\
    \ of news articles, this method is able to identify temporal word analogies such\
    \ as \u201CRonald Reagan in 1987 is like Bill Clinton in 1997\u201D, or \u201C\
    Walkman in 1987 is like iPod in 2007\u201D."
  address: Vancouver, Canada
  author:
  - first: Terrence
    full: Terrence Szymanski
    id: terrence-szymanski
    last: Szymanski
  author_string: Terrence Szymanski
  bibkey: szymanski-2017-temporal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2071
  month: July
  page_first: '448'
  page_last: '453'
  pages: "448\u2013453"
  paper_id: '71'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2071.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2071.jpg
  title: 'Temporal Word Analogies: Identifying Lexical Replacement with Diachronic
    Word Embeddings'
  title_html: 'Temporal Word Analogies: Identifying Lexical Replacement with Diachronic
    Word Embeddings'
  url: https://www.aclweb.org/anthology/P17-2071
  year: '2017'
P17-2072:
  abstract: Many unsupervised learning techniques have been proposed to obtain meaningful
    representations of words from text. In this study, we evaluate these various techniques
    when used to generate Arabic word embeddings. We first build a benchmark for the
    Arabic language that can be utilized to perform intrinsic evaluation of different
    word embeddings. We then perform additional extrinsic evaluations of the embeddings
    based on two NLP tasks.
  address: Vancouver, Canada
  author:
  - first: Mohammed
    full: Mohammed Elrazzaz
    id: mohammed-elrazzaz
    last: Elrazzaz
  - first: Shady
    full: Shady Elbassuoni
    id: shady-elbassuoni
    last: Elbassuoni
  - first: Khaled
    full: Khaled Shaban
    id: khaled-shaban
    last: Shaban
  - first: Chadi
    full: Chadi Helwe
    id: chadi-helwe
    last: Helwe
  author_string: Mohammed Elrazzaz, Shady Elbassuoni, Khaled Shaban, Chadi Helwe
  bibkey: elrazzaz-etal-2017-methodical
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2072
  month: July
  page_first: '454'
  page_last: '458'
  pages: "454\u2013458"
  paper_id: '72'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2072.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2072.jpg
  title: Methodical Evaluation of Arabic Word Embeddings
  title_html: Methodical Evaluation of <span class="acl-fixed-case">A</span>rabic
    Word Embeddings
  url: https://www.aclweb.org/anthology/P17-2072
  year: '2017'
P17-2073:
  abstract: 'People around the globe respond to major real world events through social
    media. To study targeted public sentiments across many languages and geographic
    locations, we introduce multilingual connotation frames: an extension from English
    connotation frames of Rashkin et al. (2016) with 10 additional European languages,
    focusing on the implied sentiments among event participants engaged in a frame.
    As a case study, we present large scale analysis on targeted public sentiments
    toward salient events and entities using 1.2 million multilingual connotation
    frames extracted from Twitter.'
  address: Vancouver, Canada
  author:
  - first: Hannah
    full: Hannah Rashkin
    id: hannah-rashkin
    last: Rashkin
  - first: Eric
    full: Eric Bell
    id: eric-bell
    last: Bell
  - first: Yejin
    full: Yejin Choi
    id: yejin-choi
    last: Choi
  - first: Svitlana
    full: Svitlana Volkova
    id: svitlana-volkova
    last: Volkova
  author_string: Hannah Rashkin, Eric Bell, Yejin Choi, Svitlana Volkova
  bibkey: rashkin-etal-2017-multilingual
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2073
  month: July
  page_first: '459'
  page_last: '464'
  pages: "459\u2013464"
  paper_id: '73'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2073.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2073.jpg
  title: 'Multilingual Connotation Frames: A Case Study on Social Media for Targeted
    Sentiment Analysis and Forecast'
  title_html: 'Multilingual Connotation Frames: A Case Study on Social Media for Targeted
    Sentiment Analysis and Forecast'
  url: https://www.aclweb.org/anthology/P17-2073
  year: '2017'
P17-2074:
  abstract: "Rating scales are a widely used method for data annotation; however,\
    \ they present several challenges, such as difficulty in maintaining inter- and\
    \ intra-annotator consistency. Best\u2013worst scaling (BWS) is an alternative\
    \ method of annotation that is claimed to produce high-quality annotations while\
    \ keeping the required number of annotations similar to that of rating scales.\
    \ However, the veracity of this claim has never been systematically established.\
    \ Here for the first time, we set up an experiment that directly compares the\
    \ rating scale method with BWS. We show that with the same total number of annotations,\
    \ BWS produces significantly more reliable results than the rating scale."
  address: Vancouver, Canada
  author:
  - first: Svetlana
    full: Svetlana Kiritchenko
    id: svetlana-kiritchenko
    last: Kiritchenko
  - first: Saif
    full: Saif Mohammad
    id: saif-mohammad
    last: Mohammad
  author_string: Svetlana Kiritchenko, Saif Mohammad
  bibkey: kiritchenko-mohammad-2017-best
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2074
  month: July
  page_first: '465'
  page_last: '470'
  pages: "465\u2013470"
  paper_id: '74'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2074.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2074.jpg
  title: 'Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment
    Intensity Annotation'
  title_html: 'Best-Worst Scaling More Reliable than Rating Scales: A Case Study on
    Sentiment Intensity Annotation'
  url: https://www.aclweb.org/anthology/P17-2074
  year: '2017'
P17-2075:
  abstract: "In social media, demographic inference is a critical task in order to\
    \ gain a better understanding of a cohort and to facilitate interacting with one\u2019\
    s audience. Most previous work has made independence assumptions over topological,\
    \ textual and label information on social networks. In this work, we employ recursive\
    \ neural networks to break down these independence assumptions to obtain inference\
    \ about demographic characteristics on Twitter. We show that our model performs\
    \ better than existing models including the state-of-the-art."
  address: Vancouver, Canada
  author:
  - first: Sunghwan Mac
    full: Sunghwan Mac Kim
    id: sunghwan-mac-kim
    last: Kim
  - first: Qiongkai
    full: Qiongkai Xu
    id: qiongkai-xu
    last: Xu
  - first: Lizhen
    full: Lizhen Qu
    id: lizhen-qu
    last: Qu
  - first: Stephen
    full: Stephen Wan
    id: stephen-wan
    last: Wan
  - first: "C\xE9cile"
    full: "C\xE9cile Paris"
    id: cecile-paris
    last: Paris
  author_string: "Sunghwan Mac Kim, Qiongkai Xu, Lizhen Qu, Stephen Wan, C\xE9cile\
    \ Paris"
  bibkey: kim-etal-2017-demographic
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2075
  month: July
  page_first: '471'
  page_last: '477'
  pages: "471\u2013477"
  paper_id: '75'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2075.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2075.jpg
  title: Demographic Inference on Twitter using Recursive Neural Networks
  title_html: Demographic Inference on Twitter using Recursive Neural Networks
  url: https://www.aclweb.org/anthology/P17-2075
  year: '2017'
P17-2076:
  abstract: "Twitter should be an ideal place to get a fresh read on how different\
    \ issues are playing with the public, one that\u2019s potentially more reflective\
    \ of democracy in this new media age than traditional polls. Pollsters typically\
    \ ask people a fixed set of questions, while in social media people use their\
    \ own voices to speak about whatever is on their minds. However, the demographic\
    \ distribution of users on Twitter is not representative of the general population.\
    \ In this paper, we present a demographic classifier for gender, age, political\
    \ orientation and location on Twitter. We collected and curated a robust Twitter\
    \ demographic dataset for this task. Our classifier uses a deep multi-modal multi-task\
    \ learning architecture to reach a state-of-the-art performance, achieving an\
    \ F1-score of 0.89, 0.82, 0.86, and 0.68 for gender, age, political orientation,\
    \ and location respectively."
  address: Vancouver, Canada
  author:
  - first: Prashanth
    full: Prashanth Vijayaraghavan
    id: prashanth-vijayaraghavan
    last: Vijayaraghavan
  - first: Soroush
    full: Soroush Vosoughi
    id: soroush-vosoughi
    last: Vosoughi
  - first: Deb
    full: Deb Roy
    id: deb-roy
    last: Roy
  author_string: Prashanth Vijayaraghavan, Soroush Vosoughi, Deb Roy
  bibkey: vijayaraghavan-etal-2017-twitter
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2076
  month: July
  page_first: '478'
  page_last: '483'
  pages: "478\u2013483"
  paper_id: '76'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2076.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2076.jpg
  title: Twitter Demographic Classification Using Deep Multi-modal Multi-task Learning
  title_html: Twitter Demographic Classification Using Deep Multi-modal Multi-task
    Learning
  url: https://www.aclweb.org/anthology/P17-2076
  year: '2017'
P17-2077:
  abstract: "This paper focuses on the task of noisy label aggregation in social media,\
    \ where users with different social or culture backgrounds may annotate invalid\
    \ or malicious tags for documents. To aggregate noisy labels at a small cost,\
    \ a network framework is proposed by calculating the matching degree of a document\u2019\
    s topics and the annotators\u2019 meta-data. Unlike using the back-propagation\
    \ algorithm, a probabilistic inference approach is adopted to estimate network\
    \ parameters. Finally, a new simulation method is designed for validating the\
    \ effectiveness of the proposed framework in aggregating noisy labels."
  address: Vancouver, Canada
  author:
  - first: Xueying
    full: Xueying Zhan
    id: xueying-zhan
    last: Zhan
  - first: Yaowei
    full: Yaowei Wang
    id: yaowei-wang
    last: Wang
  - first: Yanghui
    full: Yanghui Rao
    id: yanghui-rao
    last: Rao
  - first: Haoran
    full: Haoran Xie
    id: haoran-xie
    last: Xie
  - first: Qing
    full: Qing Li
    id: qing-li
    last: Li
  - first: Fu Lee
    full: Fu Lee Wang
    id: fu-lee-wang
    last: Wang
  - first: Tak-Lam
    full: Tak-Lam Wong
    id: tak-lam-wong
    last: Wong
  author_string: Xueying Zhan, Yaowei Wang, Yanghui Rao, Haoran Xie, Qing Li, Fu Lee
    Wang, Tak-Lam Wong
  bibkey: zhan-etal-2017-network
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2077
  month: July
  page_first: '484'
  page_last: '490'
  pages: "484\u2013490"
  paper_id: '77'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2077.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2077.jpg
  title: A Network Framework for Noisy Label Aggregation in Social Media
  title_html: A Network Framework for Noisy Label Aggregation in Social Media
  url: https://www.aclweb.org/anthology/P17-2077
  year: '2017'
P17-2078:
  abstract: This work explores different approaches of using normalization for parser
    adaptation. Traditionally, normalization is used as separate pre-processing step.
    We show that integrating the normalization model into the parsing algorithm is
    more beneficial. This way, multiple normalization candidates can be leveraged,
    which improves parsing performance on social media. We test this hypothesis by
    modifying the Berkeley parser; out-of-the-box it achieves an F1 score of 66.52.
    Our integrated approach reaches a significant improvement with an F1 score of
    67.36, while using the best normalization sequence results in an F1 score of only
    66.94.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2078.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-2078.Poster.pdf
  - filename: P17-2078.Software.tgz
    type: software
    url: https://www.aclweb.org/anthology/attachments/P17-2078.Software.tgz
  author:
  - first: Rob
    full: Rob van der Goot
    id: rob-van-der-goot
    last: van der Goot
  - first: Gertjan
    full: Gertjan van Noord
    id: gertjan-van-noord
    last: van Noord
  author_string: Rob van der Goot, Gertjan van Noord
  bibkey: van-der-goot-van-noord-2017-parser
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2078
  month: July
  page_first: '491'
  page_last: '497'
  pages: "491\u2013497"
  paper_id: '78'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2078.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2078.jpg
  title: Parser Adaptation for Social Media by Integrating Normalization
  title_html: Parser Adaptation for Social Media by Integrating Normalization
  url: https://www.aclweb.org/anthology/P17-2078
  year: '2017'
P17-2079:
  abstract: We propose AliMe Chat, an open-domain chatbot engine that integrates the
    joint results of Information Retrieval (IR) and Sequence to Sequence (Seq2Seq)
    based generation models. AliMe Chat uses an attentive Seq2Seq based rerank model
    to optimize the joint results. Extensive experiments show our engine outperforms
    both IR and generation based models. We launch AliMe Chat for a real-world industrial
    application and observe better results than another public chatbot.
  address: Vancouver, Canada
  author:
  - first: Minghui
    full: Minghui Qiu
    id: minghui-qiu
    last: Qiu
  - first: Feng-Lin
    full: Feng-Lin Li
    id: feng-lin-li
    last: Li
  - first: Siyu
    full: Siyu Wang
    id: siyu-wang
    last: Wang
  - first: Xing
    full: Xing Gao
    id: xing-gao
    last: Gao
  - first: Yan
    full: Yan Chen
    id: yan-chen
    last: Chen
  - first: Weipeng
    full: Weipeng Zhao
    id: weipeng-zhao
    last: Zhao
  - first: Haiqing
    full: Haiqing Chen
    id: haiqing-chen
    last: Chen
  - first: Jun
    full: Jun Huang
    id: jun-huang
    last: Huang
  - first: Wei
    full: Wei Chu
    id: wei-chu
    last: Chu
  author_string: Minghui Qiu, Feng-Lin Li, Siyu Wang, Xing Gao, Yan Chen, Weipeng
    Zhao, Haiqing Chen, Jun Huang, Wei Chu
  bibkey: qiu-etal-2017-alime
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2079
  month: July
  page_first: '498'
  page_last: '503'
  pages: "498\u2013503"
  paper_id: '79'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2079.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2079.jpg
  title: 'AliMe Chat: A Sequence to Sequence and Rerank based Chatbot Engine'
  title_html: '<span class="acl-fixed-case">A</span>li<span class="acl-fixed-case">M</span>e
    Chat: A Sequence to Sequence and Rerank based Chatbot Engine'
  url: https://www.aclweb.org/anthology/P17-2079
  year: '2017'
P17-2080:
  abstract: Deep latent variable models have been shown to facilitate the response
    generation for open-domain dialog systems. However, these latent variables are
    highly randomized, leading to uncontrollable generated responses. In this paper,
    we propose a framework allowing conditional response generation based on specific
    attributes. These attributes can be either manually assigned or automatically
    detected. Moreover, the dialog states for both speakers are modeled separately
    in order to reflect personal features. We validate this framework on two different
    scenarios, where the attribute refers to genericness and sentiment states respectively.
    The experiment result testified the potential of our model, where meaningful responses
    can be generated in accordance with the specified attributes.
  address: Vancouver, Canada
  author:
  - first: Xiaoyu
    full: Xiaoyu Shen
    id: xiaoyu-shen
    last: Shen
  - first: Hui
    full: Hui Su
    id: hui-su
    last: Su
  - first: Yanran
    full: Yanran Li
    id: yanran-li
    last: Li
  - first: Wenjie
    full: Wenjie Li
    id: wenjie-li
    last: Li
  - first: Shuzi
    full: Shuzi Niu
    id: shuzi-niu
    last: Niu
  - first: Yang
    full: Yang Zhao
    id: yang-zhao
    last: Zhao
  - first: Akiko
    full: Akiko Aizawa
    id: akiko-aizawa
    last: Aizawa
  - first: Guoping
    full: Guoping Long
    id: guoping-long
    last: Long
  author_string: Xiaoyu Shen, Hui Su, Yanran Li, Wenjie Li, Shuzi Niu, Yang Zhao,
    Akiko Aizawa, Guoping Long
  bibkey: shen-etal-2017-conditional
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2080
  month: July
  page_first: '504'
  page_last: '509'
  pages: "504\u2013509"
  paper_id: '80'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2080.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2080.jpg
  title: A Conditional Variational Framework for Dialog Generation
  title_html: A Conditional Variational Framework for Dialog Generation
  url: https://www.aclweb.org/anthology/P17-2080
  year: '2017'
P17-2081:
  abstract: We show that the task of question answering (QA) can significantly benefit
    from the transfer learning of models trained on a different large, fine-grained
    QA dataset. We achieve the state of the art in two well-studied QA datasets, WikiQA
    and SemEval-2016 (Task 3A), through a basic transfer learning technique from SQuAD.
    For WikiQA, our model outperforms the previous best model by more than 8%. We
    demonstrate that finer supervision provides better guidance for learning lexical
    and syntactic information than coarser supervision, through quantitative results
    and visual analysis. We also show that a similar transfer learning procedure achieves
    the state of the art on an entailment task.
  address: Vancouver, Canada
  author:
  - first: Sewon
    full: Sewon Min
    id: sewon-min
    last: Min
  - first: Minjoon
    full: Minjoon Seo
    id: minjoon-seo
    last: Seo
  - first: Hannaneh
    full: Hannaneh Hajishirzi
    id: hannaneh-hajishirzi
    last: Hajishirzi
  author_string: Sewon Min, Minjoon Seo, Hannaneh Hajishirzi
  bibkey: min-etal-2017-question
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2081
  month: July
  page_first: '510'
  page_last: '517'
  pages: "510\u2013517"
  paper_id: '81'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2081.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2081.jpg
  title: Question Answering through Transfer Learning from Large Fine-grained Supervision
    Data
  title_html: Question Answering through Transfer Learning from Large Fine-grained
    Supervision Data
  url: https://www.aclweb.org/anthology/P17-2081
  year: '2017'
P17-2082:
  abstract: In this paper we introduce a self-training strategy for crowdsourcing.
    The training examples are automatically selected to train the crowd workers. Our
    experimental results show an impact of 5% Improvement in terms of F1 for relation
    extraction task, compared to the method based on distant supervision.
  address: Vancouver, Canada
  author:
  - first: Azad
    full: Azad Abad
    id: azad-abad
    last: Abad
  - first: Moin
    full: Moin Nabi
    id: moin-nabi
    last: Nabi
  - first: Alessandro
    full: Alessandro Moschitti
    id: alessandro-moschitti
    last: Moschitti
  author_string: Azad Abad, Moin Nabi, Alessandro Moschitti
  bibkey: abad-etal-2017-self
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2082
  month: July
  page_first: '518'
  page_last: '523'
  pages: "518\u2013523"
  paper_id: '82'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2082.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2082.jpg
  title: Self-Crowdsourcing Training for Relation Extraction
  title_html: Self-Crowdsourcing Training for Relation Extraction
  url: https://www.aclweb.org/anthology/P17-2082
  year: '2017'
P17-2083:
  abstract: We propose a novel generative neural network architecture for Dialogue
    Act classification. Building upon the Recurrent Neural Network framework, our
    model incorporates a novel attentional technique and a label to label connection
    for sequence learning, akin to Hidden Markov Models. The experiments show that
    both of these innovations lead our model to outperform strong baselines for dialogue
    act classification on MapTask and Switchboard corpora. We further empirically
    analyse the effectiveness of each of the new innovations.
  address: Vancouver, Canada
  author:
  - first: Quan Hung
    full: Quan Hung Tran
    id: quan-hung-tran
    last: Tran
  - first: Gholamreza
    full: Gholamreza Haffari
    id: gholamreza-haffari
    last: Haffari
  - first: Ingrid
    full: Ingrid Zukerman
    id: ingrid-zukerman
    last: Zukerman
  author_string: Quan Hung Tran, Gholamreza Haffari, Ingrid Zukerman
  bibkey: tran-etal-2017-generative
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2083
  month: July
  page_first: '524'
  page_last: '529'
  pages: "524\u2013529"
  paper_id: '83'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2083.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2083.jpg
  title: A Generative Attentional Neural Network Model for Dialogue Act Classification
  title_html: A Generative Attentional Neural Network Model for Dialogue Act Classification
  url: https://www.aclweb.org/anthology/P17-2083
  year: '2017'
P17-2084:
  abstract: Topical PageRank (TPR) uses latent topic distribution inferred by Latent
    Dirichlet Allocation (LDA) to perform ranking of noun phrases extracted from documents.
    The ranking procedure consists of running PageRank K times, where K is the number
    of topics used in the LDA model. In this paper, we propose a modification of TPR,
    called Salience Rank. Salience Rank only needs to run PageRank once and extracts
    comparable or better keyphrases on benchmark datasets. In addition to quality
    and efficiency benefit, our method has the flexibility to extract keyphrases with
    varying tradeoffs between topic specificity and corpus specificity.
  address: Vancouver, Canada
  author:
  - first: Nedelina
    full: Nedelina Teneva
    id: nedelina-teneva
    last: Teneva
  - first: Weiwei
    full: Weiwei Cheng
    id: weiwei-cheng
    last: Cheng
  author_string: Nedelina Teneva, Weiwei Cheng
  bibkey: teneva-cheng-2017-salience
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2084
  month: July
  page_first: '530'
  page_last: '535'
  pages: "530\u2013535"
  paper_id: '84'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2084.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2084.jpg
  title: 'Salience Rank: Efficient Keyphrase Extraction with Topic Modeling'
  title_html: 'Salience Rank: Efficient Keyphrase Extraction with Topic Modeling'
  url: https://www.aclweb.org/anthology/P17-2084
  year: '2017'
P17-2085:
  abstract: Traditional Entity Linking (EL) technologies rely on rich structures and
    properties in the target knowledge base (KB). However, in many applications, the
    KB may be as simple and sparse as lists of names of the same type (e.g., lists
    of products). We call it as List-only Entity Linking problem. Fortunately, some
    mentions may have more cues for linking, which can be used as seed mentions to
    bridge other mentions and the uninformative entities. In this work, we select
    most linkable mentions as seed mentions and disambiguate other mentions by comparing
    them with the seed mentions rather than directly with the entities. Our experiments
    on linking mentions to seven automatically mined lists show promising results
    and demonstrate the effectiveness of our approach.
  address: Vancouver, Canada
  author:
  - first: Ying
    full: Ying Lin
    id: ying-lin
    last: Lin
  - first: Chin-Yew
    full: Chin-Yew Lin
    id: chin-yew-lin
    last: Lin
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  author_string: Ying Lin, Chin-Yew Lin, Heng Ji
  bibkey: lin-etal-2017-list
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2085
  month: July
  page_first: '536'
  page_last: '541'
  pages: "536\u2013541"
  paper_id: '85'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2085.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2085.jpg
  title: List-only Entity Linking
  title_html: List-only Entity Linking
  url: https://www.aclweb.org/anthology/P17-2085
  year: '2017'
P17-2086:
  abstract: "In this paper, we explore spelling errors as a source of information\
    \ for detecting the native language of a writer, a previously under-explored area.\
    \ We note that character n-grams from misspelled words are very indicative of\
    \ the native language of the author. In combination with other lexical features,\
    \ spelling error features lead to 1.2% improvement in accuracy on classifying\
    \ texts in the TOEFL11 corpus by the author\u2019s native language, compared to\
    \ systems participating in the NLI shared task."
  address: Vancouver, Canada
  author:
  - first: Lingzhen
    full: Lingzhen Chen
    id: lingzhen-chen
    last: Chen
  - first: Carlo
    full: Carlo Strapparava
    id: carlo-strapparava
    last: Strapparava
  - first: Vivi
    full: Vivi Nastase
    id: vivi-nastase
    last: Nastase
  author_string: Lingzhen Chen, Carlo Strapparava, Vivi Nastase
  bibkey: chen-etal-2017-improving-native
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2086
  month: July
  page_first: '542'
  page_last: '546'
  pages: "542\u2013546"
  paper_id: '86'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2086.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2086.jpg
  title: Improving Native Language Identification by Using Spelling Errors
  title_html: Improving Native Language Identification by Using Spelling Errors
  url: https://www.aclweb.org/anthology/P17-2086
  year: '2017'
P17-2087:
  abstract: This paper presents a model for disfluency detection in spontaneous speech
    transcripts called LSTM Noisy Channel Model. The model uses a Noisy Channel Model
    (NCM) to generate n-best candidate disfluency analyses and a Long Short-Term Memory
    (LSTM) language model to score the underlying fluent sentences of each analysis.
    The LSTM language model scores, along with other features, are used in a MaxEnt
    reranker to identify the most plausible analysis. We show that using an LSTM language
    model in the reranking process of noisy channel disfluency model improves the
    state-of-the-art in disfluency detection.
  address: Vancouver, Canada
  author:
  - first: Paria
    full: Paria Jamshid Lou
    id: paria-jamshid-lou
    last: Jamshid Lou
  - first: Mark
    full: Mark Johnson
    id: mark-johnson
    last: Johnson
  author_string: Paria Jamshid Lou, Mark Johnson
  bibkey: jamshid-lou-johnson-2017-disfluency
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2087
  month: July
  page_first: '547'
  page_last: '553'
  pages: "547\u2013553"
  paper_id: '87'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2087.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2087.jpg
  title: Disfluency Detection using a Noisy Channel Model and a Deep Neural Language
    Model
  title_html: Disfluency Detection using a Noisy Channel Model and a Deep Neural Language
    Model
  url: https://www.aclweb.org/anthology/P17-2087
  year: '2017'
P17-2088:
  abstract: "We show the equivalence of two state-of-the-art models for link prediction/knowledge\
    \ graph completion: Nickel et al\u2019s holographic embeddings and Trouillon et\
    \ al.\u2019s complex embeddings. We first consider a spectral version of the holographic\
    \ embeddings, exploiting the frequency domain in the Fourier transform for efficient\
    \ computation. The analysis of the resulting model reveals that it can be viewed\
    \ as an instance of the complex embeddings with a certain constraint imposed on\
    \ the initial vectors upon training. Conversely, any set of complex embeddings\
    \ can be converted to a set of equivalent holographic embeddings."
  address: Vancouver, Canada
  attachment:
  - filename: P17-2088.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2088.Notes.pdf
  author:
  - first: Katsuhiko
    full: Katsuhiko Hayashi
    id: katsuhiko-hayashi
    last: Hayashi
  - first: Masashi
    full: Masashi Shimbo
    id: masashi-shimbo
    last: Shimbo
  author_string: Katsuhiko Hayashi, Masashi Shimbo
  bibkey: hayashi-shimbo-2017-equivalence
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2088
  month: July
  page_first: '554'
  page_last: '559'
  pages: "554\u2013559"
  paper_id: '88'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2088.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2088.jpg
  title: On the Equivalence of Holographic and Complex Embeddings for Link Prediction
  title_html: On the Equivalence of Holographic and Complex Embeddings for Link Prediction
  url: https://www.aclweb.org/anthology/P17-2088
  year: '2017'
P17-2089:
  abstract: "Although new corpora are becoming increasingly available for machine\
    \ translation, only those that belong to the same or similar domains are typically\
    \ able to improve translation performance. Recently Neural Machine Translation\
    \ (NMT) has become prominent in the field. However, most of the existing domain\
    \ adaptation methods only focus on phrase-based machine translation. In this paper,\
    \ we exploit the NMT\u2019s internal embedding of the source sentence and use\
    \ the sentence embedding similarity to select the sentences which are close to\
    \ in-domain data. The empirical adaptation results on the IWSLT English-French\
    \ and NIST Chinese-English tasks show that the proposed methods can substantially\
    \ improve NMT performance by 2.4-9.0 BLEU points, outperforming the existing state-of-the-art\
    \ baseline by 2.3-4.5 BLEU points."
  address: Vancouver, Canada
  author:
  - first: Rui
    full: Rui Wang
    id: rui-wang
    last: Wang
  - first: Andrew
    full: Andrew Finch
    id: andrew-finch
    last: Finch
  - first: Masao
    full: Masao Utiyama
    id: masao-utiyama
    last: Utiyama
  - first: Eiichiro
    full: Eiichiro Sumita
    id: eiichiro-sumita
    last: Sumita
  author_string: Rui Wang, Andrew Finch, Masao Utiyama, Eiichiro Sumita
  bibkey: wang-etal-2017-sentence
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2089
  month: July
  page_first: '560'
  page_last: '566'
  pages: "560\u2013566"
  paper_id: '89'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2089.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2089.jpg
  title: Sentence Embedding for Neural Machine Translation Domain Adaptation
  title_html: Sentence Embedding for Neural Machine Translation Domain Adaptation
  url: https://www.aclweb.org/anthology/P17-2089
  year: '2017'
P17-2090:
  abstract: The quality of a Neural Machine Translation system depends substantially
    on the availability of sizable parallel corpora. For low-resource language pairs
    this is not the case, resulting in poor translation quality. Inspired by work
    in computer vision, we propose a novel data augmentation approach that targets
    low-frequency words by generating new sentence pairs containing rare words in
    new, synthetically created contexts. Experimental results on simulated low-resource
    settings show that our method improves translation quality by up to 2.9 BLEU points
    over the baseline and up to 3.2 BLEU over back-translation.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2090.Presentation.pdf
    type: presentation
    url: https://www.aclweb.org/anthology/attachments/P17-2090.Presentation.pdf
  author:
  - first: Marzieh
    full: Marzieh Fadaee
    id: marzieh-fadaee
    last: Fadaee
  - first: Arianna
    full: Arianna Bisazza
    id: arianna-bisazza
    last: Bisazza
  - first: Christof
    full: Christof Monz
    id: christof-monz
    last: Monz
  author_string: Marzieh Fadaee, Arianna Bisazza, Christof Monz
  bibkey: fadaee-etal-2017-data
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2090
  month: July
  page_first: '567'
  page_last: '573'
  pages: "567\u2013573"
  paper_id: '90'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2090.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2090.jpg
  title: Data Augmentation for Low-Resource Neural Machine Translation
  title_html: Data Augmentation for Low-Resource Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-2090
  year: '2017'
P17-2091:
  abstract: 'We speed up Neural Machine Translation (NMT) decoding by shrinking run-time
    target vocabulary. We experiment with two shrinking approaches: Locality Sensitive
    Hashing (LSH) and word alignments. Using the latter method, we get a 2x overall
    speed-up over a highly-optimized GPU implementation, without hurting BLEU. On
    certain low-resource language pairs, the same methods improve BLEU by 0.5 points.
    We also report a negative result for LSH on GPUs, due to relatively large overhead,
    though it was successful on CPUs. Compared with Locality Sensitive Hashing (LSH),
    decoding with word alignments is GPU-friendly, orthogonal to existing speedup
    methods and more robust across language pairs.'
  address: Vancouver, Canada
  author:
  - first: Xing
    full: Xing Shi
    id: xing-shi
    last: Shi
  - first: Kevin
    full: Kevin Knight
    id: kevin-knight
    last: Knight
  author_string: Xing Shi, Kevin Knight
  bibkey: shi-knight-2017-speeding
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2091
  month: July
  page_first: '574'
  page_last: '579'
  pages: "574\u2013579"
  paper_id: '91'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2091.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2091.jpg
  title: Speeding Up Neural Machine Translation Decoding by Shrinking Run-time Vocabulary
  title_html: Speeding Up Neural Machine Translation Decoding by Shrinking Run-time
    Vocabulary
  url: https://www.aclweb.org/anthology/P17-2091
  year: '2017'
P17-2092:
  abstract: In typical neural machine translation (NMT), the decoder generates a sentence
    word by word, packing all linguistic granularities in the same time-scale of RNN.
    In this paper, we propose a new type of decoder for NMT, which splits the decode
    state into two parts and updates them in two different time-scales. Specifically,
    we first predict a chunk time-scale state for phrasal modeling, on top of which
    multiple word time-scale states are generated. In this way, the target sentence
    is translated hierarchically from chunks to words, with information in different
    granularities being leveraged. Experiments show that our proposed model significantly
    improves the translation performance over the state-of-the-art NMT model.
  address: Vancouver, Canada
  author:
  - first: Hao
    full: Hao Zhou
    id: hao-zhou
    last: Zhou
  - first: Zhaopeng
    full: Zhaopeng Tu
    id: zhaopeng-tu
    last: Tu
  - first: Shujian
    full: Shujian Huang
    id: shujian-huang
    last: Huang
  - first: Xiaohua
    full: Xiaohua Liu
    id: xiaohua-liu
    last: Liu
  - first: Hang
    full: Hang Li
    id: hang-li
    last: Li
  - first: Jiajun
    full: Jiajun Chen
    id: jiajun-chen
    last: Chen
  author_string: Hao Zhou, Zhaopeng Tu, Shujian Huang, Xiaohua Liu, Hang Li, Jiajun
    Chen
  bibkey: zhou-etal-2017-chunk
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2092
  month: July
  page_first: '580'
  page_last: '586'
  pages: "580\u2013586"
  paper_id: '92'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2092.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2092.jpg
  title: Chunk-Based Bi-Scale Decoder for Neural Machine Translation
  title_html: Chunk-Based Bi-Scale Decoder for Neural Machine Translation
  url: https://www.aclweb.org/anthology/P17-2092
  year: '2017'
P17-2093:
  abstract: Cross-lingual model transfer is a compelling and popular method for predicting
    annotations in a low-resource language, whereby parallel corpora provide a bridge
    to a high-resource language, and its associated annotated corpora. However, parallel
    data is not readily available for many languages, limiting the applicability of
    these approaches. We address these drawbacks in our framework which takes advantage
    of cross-lingual word embeddings trained solely on a high coverage dictionary.
    We propose a novel neural network model for joint training from both sources of
    data based on cross-lingual word embeddings, and show substantial empirical improvements
    over baseline techniques. We also propose several active learning heuristics,
    which result in improvements over competitive benchmark methods.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2093.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-2093.Datasets.zip
  author:
  - first: Meng
    full: Meng Fang
    id: meng-fang
    last: Fang
  - first: Trevor
    full: Trevor Cohn
    id: trevor-cohn
    last: Cohn
  author_string: Meng Fang, Trevor Cohn
  bibkey: fang-cohn-2017-model
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2093
  month: July
  page_first: '587'
  page_last: '593'
  pages: "587\u2013593"
  paper_id: '93'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2093.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2093.jpg
  title: Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary
  title_html: Model Transfer for Tagging Low-resource Languages using a Bilingual
    Dictionary
  url: https://www.aclweb.org/anthology/P17-2093
  year: '2017'
P17-2094:
  abstract: Parallel corpora are widely used in a variety of Natural Language Processing
    tasks, from Machine Translation to cross-lingual Word Sense Disambiguation, where
    parallel sentences can be exploited to automatically generate high-quality sense
    annotations on a large scale. In this paper we present EuroSense, a multilingual
    sense-annotated resource based on the joint disambiguation of the Europarl parallel
    corpus, with almost 123 million sense annotations for over 155 thousand distinct
    concepts and entities from a language-independent unified sense inventory. We
    evaluate the quality of our sense annotations intrinsically and extrinsically,
    showing their effectiveness as training data for Word Sense Disambiguation.
  address: Vancouver, Canada
  author:
  - first: Claudio
    full: Claudio Delli Bovi
    id: claudio-delli-bovi
    last: Delli Bovi
  - first: Jose
    full: Jose Camacho-Collados
    id: jose-camacho-collados
    last: Camacho-Collados
  - first: Alessandro
    full: Alessandro Raganato
    id: alessandro-raganato
    last: Raganato
  - first: Roberto
    full: Roberto Navigli
    id: roberto-navigli
    last: Navigli
  author_string: Claudio Delli Bovi, Jose Camacho-Collados, Alessandro Raganato, Roberto
    Navigli
  bibkey: delli-bovi-etal-2017-eurosense
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2094
  month: July
  page_first: '594'
  page_last: '600'
  pages: "594\u2013600"
  paper_id: '94'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2094.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2094.jpg
  title: 'EuroSense: Automatic Harvesting of Multilingual Sense Annotations from Parallel
    Text'
  title_html: '<span class="acl-fixed-case">E</span>uro<span class="acl-fixed-case">S</span>ense:
    Automatic Harvesting of Multilingual Sense Annotations from Parallel Text'
  url: https://www.aclweb.org/anthology/P17-2094
  year: '2017'
P17-2095:
  abstract: 'Word segmentation plays a pivotal role in improving any Arabic NLP application.
    Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf
    tools, however, are: i) complicated to use and ii) domain/dialect dependent. We
    explore three language-independent alternatives to morphological segmentation
    using: i) data-driven sub-word units, ii) characters as a unit of learning, and
    iii) word embeddings learned using a character CNN (Convolution Neural Network).
    On the tasks of Machine Translation and POS tagging, we found these methods to
    achieve close to, and occasionally surpass state-of-the-art performance. In our
    analysis, we show that a neural machine translation system is sensitive to the
    ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal
    performance.'
  address: Vancouver, Canada
  author:
  - first: Hassan
    full: Hassan Sajjad
    id: hassan-sajjad
    last: Sajjad
  - first: Fahim
    full: Fahim Dalvi
    id: fahim-dalvi
    last: Dalvi
  - first: Nadir
    full: Nadir Durrani
    id: nadir-durrani
    last: Durrani
  - first: Ahmed
    full: Ahmed Abdelali
    id: ahmed-abdelali
    last: Abdelali
  - first: Yonatan
    full: Yonatan Belinkov
    id: yonatan-belinkov
    last: Belinkov
  - first: Stephan
    full: Stephan Vogel
    id: stephan-vogel
    last: Vogel
  author_string: Hassan Sajjad, Fahim Dalvi, Nadir Durrani, Ahmed Abdelali, Yonatan
    Belinkov, Stephan Vogel
  bibkey: sajjad-etal-2017-challenging
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2095
  month: July
  page_first: '601'
  page_last: '607'
  pages: "601\u2013607"
  paper_id: '95'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2095.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2095.jpg
  title: 'Challenging Language-Dependent Segmentation for Arabic: An Application to
    Machine Translation and Part-of-Speech Tagging'
  title_html: 'Challenging Language-Dependent Segmentation for <span class="acl-fixed-case">A</span>rabic:
    An Application to Machine Translation and Part-of-Speech Tagging'
  url: https://www.aclweb.org/anthology/P17-2095
  year: '2017'
P17-2096:
  abstract: Neural models with minimal feature engineering have achieved competitive
    performance against traditional methods for the task of Chinese word segmentation.
    However, both training and working procedures of the current neural models are
    computationally inefficient. In this paper, we propose a greedy neural word segmenter
    with balanced word and character embedding inputs to alleviate the existing drawbacks.
    Our segmenter is truly end-to-end, capable of performing segmentation much faster
    and even more accurate than state-of-the-art neural models on Chinese benchmark
    datasets.
  address: Vancouver, Canada
  author:
  - first: Deng
    full: Deng Cai
    id: deng-cai
    last: Cai
  - first: Hai
    full: Hai Zhao
    id: hai-zhao
    last: Zhao
  - first: Zhisong
    full: Zhisong Zhang
    id: zhisong-zhang
    last: Zhang
  - first: Yuan
    full: Yuan Xin
    id: yuan-xin
    last: Xin
  - first: Yongjian
    full: Yongjian Wu
    id: yongjian-wu
    last: Wu
  - first: Feiyue
    full: Feiyue Huang
    id: feiyue-huang
    last: Huang
  author_string: Deng Cai, Hai Zhao, Zhisong Zhang, Yuan Xin, Yongjian Wu, Feiyue
    Huang
  bibkey: cai-etal-2017-fast
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2096
  month: July
  page_first: '608'
  page_last: '615'
  pages: "608\u2013615"
  paper_id: '96'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2096.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2096.jpg
  title: Fast and Accurate Neural Word Segmentation for Chinese
  title_html: Fast and Accurate Neural Word Segmentation for <span class="acl-fixed-case">C</span>hinese
  url: https://www.aclweb.org/anthology/P17-2096
  year: '2017'
P17-2097:
  abstract: "We consider the ROC story cloze task (Mostafazadeh et al., 2016) and\
    \ present several findings. We develop a model that uses hierarchical recurrent\
    \ networks with attention to encode the sentences in the story and score candidate\
    \ endings. By discarding the large training set and only training on the validation\
    \ set, we achieve an accuracy of 74.7%. Even when we discard the story plots (sentences\
    \ before the ending) and only train to choose the better of two endings, we can\
    \ still reach 72.5%. We then analyze this \u201Cending-only\u201D task setting.\
    \ We estimate human accuracy to be 78% and find several types of clues that lead\
    \ to this high accuracy, including those related to sentiment, negation, and general\
    \ ending likelihood regardless of the story context."
  address: Vancouver, Canada
  author:
  - first: Zheng
    full: Zheng Cai
    id: zheng-cai
    last: Cai
  - first: Lifu
    full: Lifu Tu
    id: lifu-tu
    last: Tu
  - first: Kevin
    full: Kevin Gimpel
    id: kevin-gimpel
    last: Gimpel
  author_string: Zheng Cai, Lifu Tu, Kevin Gimpel
  bibkey: cai-etal-2017-pay
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2097
  month: July
  page_first: '616'
  page_last: '622'
  pages: "616\u2013622"
  paper_id: '97'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2097.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2097.jpg
  title: Pay Attention to the Ending:Strong Neural Baselines for the ROC Story Cloze
    Task
  title_html: Pay Attention to the Ending:Strong Neural Baselines for the <span class="acl-fixed-case">ROC</span>
    Story Cloze Task
  url: https://www.aclweb.org/anthology/P17-2097
  year: '2017'
P17-2098:
  abstract: A fundamental challenge in developing semantic parsers is the paucity
    of strong supervision in the form of language utterances annotated with logical
    form. In this paper, we propose to exploit structural regularities in language
    in different domains, and train semantic parsers over multiple knowledge-bases
    (KBs), while sharing information across datasets. We find that we can substantially
    improve parsing accuracy by training a single sequence-to-sequence model over
    multiple KBs, when providing an encoding of the domain at decoding time. Our model
    achieves state-of-the-art performance on the Overnight dataset (containing eight
    domains), improves performance over a single KB baseline from 75.6% to 79.6%,
    while obtaining a 7x reduction in the number of model parameters.
  address: Vancouver, Canada
  author:
  - first: Jonathan
    full: Jonathan Herzig
    id: jonathan-herzig
    last: Herzig
  - first: Jonathan
    full: Jonathan Berant
    id: jonathan-berant
    last: Berant
  author_string: Jonathan Herzig, Jonathan Berant
  bibkey: herzig-berant-2017-neural
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2098
  month: July
  page_first: '623'
  page_last: '628'
  pages: "623\u2013628"
  paper_id: '98'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2098.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2098.jpg
  title: Neural Semantic Parsing over Multiple Knowledge-bases
  title_html: Neural Semantic Parsing over Multiple Knowledge-bases
  url: https://www.aclweb.org/anthology/P17-2098
  year: '2017'
P17-2099:
  abstract: "Sentences are important semantic units of natural language. A generic,\
    \ distributional representation of sentences that can capture the latent semantics\
    \ is beneficial to multiple downstream applications. We observe a simple geometry\
    \ of sentences \u2013 the word representations of a given sentence (on average\
    \ 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly\
    \ lie in a low-rank subspace (roughly, rank 4). Motivated by this observation,\
    \ we represent a sentence by the low-rank subspace spanned by its word vectors.\
    \ Such an unsupervised representation is empirically validated via semantic textual\
    \ similarity tasks on 19 different datasets, where it outperforms the sophisticated\
    \ neural network models, including skip-thought vectors, by 15% on average."
  address: Vancouver, Canada
  author:
  - first: Jiaqi
    full: Jiaqi Mu
    id: jiaqi-mu
    last: Mu
  - first: Suma
    full: Suma Bhat
    id: suma-bhat
    last: Bhat
  - first: Pramod
    full: Pramod Viswanath
    id: pramod-viswanath
    last: Viswanath
  author_string: Jiaqi Mu, Suma Bhat, Pramod Viswanath
  bibkey: mu-etal-2017-representing
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2099
  month: July
  page_first: '629'
  page_last: '634'
  pages: "629\u2013634"
  paper_id: '99'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2099.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2099.jpg
  title: Representing Sentences as Low-Rank Subspaces
  title_html: Representing Sentences as Low-Rank Subspaces
  url: https://www.aclweb.org/anthology/P17-2099
  year: '2017'
P17-2100:
  abstract: Current Chinese social media text summarization models are based on an
    encoder-decoder framework. Although its generated summaries are similar to source
    texts literally, they have low semantic relevance. In this work, our goal is to
    improve semantic relevance between source texts and summaries for Chinese social
    media summarization. We introduce a Semantic Relevance Based neural model to encourage
    high semantic similarity between texts and summaries. In our model, the source
    text is represented by a gated attention encoder, while the summary representation
    is produced by a decoder. Besides, the similarity score between the representations
    is maximized during training. Our experiments show that the proposed model outperforms
    baseline systems on a social media corpus.
  address: Vancouver, Canada
  author:
  - first: Shuming
    full: Shuming Ma
    id: shuming-ma
    last: Ma
  - first: Xu
    full: Xu Sun
    id: xu-sun
    last: Sun
  - first: Jingjing
    full: Jingjing Xu
    id: jingjing-xu
    last: Xu
  - first: Houfeng
    full: Houfeng Wang
    id: houfeng-wang
    last: Wang
  - first: Wenjie
    full: Wenjie Li
    id: wenjie-li
    last: Li
  - first: Qi
    full: Qi Su
    id: qi-su
    last: Su
  author_string: Shuming Ma, Xu Sun, Jingjing Xu, Houfeng Wang, Wenjie Li, Qi Su
  bibkey: ma-etal-2017-improving
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2100
  month: July
  page_first: '635'
  page_last: '640'
  pages: "635\u2013640"
  paper_id: '100'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2100.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2100.jpg
  title: Improving Semantic Relevance for Sequence-to-Sequence Learning of Chinese
    Social Media Text Summarization
  title_html: Improving Semantic Relevance for Sequence-to-Sequence Learning of <span
    class="acl-fixed-case">C</span>hinese Social Media Text Summarization
  url: https://www.aclweb.org/anthology/P17-2100
  year: '2017'
P17-2101:
  abstract: This paper describes an approach to determine whether people participate
    in the events they tweet about. Specifically, we determine whether people are
    participants in events with respect to the tweet timestamp. We target all events
    expressed by verbs in tweets, including past, present and events that may occur
    in the future. We present new annotations using 1,096 event mentions, and experimental
    results showing that the task is challenging.
  address: Vancouver, Canada
  author:
  - first: Krishna Chaitanya
    full: Krishna Chaitanya Sanagavarapu
    id: krishna-chaitanya-sanagavarapu
    last: Sanagavarapu
  - first: Alakananda
    full: Alakananda Vempala
    id: alakananda-vempala
    last: Vempala
  - first: Eduardo
    full: Eduardo Blanco
    id: eduardo-blanco
    last: Blanco
  author_string: Krishna Chaitanya Sanagavarapu, Alakananda Vempala, Eduardo Blanco
  bibkey: sanagavarapu-etal-2017-determining
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2101
  month: July
  page_first: '641'
  page_last: '646'
  pages: "641\u2013646"
  paper_id: '101'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2101.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2101.jpg
  title: Determining Whether and When People Participate in the Events They Tweet
    About
  title_html: Determining Whether and When People Participate in the Events They Tweet
    About
  url: https://www.aclweb.org/anthology/P17-2101
  year: '2017'
P17-2102:
  abstract: "Pew research polls report 62 percent of U.S. adults get news on social\
    \ media (Gottfried and Shearer, 2016). In a December poll, 64 percent of U.S.\
    \ adults said that \u201Cmade-up news\u201D has caused a \u201Cgreat deal of confusion\u201D\
    \ about the facts of current events (Barthel et al., 2016). Fabricated stories\
    \ in social media, ranging from deliberate propaganda to hoaxes and satire, contributes\
    \ to this confusion in addition to having serious effects on global stability.\
    \ In this work we build predictive models to classify 130 thousand news posts\
    \ as suspicious or verified, and predict four sub-types of suspicious news \u2013\
    \ satire, hoaxes, clickbait and propaganda. We show that neural network models\
    \ trained on tweet content and social network interactions outperform lexical\
    \ models. Unlike previous work on deception detection, we find that adding syntax\
    \ and grammar features to our models does not improve performance. Incorporating\
    \ linguistic features improves classification results, however, social interaction\
    \ features are most informative for finer-grained separation between four types\
    \ of suspicious news posts."
  address: Vancouver, Canada
  attachment:
  - filename: P17-2102.Datasets.zip
    type: dataset
    url: https://www.aclweb.org/anthology/attachments/P17-2102.Datasets.zip
  author:
  - first: Svitlana
    full: Svitlana Volkova
    id: svitlana-volkova
    last: Volkova
  - first: Kyle
    full: Kyle Shaffer
    id: kyle-shaffer
    last: Shaffer
  - first: Jin Yea
    full: Jin Yea Jang
    id: jin-yea-jang
    last: Jang
  - first: Nathan
    full: Nathan Hodas
    id: nathan-hodas
    last: Hodas
  author_string: Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, Nathan Hodas
  bibkey: volkova-etal-2017-separating
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2102
  month: July
  page_first: '647'
  page_last: '653'
  pages: "647\u2013653"
  paper_id: '102'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2102.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2102.jpg
  title: 'Separating Facts from Fiction: Linguistic Models to Classify Suspicious
    and Trusted News Posts on Twitter'
  title_html: 'Separating Facts from Fiction: Linguistic Models to Classify Suspicious
    and Trusted News Posts on Twitter'
  url: https://www.aclweb.org/anthology/P17-2102
  year: '2017'
P17-2103:
  abstract: Counterfactual statements, describing events that did not occur and their
    consequents, have been studied in areas including problem-solving, affect management,
    and behavior regulation. People with more counterfactual thinking tend to perceive
    life events as more personally meaningful. Nevertheless, counterfactuals have
    not been studied in computational linguistics. We create a counterfactual tweet
    dataset and explore approaches for detecting counterfactuals using rule-based
    and supervised statistical approaches. A combined rule-based and statistical approach
    yielded the best results (F1 = 0.77) outperforming either approach used alone.
  address: Vancouver, Canada
  attachment:
  - filename: P17-2103.Notes.pdf
    type: note
    url: https://www.aclweb.org/anthology/attachments/P17-2103.Notes.pdf
  author:
  - first: Youngseo
    full: Youngseo Son
    id: youngseo-son
    last: Son
  - first: Anneke
    full: Anneke Buffone
    id: anneke-buffone
    last: Buffone
  - first: Joe
    full: Joe Raso
    id: joe-raso
    last: Raso
  - first: Allegra
    full: Allegra Larche
    id: allegra-larche
    last: Larche
  - first: Anthony
    full: Anthony Janocko
    id: anthony-janocko
    last: Janocko
  - first: Kevin
    full: Kevin Zembroski
    id: kevin-zembroski
    last: Zembroski
  - first: H Andrew
    full: H Andrew Schwartz
    id: h-andrew-schwartz
    last: Schwartz
  - first: Lyle
    full: Lyle Ungar
    id: lyle-ungar
    last: Ungar
  author_string: Youngseo Son, Anneke Buffone, Joe Raso, Allegra Larche, Anthony Janocko,
    Kevin Zembroski, H Andrew Schwartz, Lyle Ungar
  bibkey: son-etal-2017-recognizing
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2103
  month: July
  page_first: '654'
  page_last: '658'
  pages: "654\u2013658"
  paper_id: '103'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2103.pdf
  publisher: Association for Computational Linguistics
  revision:
  - id: '1'
    url: https://www.aclweb.org/anthology/P17-2103v1.pdf
    value: P17-2103v1
  - explanation: No description of the changes were recorded.
    id: '2'
    url: https://www.aclweb.org/anthology/P17-2103v2.pdf
    value: P17-2103v2
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2103.jpg
  title: Recognizing Counterfactual Thinking in Social Media Texts
  title_html: Recognizing Counterfactual Thinking in Social Media Texts
  url: https://www.aclweb.org/anthology/P17-2103
  year: '2017'
P17-2104:
  abstract: "Automatically estimating a user\u2019s socio-economic profile from their\
    \ language use in social media can significantly help social science research\
    \ and various downstream applications ranging from business to politics. The current\
    \ paper presents the first study where user cognitive structure is used to build\
    \ a predictive model of income. In particular, we first develop a classifier using\
    \ a weakly supervised learning framework to automatically time-tag tweets as past,\
    \ present, or future. We quantify a user\u2019s overall temporal orientation based\
    \ on their distribution of tweets, and use it to build a predictive model of income.\
    \ Our analysis uncovers a correlation between future temporal orientation and\
    \ income. Finally, we measure the predictive power of future temporal orientation\
    \ on income by performing regression."
  address: Vancouver, Canada
  author:
  - first: Mohammed
    full: Mohammed Hasanuzzaman
    id: mohammed-hasanuzzaman
    last: Hasanuzzaman
  - first: Sabyasachi
    full: Sabyasachi Kamila
    id: sabyasachi-kamila
    last: Kamila
  - first: Mandeep
    full: Mandeep Kaur
    id: mandeep-kaur
    last: Kaur
  - first: Sriparna
    full: Sriparna Saha
    id: sriparna-saha
    last: Saha
  - first: Asif
    full: Asif Ekbal
    id: asif-ekbal
    last: Ekbal
  author_string: Mohammed Hasanuzzaman, Sabyasachi Kamila, Mandeep Kaur, Sriparna
    Saha, Asif Ekbal
  bibkey: hasanuzzaman-etal-2017-temporal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2104
  month: July
  page_first: '659'
  page_last: '665'
  pages: "659\u2013665"
  paper_id: '104'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2104.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2104.jpg
  title: Temporal Orientation of Tweets for Predicting Income of Users
  title_html: Temporal Orientation of Tweets for Predicting Income of Users
  url: https://www.aclweb.org/anthology/P17-2104
  year: '2017'
P17-2105:
  abstract: "We develop a language-independent, deep learning-based approach to the\
    \ task of morphological disambiguation. Guided by the intuition that the correct\
    \ analysis should be \u201Cmost similar\u201D to the context, we propose dense\
    \ representations for morphological analyses and surface context and a simple\
    \ yet effective way of combining the two to perform disambiguation. Our approach\
    \ improves on the language-dependent state of the art for two agglutinative languages\
    \ (Turkish and Kazakh) and can be potentially applied to other morphologically\
    \ complex languages."
  address: Vancouver, Canada
  author:
  - first: Alymzhan
    full: Alymzhan Toleu
    id: alymzhan-toleu
    last: Toleu
  - first: Gulmira
    full: Gulmira Tolegen
    id: gulmira-tolegen
    last: Tolegen
  - first: Aibek
    full: Aibek Makazhanov
    id: aibek-makazhanov
    last: Makazhanov
  author_string: Alymzhan Toleu, Gulmira Tolegen, Aibek Makazhanov
  bibkey: toleu-etal-2017-character
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2105
  month: July
  page_first: '666'
  page_last: '671'
  pages: "666\u2013671"
  paper_id: '105'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2105.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2105.jpg
  title: Character-Aware Neural Morphological Disambiguation
  title_html: Character-Aware Neural Morphological Disambiguation
  url: https://www.aclweb.org/anthology/P17-2105
  year: '2017'
P17-2106:
  abstract: We present a transition-based dependency parser that uses a convolutional
    neural network to compose word representations from characters. The character
    composition model shows great improvement over the word-lookup model, especially
    for parsing agglutinative languages. These improvements are even better than using
    pre-trained word embeddings from extra data. On the SPMRL data sets, our system
    outperforms the previous best greedy parser (Ballesteros et. al, 2015) by a margin
    of 3% on average.
  address: Vancouver, Canada
  author:
  - first: Xiang
    full: Xiang Yu
    id: xiang-yu
    last: Yu
  - first: Ngoc Thang
    full: Ngoc Thang Vu
    id: ngoc-thang-vu
    last: Vu
  author_string: Xiang Yu, Ngoc Thang Vu
  bibkey: yu-vu-2017-character
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2106
  month: July
  page_first: '672'
  page_last: '678'
  pages: "672\u2013678"
  paper_id: '106'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2106.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2106.jpg
  title: Character Composition Model with Convolutional Neural Networks for Dependency
    Parsing on Morphologically Rich Languages
  title_html: Character Composition Model with Convolutional Neural Networks for Dependency
    Parsing on Morphologically Rich Languages
  url: https://www.aclweb.org/anthology/P17-2106
  year: '2017'
P17-2107:
  abstract: In dependency parsing, jackknifing taggers is indiscriminately used as
    a simple adaptation strategy. Here, we empirically evaluate when and how (not)
    to use jackknifing in parsing. On 26 languages, we reveal a preference that conflicts
    with, and surpasses the ubiquitous ten-folding. We show no clear benefits of tagging
    the training data in cross-lingual parsing.
  address: Vancouver, Canada
  author:
  - first: "\u017Deljko"
    full: "\u017Deljko Agi\u0107"
    id: zeljko-agic
    last: "Agi\u0107"
  - first: Natalie
    full: Natalie Schluter
    id: natalie-schluter
    last: Schluter
  author_string: "\u017Deljko Agi\u0107, Natalie Schluter"
  bibkey: agic-schluter-2017-train
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)'
  doi: 10.18653/v1/P17-2107
  month: July
  page_first: '679'
  page_last: '684'
  pages: "679\u2013684"
  paper_id: '107'
  parent_volume_id: P17-2
  pdf: https://www.aclweb.org/anthology/P17-2107.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-2107.jpg
  title: 'How (not) to train a dependency parser: The curious case of jackknifing
    part-of-speech taggers'
  title_html: 'How (not) to train a dependency parser: The curious case of jackknifing
    part-of-speech taggers'
  url: https://www.aclweb.org/anthology/P17-2107
  year: '2017'
P17-3000:
  address: Vancouver, Canada
  author:
  - first: Allyson
    full: Allyson Ettinger
    id: allyson-ettinger
    last: Ettinger
  - first: Spandana
    full: Spandana Gella
    id: spandana-gella
    last: Gella
  - first: Matthieu
    full: Matthieu Labeau
    id: matthieu-labeau
    last: Labeau
  - first: Cecilia Ovesdotter
    full: Cecilia Ovesdotter Alm
    id: cecilia-ovesdotter-alm
    last: Alm
  - first: Marine
    full: Marine Carpuat
    id: marine-carpuat
    last: Carpuat
  - first: Mark
    full: Mark Dredze
    id: mark-dredze
    last: Dredze
  author_string: Allyson Ettinger, Spandana Gella, Matthieu Labeau, Cecilia Ovesdotter
    Alm, Marine Carpuat, Mark Dredze
  bibkey: acl-2017-acl
  bibtype: proceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  month: July
  paper_id: '0'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3000.jpg
  title: Proceedings of ACL 2017, Student Research Workshop
  title_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  url: https://www.aclweb.org/anthology/P17-3000
  year: '2017'
P17-3001:
  address: Vancouver, Canada
  author:
  - first: Facundo
    full: Facundo Carrillo
    id: facundo-carrillo
    last: Carrillo
  author_string: Facundo Carrillo
  bibkey: carrillo-2017-computational
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '1'
  page_last: '3'
  pages: "1\u20133"
  paper_id: '1'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3001.jpg
  title: 'Computational Characterization of Mental States: A Natural Language Processing
    Approach'
  title_html: 'Computational Characterization of Mental States: A Natural Language
    Processing Approach'
  url: https://www.aclweb.org/anthology/P17-3001
  year: '2017'
P17-3002:
  address: Vancouver, Canada
  author:
  - first: Ganesh
    full: Ganesh Jawahar
    id: ganesh-jawahar
    last: Jawahar
  author_string: Ganesh Jawahar
  bibkey: jawahar-2017-improving
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '4'
  page_last: '10'
  pages: "4\u201310"
  paper_id: '2'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3002.jpg
  title: Improving Distributed Representations of Tweets - Present and Future
  title_html: Improving Distributed Representations of Tweets - Present and Future
  url: https://www.aclweb.org/anthology/P17-3002
  year: '2017'
P17-3003:
  address: Vancouver, Canada
  author:
  - first: Jeenu
    full: Jeenu Grover
    id: jeenu-grover
    last: Grover
  - first: Pabitra
    full: Pabitra Mitra
    id: pabitra-mitra
    last: Mitra
  author_string: Jeenu Grover, Pabitra Mitra
  bibkey: grover-mitra-2017-bilingual
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '11'
  page_last: '16'
  pages: "11\u201316"
  paper_id: '3'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3003.jpg
  title: Bilingual Word Embeddings with Bucketed CNN for Parallel Sentence Extraction
  title_html: Bilingual Word Embeddings with Bucketed <span class="acl-fixed-case">CNN</span>
    for Parallel Sentence Extraction
  url: https://www.aclweb.org/anthology/P17-3003
  year: '2017'
P17-3004:
  address: Vancouver, Canada
  author:
  - first: Nandan
    full: Nandan Sukthankar
    id: nandan-sukthankar
    last: Sukthankar
  - first: Sanket
    full: Sanket Maharnawar
    id: sanket-maharnawar
    last: Maharnawar
  - first: Pranay
    full: Pranay Deshmukh
    id: pranay-deshmukh
    last: Deshmukh
  - first: Yashodhara
    full: Yashodhara Haribhakta
    id: yashodhara-haribhakta
    last: Haribhakta
  - first: Vibhavari
    full: Vibhavari Kamble
    id: vibhavari-kamble
    last: Kamble
  author_string: Nandan Sukthankar, Sanket Maharnawar, Pranay Deshmukh, Yashodhara
    Haribhakta, Vibhavari Kamble
  bibkey: sukthankar-etal-2017-nquery
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '17'
  page_last: '23'
  pages: "17\u201323"
  paper_id: '4'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3004.jpg
  title: nQuery - A Natural Language Statement to SQL Query Generator
  title_html: n<span class="acl-fixed-case">Q</span>uery - A Natural Language Statement
    to <span class="acl-fixed-case">SQL</span> Query Generator
  url: https://www.aclweb.org/anthology/P17-3004
  year: '2017'
P17-3005:
  address: Vancouver, Canada
  author:
  - first: Nihal V.
    full: Nihal V. Nayak
    id: nihal-v-nayak
    last: Nayak
  - first: Tanmay
    full: Tanmay Chinchore
    id: tanmay-chinchore
    last: Chinchore
  - first: Aishwarya
    full: Aishwarya Hanumanth Rao
    id: aishwarya-hanumanth-rao
    last: Hanumanth Rao
  - first: Shane Michael
    full: Shane Michael Martin
    id: shane-michael-martin
    last: Martin
  - first: Sagar Nagaraj
    full: Sagar Nagaraj Simha
    id: sagar-nagaraj-simha
    last: Simha
  - first: G. M.
    full: G. M. Lingaraju
    id: g-m-lingaraju
    last: Lingaraju
  - first: H. S.
    full: H. S. Jamadagni
    id: h-s-jamadagni
    last: Jamadagni
  author_string: Nihal V. Nayak, Tanmay Chinchore, Aishwarya Hanumanth Rao, Shane
    Michael Martin, Sagar Nagaraj Simha, G. M. Lingaraju, H. S. Jamadagni
  bibkey: nayak-etal-2017-v
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '24'
  page_last: '29'
  pages: "24\u201329"
  paper_id: '5'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3005.jpg
  title: 'V for Vocab: An Intelligent Flashcard Application'
  title_html: 'V for Vocab: An Intelligent <span class="acl-fixed-case">F</span>lashcard
    Application'
  url: https://www.aclweb.org/anthology/P17-3005
  year: '2017'
P17-3006:
  address: Vancouver, Canada
  author:
  - first: Sudha
    full: Sudha Rao
    id: sudha-rao
    last: Rao
  author_string: Sudha Rao
  bibkey: rao-2017-asking
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '30'
  page_last: '35'
  pages: "30\u201335"
  paper_id: '6'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3006.jpg
  title: Are You Asking the Right Questions? Teaching Machines to Ask Clarification
    Questions
  title_html: Are You Asking the Right Questions? Teaching Machines to Ask Clarification
    Questions
  url: https://www.aclweb.org/anthology/P17-3006
  year: '2017'
P17-3007:
  address: Vancouver, Canada
  author:
  - first: Yui
    full: Yui Suzuki
    id: yui-suzuki
    last: Suzuki
  - first: Tomoyuki
    full: Tomoyuki Kajiwara
    id: tomoyuki-kajiwara
    last: Kajiwara
  - first: Mamoru
    full: Mamoru Komachi
    id: mamoru-komachi
    last: Komachi
  author_string: Yui Suzuki, Tomoyuki Kajiwara, Mamoru Komachi
  bibkey: suzuki-etal-2017-building
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '36'
  page_last: '42'
  pages: "36\u201342"
  paper_id: '7'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3007.jpg
  title: Building a Non-Trivial Paraphrase Corpus Using Multiple Machine Translation
    Systems
  title_html: Building a Non-Trivial Paraphrase Corpus Using Multiple Machine Translation
    Systems
  url: https://www.aclweb.org/anthology/P17-3007
  year: '2017'
P17-3008:
  address: Vancouver, Canada
  author:
  - first: Vasu
    full: Vasu Sharma
    id: vasu-sharma
    last: Sharma
  - first: Ankita
    full: Ankita Bishnu
    id: ankita-bishnu
    last: Bishnu
  - first: Labhesh
    full: Labhesh Patel
    id: labhesh-patel
    last: Patel
  author_string: Vasu Sharma, Ankita Bishnu, Labhesh Patel
  bibkey: sharma-etal-2017-segmentation
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '43'
  page_last: '48'
  pages: "43\u201348"
  paper_id: '8'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3008.jpg
  title: Segmentation Guided Attention Networks for Visual Question Answering
  title_html: Segmentation Guided Attention Networks for Visual Question Answering
  url: https://www.aclweb.org/anthology/P17-3008
  year: '2017'
P17-3009:
  address: Vancouver, Canada
  author:
  - first: Kaixin
    full: Kaixin Ma
    id: kaixin-ma
    last: Ma
  - first: Catherine
    full: Catherine Xiao
    id: catherine-xiao
    last: Xiao
  - first: Jinho D.
    full: Jinho D. Choi
    id: jinho-d-choi
    last: Choi
  author_string: Kaixin Ma, Catherine Xiao, Jinho D. Choi
  bibkey: ma-etal-2017-text
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '49'
  page_last: '55'
  pages: "49\u201355"
  paper_id: '9'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3009.jpg
  title: Text-based Speaker Identification on Multiparty Dialogues Using Multi-document
    Convolutional Neural Networks
  title_html: Text-based Speaker Identification on Multiparty Dialogues Using Multi-document
    Convolutional Neural Networks
  url: https://www.aclweb.org/anthology/P17-3009
  year: '2017'
P17-3010:
  address: Vancouver, Canada
  author:
  - first: Hang
    full: Hang Li
    id: hang-li
    last: Li
  - first: Haozheng
    full: Haozheng Wang
    id: haozheng-wang
    last: Wang
  - first: Zhenglu
    full: Zhenglu Yang
    id: zhenglu-yang
    last: Yang
  - first: Masato
    full: Masato Odagaki
    id: masato-odagaki
    last: Odagaki
  author_string: Hang Li, Haozheng Wang, Zhenglu Yang, Masato Odagaki
  bibkey: li-etal-2017-variation
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '56'
  page_last: '61'
  pages: "56\u201361"
  paper_id: '10'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3010.jpg
  title: Variation Autoencoder Based Network Representation Learning for Classification
  title_html: Variation Autoencoder Based Network Representation Learning for Classification
  url: https://www.aclweb.org/anthology/P17-3010
  year: '2017'
P17-3011:
  address: Vancouver, Canada
  author:
  - first: Paul
    full: Paul Michel
    id: paul-michel
    last: Michel
  - first: Okko
    full: Okko Rasanen
    id: okko-rasanen1
    last: Rasanen
  - first: Roland
    full: "Roland Thiolli\xE8re"
    id: roland-thiolliere
    last: "Thiolli\xE8re"
  - first: Emmanuel
    full: Emmanuel Dupoux
    id: emmanuel-dupoux
    last: Dupoux
  author_string: "Paul Michel, Okko Rasanen, Roland Thiolli\xE8re, Emmanuel Dupoux"
  bibkey: michel-etal-2017-blind
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '62'
  page_last: '68'
  pages: "62\u201368"
  paper_id: '11'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3011.jpg
  title: Blind Phoneme Segmentation With Temporal Prediction Errors
  title_html: Blind Phoneme Segmentation With Temporal Prediction Errors
  url: https://www.aclweb.org/anthology/P17-3011
  year: '2017'
P17-3012:
  address: Vancouver, Canada
  author:
  - first: Srishti
    full: Srishti Aggarwal
    id: srishti-aggarwal
    last: Aggarwal
  - first: Radhika
    full: Radhika Mamidi
    id: radhika-mamidi
    last: Mamidi
  author_string: Srishti Aggarwal, Radhika Mamidi
  bibkey: aggarwal-mamidi-2017-automatic
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '69'
  page_last: '74'
  pages: "69\u201374"
  paper_id: '12'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3012.jpg
  title: Automatic Generation of Jokes in Hindi
  title_html: Automatic Generation of Jokes in <span class="acl-fixed-case">H</span>indi
  url: https://www.aclweb.org/anthology/P17-3012
  year: '2017'
P17-3013:
  address: Vancouver, Canada
  author:
  - first: Haoran
    full: Haoran Zhang
    id: haoran-zhang
    last: Zhang
  - first: Diane
    full: Diane Litman
    id: diane-litman
    last: Litman
  author_string: Haoran Zhang, Diane Litman
  bibkey: zhang-litman-2017-word
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '75'
  page_last: '81'
  pages: "75\u201381"
  paper_id: '13'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3013.jpg
  title: Word Embedding for Response-To-Text Assessment of Evidence
  title_html: Word Embedding for Response-To-Text Assessment of Evidence
  url: https://www.aclweb.org/anthology/P17-3013
  year: '2017'
P17-3014:
  address: Vancouver, Canada
  author:
  - first: Katira
    full: Katira Soleymanzadeh
    id: katira-soleymanzadeh
    last: Soleymanzadeh
  author_string: Katira Soleymanzadeh
  bibkey: soleymanzadeh-2017-domain
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '82'
  page_last: '88'
  pages: "82\u201388"
  paper_id: '14'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3014.jpg
  title: Domain Specific Automatic Question Generation from Text
  title_html: Domain Specific Automatic Question Generation from Text
  url: https://www.aclweb.org/anthology/P17-3014
  year: '2017'
P17-3015:
  address: Vancouver, Canada
  author:
  - first: Jose
    full: Jose Ramirez
    id: jose-ramirez
    last: Ramirez
  - first: Matthew
    full: Matthew Garber
    id: matthew-gerber
    last: Garber
  - first: Xinhao
    full: Xinhao Wang
    id: xinhao-wang
    last: Wang
  author_string: Jose Ramirez, Matthew Garber, Xinhao Wang
  bibkey: ramirez-etal-2017-socceval
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '89'
  page_last: '94'
  pages: "89\u201394"
  paper_id: '15'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3015.jpg
  title: 'SoccEval: An Annotation Schema for Rating Soccer Players'
  title_html: '<span class="acl-fixed-case">S</span>occ<span class="acl-fixed-case">E</span>val:
    An Annotation Schema for Rating Soccer Players'
  url: https://www.aclweb.org/anthology/P17-3015
  year: '2017'
P17-3016:
  address: Vancouver, Canada
  author:
  - first: Matthew
    full: Matthew Garber
    id: matthew-gerber
    last: Garber
  - first: Meital
    full: Meital Singer
    id: meital-singer
    last: Singer
  - first: Christopher
    full: Christopher Ward
    id: christopher-ward
    last: Ward
  author_string: Matthew Garber, Meital Singer, Christopher Ward
  bibkey: garber-etal-2017-accent
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '95'
  page_last: '99'
  pages: "95\u201399"
  paper_id: '16'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3016.jpg
  title: Accent Adaptation for the Air Traffic Control Domain
  title_html: Accent Adaptation for the Air Traffic Control Domain
  url: https://www.aclweb.org/anthology/P17-3016
  year: '2017'
P17-3017:
  address: Vancouver, Canada
  author:
  - first: Tina
    full: Tina Fang
    id: tina-fang
    last: Fang
  - first: Martin
    full: Martin Jaggi
    id: martin-jaggi
    last: Jaggi
  - first: Katerina
    full: Katerina Argyraki
    id: katerina-argyraki
    last: Argyraki
  author_string: Tina Fang, Martin Jaggi, Katerina Argyraki
  bibkey: fang-etal-2017-generating
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '100'
  page_last: '106'
  pages: "100\u2013106"
  paper_id: '17'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3017.jpg
  title: Generating Steganographic Text with LSTMs
  title_html: Generating Steganographic Text with <span class="acl-fixed-case">LSTM</span>s
  url: https://www.aclweb.org/anthology/P17-3017
  year: '2017'
P17-3018:
  address: Vancouver, Canada
  author:
  - first: Misato
    full: Misato Hiraga
    id: misato-hiraga
    last: Hiraga
  author_string: Misato Hiraga
  bibkey: hiraga-2017-predicting
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '107'
  page_last: '113'
  pages: "107\u2013113"
  paper_id: '18'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3018.jpg
  title: Predicting Depression for Japanese Blog Text
  title_html: Predicting Depression for <span class="acl-fixed-case">J</span>apanese
    Blog Text
  url: https://www.aclweb.org/anthology/P17-3018
  year: '2017'
P17-3019:
  address: Vancouver, Canada
  author:
  - first: Petr
    full: Petr Babkin
    id: petr-babkin
    last: Babkin
  - first: Sergei
    full: Sergei Nirenburg
    id: sergei-nirenburg
    last: Nirenburg
  author_string: Petr Babkin, Sergei Nirenburg
  bibkey: babkin-nirenburg-2017-fast
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '114'
  page_last: '119'
  pages: "114\u2013119"
  paper_id: '19'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3019.jpg
  title: Fast Forward Through Opportunistic Incremental Meaning Representation Construction
  title_html: Fast Forward Through Opportunistic Incremental Meaning Representation
    Construction
  url: https://www.aclweb.org/anthology/P17-3019
  year: '2017'
P17-3020:
  address: Vancouver, Canada
  author:
  - first: Shoetsu
    full: Shoetsu Sato
    id: shoetsu-sato
    last: Sato
  - first: Naoki
    full: Naoki Yoshinaga
    id: naoki-yoshinaga
    last: Yoshinaga
  - first: Masashi
    full: Masashi Toyoda
    id: masashi-toyoda
    last: Toyoda
  - first: Masaru
    full: Masaru Kitsuregawa
    id: masaru-kitsuregawa
    last: Kitsuregawa
  author_string: Shoetsu Sato, Naoki Yoshinaga, Masashi Toyoda, Masaru Kitsuregawa
  bibkey: sato-etal-2017-modeling
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '120'
  page_last: '127'
  pages: "120\u2013127"
  paper_id: '20'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3020.jpg
  title: Modeling Situations in Neural Chat Bots
  title_html: Modeling Situations in Neural Chat Bots
  url: https://www.aclweb.org/anthology/P17-3020
  year: '2017'
P17-3021:
  address: Vancouver, Canada
  author:
  - first: Kurt Junshean
    full: Kurt Junshean Espinosa
    id: kurt-junshean-espinosa
    last: Espinosa
  author_string: Kurt Junshean Espinosa
  bibkey: espinosa-2017-empirical
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '128'
  page_last: '135'
  pages: "128\u2013135"
  paper_id: '21'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3021.jpg
  title: An Empirical Study on End-to-End Sentence Modelling
  title_html: An Empirical Study on End-to-End Sentence Modelling
  url: https://www.aclweb.org/anthology/P17-3021
  year: '2017'
P17-3022:
  address: Vancouver, Canada
  attachment:
  - filename: P17-3022.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-3022.Poster.pdf
  author:
  - first: Noa
    full: "Noa Na\u2019aman"
    id: noa-naaman
    last: "Na\u2019aman"
  - first: Hannah
    full: Hannah Provenza
    id: hannah-provenza
    last: Provenza
  - first: Orion
    full: Orion Montoya
    id: orion-montoya
    last: Montoya
  author_string: "Noa Na\u2019aman, Hannah Provenza, Orion Montoya"
  bibkey: naaman-etal-2017-varying
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '136'
  page_last: '141'
  pages: "136\u2013141"
  paper_id: '22'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3022.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3022.jpg
  title: Varying Linguistic Purposes of Emoji in (Twitter) Context
  title_html: Varying Linguistic Purposes of Emoji in (Twitter) Context
  url: https://www.aclweb.org/anthology/P17-3022
  year: '2017'
P17-3023:
  address: Vancouver, Canada
  author:
  - first: Nan
    full: Nan Wang
    id: nan-wang
    last: Wang
  author_string: Nan Wang
  bibkey: wang-2017-negotiation
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, Student Research Workshop
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, Student
    Research Workshop
  month: July
  page_first: '142'
  page_last: '149'
  pages: "142\u2013149"
  paper_id: '23'
  parent_volume_id: P17-3
  pdf: https://www.aclweb.org/anthology/P17-3023.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-3023.jpg
  title: 'Negotiation of Antibiotic Treatment in Medical Consultations: A Corpus Based
    Study'
  title_html: 'Negotiation of Antibiotic Treatment in Medical Consultations: A Corpus
    Based Study'
  url: https://www.aclweb.org/anthology/P17-3023
  year: '2017'
P17-4000:
  address: Vancouver, Canada
  author:
  - first: Mohit
    full: Mohit Bansal
    id: mohit-bansal
    last: Bansal
  - first: Heng
    full: Heng Ji
    id: heng-ji
    last: Ji
  author_string: Mohit Bansal, Heng Ji
  bibkey: acl-2017-acl-2017
  bibtype: proceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  month: July
  paper_id: '0'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4000.jpg
  title: Proceedings of ACL 2017, System Demonstrations
  title_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  url: https://www.aclweb.org/anthology/P17-4000
  year: '2017'
P17-4001:
  address: Vancouver, Canada
  attachment:
  - filename: P17-4001.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-4001.Poster.pdf
  author:
  - first: Anita
    full: Anita Ramm
    id: anita-ramm
    last: Ramm
  - first: Sharid
    full: "Sharid Lo\xE1iciga"
    id: sharid-loaiciga
    last: "Lo\xE1iciga"
  - first: Annemarie
    full: Annemarie Friedrich
    id: annemarie-friedrich
    last: Friedrich
  - first: Alexander
    full: Alexander Fraser
    id: alexander-fraser
    last: Fraser
  author_string: "Anita Ramm, Sharid Lo\xE1iciga, Annemarie Friedrich, Alexander Fraser"
  bibkey: ramm-etal-2017-annotating
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '1'
  page_last: '6'
  pages: "1\u20136"
  paper_id: '1'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4001.jpg
  title: Annotating tense, mood and voice for English, French and German
  title_html: Annotating tense, mood and voice for <span class="acl-fixed-case">E</span>nglish,
    <span class="acl-fixed-case">F</span>rench and <span class="acl-fixed-case">G</span>erman
  url: https://www.aclweb.org/anthology/P17-4001
  year: '2017'
P17-4002:
  address: Vancouver, Canada
  author:
  - first: Iain
    full: Iain Marshall
    id: iain-marshall
    last: Marshall
  - first: "Jo\xEBl"
    full: "Jo\xEBl Kuiper"
    id: joel-kuiper
    last: Kuiper
  - first: Edward
    full: Edward Banner
    id: edward-banner
    last: Banner
  - first: Byron C.
    full: Byron C. Wallace
    id: byron-c-wallace
    last: Wallace
  author_string: "Iain Marshall, Jo\xEBl Kuiper, Edward Banner, Byron C. Wallace"
  bibkey: marshall-etal-2017-automating
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '7'
  page_last: '12'
  pages: "7\u201312"
  paper_id: '2'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4002.jpg
  title: 'Automating Biomedical Evidence Synthesis: RobotReviewer'
  title_html: 'Automating Biomedical Evidence Synthesis: <span class="acl-fixed-case">R</span>obot<span
    class="acl-fixed-case">R</span>eviewer'
  url: https://www.aclweb.org/anthology/P17-4002
  year: '2017'
P17-4003:
  address: Vancouver, Canada
  author:
  - first: Wei-Nan
    full: Wei-Nan Zhang
    id: weinan-zhang
    last: Zhang
  - first: Ting
    full: Ting Liu
    id: ting-liu
    last: Liu
  - first: Bing
    full: Bing Qin
    id: bing-qin
    last: Qin
  - first: Yu
    full: Yu Zhang
    id: yu-zhang
    last: Zhang
  - first: Wanxiang
    full: Wanxiang Che
    id: wanxiang-che
    last: Che
  - first: Yanyan
    full: Yanyan Zhao
    id: yanyan-zhao
    last: Zhao
  - first: Xiao
    full: Xiao Ding
    id: xiao-ding
    last: Ding
  author_string: Wei-Nan Zhang, Ting Liu, Bing Qin, Yu Zhang, Wanxiang Che, Yanyan
    Zhao, Xiao Ding
  bibkey: zhang-etal-2017-benben
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '13'
  page_last: '18'
  pages: "13\u201318"
  paper_id: '3'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4003.jpg
  title: 'Benben: A Chinese Intelligent Conversational Robot'
  title_html: '<span class="acl-fixed-case">B</span>enben: A <span class="acl-fixed-case">C</span>hinese
    Intelligent Conversational Robot'
  url: https://www.aclweb.org/anthology/P17-4003
  year: '2017'
P17-4004:
  address: Vancouver, Canada
  attachment:
  - filename: P17-4004.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-4004.Poster.pdf
  author:
  - first: Andreas
    full: "Andreas R\xFCckl\xE9"
    id: andreas-ruckle
    last: "R\xFCckl\xE9"
  - first: Iryna
    full: Iryna Gurevych
    id: iryna-gurevych
    last: Gurevych
  author_string: "Andreas R\xFCckl\xE9, Iryna Gurevych"
  bibkey: ruckle-gurevych-2017-end
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '19'
  page_last: '24'
  pages: "19\u201324"
  paper_id: '4'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4004.jpg
  title: End-to-End Non-Factoid Question Answering with an Interactive Visualization
    of Neural Attention Weights
  title_html: End-to-End Non-Factoid Question Answering with an Interactive Visualization
    of Neural Attention Weights
  url: https://www.aclweb.org/anthology/P17-4004
  year: '2017'
P17-4005:
  address: Vancouver, Canada
  author:
  - first: Dustin
    full: Dustin Arendt
    id: dustin-arendt
    last: Arendt
  - first: Svitlana
    full: Svitlana Volkova
    id: svitlana-volkova
    last: Volkova
  author_string: Dustin Arendt, Svitlana Volkova
  bibkey: arendt-volkova-2017-esteem
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '25'
  page_last: '30'
  pages: "25\u201330"
  paper_id: '5'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4005.jpg
  title: 'ESTEEM: A Novel Framework for Qualitatively Evaluating and Visualizing Spatiotemporal
    Embeddings in Social Media'
  title_html: '<span class="acl-fixed-case">ESTEEM</span>: A Novel Framework for Qualitatively
    Evaluating and Visualizing Spatiotemporal Embeddings in Social Media'
  url: https://www.aclweb.org/anthology/P17-4005
  year: '2017'
P17-4006:
  address: Vancouver, Canada
  author:
  - first: Johannes
    full: Johannes Hellrich
    id: johannes-hellrich
    last: Hellrich
  - first: Udo
    full: Udo Hahn
    id: udo-hahn
    last: Hahn
  author_string: Johannes Hellrich, Udo Hahn
  bibkey: hellrich-hahn-2017-exploring
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '31'
  page_last: '36'
  pages: "31\u201336"
  paper_id: '6'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4006.jpg
  title: Exploring Diachronic Lexical Semantics with JeSemE
  title_html: Exploring Diachronic Lexical Semantics with <span class="acl-fixed-case">J</span>e<span
    class="acl-fixed-case">S</span>em<span class="acl-fixed-case">E</span>
  url: https://www.aclweb.org/anthology/P17-4006
  year: '2017'
P17-4007:
  address: Vancouver, Canada
  author:
  - first: Tuan Duc
    full: Tuan Duc Nguyen
    id: tuan-duc-nguyen
    last: Nguyen
  - first: Khai
    full: Khai Mai
    id: khai-mai
    last: Mai
  - first: Thai-Hoang
    full: Thai-Hoang Pham
    id: thai-hoang-pham
    last: Pham
  - first: Minh Trung
    full: Minh Trung Nguyen
    id: minh-trung-nguyen
    last: Nguyen
  - first: Truc-Vien T.
    full: Truc-Vien T. Nguyen
    id: truc-vien-t-nguyen
    last: Nguyen
  - first: Takashi
    full: Takashi Eguchi
    id: takashi-eguchi
    last: Eguchi
  - first: Ryohei
    full: Ryohei Sasano
    id: ryohei-sasano
    last: Sasano
  - first: Satoshi
    full: Satoshi Sekine
    id: satoshi-sekine
    last: Sekine
  author_string: Tuan Duc Nguyen, Khai Mai, Thai-Hoang Pham, Minh Trung Nguyen, Truc-Vien
    T. Nguyen, Takashi Eguchi, Ryohei Sasano, Satoshi Sekine
  bibkey: nguyen-etal-2017-extended
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '37'
  page_last: '42'
  pages: "37\u201342"
  paper_id: '7'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4007.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4007.jpg
  title: Extended Named Entity Recognition API and Its Applications in Language Education
  title_html: Extended Named Entity Recognition <span class="acl-fixed-case">API</span>
    and Its Applications in Language Education
  url: https://www.aclweb.org/anthology/P17-4007
  year: '2017'
P17-4008:
  address: Vancouver, Canada
  author:
  - first: Marjan
    full: Marjan Ghazvininejad
    id: marjan-ghazvininejad
    last: Ghazvininejad
  - first: Xing
    full: Xing Shi
    id: xing-shi
    last: Shi
  - first: Jay
    full: Jay Priyadarshi
    id: jay-priyadarshi
    last: Priyadarshi
  - first: Kevin
    full: Kevin Knight
    id: kevin-knight
    last: Knight
  author_string: Marjan Ghazvininejad, Xing Shi, Jay Priyadarshi, Kevin Knight
  bibkey: ghazvininejad-etal-2017-hafez
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '43'
  page_last: '48'
  pages: "43\u201348"
  paper_id: '8'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4008.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4008.jpg
  title: 'Hafez: an Interactive Poetry Generation System'
  title_html: '<span class="acl-fixed-case">H</span>afez: an Interactive Poetry Generation
    System'
  url: https://www.aclweb.org/anthology/P17-4008
  year: '2017'
P17-4009:
  address: Vancouver, Canada
  author:
  - first: Mennatallah
    full: Mennatallah El-Assady
    id: mennatallah-el-assady
    last: El-Assady
  - first: Annette
    full: Annette Hautli-Janisz
    id: annette-hautli
    last: Hautli-Janisz
  - first: Valentin
    full: Valentin Gold
    id: valentin-gold
    last: Gold
  - first: Miriam
    full: Miriam Butt
    id: miriam-butt
    last: Butt
  - first: Katharina
    full: Katharina Holzinger
    id: katharina-holzinger
    last: Holzinger
  - first: Daniel
    full: Daniel Keim
    id: daniel-keim
    last: Keim
  author_string: Mennatallah El-Assady, Annette Hautli-Janisz, Valentin Gold, Miriam
    Butt, Katharina Holzinger, Daniel Keim
  bibkey: el-assady-etal-2017-interactive
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '49'
  page_last: '54'
  pages: "49\u201354"
  paper_id: '9'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4009.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4009.jpg
  title: Interactive Visual Analysis of Transcribed Multi-Party Discourse
  title_html: Interactive Visual Analysis of Transcribed Multi-Party Discourse
  url: https://www.aclweb.org/anthology/P17-4009
  year: '2017'
P17-4010:
  address: Vancouver, Canada
  author:
  - first: Xiang
    full: Xiang Ren
    id: xiang-ren
    last: Ren
  - first: Jiaming
    full: Jiaming Shen
    id: jiaming-shen
    last: Shen
  - first: Meng
    full: Meng Qu
    id: meng-qu
    last: Qu
  - first: Xuan
    full: Xuan Wang
    id: xuan-wang
    last: Wang
  - first: Zeqiu
    full: Zeqiu Wu
    id: zeqiu-wu
    last: Wu
  - first: Qi
    full: Qi Zhu
    id: qi-zhu
    last: Zhu
  - first: Meng
    full: Meng Jiang
    id: meng-jiang
    last: Jiang
  - first: Fangbo
    full: Fangbo Tao
    id: fangbo-tao
    last: Tao
  - first: Saurabh
    full: Saurabh Sinha
    id: saurabh-sinha
    last: Sinha
  - first: David
    full: David Liem
    id: david-liem
    last: Liem
  - first: Peipei
    full: Peipei Ping
    id: peipei-ping
    last: Ping
  - first: Richard
    full: Richard Weinshilboum
    id: richard-weinshilboum
    last: Weinshilboum
  - first: Jiawei
    full: Jiawei Han
    id: jiawei-han
    last: Han
  author_string: Xiang Ren, Jiaming Shen, Meng Qu, Xuan Wang, Zeqiu Wu, Qi Zhu, Meng
    Jiang, Fangbo Tao, Saurabh Sinha, David Liem, Peipei Ping, Richard Weinshilboum,
    Jiawei Han
  bibkey: ren-etal-2017-life
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '55'
  page_last: '60'
  pages: "55\u201360"
  paper_id: '10'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4010.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4010.jpg
  title: 'Life-iNet: A Structured Network-Based Knowledge Exploration and Analytics
    System for Life Sciences'
  title_html: 'Life-i<span class="acl-fixed-case">N</span>et: A Structured Network-Based
    Knowledge Exploration and Analytics System for Life Sciences'
  url: https://www.aclweb.org/anthology/P17-4010
  year: '2017'
P17-4011:
  address: Vancouver, Canada
  attachment:
  - filename: P17-4011.Poster.pdf
    type: poster
    url: https://www.aclweb.org/anthology/attachments/P17-4011.Poster.pdf
  author:
  - first: Mariana
    full: Mariana Neves
    id: mariana-neves
    last: Neves
  - first: Hendrik
    full: Hendrik Folkerts
    id: hendrik-folkerts
    last: Folkerts
  - first: Marcel
    full: Marcel Jankrift
    id: marcel-jankrift
    last: Jankrift
  - first: Julian
    full: Julian Niedermeier
    id: julian-niedermeier
    last: Niedermeier
  - first: Toni
    full: Toni Stachewicz
    id: toni-stachewicz
    last: Stachewicz
  - first: "S\xF6ren"
    full: "S\xF6ren Tietb\xF6hl"
    id: soren-tietbohl
    last: "Tietb\xF6hl"
  - first: Milena
    full: Milena Kraus
    id: milena-kraus
    last: Kraus
  - first: Matthias
    full: Matthias Uflacker
    id: matthias-uflacker
    last: Uflacker
  author_string: "Mariana Neves, Hendrik Folkerts, Marcel Jankrift, Julian Niedermeier,\
    \ Toni Stachewicz, S\xF6ren Tietb\xF6hl, Milena Kraus, Matthias Uflacker"
  bibkey: neves-etal-2017-olelo
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '61'
  page_last: '66'
  pages: "61\u201366"
  paper_id: '11'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4011.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4011.jpg
  title: 'Olelo: A Question Answering Application for Biomedicine'
  title_html: '<span class="acl-fixed-case">O</span>lelo: A Question Answering Application
    for Biomedicine'
  url: https://www.aclweb.org/anthology/P17-4011
  year: '2017'
P17-4012:
  address: Vancouver, Canada
  author:
  - first: Guillaume
    full: Guillaume Klein
    id: guillaume-klein
    last: Klein
  - first: Yoon
    full: Yoon Kim
    id: yoon-kim
    last: Kim
  - first: Yuntian
    full: Yuntian Deng
    id: yuntian-deng
    last: Deng
  - first: Jean
    full: Jean Senellart
    id: jean-senellart
    last: Senellart
  - first: Alexander
    full: Alexander Rush
    id: alexander-m-rush
    last: Rush
  author_string: Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander
    Rush
  bibkey: klein-etal-2017-opennmt
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '67'
  page_last: '72'
  pages: "67\u201372"
  paper_id: '12'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4012.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4012.jpg
  title: 'OpenNMT: Open-Source Toolkit for Neural Machine Translation'
  title_html: '<span class="acl-fixed-case">O</span>pen<span class="acl-fixed-case">NMT</span>:
    Open-Source Toolkit for Neural Machine Translation'
  url: https://www.aclweb.org/anthology/P17-4012
  year: '2017'
P17-4013:
  address: Vancouver, Canada
  author:
  - first: Stefan
    full: Stefan Ultes
    id: stefan-ultes
    last: Ultes
  - first: Lina M.
    full: Lina M. Rojas-Barahona
    id: lina-m-rojas-barahona
    last: Rojas-Barahona
  - first: Pei-Hao
    full: Pei-Hao Su
    id: pei-hao-su
    last: Su
  - first: David
    full: David Vandyke
    id: david-vandyke
    last: Vandyke
  - first: Dongho
    full: Dongho Kim
    id: dongho-kim
    last: Kim
  - first: "I\xF1igo"
    full: "I\xF1igo Casanueva"
    id: inigo-casanueva
    last: Casanueva
  - first: "Pawe\u0142"
    full: "Pawe\u0142 Budzianowski"
    id: pawel-budzianowski
    last: Budzianowski
  - first: Nikola
    full: "Nikola Mrk\u0161i\u0107"
    id: nikola-mrksic
    last: "Mrk\u0161i\u0107"
  - first: Tsung-Hsien
    full: Tsung-Hsien Wen
    id: tsung-hsien-wen
    last: Wen
  - first: Milica
    full: "Milica Ga\u0161i\u0107"
    id: milica-gasic
    last: "Ga\u0161i\u0107"
  - first: Steve
    full: Steve Young
    id: steve-young
    last: Young
  author_string: "Stefan Ultes, Lina M. Rojas-Barahona, Pei-Hao Su, David Vandyke,\
    \ Dongho Kim, I\xF1igo Casanueva, Pawe\u0142 Budzianowski, Nikola Mrk\u0161i\u0107\
    , Tsung-Hsien Wen, Milica Ga\u0161i\u0107, Steve Young"
  bibkey: ultes-etal-2017-pydial
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '73'
  page_last: '78'
  pages: "73\u201378"
  paper_id: '13'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4013.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4013.jpg
  title: 'PyDial: A Multi-domain Statistical Dialogue System Toolkit'
  title_html: '<span class="acl-fixed-case">P</span>y<span class="acl-fixed-case">D</span>ial:
    A Multi-domain Statistical Dialogue System Toolkit'
  url: https://www.aclweb.org/anthology/P17-4013
  year: '2017'
P17-4014:
  address: Vancouver, Canada
  author:
  - first: Kateryna
    full: Kateryna Tymoshenko
    id: kateryna-tymoshenko
    last: Tymoshenko
  - first: Alessandro
    full: Alessandro Moschitti
    id: alessandro-moschitti
    last: Moschitti
  - first: Massimo
    full: Massimo Nicosia
    id: massimo-nicosia
    last: Nicosia
  - first: Aliaksei
    full: Aliaksei Severyn
    id: aliaksei-severyn
    last: Severyn
  author_string: Kateryna Tymoshenko, Alessandro Moschitti, Massimo Nicosia, Aliaksei
    Severyn
  bibkey: tymoshenko-etal-2017-reltextrank
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '79'
  page_last: '84'
  pages: "79\u201384"
  paper_id: '14'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4014.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4014.jpg
  title: 'RelTextRank: An Open Source Framework for Building Relational Syntactic-Semantic
    Text Pair Representations'
  title_html: '<span class="acl-fixed-case">R</span>el<span class="acl-fixed-case">T</span>ext<span
    class="acl-fixed-case">R</span>ank: An Open Source Framework for Building Relational
    Syntactic-Semantic Text Pair Representations'
  url: https://www.aclweb.org/anthology/P17-4014
  year: '2017'
P17-4015:
  address: Vancouver, Canada
  author:
  - first: Jason
    full: Jason Kessler
    id: jason-kessler
    last: Kessler
  author_string: Jason Kessler
  bibkey: kessler-2017-scattertext
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '85'
  page_last: '90'
  pages: "85\u201390"
  paper_id: '15'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4015.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4015.jpg
  title: 'Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ'
  title_html: '<span class="acl-fixed-case">S</span>cattertext: a Browser-Based Tool
    for Visualizing how Corpora Differ'
  url: https://www.aclweb.org/anthology/P17-4015
  year: '2017'
P17-4016:
  address: Vancouver, Canada
  author:
  - first: Erik
    full: Erik Faessler
    id: erik-faessler
    last: Faessler
  - first: Udo
    full: Udo Hahn
    id: udo-hahn
    last: Hahn
  author_string: Erik Faessler, Udo Hahn
  bibkey: faessler-hahn-2017-semedico
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '91'
  page_last: '96'
  pages: "91\u201396"
  paper_id: '16'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4016.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4016.jpg
  title: 'Semedico: A Comprehensive Semantic Search Engine for the Life Sciences'
  title_html: '<span class="acl-fixed-case">S</span>emedico: A Comprehensive Semantic
    Search Engine for the Life Sciences'
  url: https://www.aclweb.org/anthology/P17-4016
  year: '2017'
P17-4017:
  address: Vancouver, Canada
  author:
  - first: Lei
    full: Lei Cui
    id: lei-cui
    last: Cui
  - first: Shaohan
    full: Shaohan Huang
    id: shaohan-huang
    last: Huang
  - first: Furu
    full: Furu Wei
    id: furu-wei
    last: Wei
  - first: Chuanqi
    full: Chuanqi Tan
    id: chuanqi-tan
    last: Tan
  - first: Chaoqun
    full: Chaoqun Duan
    id: chaoqun-duan
    last: Duan
  - first: Ming
    full: Ming Zhou
    id: ming-zhou
    last: Zhou
  author_string: Lei Cui, Shaohan Huang, Furu Wei, Chuanqi Tan, Chaoqun Duan, Ming
    Zhou
  bibkey: cui-etal-2017-superagent
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '97'
  page_last: '102'
  pages: "97\u2013102"
  paper_id: '17'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4017.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4017.jpg
  title: 'SuperAgent: A Customer Service Chatbot for E-commerce Websites'
  title_html: '<span class="acl-fixed-case">S</span>uper<span class="acl-fixed-case">A</span>gent:
    A Customer Service Chatbot for E-commerce Websites'
  url: https://www.aclweb.org/anthology/P17-4017
  year: '2017'
P17-4018:
  address: Vancouver, Canada
  author:
  - first: Gus
    full: Gus Hahn-Powell
    id: gus-hahn-powell
    last: Hahn-Powell
  - first: Marco A.
    full: "Marco A. Valenzuela-Esc\xE1rcega"
    id: marco-a-valenzuela-escarcega
    last: "Valenzuela-Esc\xE1rcega"
  - first: Mihai
    full: Mihai Surdeanu
    id: mihai-surdeanu
    last: Surdeanu
  author_string: "Gus Hahn-Powell, Marco A. Valenzuela-Esc\xE1rcega, Mihai Surdeanu"
  bibkey: hahn-powell-etal-2017-swanson
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '103'
  page_last: '108'
  pages: "103\u2013108"
  paper_id: '18'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4018.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4018.jpg
  title: 'Swanson linking revisited: Accelerating literature-based discovery across
    domains using a conceptual influence graph'
  title_html: 'Swanson linking revisited: Accelerating literature-based discovery
    across domains using a conceptual influence graph'
  url: https://www.aclweb.org/anthology/P17-4018
  year: '2017'
P17-4019:
  address: Vancouver, Canada
  author:
  - first: Omri
    full: Omri Abend
    id: omri-abend
    last: Abend
  - first: Shai
    full: Shai Yerushalmi
    id: shai-yerushalmi
    last: Yerushalmi
  - first: Ari
    full: Ari Rappoport
    id: ari-rappoport
    last: Rappoport
  author_string: Omri Abend, Shai Yerushalmi, Ari Rappoport
  bibkey: abend-etal-2017-uccaapp
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '109'
  page_last: '114'
  pages: "109\u2013114"
  paper_id: '19'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4019.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4019.jpg
  title: 'UCCAApp: Web-application for Syntactic and Semantic Phrase-based Annotation'
  title_html: '<span class="acl-fixed-case">UCCAA</span>pp: Web-application for Syntactic
    and Semantic Phrase-based Annotation'
  url: https://www.aclweb.org/anthology/P17-4019
  year: '2017'
P17-4020:
  address: Vancouver, Canada
  author:
  - first: Niket
    full: Niket Tandon
    id: niket-tandon
    last: Tandon
  - first: Gerard
    full: Gerard de Melo
    id: gerard-de-melo
    last: de Melo
  - first: Gerhard
    full: Gerhard Weikum
    id: gerhard-weikum
    last: Weikum
  author_string: Niket Tandon, Gerard de Melo, Gerhard Weikum
  bibkey: tandon-etal-2017-webchild
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '115'
  page_last: '120'
  pages: "115\u2013120"
  paper_id: '20'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4020.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4020.jpg
  title: 'WebChild 2.0 : Fine-Grained Commonsense Knowledge Distillation'
  title_html: '<span class="acl-fixed-case">W</span>eb<span class="acl-fixed-case">C</span>hild
    2.0 : Fine-Grained Commonsense Knowledge Distillation'
  url: https://www.aclweb.org/anthology/P17-4020
  year: '2017'
P17-4021:
  address: Vancouver, Canada
  author:
  - first: Farhad Bin
    full: Farhad Bin Siddique
    id: farhad-bin-siddique
    last: Siddique
  - first: Onno
    full: Onno Kampman
    id: onno-kampman
    last: Kampman
  - first: Yang
    full: Yang Yang
    id: yang-yang
    last: Yang
  - first: Anik
    full: Anik Dey
    id: anik-dey
    last: Dey
  - first: Pascale
    full: Pascale Fung
    id: pascale-fung
    last: Fung
  author_string: Farhad Bin Siddique, Onno Kampman, Yang Yang, Anik Dey, Pascale Fung
  bibkey: siddique-etal-2017-zara
  bibtype: inproceedings
  booktitle: Proceedings of ACL 2017, System Demonstrations
  booktitle_html: Proceedings of <span class="acl-fixed-case">ACL</span> 2017, System
    Demonstrations
  month: July
  page_first: '121'
  page_last: '126'
  pages: "121\u2013126"
  paper_id: '21'
  parent_volume_id: P17-4
  pdf: https://www.aclweb.org/anthology/P17-4021.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-4021.jpg
  title: 'Zara Returns: Improved Personality Induction and Adaptation by an Empathetic
    Virtual Agent'
  title_html: '<span class="acl-fixed-case">Z</span>ara Returns: Improved Personality
    Induction and Adaptation by an Empathetic Virtual Agent'
  url: https://www.aclweb.org/anthology/P17-4021
  year: '2017'
P17-5000:
  address: Vancouver, Canada
  author:
  - first: Maja
    full: "Maja Popovi\u0107"
    id: maja-popovic
    last: "Popovi\u0107"
  - first: Jordan
    full: Jordan Boyd-Graber
    id: jordan-boyd-graber
    last: Boyd-Graber
  author_string: "Maja Popovi\u0107, Jordan Boyd-Graber"
  bibkey: acl-2017-association-linguistics-tutorial
  bibtype: proceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  paper_id: '0'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5000.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5000.jpg
  title: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  title_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  url: https://www.aclweb.org/anthology/P17-5000
  year: '2017'
P17-5001:
  abstract: We will introduce precision medicine and showcase the vast opportunities
    for NLP in this burgeoning field with great societal impact. We will review pressing
    NLP problems, state-of-the art methods, and important applications, as well as
    datasets, medical resources, and practical issues. The tutorial will provide an
    accessible overview of biomedicine, and does not presume knowledge in biology
    or healthcare. The ultimate goal is to reduce the entry barrier for NLP researchers
    to contribute to this exciting domain.
  address: Vancouver, Canada
  author:
  - first: Hoifung
    full: Hoifung Poon
    id: hoifung-poon
    last: Poon
  - first: Chris
    full: Chris Quirk
    id: chris-quirk
    last: Quirk
  - first: Kristina
    full: Kristina Toutanova
    id: kristina-toutanova
    last: Toutanova
  - first: Wen-tau
    full: Wen-tau Yih
    id: wen-tau-yih
    last: Yih
  author_string: Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau Yih
  bibkey: poon-etal-2017-nlp
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '1'
  page_last: '2'
  pages: "1\u20132"
  paper_id: '1'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5001.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5001.jpg
  title: NLP for Precision Medicine
  title_html: <span class="acl-fixed-case">NLP</span> for Precision Medicine
  url: https://www.aclweb.org/anthology/P17-5001
  year: '2017'
P17-5002:
  abstract: 'Multimodal machine learning is a vibrant multi-disciplinary research
    field which addresses some of the original goals of artificial intelligence by
    integrating and modeling multiple communicative modalities, including linguistic,
    acoustic and visual messages. With the initial research on audio-visual speech
    recognition and more recently with image and video captioning projects, this research
    field brings some unique challenges for multimodal researchers given the heterogeneity
    of the data and the contingency often found between modalities.This tutorial builds
    upon a recent course taught at Carnegie Mellon University during the Spring 2016
    semester (CMU course 11-777) and two tutorials presented at CVPR 2016 and ICMI
    2016. The present tutorial will review fundamental concepts of machine learning
    and deep neural networks before describing the five main challenges in multimodal
    machine learning: (1) multimodal representation learning, (2) translation & mapping,
    (3) modality alignment, (4) multimodal fusion and (5) co-learning. The tutorial
    will also present state-of-the-art algorithms that were recently proposed to solve
    multimodal applications such as image captioning, video descriptions and visual
    question-answer. We will also discuss the current and upcoming challenges.'
  address: Vancouver, Canada
  author:
  - first: Louis-Philippe
    full: Louis-Philippe Morency
    id: louis-philippe-morency
    last: Morency
  - first: Tadas
    full: "Tadas Baltru\u0161aitis"
    id: tadas-baltrusaitis
    last: "Baltru\u0161aitis"
  author_string: "Louis-Philippe Morency, Tadas Baltru\u0161aitis"
  bibkey: morency-baltrusaitis-2017-multimodal
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '3'
  page_last: '5'
  pages: "3\u20135"
  paper_id: '2'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5002.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5002.jpg
  title: 'Multimodal Machine Learning: Integrating Language, Vision and Speech'
  title_html: 'Multimodal Machine Learning: Integrating Language, Vision and Speech'
  url: https://www.aclweb.org/anthology/P17-5002
  year: '2017'
P17-5003:
  abstract: Learning representation to model the meaning of text has been a core problem
    in NLP. The last several years have seen extensive interests on distributional
    approaches, in which text spans of different granularities are encoded as vectors
    of numerical values. If properly learned, such representation has showed to achieve
    the state-of-the-art performance on a wide range of NLP problems.In this tutorial,
    we will cover the fundamentals and the state-of-the-art research on neural network-based
    modeling for semantic composition, which aims to learn distributed representation
    for different granularities of text, e.g., phrases, sentences, or even documents,
    from their sub-component meaning representation, e.g., word embedding.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234950059
    type: video
    url: https://vimeo.com/234950059
  author:
  - first: Xiaodan
    full: Xiaodan Zhu
    id: xiaodan-zhu
    last: Zhu
  - first: Edward
    full: Edward Grefenstette
    id: edward-grefenstette
    last: Grefenstette
  author_string: Xiaodan Zhu, Edward Grefenstette
  bibkey: zhu-grefenstette-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '6'
  page_last: '7'
  pages: "6\u20137"
  paper_id: '3'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5003.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5003.jpg
  title: Deep Learning for Semantic Composition
  title_html: Deep Learning for Semantic Composition
  url: https://www.aclweb.org/anthology/P17-5003
  year: '2017'
P17-5004:
  abstract: In the past decade, goal-oriented spoken dialogue systems have been the
    most prominent component in today's virtual personal assistants. The classic dialogue
    systems have rather complex and/or modular pipelines. The advance of deep learning
    technologies has recently risen the applications of neural models to dialogue
    modeling. However, how to successfully apply deep learning based approaches to
    a dialogue system is still challenging. Hence, this tutorial is designed to focus
    on an overview of the dialogue system development while describing most recent
    research for building dialogue systems and summarizing the challenges, in order
    to allow researchers to study the potential improvements of the state-of-the-art
    dialogue systems. The tutorial material is available at http://deepdialogue.miulab.tw.
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234950627
    type: video
    url: https://vimeo.com/234950627
  author:
  - first: Yun-Nung
    full: Yun-Nung Chen
    id: yun-nung-chen
    last: Chen
  - first: Asli
    full: Asli Celikyilmaz
    id: asli-celikyilmaz
    last: Celikyilmaz
  - first: Dilek
    full: "Dilek Hakkani-T\xFCr"
    id: dilek-hakkani-tur
    last: "Hakkani-T\xFCr"
  author_string: "Yun-Nung Chen, Asli Celikyilmaz, Dilek Hakkani-T\xFCr"
  bibkey: chen-etal-2017-deep
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '8'
  page_last: '14'
  pages: "8\u201314"
  paper_id: '4'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5004.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5004.jpg
  title: Deep Learning for Dialogue Systems
  title_html: Deep Learning for Dialogue Systems
  url: https://www.aclweb.org/anthology/P17-5004
  year: '2017'
P17-5005:
  abstract: Deep learning has recently shown much promise for NLP applications. Traditionally,
    in most NLP approaches, documents or sentences are represented by a sparse bag-of-words
    representation. There is now a lot of work which goes beyond this by adopting
    a distributed representation of words, by constructing a so-called ``neural embedding''
    or vector space representation of each word or document. The aim of this tutorial
    is to go beyond the learning of word vectors and present methods for learning
    vector representations for Multiword Expressions and bilingual phrase pairs, all
    of which are useful for various NLP applications.This tutorial aims to provide
    attendees with a clear notion of the linguistic and distributional characteristics
    of Multiword Expressions (MWEs), their relevance for the intersection of deep
    learning and natural language processing, what methods and resources are available
    to support their use, and what more could be done in the future. Our target audience
    are researchers and practitioners in machine learning, parsing (syntactic and
    semantic) and language technology, not necessarily experts in MWEs, who are interested
    in tasks that involve or could benefit from considering MWEs as a pervasive phenomenon
    in human language and communication.
  address: Vancouver, Canada
  author:
  - first: Valia
    full: Valia Kordoni
    id: valia-kordoni
    last: Kordoni
  author_string: Valia Kordoni
  bibkey: kordoni-2017-beyond
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '15'
  page_last: '16'
  pages: "15\u201316"
  paper_id: '5'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5005.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5005.jpg
  title: 'Beyond Words: Deep Learning for Multiword Expressions and Collocations'
  title_html: 'Beyond Words: Deep Learning for Multiword Expressions and Collocations'
  url: https://www.aclweb.org/anthology/P17-5005
  year: '2017'
P17-5006:
  abstract: "Over the last decade, crowdsourcing has been used to harness the power\
    \ of human computation to solve tasks that are notoriously difficult to solve\
    \ with computers alone, such as determining whether or not an image contains a\
    \ tree, rating the relevance of a website, or verifying the phone number of a\
    \ business. The natural language processing community was early to embrace crowdsourcing\
    \ as a tool for quickly and inexpensively obtaining annotated data to train NLP\
    \ systems. Once this data is collected, it can be handed off to algorithms that\
    \ learn to perform basic NLP tasks such as translation or parsing. Usually this\
    \ handoff is where interaction with the crowd ends. The crowd provides the data,\
    \ but the ultimate goal is to eventually take humans out of the loop. Are there\
    \ better ways to make use of the crowd?In this tutorial, I will begin with a showcase\
    \ of innovative uses of crowdsourcing that go beyond data collection and annotation.\
    \ I will discuss applications to natural language processing and machine learning,\
    \ hybrid intelligence or \u201Chuman in the loop\u201D AI systems that leverage\
    \ the complementary strengths of humans and machines in order to achieve more\
    \ than either could achieve alone, and large scale studies of human behavior online.\
    \ I will then spend the majority of the tutorial diving into recent research aimed\
    \ at understanding who crowdworkers are, how they behave, and what this should\
    \ teach us about best practices for interacting with the crowd."
  address: Vancouver, Canada
  attachment:
  - filename: https://vimeo.com/234948956
    type: video
    url: https://vimeo.com/234948956
  author:
  - first: Jennifer Wortman
    full: Jennifer Wortman Vaughan
    id: jennifer-wortman-vaughan
    last: Vaughan
  author_string: Jennifer Wortman Vaughan
  bibkey: vaughan-2017-tutorial
  bibtype: inproceedings
  booktitle: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  booktitle_html: 'Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts'
  month: July
  page_first: '17'
  page_last: '18'
  pages: "17\u201318"
  paper_id: '6'
  parent_volume_id: P17-5
  pdf: https://www.aclweb.org/anthology/P17-5006.pdf
  publisher: Association for Computational Linguistics
  thumbnail: https://www.aclweb.org/anthology/thumb/P17-5006.jpg
  title: 'Tutorial: Making Better Use of the Crowd'
  title_html: '<span class="acl-fixed-case">T</span>utorial: Making Better Use of
    the Crowd'
  url: https://www.aclweb.org/anthology/P17-5006
  year: '2017'
