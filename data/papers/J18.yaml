J18-1000:
  bibkey: cl-2018-linguistics
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  month: March
  paper_id: '0'
  parent_volume_id: J18-1
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1000.jpg
  title: Computational Linguistics, Volume 44, Issue 1 - April 2018
  title_html: Computational Linguistics, Volume 44, Issue 1 - <span class="acl-fixed-case">A</span>pril
    2018
  year: '2018'
J18-1001:
  author:
  - first: Barbara J.
    full: Barbara J. Grosz
    id: barbara-j-grosz
    last: Grosz
  author_string: Barbara J. Grosz
  bibkey: grosz-2018-smart
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_a_00313
  month: March
  page_first: '1'
  page_last: '15'
  pages: "1\u201315"
  paper_id: '1'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1001.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1001.jpg
  title: Smart Enough to Talk With Us? Foundations and Challenges for Dialogue Capable
    AI Systems
  title_html: Smart Enough to Talk With Us? Foundations and Challenges for Dialogue
    Capable <span class="acl-fixed-case">AI</span> Systems
  url: https://www.aclweb.org/anthology/J18-1001
  year: '2018'
J18-1002:
  abstract: Probabilistic finite-state automata are a formalism that is widely used
    in many problems of automatic speech recognition and natural language processing.
    Probabilistic finite-state automata are closely related to other finite-state
    models as weighted finite-state automata, word lattices, and hidden Markov models.
    Therefore, they share many similar properties and problems. Entropy measures of
    finite-state models have been investigated in the past in order to study the information
    capacity of these models. The derivational entropy quantifies the uncertainty
    that the model has about the probability distribution it represents. The derivational
    entropy in a finite-state automaton is computed from the probability that is accumulated
    in all of its individual state sequences. The computation of the entropy from
    a weighted finite-state automaton requires a normalized model. This article studies
    an efficient computation of the derivational entropy of left-to-right probabilistic
    finite-state automata, and it introduces an efficient algorithm for normalizing
    weighted finite-state automata. The efficient computation of the derivational
    entropy is also extended to continuous hidden Markov models.
  author:
  - first: Joan Andreu
    full: "Joan Andreu S\xE1nchez"
    id: joan-andreu-sanchez
    last: "S\xE1nchez"
  - first: Martha Alicia
    full: Martha Alicia Rocha
    id: martha-alicia-rocha
    last: Rocha
  - first: "Ver\xF3nica"
    full: "Ver\xF3nica Romero"
    id: veronica-romero
    last: Romero
  - first: Mauricio
    full: Mauricio Villegas
    id: mauricio-villegas
    last: Villegas
  author_string: "Joan Andreu S\xE1nchez, Martha Alicia Rocha, Ver\xF3nica Romero,\
    \ Mauricio Villegas"
  bibkey: sanchez-etal-2018-derivational
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_a_00306
  month: March
  page_first: '17'
  page_last: '37'
  pages: "17\u201337"
  paper_id: '2'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1002.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1002.jpg
  title: On the Derivational Entropy of Left-to-Right Probabilistic Finite-State Automata
    and Hidden Markov Models
  title_html: On the Derivational Entropy of Left-to-Right Probabilistic Finite-State
    Automata and Hidden <span class="acl-fixed-case">M</span>arkov Models
  url: https://www.aclweb.org/anthology/J18-1002
  year: '2018'
J18-1003:
  abstract: The general problem of finding satisfying solutions to constraint-based
    underspecified representations of quantifier scope is NP-complete. Existing frameworks,
    including Dominance Graphs, Minimal Recursion Semantics, and Hole Semantics, have
    struggled to balance expressivity and tractability in order to cover real natural
    language sentences with efficient algorithms. We address this trade-off with a
    general principle of coherence, which requires that every variable introduced
    in the domain of discourse must contribute to the overall semantics of the sentence.
    We show that every underspecified representation meeting this criterion can be
    efficiently processed, and that our set of representations subsumes all previously
    identified tractable sets.
  author:
  - first: Mehdi
    full: Mehdi Manshadi
    id: mehdi-manshadi
    last: Manshadi
  - first: Daniel
    full: Daniel Gildea
    id: daniel-gildea
    last: Gildea
  - first: James F.
    full: James F. Allen
    id: james-allen
    last: Allen
  author_string: Mehdi Manshadi, Daniel Gildea, James F. Allen
  bibkey: manshadi-etal-2018-notion
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_a_00307
  month: March
  page_first: '39'
  page_last: '83'
  pages: "39\u201383"
  paper_id: '3'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1003.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1003.jpg
  title: A Notion of Semantic Coherence for Underspecified Semantic Representation
  title_html: A Notion of Semantic Coherence for Underspecified Semantic Representation
  url: https://www.aclweb.org/anthology/J18-1003
  year: '2018'
J18-1004:
  abstract: Motivated by the task of semantic parsing, we describe a transition system
    that generalizes standard transition-based dependency parsing techniques to generate
    a graph rather than a tree. Our system includes a cache with fixed size m, and
    we characterize the relationship between the parameter m and the class of graphs
    that can be produced through the graph-theoretic concept of tree decomposition.
    We find empirically that small cache sizes cover a high percentage of sentences
    in existing semantic corpora.
  author:
  - first: Daniel
    full: Daniel Gildea
    id: daniel-gildea
    last: Gildea
  - first: Giorgio
    full: Giorgio Satta
    id: giorgio-satta
    last: Satta
  - first: Xiaochang
    full: Xiaochang Peng
    id: xiaochang-peng
    last: Peng
  author_string: Daniel Gildea, Giorgio Satta, Xiaochang Peng
  bibkey: gildea-etal-2018-cache
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_a_00308
  month: March
  page_first: '85'
  page_last: '118'
  pages: "85\u2013118"
  paper_id: '4'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1004.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1004.jpg
  title: Cache Transition Systems for Graph Parsing
  title_html: Cache Transition Systems for Graph Parsing
  url: https://www.aclweb.org/anthology/J18-1004
  year: '2018'
J18-1005:
  abstract: Graphs have a variety of uses in natural language processing, particularly
    as representations of linguistic meaning. A deficit in this area of research is
    a formal framework for creating, combining, and using models involving graphs
    that parallels the frameworks of finite automata for strings and finite tree automata
    for trees. A possible starting point for such a framework is the formalism of
    directed acyclic graph (DAG) automata, defined by Kamimura and Slutzki and extended
    by Quernheim and Knight. In this article, we study the latter in depth, demonstrating
    several new results, including a practical recognition algorithm that can be used
    for inference and learning with models defined on DAG automata. We also propose
    an extension to graphs with unbounded node degree and show that our results carry
    over to the extended formalism.
  author:
  - first: David
    full: David Chiang
    id: david-chiang
    last: Chiang
  - first: Frank
    full: Frank Drewes
    id: frank-drewes
    last: Drewes
  - first: Daniel
    full: Daniel Gildea
    id: daniel-gildea
    last: Gildea
  - first: Adam
    full: Adam Lopez
    id: adam-lopez
    last: Lopez
  - first: Giorgio
    full: Giorgio Satta
    id: giorgio-satta
    last: Satta
  author_string: David Chiang, Frank Drewes, Daniel Gildea, Adam Lopez, Giorgio Satta
  bibkey: chiang-etal-2018-weighted
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_a_00309
  month: March
  page_first: '119'
  page_last: '186'
  pages: "119\u2013186"
  paper_id: '5'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1005.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1005.jpg
  title: Weighted DAG Automata for Semantic Graphs
  title_html: Weighted <span class="acl-fixed-case">DAG</span> Automata for Semantic
    Graphs
  url: https://www.aclweb.org/anthology/J18-1005
  year: '2018'
J18-1006:
  author:
  - first: Kevin
    full: Kevin Duh
    id: kevin-duh
    last: Duh
  author_string: Kevin Duh
  bibkey: duh-2018-book
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_r_00310
  month: March
  page_first: '187'
  page_last: '189'
  pages: "187\u2013189"
  paper_id: '6'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1006.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1006.jpg
  title: 'Book Review: Bayesian Analysis in Natural Language Processing by Shay Cohen'
  title_html: 'Book Review: <span class="acl-fixed-case">B</span>ayesian Analysis
    in Natural Language Processing by Shay <span class="acl-fixed-case">C</span>ohen'
  url: https://www.aclweb.org/anthology/J18-1006
  year: '2018'
J18-1007:
  author:
  - first: Carlo
    full: Carlo Strapparava
    id: carlo-strapparava
    last: Strapparava
  author_string: Carlo Strapparava
  bibkey: strapparava-2018-metaphor
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/COLI_r_00311
  month: March
  page_first: '191'
  page_last: '192'
  pages: "191\u2013192"
  paper_id: '7'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1007.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1007.jpg
  title: 'Metaphor: A Computational Perspective by Tony Veale, Ekaterina Shutova and
    Beata Beigman Klebanov'
  title_html: '<span class="acl-fixed-case">M</span>etaphor: A Computational Perspective
    by Tony Veale, Ekaterina <span class="acl-fixed-case">S</span>hutova and Beata
    Beigman Klebanov'
  url: https://www.aclweb.org/anthology/J18-1007
  year: '2018'
J18-1008:
  author:
  - first: Yang
    full: Yang Liu
    id: yang-liu-ict
    last: Liu
  - first: Meng
    full: Meng Zhang
    id: meng-zhang
    last: Zhang
  author_string: Yang Liu, Meng Zhang
  bibkey: liu-zhang-2018-neural
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 1 - April 2018
  doi: 10.1162/
  month: March
  page_first: '193'
  page_last: '195'
  pages: "193\u2013195"
  paper_id: '8'
  parent_volume_id: J18-1
  pdf: https://www.aclweb.org/anthology/J18-1008.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-1008.jpg
  title: Neural Network Methods for Natural Language Processing by Yoav Goldberg
  title_html: Neural Network Methods for Natural Language Processing by Yoav <span
    class="acl-fixed-case">G</span>oldberg
  url: https://www.aclweb.org/anthology/J18-1008
  year: '2018'
J18-2000:
  bibkey: cl-2018-linguistics-44
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  month: June
  paper_id: '0'
  parent_volume_id: J18-2
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2000.jpg
  title: Computational Linguistics, Volume 44, Issue 2 - June 2018
  title_html: Computational Linguistics, Volume 44, Issue 2 - June 2018
  year: '2018'
J18-2001:
  abstract: "Computational text-level discourse analysis mostly happens within Rhetorical\
    \ Structure Theory (RST), whose structures have classically been presented as\
    \ constituency trees, and relies on data from the RST Discourse Treebank (RST-DT);\
    \ as a result, the RST discourse parsing community has largely borrowed from the\
    \ syntactic constituency parsing community. The standard evaluation procedure\
    \ for RST discourse parsers is thus a simplified variant of PARSEVAL, and most\
    \ RST discourse parsers use techniques that originated in syntactic constituency\
    \ parsing. In this article, we isolate a number of conceptual and computational\
    \ problems with the constituency hypothesis. We then examine the consequences,\
    \ for the implementation and evaluation of RST discourse parsers, of adopting\
    \ a dependency perspective on RST structures, a view advocated so far only by\
    \ a few approaches to discourse parsing. While doing that, we show the importance\
    \ of the notion of headedness of RST structures. We analyze RST discourse parsing\
    \ as dependency parsing by adapting to RST a recent proposal in syntactic parsing\
    \ that relies on head-ordered dependency trees, a representation isomorphic to\
    \ headed constituency trees. We show how to convert the original trees from the\
    \ RST corpus, RST-DT, and their binarized versions used by all existing RST parsers\
    \ to head-ordered dependency trees. We also propose a way to convert existing\
    \ simple dependency parser output to constituent trees. This allows us to evaluate\
    \ and to compare approaches from both constituent-based and dependency-based perspectives\
    \ in a unified framework, using constituency and dependency metrics. We thus propose\
    \ an evaluation framework to compare extant approaches easily and uniformly, something\
    \ the RST parsing community has lacked up to now. We can also compare parsers\u2019\
    \ predictions to each other across frameworks. This allows us to characterize\
    \ families of parsing strategies across the different frameworks, in particular\
    \ with respect to the notion of headedness. Our experiments provide evidence for\
    \ the conceptual similarities between dependency parsers and shift-reduce constituency\
    \ parsers, and confirm that dependency parsing constitutes a viable approach to\
    \ RST discourse parsing."
  author:
  - first: Mathieu
    full: Mathieu Morey
    id: mathieu-morey
    last: Morey
  - first: Philippe
    full: Philippe Muller
    id: philippe-muller
    last: Muller
  - first: Nicholas
    full: Nicholas Asher
    id: nicholas-asher
    last: Asher
  author_string: Mathieu Morey, Philippe Muller, Nicholas Asher
  bibkey: morey-etal-2018-dependency
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_a_00314
  month: June
  page_first: '197'
  page_last: '235'
  pages: "197\u2013235"
  paper_id: '1'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2001.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2001.jpg
  title: A Dependency Perspective on RST Discourse Parsing and Evaluation
  title_html: A Dependency Perspective on <span class="acl-fixed-case">RST</span>
    Discourse Parsing and Evaluation
  url: https://www.aclweb.org/anthology/J18-2001
  year: '2018'
J18-2002:
  abstract: In contrast to identity anaphors, which indicate coreference between a
    noun phrase and its antecedent, bridging anaphors link to their antecedent(s)
    via lexico-semantic, frame, or encyclopedic relations. Bridging resolution involves
    recognizing bridging anaphors and finding links to antecedents. In contrast to
    most prior work, we tackle both problems. Our work also follows a more wide-ranging
    definition of bridging than most previous work and does not impose any restrictions
    on the type of bridging anaphora or relations between anaphor and antecedent.
    We create a corpus (ISNotes) annotated for information status (IS), bridging being
    one of the IS subcategories. The annotations reach high reliability for all categories
    and marginal reliability for the bridging subcategory. We use a two-stage statistical
    global inference method for bridging resolution. Given all mentions in a document,
    the first stage, bridging anaphora recognition, recognizes bridging anaphors as
    a subtask of learning fine-grained IS. We use a cascading collective classification
    method where (i) collective classification allows us to investigate relations
    among several mentions and autocorrelation among IS classes and (ii) cascaded
    classification allows us to tackle class imbalance, important for minority classes
    such as bridging. We show that our method outperforms current methods both for
    IS recognition overall as well as for bridging, specifically. The second stage,
    bridging antecedent selection, finds the antecedents for all predicted bridging
    anaphors. We investigate the phenomenon of semantically or syntactically related
    bridging anaphors that share the same antecedent, a phenomenon we call sibling
    anaphors. We show that taking sibling anaphors into account in a joint inference
    model improves antecedent selection performance. In addition, we develop semantic
    and salience features for antecedent selection and suggest a novel method to build
    the candidate antecedent list for an anaphor, using the discourse scope of the
    anaphor. Our model outperforms previous work significantly.
  author:
  - first: Yufang
    full: Yufang Hou
    id: yufang-hou
    last: Hou
  - first: Katja
    full: Katja Markert
    id: katja-markert
    last: Markert
  - first: Michael
    full: Michael Strube
    id: michael-strube
    last: Strube
  author_string: Yufang Hou, Katja Markert, Michael Strube
  bibkey: hou-etal-2018-unrestricted
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_a_00315
  month: June
  page_first: '237'
  page_last: '284'
  pages: "237\u2013284"
  paper_id: '2'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2002.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2002.jpg
  title: Unrestricted Bridging Resolution
  title_html: Unrestricted Bridging Resolution
  url: https://www.aclweb.org/anthology/J18-2002
  year: '2018'
J18-2003:
  abstract: Spurious ambiguity is the phenomenon whereby distinct derivations in grammar
    may assign the same structural reading, resulting in redundancy in the parse search
    space and inefficiency in parsing. Understanding the problem depends on identifying
    the essential mathematical structure of derivations. This is trivial in the case
    of context free grammar, where the parse structures are ordered trees; in the
    case of type logical categorial grammar, the parse structures are proof nets.
    However, with respect to multiplicatives, intrinsic proof nets have not yet been
    given for displacement calculus, and proof nets for additives, which have applications
    to polymorphism, are not easy to characterize. In this context we approach here
    multiplicative-additive spurious ambiguity by means of the proof-theoretic technique
    of focalization.
  author:
  - first: Glyn
    full: Glyn Morrill
    id: glyn-morrill
    last: Morrill
  - first: Oriol
    full: "Oriol Valent\xEDn"
    id: oriol-valentin
    last: "Valent\xEDn"
  author_string: "Glyn Morrill, Oriol Valent\xEDn"
  bibkey: morrill-valentin-2018-spurious
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_a_00316
  month: June
  page_first: '285'
  page_last: '327'
  pages: "285\u2013327"
  paper_id: '3'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2003.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2003.jpg
  title: Spurious Ambiguity and Focalization
  title_html: Spurious Ambiguity and Focalization
  url: https://www.aclweb.org/anthology/J18-2003
  year: '2018'
J18-2004:
  abstract: Languages vary in the way stress is assigned to syllables within words.
    This article investigates the learnability of stress systems in a wide range of
    languages. The stress systems can be described using finite-state automata with
    symbols indicating levels of stress (primary, secondary, or no stress). Finite-state
    automata have been the focus of research in the area of grammatical inference
    for some time now. It has been shown that finite-state machines are learnable
    from examples using state-merging. One such approach, which aims to learn k-testable
    languages, has been applied to stress systems with some success. The family of
    k-testable languages has been shown to be efficiently learnable (in polynomial
    time). Here, we extend this approach to k, l-local languages by taking not only
    left context, but also right context, into account. We consider empirical results
    testing the performance of our learner using various amounts of context (corresponding
    to varying definitions of phonological locality). Our results show that our approach
    of learning stress patterns using state-merging is more reliant on left context
    than on right context. Additionally, some stress systems fail to be learned by
    our learner using either the left-context k-testable or the left-and-right-context
    k, l-local learning system. A more complex merging strategy, and hence grammar
    representation, is required for these stress systems.
  author:
  - first: Cesko
    full: Cesko Voeten
    id: cesko-voeten
    last: Voeten
  - first: Menno
    full: Menno van Zaanen
    id: menno-van-zaanen
    last: van Zaanen
  author_string: Cesko Voeten, Menno van Zaanen
  bibkey: voeten-van-zaanen-2018-influence
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_a_00317
  month: June
  page_first: '329'
  page_last: '348'
  pages: "329\u2013348"
  paper_id: '4'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2004.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2004.jpg
  title: The Influence of Context on the Learning of Metrical Stress Systems Using
    Finite-State Machines
  title_html: The Influence of Context on the Learning of Metrical Stress Systems
    Using Finite-State Machines
  url: https://www.aclweb.org/anthology/J18-2004
  year: '2018'
J18-2005:
  abstract: This article presents a probabilistic hierarchical clustering model for
    morphological segmentation. In contrast to existing approaches to morphology learning,
    our method allows learning hierarchical organization of word morphology as a collection
    of tree structured paradigms. The model is fully unsupervised and based on the
    hierarchical Dirichlet process. Tree hierarchies are learned along with the corresponding
    morphological paradigms simultaneously. Our model is evaluated on Morpho Challenge
    and shows competitive performance when compared to state-of-the-art unsupervised
    morphological segmentation systems. Although we apply this model for morphological
    segmentation, the model itself can also be used for hierarchical clustering of
    other types of data.
  author:
  - first: Burcu
    full: Burcu Can
    id: burcu-can
    last: Can
  - first: Suresh
    full: Suresh Manandhar
    id: suresh-manandhar
    last: Manandhar
  author_string: Burcu Can, Suresh Manandhar
  bibkey: can-manandhar-2018-tree
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_a_00318
  month: June
  page_first: '349'
  page_last: '374'
  pages: "349\u2013374"
  paper_id: '5'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2005.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2005.jpg
  title: Tree Structured Dirichlet Processes for Hierarchical Morphological Segmentation
  title_html: Tree Structured <span class="acl-fixed-case">D</span>irichlet Processes
    for Hierarchical Morphological Segmentation
  url: https://www.aclweb.org/anthology/J18-2005
  year: '2018'
J18-2006:
  author:
  - first: Ruihong
    full: Ruihong Huang
    id: ruihong-huang
    last: Huang
  author_string: Ruihong Huang
  bibkey: huang-2018-domain
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_r_00319
  month: June
  page_first: '375'
  page_last: '377'
  pages: "375\u2013377"
  paper_id: '6'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2006.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2006.jpg
  title: "Domain-Sensitive Temporal Tagging By Jannik Str\xF6tgen, Michael Gertz"
  title_html: "Domain-Sensitive Temporal Tagging By Jannik Str\xF6tgen, <span class=\"\
    acl-fixed-case\">M</span>ichael Gertz"
  url: https://www.aclweb.org/anthology/J18-2006
  year: '2018'
J18-2007:
  author:
  - first: Paola
    full: Paola Merlo
    id: paola-merlo
    last: Merlo
  author_string: Paola Merlo
  bibkey: merlo-2018-festina
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 2 - June 2018
  doi: 10.1162/COLI_e_00320
  month: June
  page_first: '379'
  page_last: '385'
  pages: "379\u2013385"
  paper_id: '7'
  parent_volume_id: J18-2
  pdf: https://www.aclweb.org/anthology/J18-2007.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-2007.jpg
  title: 'Festina Lente: A Farewell from the Editor'
  title_html: 'Festina Lente: A Farewell from the Editor'
  url: https://www.aclweb.org/anthology/J18-2007
  year: '2018'
J18-3000:
  bibkey: cl-2018-linguistics-44-issue
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  month: September
  paper_id: '0'
  parent_volume_id: J18-3
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3000.jpg
  title: Computational Linguistics, Volume 44, Issue 3 - September 2018
  title_html: Computational Linguistics, Volume 44, Issue 3 - September 2018
  year: '2018'
J18-3001:
  author:
  - first: Bonnie
    full: Bonnie Webber
    id: bonnie-webber
    last: Webber
  author_string: Bonnie Webber
  bibkey: webber-2018-obituary
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00321
  month: September
  page_first: '387'
  page_last: '392'
  pages: "387\u2013392"
  paper_id: '1'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3001.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3001.jpg
  title: 'Obituary: Aravind K. Joshi'
  title_html: '<span class="acl-fixed-case">O</span>bituary: Aravind K. Joshi'
  url: https://www.aclweb.org/anthology/J18-3001
  year: '2018'
J18-3002:
  abstract: "The BLEU metric has been widely used in NLP for over 15 years to evaluate\
    \ NLP systems, especially in machine translation and natural language generation.\
    \ I present a structured review of the evidence on whether BLEU is a valid evaluation\
    \ technique\u2014in other words, whether BLEU scores correlate with real-world\
    \ utility and user-satisfaction of NLP systems; this review covers 284 correlations\
    \ reported in 34 papers. Overall, the evidence supports using BLEU for diagnostic\
    \ evaluation of MT systems (which is what it was originally proposed for), but\
    \ does not support using BLEU outside of MT, for evaluation of individual texts,\
    \ or for scientific hypothesis testing."
  author:
  - first: Ehud
    full: Ehud Reiter
    id: ehud-reiter
    last: Reiter
  author_string: Ehud Reiter
  bibkey: reiter-2018-structured
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00322
  month: September
  page_first: '393'
  page_last: '401'
  pages: "393\u2013401"
  paper_id: '2'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3002.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3002.jpg
  title: A Structured Review of the Validity of BLEU
  title_html: A Structured Review of the Validity of <span class="acl-fixed-case">BLEU</span>
  url: https://www.aclweb.org/anthology/J18-3002
  year: '2018'
J18-3003:
  abstract: Ensemble methods using multiple classifiers have proven to be among the
    most successful approaches for the task of Native Language Identification (NLI),
    achieving the current state of the art. However, a systematic examination of ensemble
    methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures
    such as classifier stacking have not been closely evaluated. We present a set
    of experiments using three ensemble-based models, testing each with multiple configurations
    and algorithms. This includes a rigorous application of meta-classification models
    for NLI, achieving state-of-the-art results on several large data sets, evaluated
    in both intra-corpus and cross-corpus modes.
  author:
  - first: Shervin
    full: Shervin Malmasi
    id: shervin-malmasi
    last: Malmasi
  - first: Mark
    full: Mark Dras
    id: mark-dras
    last: Dras
  author_string: Shervin Malmasi, Mark Dras
  bibkey: malmasi-dras-2018-native
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00323
  month: September
  page_first: '403'
  page_last: '446'
  pages: "403\u2013446"
  paper_id: '3'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3003.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3003.jpg
  title: Native Language Identification With Classifier Stacking and Ensembles
  title_html: Native Language Identification With Classifier Stacking and Ensembles
  url: https://www.aclweb.org/anthology/J18-3003
  year: '2018'
J18-3004:
  abstract: We study the parsing complexity of Combinatory Categorial Grammar (CCG)
    in the formalism of Vijay-Shanker and Weir (1994). As our main result, we prove
    that any parsing algorithm for this formalism will take in the worst case exponential
    time when the size of the grammar, and not only the length of the input sentence,
    is included in the analysis. This sets the formalism of Vijay-Shanker and Weir
    (1994) apart from weakly equivalent formalisms such as Tree Adjoining Grammar,
    for which parsing can be performed in time polynomial in the combined size of
    grammar and input sentence. Our results contribute to a refined understanding
    of the class of mildly context-sensitive grammars, and inform the search for new,
    mildly context-sensitive versions of CCG.
  author:
  - first: Marco
    full: Marco Kuhlmann
    id: marco-kuhlmann
    last: Kuhlmann
  - first: Giorgio
    full: Giorgio Satta
    id: giorgio-satta
    last: Satta
  - first: Peter
    full: Peter Jonsson
    id: peter-jonsson
    last: Jonsson
  author_string: Marco Kuhlmann, Giorgio Satta, Peter Jonsson
  bibkey: kuhlmann-etal-2018-complexity
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00324
  month: September
  page_first: '447'
  page_last: '482'
  pages: "447\u2013482"
  paper_id: '4'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3004.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3004.jpg
  title: On the Complexity of CCG Parsing
  title_html: On the Complexity of <span class="acl-fixed-case">CCG</span> Parsing
  url: https://www.aclweb.org/anthology/J18-3004
  year: '2018'
J18-3005:
  abstract: 'Depending on downstream applications, it is advisable to extend the notion
    of tokenization from low-level character-based token boundary detection to identification
    of meaningful and useful language units. This entails both identifying units composed
    of several single words that form a several single words that form a, as well
    as splitting single-word compounds into their meaningful parts. In this article,
    we introduce unsupervised and knowledge-free methods for these two tasks. The
    main novelty of our research is based on the fact that methods are primarily based
    on distributional similarity, of which we use two flavors: a sparse count-based
    and a dense neural-based distributional semantic model. First, we introduce DRUID,
    which is a method for detecting MWEs. The evaluation on MWE-annotated data sets
    in two languages and newly extracted evaluation data sets for 32 languages shows
    that DRUID compares favorably over previous methods not utilizing distributional
    information. Second, we present SECOS, an algorithm for decompounding close compounds.
    In an evaluation of four dedicated decompounding data sets across four languages
    and on data sets extracted from Wiktionary for 14 languages, we demonstrate the
    superiority of our approach over unsupervised baselines, sometimes even matching
    the performance of previous language-specific and supervised methods. In a final
    experiment, we show how both decompounding and MWE information can be used in
    information retrieval. Here, we obtain the best results when combining word information
    with MWEs and the compound parts in a bag-of-words retrieval set-up. Overall,
    our methodology paves the way to automatic detection of lexical units beyond standard
    tokenization techniques without language-specific preprocessing steps such as
    POS tagging.'
  author:
  - first: Martin
    full: Martin Riedl
    id: martin-riedl
    last: Riedl
  - first: Chris
    full: Chris Biemann
    id: chris-biemann
    last: Biemann
  author_string: Martin Riedl, Chris Biemann
  bibkey: riedl-biemann-2018-using
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00325
  month: September
  page_first: '483'
  page_last: '524'
  pages: "483\u2013524"
  paper_id: '5'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3005.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3005.jpg
  title: Using Semantics for Granularities of Tokenization
  title_html: Using Semantics for Granularities of Tokenization
  url: https://www.aclweb.org/anthology/J18-3005
  year: '2018'
J18-3006:
  abstract: Orthographic similarities across languages provide a strong signal for
    unsupervised probabilistic transduction (decipherment) for closely related language
    pairs. The existing decipherment models, however, are not well suited for exploiting
    these orthographic similarities. We propose a log-linear model with latent variables
    that incorporates orthographic similarity features. Maximum likelihood training
    is computationally expensive for the proposed log-linear model. To address this
    challenge, we perform approximate inference via Markov chain Monte Carlo sampling
    and contrastive divergence. Our results show that the proposed log-linear model
    with contrastive divergence outperforms the existing generative decipherment models
    by exploiting the orthographic features. The model both scales to large vocabularies
    and preserves accuracy in low- and no-resource contexts.
  author:
  - first: Iftekhar
    full: Iftekhar Naim
    id: iftekhar-naim
    last: Naim
  - first: Parker
    full: Parker Riley
    id: parker-riley
    last: Riley
  - first: Daniel
    full: Daniel Gildea
    id: daniel-gildea
    last: Gildea
  author_string: Iftekhar Naim, Parker Riley, Daniel Gildea
  bibkey: naim-etal-2018-feature
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00326
  month: September
  page_first: '525'
  page_last: '546'
  pages: "525\u2013546"
  paper_id: '6'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3006.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3006.jpg
  title: Feature-Based Decipherment for Machine Translation
  title_html: Feature-Based Decipherment for Machine Translation
  url: https://www.aclweb.org/anthology/J18-3006
  year: '2018'
J18-3007:
  abstract: "This article provides an extensive overview of the literature related\
    \ to the phenomenon of non-nominal-antecedent anaphora (also known as abstract\
    \ anaphora or discourse deixis), a type of anaphora in which an anaphor like \u201C\
    that\u201D refers to an antecedent (marked in boldface) that is syntactically\
    \ non-nominal, such as the first sentence in \u201CIt\u2019s way too hot here.\
    \ That\u2019s why I\u2019m moving to Alaska.\u201D Annotating and automatically\
    \ resolving these cases of anaphora is interesting in its own right because of\
    \ the complexities involved in identifying non-nominal antecedents, which typically\
    \ represent abstract objects such as events, facts, and propositions. There is\
    \ also practical value in the resolution of non-nominal-antecedent anaphora, as\
    \ this would help computational systems in machine translation, summarization,\
    \ and question answering, as well as, conceivably, any other task dependent on\
    \ some measure of text understanding. Most of the existing approaches to anaphora\
    \ annotation and resolution focus on nominal-antecedent anaphora, classifying\
    \ many of the cases where the antecedents are syntactically non-nominal as non-anaphoric.\
    \ There has been some work done on this topic, but it remains scattered and difficult\
    \ to collect and assess. With this article, we hope to bring together and synthesize\
    \ work done in disparate contexts up to now in order to identify fundamental problems\
    \ and draw conclusions from an overarching perspective. Having a good picture\
    \ of the current state of the art in this field can help researchers direct their\
    \ efforts to where they are most necessary. Because of the great variety of theoretical\
    \ approaches that have been brought to bear on the problem, there is an equally\
    \ diverse array of terminologies that are used to describe it, so we will provide\
    \ an overview and discussion of these terminologies. We also describe the linguistic\
    \ properties of non-nominal-antecedent anaphora, examine previous annotation efforts\
    \ that have addressed this topic, and present the computational approaches that\
    \ aim at resolving non-nominal-antecedent anaphora automatically. We close with\
    \ a review of the remaining open questions in this area and some of our recommendations\
    \ for future research."
  author:
  - first: Varada
    full: Varada Kolhatkar
    id: varada-kolhatkar
    last: Kolhatkar
  - first: Adam
    full: Adam Roussel
    id: adam-roussel
    last: Roussel
  - first: Stefanie
    full: Stefanie Dipper
    id: stefanie-dipper
    last: Dipper
  - first: Heike
    full: Heike Zinsmeister
    id: heike-zinsmeister
    last: Zinsmeister
  author_string: Varada Kolhatkar, Adam Roussel, Stefanie Dipper, Heike Zinsmeister
  bibkey: kolhatkar-etal-2018-survey
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 3 - September 2018
  doi: 10.1162/coli_a_00327
  month: September
  page_first: '547'
  page_last: '612'
  pages: "547\u2013612"
  paper_id: '7'
  parent_volume_id: J18-3
  pdf: https://www.aclweb.org/anthology/J18-3007.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-3007.jpg
  title: 'Survey: Anaphora With Non-nominal Antecedents in Computational Linguistics:
    a Survey'
  title_html: '<span class="acl-fixed-case">S</span>urvey: Anaphora With Non-nominal
    Antecedents in Computational Linguistics: a <span class="acl-fixed-case">S</span>urvey'
  url: https://www.aclweb.org/anthology/J18-3007
  year: '2018'
J18-4000:
  bibkey: cl-2018-linguistics-44-issue-4
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  month: December
  paper_id: '0'
  parent_volume_id: J18-4
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4000.jpg
  title: Computational Linguistics, Volume 44, Issue 4 - December 2018
  title_html: Computational Linguistics, Volume 44, Issue 4 - <span class="acl-fixed-case">D</span>ecember
    2018
  year: '2018'
J18-4001:
  abstract: ''
  author:
  - first: Mark
    full: Mark Steedman
    id: mark-steedman
    last: Steedman
  author_string: Mark Steedman
  bibkey: steedman-2018-lost
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00328
  month: December
  page_first: '613'
  page_last: '629'
  pages: "613\u2013629"
  paper_id: '1'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4001.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4001.jpg
  title: The Lost Combinator
  title_html: The Lost Combinator
  url: https://www.aclweb.org/anthology/J18-4001
  year: '2018'
J18-4002:
  abstract: The CLARIN research infrastructure gives users access to an increasingly
    rich and diverse set of language-related resources and tools. Whereas there is
    ample support for searching resources using metadata-based search, or full-text
    search, or for aggregating resources into virtual collections, there is little
    support for users to help them process resources in one way or another. In spite
    of the large number of tools that process texts in many different languages, there
    is no single point of access where users can find tools to fit their needs and
    the resources they have. In this squib, we present the Language Resource Switchboard
    (LRS), which helps users to discover tools that can process their resources. For
    this, the LRS identifies all applicable tools for a given resource, lists the
    tasks the tools can achieve, and invokes the selected tool in such a way so that
    processing can start immediately with little or no prior tool parameterization.
  author:
  - first: Claus
    full: Claus Zinn
    id: claus-zinn
    last: Zinn
  author_string: Claus Zinn
  bibkey: zinn-2018-squib
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00329
  month: December
  page_first: '631'
  page_last: '639'
  pages: "631\u2013639"
  paper_id: '2'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4002.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4002.jpg
  title: 'Squib: The Language Resource Switchboard'
  title_html: '<span class="acl-fixed-case">S</span>quib: The Language Resource Switchboard'
  url: https://www.aclweb.org/anthology/J18-4002
  year: '2018'
J18-4003:
  abstract: "This study focuses on an essential precondition for reproducibility in\
    \ computational linguistics: the willingness of authors to share relevant source\
    \ code and data. Ten years after Ted Pedersen\u2019s influential \u201CLast Words\u201D\
    \ contribution in Computational Linguistics, we investigate to what extent researchers\
    \ in computational linguistics are willing and able to share their data and code.\
    \ We surveyed all 395 full papers presented at the 2011 and 2016 ACL Annual Meetings,\
    \ and identified whether links to data and code were provided. If working links\
    \ were not provided, authors were requested to provide this information. Although\
    \ data were often available, code was shared less often. When working links to\
    \ code or data were not provided in the paper, authors provided the code in about\
    \ one third of cases. For a selection of ten papers, we attempted to reproduce\
    \ the results using the provided data and code. We were able to reproduce the\
    \ results approximately for six papers. For only a single paper did we obtain\
    \ the exact same results. Our findings show that even though the situation appears\
    \ to have improved comparing 2016 to 2011, empiricism in computational linguistics\
    \ still largely remains a matter of faith. Nevertheless, we are somewhat optimistic\
    \ about the future. Ensuring reproducibility is not only important for the field\
    \ as a whole, but also seems worthwhile for individual researchers: The median\
    \ citation count for studies with working links to the source code is higher."
  author:
  - first: Martijn
    full: Martijn Wieling
    id: martijn-wieling
    last: Wieling
  - first: Josine
    full: Josine Rawee
    id: josine-rawee
    last: Rawee
  - first: Gertjan
    full: Gertjan van Noord
    id: gertjan-van-noord
    last: van Noord
  author_string: Martijn Wieling, Josine Rawee, Gertjan van Noord
  bibkey: wieling-etal-2018-squib
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00330
  month: December
  page_first: '641'
  page_last: '649'
  pages: "641\u2013649"
  paper_id: '3'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4003.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4003.jpg
  title: 'Squib: Reproducibility in Computational Linguistics: Are We Willing to Share?'
  title_html: '<span class="acl-fixed-case">S</span>quib: Reproducibility in Computational
    Linguistics: Are We Willing to Share?'
  url: https://www.aclweb.org/anthology/J18-4003
  year: '2018'
J18-4004:
  abstract: "Though information extraction (IE) research has more than a 25-year history,\
    \ F1 scores remain low. Thus, one could question continued investment in IE research.\
    \ In this article, we present three applications where information extraction\
    \ of entities, relations, and/or events has been used, and note the common features\
    \ that seem to have led to success. We also identify key research challenges whose\
    \ solution seems essential for broader successes. Because a few practical deployments\
    \ already exist and because breakthroughs on particular challenges would greatly\
    \ broaden the technology\u2019s deployment, further R and D investments are justified."
  author:
  - first: Ralph
    full: Ralph Weischedel
    id: ralph-weischedel
    last: Weischedel
  - first: Elizabeth
    full: Elizabeth Boschee
    id: elizabeth-boschee
    last: Boschee
  author_string: Ralph Weischedel, Elizabeth Boschee
  bibkey: weischedel-boschee-2018-last
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00331
  month: December
  page_first: '651'
  page_last: '658'
  pages: "651\u2013658"
  paper_id: '4'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4004.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4004.jpg
  title: 'Last Words: What Can Be Accomplished with the State of the Art in Information
    Extraction? A Personal View'
  title_html: 'Last Words: What Can Be Accomplished with the State of the Art in Information
    Extraction? A Personal View'
  url: https://www.aclweb.org/anthology/J18-4004
  year: '2018'
J18-4005:
  author:
  - first: Xiaojun
    full: Xiaojun Wan
    id: xiaojun-wan
    last: Wan
  author_string: Xiaojun Wan
  bibkey: wan-2018-book
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_r_00332
  month: December
  page_first: '659'
  page_last: '661'
  pages: "659\u2013661"
  paper_id: '5'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4005.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4005.jpg
  title: 'Book Review: Automatic Text Simplification by Horacio Saggion'
  title_html: 'Book Review: Automatic Text Simplification by Horacio Saggion'
  url: https://www.aclweb.org/anthology/J18-4005
  year: '2018'
J18-4006:
  abstract: "Social media content is changing the way people interact with each other\
    \ and share information, personal messages, and opinions about situations, objects,\
    \ and past experiences. Most social media texts are short online conversational\
    \ posts or comments that do not contain enough information for natural language\
    \ processing (NLP) tools, as they are often accompanied by non-linguistic contextual\
    \ information, including meta-data (e.g., the user\u2019s profile, the social\
    \ network of the user, and their interactions with other users). Exploiting such\
    \ different types of context and their interactions makes the automatic processing\
    \ of social media texts a challenging research task. Indeed, simply applying traditional\
    \ text mining tools is clearly sub-optimal, as, typically, these tools take into\
    \ account neither the interactive dimension nor the particular nature of this\
    \ data, which shares properties with both spoken and written language. This special\
    \ issue contributes to a deeper understanding of the role of these interactions\
    \ to process social media data from a new perspective in discourse interpretation.\
    \ This introduction first provides the necessary background to understand what\
    \ context is from both the linguistic and computational linguistic perspectives,\
    \ then presents the most recent context-based approaches to NLP for social media.\
    \ We conclude with an overview of the papers accepted in this special issue, highlighting\
    \ what we believe are the future directions in processing social media texts."
  author:
  - first: Farah
    full: Farah Benamara
    id: farah-benamara
    last: Benamara
  - first: Diana
    full: Diana Inkpen
    id: diana-inkpen
    last: Inkpen
  - first: Maite
    full: Maite Taboada
    id: maite-taboada
    last: Taboada
  author_string: Farah Benamara, Diana Inkpen, Maite Taboada
  bibkey: benamara-etal-2018-introduction
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00333
  month: December
  page_first: '663'
  page_last: '681'
  pages: "663\u2013681"
  paper_id: '6'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4006.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4006.jpg
  title: 'Introduction to the Special Issue on Language in Social Media: Exploiting
    Discourse and Other Contextual Information'
  title_html: 'Introduction to the Special Issue on Language in Social Media: Exploiting
    Discourse and Other Contextual Information'
  url: https://www.aclweb.org/anthology/J18-4006
  year: '2018'
J18-4007:
  abstract: "Language is shaped by the relationships between the speaker/writer and\
    \ the audience, the object of discussion, and the talk itself. In turn, language\
    \ is used to reshape these relationships over the course of an interaction. Computational\
    \ researchers have succeeded in operationalizing sentiment, formality, and politeness,\
    \ but each of these constructs captures only some aspects of social and relational\
    \ meaning. Theories of interactional stancetaking have been put forward as holistic\
    \ accounts, but until now, these theories have been applied only through detailed\
    \ qualitative analysis of (portions of) a few individual conversations. In this\
    \ article, we propose a new computational operationalization of interpersonal\
    \ stancetaking. We begin with annotations of three linked stance dimensions\u2014\
    affect, investment, and alignment\u2014on 68 conversation threads from the online\
    \ platform Reddit. Using these annotations, we investigate thread structure and\
    \ linguistic properties of stancetaking in online conversations. We identify lexical\
    \ features that characterize the extremes along each stancetaking dimension, and\
    \ show that these stancetaking properties can be predicted with moderate accuracy\
    \ from bag-of-words features, even with a relatively small labeled training set.\
    \ These quantitative analyses are supplemented by extensive qualitative analysis,\
    \ highlighting the compatibility of computational and qualitative methods in synthesizing\
    \ evidence about the creation of interactional meaning."
  author:
  - first: Scott F.
    full: Scott F. Kiesling
    id: scott-f-kiesling
    last: Kiesling
  - first: Umashanthi
    full: Umashanthi Pavalanathan
    id: umashanthi-pavalanathan
    last: Pavalanathan
  - first: Jim
    full: Jim Fitzpatrick
    id: jim-fitzpatrick
    last: Fitzpatrick
  - first: Xiaochuang
    full: Xiaochuang Han
    id: xiaochuang-han
    last: Han
  - first: Jacob
    full: Jacob Eisenstein
    id: jacob-eisenstein
    last: Eisenstein
  author_string: Scott F. Kiesling, Umashanthi Pavalanathan, Jim Fitzpatrick, Xiaochuang
    Han, Jacob Eisenstein
  bibkey: kiesling-etal-2018-interactional
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00334
  month: December
  page_first: '683'
  page_last: '718'
  pages: "683\u2013718"
  paper_id: '7'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4007.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4007.jpg
  title: Interactional Stancetaking in Online Forums
  title_html: Interactional Stancetaking in Online Forums
  url: https://www.aclweb.org/anthology/J18-4007
  year: '2018'
J18-4008:
  abstract: 'Conventional topic models are ineffective for topic extraction from microblog
    messages, because the data sparseness exhibited in short messages lacking structure
    and contexts results in poor message-level word co-occurrence patterns. To address
    this issue, we organize microblog messages as conversation trees based on their
    reposting and replying relations, and propose an unsupervised model that jointly
    learns word distributions to represent: (1) different roles of conversational
    discourse, and (2) various latent topics in reflecting content information. By
    explicitly distinguishing the probabilities of messages with varying discourse
    roles in containing topical words, our model is able to discover clusters of discourse
    words that are indicative of topical content. In an automatic evaluation on large-scale
    microblog corpora, our joint model yields topics with better coherence scores
    than competitive topic models from previous studies. Qualitative analysis on model
    outputs indicates that our model induces meaningful representations for both discourse
    and topics. We further present an empirical study on microblog summarization based
    on the outputs of our joint model. The results show that the jointly modeled discourse
    and topic representations can effectively indicate summary-worthy content in microblog
    conversations.'
  author:
  - first: Jing
    full: Jing Li
    id: jing-li
    last: Li
  - first: Yan
    full: Yan Song
    id: yan-song
    last: Song
  - first: Zhongyu
    full: Zhongyu Wei
    id: zhongyu-wei
    last: Wei
  - first: Kam-Fai
    full: Kam-Fai Wong
    id: kam-fai-wong
    last: Wong
  author_string: Jing Li, Yan Song, Zhongyu Wei, Kam-Fai Wong
  bibkey: li-etal-2018-joint-model
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00335
  month: December
  page_first: '719'
  page_last: '754'
  pages: "719\u2013754"
  paper_id: '8'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4008.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4008.jpg
  title: A Joint Model of Conversational Discourse Latent Topics on Microblogs
  title_html: A Joint Model of Conversational Discourse Latent Topics on Microblogs
  url: https://www.aclweb.org/anthology/J18-4008
  year: '2018'
J18-4009:
  abstract: "Computational models for sarcasm detection have often relied on the content\
    \ of utterances in isolation. However, the speaker\u2019s sarcastic intent is\
    \ not always apparent without additional context. Focusing on social media discussions,\
    \ we investigate three issues: (1) does modeling conversation context help in\
    \ sarcasm detection? (2) can we identify what part of conversation context triggered\
    \ the sarcastic reply? and (3) given a sarcastic post that contains multiple sentences,\
    \ can we identify the specific sentence that is sarcastic? To address the first\
    \ issue, we investigate several types of Long Short-Term Memory (LSTM) networks\
    \ that can model both the conversation context and the current turn. We show that\
    \ LSTM networks with sentence-level attention on context and current turn, as\
    \ well as the conditional LSTM network, outperform the LSTM model that reads only\
    \ the current turn. As conversation context, we consider the prior turn, the succeeding\
    \ turn, or both. Our computational models are tested on two types of social media\
    \ platforms: Twitter and discussion forums. We discuss several differences between\
    \ these data sets, ranging from their size to the nature of the gold-label annotations.\
    \ To address the latter two issues, we present a qualitative analysis of the attention\
    \ weights produced by the LSTM models (with attention) and discuss the results\
    \ compared with human performance on the two tasks."
  author:
  - first: Debanjan
    full: Debanjan Ghosh
    id: debanjan-ghosh
    last: Ghosh
  - first: Alexander R.
    full: Alexander R. Fabbri
    id: alexander-richard-fabbri
    last: Fabbri
  - first: Smaranda
    full: Smaranda Muresan
    id: smaranda-muresan
    last: Muresan
  author_string: Debanjan Ghosh, Alexander R. Fabbri, Smaranda Muresan
  bibkey: ghosh-etal-2018-sarcasm
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00336
  month: December
  page_first: '755'
  page_last: '792'
  pages: "755\u2013792"
  paper_id: '9'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4009.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4009.jpg
  title: Sarcasm Analysis Using Conversation Context
  title_html: Sarcasm Analysis Using Conversation Context
  url: https://www.aclweb.org/anthology/J18-4009
  year: '2018'
J18-4010:
  abstract: "Although common sense and connotative knowledge come naturally to most\
    \ people, computers still struggle to perform well on tasks for which such extratextual\
    \ information is required. Automatic approaches to sentiment analysis and irony\
    \ detection have revealed that the lack of such world knowledge undermines classification\
    \ performance. In this article, we therefore address the challenge of modeling\
    \ implicit or prototypical sentiment in the framework of automatic irony detection.\
    \ Starting from manually annotated connoted situation phrases (e.g., \u201Cflight\
    \ delays,\u201D \u201Csitting the whole day at the doctor\u2019s office\u201D\
    ), we defined the implicit sentiment held towards such situations automatically\
    \ by using both a lexico-semantic knowledge base and a data-driven method. We\
    \ further investigate how such implicit sentiment information affects irony detection\
    \ by assessing a state-of-the-art irony classifier before and after it is informed\
    \ with implicit sentiment information."
  author:
  - first: Cynthia Van
    full: Cynthia Van Hee
    id: cynthia-van-hee
    last: Hee
  - first: Els
    full: Els Lefever
    id: els-lefever
    last: Lefever
  - first: "V\xE9ronique"
    full: "V\xE9ronique Hoste"
    id: veronique-hoste
    last: Hoste
  author_string: "Cynthia Van Hee, Els Lefever, V\xE9ronique Hoste"
  bibkey: hee-etal-2018-usually
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00337
  month: December
  page_first: '793'
  page_last: '832'
  pages: "793\u2013832"
  paper_id: '10'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4010.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4010.jpg
  title: "We Usually Don\u2019t Like Going to the Dentist: Using Common Sense to Detect\
    \ Irony on Twitter"
  title_html: "We Usually Don\u2019t Like Going to the Dentist: Using Common Sense\
    \ to Detect Irony on Twitter"
  url: https://www.aclweb.org/anthology/J18-4010
  year: '2018'
J18-4011:
  abstract: "The use of social media has become a regular habit for many and has changed\
    \ the way people interact with each other. In this article, we focus on analyzing\
    \ whether news headlines support tweets and whether reviews are deceptive by analyzing\
    \ the interaction or the influence that these texts have on the others, thus exploiting\
    \ contextual information. Concretely, we define a deep learning method for relation\u2013\
    based argument mining to extract argumentative relations of attack and support.\
    \ We then use this method for determining whether news articles support tweets,\
    \ a useful task in fact-checking settings, where determining agreement toward\
    \ a statement is a useful step toward determining its truthfulness. Furthermore,\
    \ we use our method for extracting bipolar argumentation frameworks from reviews\
    \ to help detect whether they are deceptive. We show experimentally that our method\
    \ performs well in both settings. In particular, in the case of deception detection,\
    \ our method contributes a novel argumentative feature that, when used in combination\
    \ with other features in standard supervised classifiers, outperforms the latter\
    \ even on small data sets."
  author:
  - first: Oana
    full: Oana Cocarascu
    id: oana-cocarascu
    last: Cocarascu
  - first: Francesca
    full: Francesca Toni
    id: francesca-toni
    last: Toni
  author_string: Oana Cocarascu, Francesca Toni
  bibkey: cocarascu-toni-2018-combining
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00338
  month: December
  page_first: '833'
  page_last: '858'
  pages: "833\u2013858"
  paper_id: '11'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4011.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4011.jpg
  title: Combining Deep Learning and Argumentative Reasoning for the Analysis of Social
    Media Textual Content Using Small Data Sets
  title_html: Combining Deep Learning and Argumentative Reasoning for the Analysis
    of Social Media Textual Content Using Small Data Sets
  url: https://www.aclweb.org/anthology/J18-4011
  year: '2018'
J18-4012:
  abstract: 'Participants in an asynchronous conversation (e.g., forum, e-mail) interact
    with each other at different times, performing certain communicative acts, called
    speech acts (e.g., question, request). In this article, we propose a hybrid approach
    to speech act recognition in asynchronous conversations. Our approach works in
    two main steps: a long short-term memory recurrent neural network (LSTM-RNN) first
    encodes each sentence separately into a task-specific distributed representation,
    and this is then used in a conditional random field (CRF) model to capture the
    conversational dependencies between sentences. The LSTM-RNN model uses pretrained
    word embeddings learned from a large conversational corpus and is trained to classify
    sentences into speech act types. The CRF model can consider arbitrary graph structures
    to model conversational dependencies in an asynchronous conversation. In addition,
    to mitigate the problem of limited annotated data in the asynchronous domains,
    we adapt the LSTM-RNN model to learn from synchronous conversations (e.g., meetings),
    using domain adversarial training of neural networks. Empirical evaluation shows
    the effectiveness of our approach over existing ones: (i) LSTM-RNNs provide better
    task-specific representations, (ii) conversational word embeddings benefit the
    LSTM-RNNs more than the off-the-shelf ones, (iii) adversarial training gives better
    domain-invariant representations, and (iv) the global CRF model improves over
    local models.'
  author:
  - first: Shafiq
    full: Shafiq Joty
    id: shafiq-joty
    last: Joty
  - first: Tasnim
    full: Tasnim Mohiuddin
    id: muhammad-tasnim-mohiuddin
    last: Mohiuddin
  author_string: Shafiq Joty, Tasnim Mohiuddin
  bibkey: joty-mohiuddin-2018-modeling
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_a_00339
  month: December
  page_first: '859'
  page_last: '894'
  pages: "859\u2013894"
  paper_id: '12'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4012.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4012.jpg
  title: 'Modeling Speech Acts in Asynchronous Conversations: A Neural-CRF Approach'
  title_html: 'Modeling Speech Acts in Asynchronous Conversations: A Neural-<span
    class="acl-fixed-case">CRF</span> Approach'
  url: https://www.aclweb.org/anthology/J18-4012
  year: '2018'
J18-4013:
  bibkey: nn-2018-reviewers
  bibtype: article
  booktitle: Computational Linguistics, Volume 44, Issue 4 - December 2018
  doi: 10.1162/coli_x_00340
  month: December
  page_first: '895'
  page_last: '896'
  pages: "895\u2013896"
  paper_id: '13'
  parent_volume_id: J18-4
  pdf: https://www.aclweb.org/anthology/J18-4013.pdf
  thumbnail: https://www.aclweb.org/anthology/thumb/J18-4013.jpg
  title: Reviewers for Volume 44
  title_html: Reviewers for Volume 44
  url: https://www.aclweb.org/anthology/J18-4013
  year: '2018'
